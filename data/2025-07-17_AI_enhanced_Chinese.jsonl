{"id": "2507.11595", "categories": ["cs.AI", "cs.CY", "I.4.8; I.2.6"], "pdf": "https://arxiv.org/pdf/2507.11595", "abs": "https://arxiv.org/abs/2507.11595", "authors": ["Hengyue Zhao"], "title": "A Study on the Application of Artificial Intelligence in Ecological Design", "comment": null, "summary": "This paper asks whether our relationship with nature can move from human\ndominance to genuine interdependence, and whether artificial intelligence (AI)\ncan mediate that shift. We examine a new ecological-design paradigm in which AI\ninteracts with non-human life forms. Through case studies we show how artists\nand designers apply AI for data analysis, image recognition, and ecological\nrestoration, producing results that differ from conventional media. We argue\nthat AI not only expands creative methods but also reframes the theory and\npractice of ecological design. Building on the author's prototype for\nAI-assisted water remediation, the study proposes design pathways that couple\nreinforcement learning with plant-based phytoremediation. The findings\nhighlight AI's potential to link scientific insight, artistic practice, and\nenvironmental stewardship, offering a roadmap for future research on\nsustainable, technology-enabled ecosystems.", "AI": {"tldr": "AI\u53ef\u4fc3\u8fdb\u4eba\u4e0e\u81ea\u7136\u548c\u8c10\u5171\u751f\uff0c\u5728\u751f\u6001\u8bbe\u8ba1\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002", "motivation": "\u63a2\u7a76AI\u5728\u751f\u6001\u8bbe\u8ba1\u4e2d\u4fc3\u8fdb\u4eba\u4e0e\u81ea\u7136\u548c\u8c10\u5171\u751f\u7684\u6f5c\u529b\u3002", "method": "\u6848\u4f8b\u7814\u7a76\u548c\u539f\u578b\u8bbe\u8ba1\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u690d\u7269\u4fee\u590d\u6280\u672f\u3002", "result": "AI\u6269\u5c55\u4e86\u521b\u4f5c\u65b9\u6cd5\uff0c\u5e76\u91cd\u5851\u4e86\u751f\u6001\u8bbe\u8ba1\u7684\u7406\u8bba\u548c\u5b9e\u8df5\uff0c\u4e3a\u53ef\u6301\u7eed\u7684\u3001\u6280\u672f\u8d4b\u80fd\u7684\u751f\u6001\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002", "conclusion": "AI \u53ef\u4ee5\u4fc3\u8fdb\u4eba\u4e0e\u81ea\u7136\u4ece\u652f\u914d\u5173\u7cfb\u5411\u4e92\u5229\u5171\u751f\u7684\u8f6c\u53d8\uff0c\u5e76\u4e3a\u751f\u6001\u8bbe\u8ba1\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u65b0\u7684\u6846\u67b6\u3002"}}
{"id": "2507.11633", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11633", "abs": "https://arxiv.org/abs/2507.11633", "authors": ["Yuxuan Zhang", "Haoyang Yu", "Lanxiang Hu", "Haojian Jin", "Hao Zhang"], "title": "General Modular Harness for LLM Agents in Multi-Turn Gaming Environments", "comment": "8 pages, ICML MAS workshop", "summary": "We introduce a modular harness design for LLM agents that composes of\nperception, memory, and reasoning components, enabling a single LLM or VLM\nbackbone to tackle a wide spectrum of multi turn gaming environments without\ndomain-specific engineering. Using classic and modern game suites as\nlow-barrier, high-diversity testbeds, our framework provides a unified workflow\nfor analyzing how each module affects performance across dynamic interactive\nsettings. Extensive experiments demonstrate that the harness lifts gameplay\nperformance consistently over un-harnessed baselines and reveals distinct\ncontribution patterns, for example, memory dominates in long-horizon puzzles\nwhile perception is critical in vision noisy arcades. These findings highlight\nthe effectiveness of our modular harness design in advancing general-purpose\nagent, given the familiarity and ubiquity of games in everyday human\nexperience.", "AI": {"tldr": "\u6a21\u5757\u5316LLM\u667a\u80fd\u4f53\u6846\u67b6\u63d0\u5347\u4e86\u6e38\u620f\u6027\u80fd\uff0c\u8bb0\u5fc6\u548c\u611f\u77e5\u5728\u4e0d\u540c\u6e38\u620f\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\u3002", "motivation": "\u4e3a\u4e86\u6784\u5efa\u80fd\u591f\u5904\u7406\u5404\u79cd\u591a\u56de\u5408\u6e38\u620f\u73af\u5883\u7684\u901a\u7528\u667a\u80fd\u4f53\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684LLM\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u611f\u77e5\u3001\u8bb0\u5fc6\u548c\u63a8\u7406\u7ec4\u4ef6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u6e38\u620f\u6027\u80fd\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u5757\u5728\u4e0d\u540c\u6e38\u620f\u7c7b\u578b\u4e2d\u7684\u8d21\u732e\u6a21\u5f0f\u5dee\u5f02\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684LLM\u667a\u80fd\u4f53\u8bbe\u8ba1\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u65e0\u9700\u7279\u5b9a\u9886\u57df\u5de5\u7a0b\u7684\u60c5\u51b5\u4e0b\u5904\u7406\u5404\u79cd\u591a\u56de\u5408\u6e38\u620f\u73af\u5883\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u8bbe\u8ba1\u63d0\u9ad8\u4e86\u6e38\u620f\u6027\u80fd\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u5757\u5728\u4e0d\u540c\u6e38\u620f\u7c7b\u578b\u4e2d\u7684\u4f5c\u7528\u5dee\u5f02\u3002"}}
{"id": "2507.11662", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11662", "abs": "https://arxiv.org/abs/2507.11662", "authors": ["Moises Andrade", "Joonhyuk Cha", "Brandon Ho", "Vriksha Srihari", "Karmesh Yadav", "Zsolt Kira"], "title": "Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification", "comment": "Our code and data are publicly available at\n  https://github.com/mshalimay/mllm-verifiers-abias-sgv", "summary": "Verifiers -- functions assigning rewards to agent behavior -- have been key\nfor AI progress in domains like math and board games. However, extending these\ngains to domains without clear-cut success criteria (e.g.,computer use) remains\na challenge: while humans can recognize suitable outcomes, translating this\nintuition into scalable rules is non-trivial. Multimodal Large Language\nModels(MLLMs) emerge as a promising solution, given their world knowledge,\nhuman-preference alignment, and reasoning skills. We evaluate MLLMs as\nverifiers of agent trajectories across web navigation, computer use, and\nrobotic manipulation, and identify a critical limitation: agreement bias, a\nstrong tendency for MLLMs to favor information in their context window, often\ngenerating chains of thought to rationalize flawed behavior. This bias is\npervasive across models, resilient to test-time scaling, and can impact several\nmethods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs\ndespite MLLMs showing strong, human-aligned priors on desired behavior. To\naddress this, we propose Self-Grounded Verification (SGV), a lightweight method\nthat enables more effective use of MLLMs' knowledge and reasoning by harnessing\ntheir own sampling mechanisms via unconditional and conditional generation. SGV\noperates in two steps: first, the MLLM is elicited to retrieve broad priors\nabout task completion, independent of the data under evaluation. Then,\nconditioned on self-generated priors, it reasons over and evaluates a candidate\ntrajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in\naccuracy and failure detection rates, and can perform real-time supervision of\nheterogeneous agents, boosting task completion of a GUI specialist in OSWorld,\na diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting\na new state of the art on the benchmark, surpassing the previous best by 48%.", "AI": {"tldr": "\u5229\u7528MLLM\u81ea\u8eab\u91c7\u6837\u673a\u5236\u6539\u8fdb\u5176\u4f5c\u4e3a\u9a8c\u8bc1\u5668\u7684\u80fd\u529b\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u504f\u5dee\uff0c\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387", "motivation": "\u73b0\u6709\u9a8c\u8bc1\u8005\u96be\u4ee5\u6269\u5c55\u5230\u6ca1\u6709\u660e\u786e\u6210\u529f\u6807\u51c6\u7684\u9886\u57df(\u4f8b\u5982\u8ba1\u7b97\u673a\u4f7f\u7528)\uff0c\u800cMLLM\u56e0\u5176\u4e16\u754c\u77e5\u8bc6\u3001\u4eba\u7c7b\u504f\u597d\u4e00\u81f4\u6027\u548c\u63a8\u7406\u80fd\u529b\u800c\u6210\u4e3a\u4e00\u79cd\u5f88\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u81ea\u57fa\u7840\u9a8c\u8bc1(SGV)\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b(MLLM)\u81ea\u8eab\u7684\u91c7\u6837\u673a\u5236\uff0c\u901a\u8fc7\u65e0\u6761\u4ef6\u548c\u6709\u6761\u4ef6\u751f\u6210\u6765\u63d0\u9ad8MLLM\u77e5\u8bc6\u548c\u63a8\u7406\u7684\u6709\u6548\u6027\u3002", "result": "SGV\u65b9\u6cd5\u63d0\u9ad8\u4e86MLLM\u9a8c\u8bc1\u5668\u7684\u51c6\u786e\u6027\u548c\u6545\u969c\u68c0\u6d4b\u7387\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u8d85\u8fc7\u4e86\u4e4b\u524d\u7684\u6700\u597d\u7ed3\u679c48%\u3002", "conclusion": "\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b(MLLM)\u4f5c\u4e3a\u9a8c\u8bc1\u8005\u5728\u8bc4\u4f30\u667a\u80fd\u4f53\u8f68\u8ff9\u65b9\u9762\u5b58\u5728\u504f\u5dee\uff0c\u8be5\u504f\u5dee\u4f1a\u5bfc\u81f4\u5bf9\u9519\u8bef\u884c\u4e3a\u7684\u5408\u7406\u5316\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u81ea\u57fa\u7840\u9a8c\u8bc1(SGV)\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528MLLM\u81ea\u8eab\u7684\u91c7\u6837\u673a\u5236\uff0c\u901a\u8fc7\u65e0\u6761\u4ef6\u548c\u6709\u6761\u4ef6\u751f\u6210\u6765\u63d0\u9ad8MLLM\u77e5\u8bc6\u548c\u63a8\u7406\u7684\u6709\u6548\u6027\u3002SGV\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6545\u969c\u68c0\u6d4b\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u9ad8\u8fbe20\u4e2a\u70b9\u7684\u589e\u76ca\uff0c\u5e76\u5728OSWorld\u3001robomimic\u548cVisualWebArena\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002"}}
{"id": "2507.11733", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11733", "abs": "https://arxiv.org/abs/2507.11733", "authors": ["Srikanth Vemula"], "title": "ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making", "comment": null, "summary": "This Study introduces Clarity and Reasoning Interface for Artificial\nIntelligence(ClarifAI), a novel approach designed to augment the transparency\nand interpretability of artificial intelligence (AI) in the realm of improved\ndecision making. Leveraging the Case-Based Reasoning (CBR) methodology and\nintegrating an ontology-driven approach, ClarifAI aims to meet the intricate\nexplanatory demands of various stakeholders involved in AI-powered\napplications. The paper elaborates on ClarifAI's theoretical foundations,\ncombining CBR and ontologies to furnish exhaustive explanation mechanisms. It\nfurther elaborates on the design principles and architectural blueprint,\nhighlighting ClarifAI's potential to enhance AI interpretability across\ndifferent sectors and its applicability in high-stake environments. This\nresearch delineates the significant role of ClariAI in advancing the\ninterpretability of AI systems, paving the way for its deployment in critical\ndecision-making processes.", "AI": {"tldr": "ClarifAI\u901a\u8fc7\u7ed3\u5408\u6848\u4f8b\u63a8\u7406\u548c\u672c\u4f53\u8bba\uff0c\u63d0\u9ad8\u4e86AI\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u5176\u80fd\u591f\u5e94\u7528\u4e8e\u5173\u952e\u51b3\u7b56\u8fc7\u7a0b\u3002", "motivation": "\u6ee1\u8db3AI\u5e94\u7528\u4e2d\u4e0d\u540c\u5229\u76ca\u76f8\u5173\u8005\u5bf9\u89e3\u91ca\u7684\u9700\u6c42\u3002", "method": "\u7ed3\u5408\u6848\u4f8b\u63a8\u7406(CBR)\u548c\u672c\u4f53\u8bba\u65b9\u6cd5\u3002", "result": "\u9610\u8ff0\u4e86ClarifAI\u7684\u7406\u8bba\u57fa\u7840\u3001\u8bbe\u8ba1\u539f\u5219\u548c\u67b6\u6784\uff0c\u5e76\u5f3a\u8c03\u5176\u5728\u4e0d\u540c\u884c\u4e1a\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "ClarifAI\u589e\u5f3a\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u51b3\u7b56\u4e2d\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.11737", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11737", "abs": "https://arxiv.org/abs/2507.11737", "authors": ["Chenyu Zhou", "Jingyuan Yang", "Linwei Xin", "Yitian Chen", "Ziyan He", "Dongdong Ge"], "title": "Auto-Formulating Dynamic Programming Problems with Large Language Models", "comment": null, "summary": "Dynamic programming (DP) is a fundamental method in operations research, but\nformulating DP models has traditionally required expert knowledge of both the\nproblem context and DP techniques. Large Language Models (LLMs) offer the\npotential to automate this process. However, DP problems pose unique challenges\ndue to their inherently stochastic transitions and the limited availability of\ntraining data. These factors make it difficult to directly apply existing\nLLM-based models or frameworks developed for other optimization problems, such\nas linear or integer programming. We introduce DP-Bench, the first benchmark\ncovering a wide range of textbook-level DP problems to enable systematic\nevaluation. We present Dynamic Programming Language Model (DPLM), a\n7B-parameter specialized model that achieves performance comparable to\nstate-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on\nhard problems. Central to DPLM's effectiveness is DualReflect, our novel\nsynthetic data generation pipeline, designed to scale up training data from a\nlimited set of initial examples. DualReflect combines forward generation for\ndiversity and backward generation for reliability. Our results reveal a key\ninsight: backward generation is favored in low-data regimes for its strong\ncorrectness guarantees, while forward generation, though lacking such\nguarantees, becomes increasingly valuable at scale for introducing diverse\nformulations. This trade-off highlights the complementary strengths of both\napproaches and the importance of combining them.", "AI": {"tldr": "\u9488\u5bf9\u52a8\u6001\u89c4\u5212\u95ee\u9898\u6570\u636e\u7a00\u7f3a\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u76847B\u53c2\u6570\u6a21\u578bDPLM\u548c\u6570\u636e\u589e\u5f3a\u65b9\u6cd5DualReflect\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86SOTA\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u52a8\u6001\u89c4\u5212\u5efa\u6a21\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\uff0cLLM\u6709\u6f5c\u529b\u81ea\u52a8\u5316\u6b64\u8fc7\u7a0b\uff0c\u4f46DP\u95ee\u9898\u7684\u968f\u673a\u6027\u548c\u6570\u636e\u7a00\u7f3a\u6027\u5e26\u6765\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDPLM\u76847B\u53c2\u6570\u4e13\u7528\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u4e86DualReflect\u6570\u636e\u751f\u6210\u7ba1\u7ebf\uff0c\u8be5\u7ba1\u7ebf\u7ed3\u5408\u6b63\u5411\u548c\u53cd\u5411\u751f\u6210\u7b56\u7565\u3002", "result": "DPLM\u6a21\u578b\u5728DP-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4e0e\u73b0\u6709SOTA LLM\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86DualReflect\u6570\u636e\u751f\u6210\u7ba1\u7ebf\u7684\u6709\u6548\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6b63\u5411\u548c\u53cd\u5411\u751f\u6210\u7b56\u7565\u5728\u4e0d\u540c\u6570\u636e\u89c4\u6a21\u4e0b\u7684\u6743\u8861\u3002", "conclusion": "DPLM\u6a21\u578b\u5728DP\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u4e0e\u73b0\u6709SOTA LLM\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u96be\u9898\u4e0a\u8868\u73b0\u7a81\u51fa\u3002\u5176\u5173\u952e\u5728\u4e8eDualReflect\u6570\u636e\u751f\u6210\u7ba1\u7ebf\uff0c\u8be5\u7ba1\u7ebf\u7ed3\u5408\u4e86\u6b63\u5411\u548c\u53cd\u5411\u751f\u6210\uff0c\u6709\u6548\u89e3\u51b3\u4e86DP\u95ee\u9898\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002"}}
{"id": "2507.11787", "categories": ["cs.AI", "68-68W50"], "pdf": "https://arxiv.org/pdf/2507.11787", "abs": "https://arxiv.org/abs/2507.11787", "authors": ["Chandrashekar Muniyappa", "Eunjin Kim"], "title": "Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity", "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "summary": "Swarm Intelligence (SI) is gaining a lot of popularity in artificial\nintelligence, where the natural behavior of animals and insects is observed and\ntranslated into computer algorithms called swarm computing to solve real-world\nproblems. Due to their effectiveness, they are applied in solving various\ncomputer optimization problems. This survey will review all the latest\ndevelopments in Searching for documents based on semantic similarity using\nSwarm Intelligence algorithms and recommend future research directions.", "AI": {"tldr": "\u7efc\u8ff0\u4e86\u4f7f\u7528\u7fa4\u4f53\u667a\u80fd\u7b97\u6cd5\u8fdb\u884c\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6587\u6863\u641c\u7d22\u7684\u6700\u65b0\u7814\u7a76\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7fa4\u4f53\u667a\u80fd\u7b97\u6cd5\u5728\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u4e2d\u8d8a\u6765\u8d8a\u53d7\u6b22\u8fce\uff0c\u5176\u5728\u8ba1\u7b97\u673a\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6709\u6548\u6027\u4fc3\u4f7f\u4e86\u8be5\u7efc\u8ff0\u7684\u4ea7\u751f\u3002", "method": "\u6587\u732e\u7efc\u8ff0", "result": "\u5bf9\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u6587\u6863\u641c\u7d22\u4e2d\u7fa4\u4f53\u667a\u80fd\u7b97\u6cd5\u7684\u6700\u65b0\u53d1\u5c55\u8fdb\u884c\u4e86\u7efc\u8ff0\u3002", "conclusion": "\u672c\u6587\u7efc\u8ff0\u4e86\u4f7f\u7528\u7fa4\u4f53\u667a\u80fd\u7b97\u6cd5\u8fdb\u884c\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u6587\u6863\u641c\u7d22\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u63a8\u8350\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.11916", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.11916", "abs": "https://arxiv.org/abs/2507.11916", "authors": ["Ehsan Futuhi", "Nathan R. Sturtevant"], "title": "A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS", "comment": null, "summary": "The rapid advancement of GPU technology has unlocked powerful parallel\nprocessing capabilities, creating new opportunities to enhance classic search\nalgorithms. A recent successful application of GPUs is in compressing large\npattern database (PDB) heuristics using neural networks while preserving\nheuristic admissibility. However, very few algorithms have been designed to\nexploit GPUs during search. Several variants of A* exist that batch GPU\ncomputations. In this paper we introduce a method for batching GPU computations\nin depth first search. In particular, we describe a new cost-bounded\ndepth-first search (CB-DFS) method that leverages the combined parallelism of\nmodern CPUs and GPUs. This is used to create algorithms like \\emph{Batch IDA*},\nan extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an\nextensions of Budgeted Tree Search. Our approach builds on the general approach\nused by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality\nguarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding\ntile puzzle (STP), showing that GPU operations can be efficiently batched in\nDFS. Additionally, we conduct extensive experiments to analyze the effects of\nhyperparameters, neural network heuristic size, and hardware resources on\nperformance.", "AI": {"tldr": "\u5229\u7528CPU\u548cGPU\u7684\u5e76\u884c\u6027\uff0c\u6539\u8fdb\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u7b97\u6cd5\uff0c\u63d0\u5347\u6c42\u89e3Rubik's Cube\u548cSTP\u96be\u9898\u7684\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684GPU\u52a0\u901f\u641c\u7d22\u7b97\u6cd5\u8f83\u5c11\uff0c\u672c\u6587\u65e8\u5728\u5229\u7528GPU\u7684\u5e76\u884c\u8ba1\u7b97\u80fd\u529b\u6765\u63d0\u9ad8\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u7b97\u6cd5\u7684\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6210\u672c\u8fb9\u754c\u6df1\u5ea6\u4f18\u5148\u641c\u7d22(CB-DFS)\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u73b0\u4ee3CPU\u548cGPU\u7684\u5e76\u884c\u6027\uff0c\u901a\u8fc7\u6279\u91cf\u5904\u7406GPU\u8ba1\u7b97\u6765\u6539\u8fdbIDA*\u548cBudgeted Tree Search\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u6279\u91cf\u5904\u7406GPU\u8ba1\u7b97\uff0c\u5e76\u5728Rubik's Cube\u548cSTP\u96be\u9898\u4e0a\u53d6\u5f97\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5206\u6790\u4e86\u76f8\u5173\u56e0\u7d20\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5728\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u4e2d\u6279\u91cf\u5904\u7406GPU\u8ba1\u7b97\u7684\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u8fed\u4ee3\u6df1\u5316A*\u7b97\u6cd5\u548c\u9884\u7b97\u6811\u641c\u7d22\u7b97\u6cd5\u7684\u6539\u8fdb\u7248\u672c\uff0c\u5728Rubik's Cube\u548cSTP\u96be\u9898\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660eGPU\u8ba1\u7b97\u53ef\u4ee5\u6709\u6548\u5730\u6279\u91cf\u5904\u7406\uff0c\u5e76\u5206\u6790\u4e86\u8d85\u53c2\u6570\u3001\u795e\u7ecf\u7f51\u7edc\u542f\u53d1\u5f0f\u5927\u5c0f\u548c\u786c\u4ef6\u8d44\u6e90\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.11988", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11988", "abs": "https://arxiv.org/abs/2507.11988", "authors": ["Yexuan Shi", "Mingyu Wang", "Yunxiang Cao", "Hongjie Lai", "Junjian Lan", "Xin Han", "Yu Wang", "Jie Geng", "Zhenan Li", "Zihao Xia", "Xiang Chen", "Chen Li", "Jian Xu", "Wenbo Duan", "Yuanshuo Zhu"], "title": "Aime: Towards Fully-Autonomous Multi-Agent Framework", "comment": "14 pages, 1 figures,", "summary": "Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are\nemerging as a powerful paradigm for solving complex, multifaceted problems.\nHowever, the potential of these systems is often constrained by the prevalent\nplan-and-execute framework, which suffers from critical limitations: rigid plan\nexecution, static agent capabilities, and inefficient communication. These\nweaknesses hinder their adaptability and robustness in dynamic environments.\nThis paper introduces Aime, a novel multi-agent framework designed to overcome\nthese challenges through dynamic, reactive planning and execution. Aime\nreplaces the conventional static workflow with a fluid and adaptive\narchitecture. Its core innovations include: (1) a Dynamic Planner that\ncontinuously refines the overall strategy based on real-time execution\nfeedback; (2) an Actor Factory that implements Dynamic Actor instantiation,\nassembling specialized agents on-demand with tailored tools and knowledge; and\n(3) a centralized Progress Management Module that serves as a single source of\ntruth for coherent, system-wide state awareness. We empirically evaluated Aime\non a diverse suite of benchmarks spanning general reasoning (GAIA), software\nengineering (SWE-bench Verified), and live web navigation (WebVoyager). The\nresults demonstrate that Aime consistently outperforms even highly specialized\nstate-of-the-art agents in their respective domains. Its superior adaptability\nand task success rate establish Aime as a more resilient and effective\nfoundation for multi-agent collaboration.", "AI": {"tldr": "Aime\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u89c4\u5212\u3001\u6309\u9700\u521b\u5efa\u667a\u80fd\u4f53\u548c\u96c6\u4e2d\u7684\u8fdb\u5ea6\u7ba1\u7406\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5e38\u53d7\u9650\u4e8e\u50f5\u5316\u7684\u8ba1\u5212\u6267\u884c\u3001\u9759\u6001\u7684\u667a\u80fd\u4f53\u80fd\u529b\u548c\u4f4e\u6548\u7684\u901a\u4fe1\uff0c\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u73af\u5883\u3002", "method": "Aime\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u3001\u53cd\u5e94\u5f0f\u89c4\u5212\u548c\u6267\u884c\u6765\u514b\u670d\u73b0\u6709\u8ba1\u5212-\u6267\u884c\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u5176\u6838\u5fc3\u521b\u65b0\u5305\u62ec\u52a8\u6001\u89c4\u5212\u5668\u3001Actor\u5de5\u5382\u548c\u96c6\u4e2d\u7684\u8fdb\u5ea6\u7ba1\u7406\u6a21\u5757\u3002", "result": "Aime\u6846\u67b6\u5728\u901a\u7528\u63a8\u7406\u3001\u8f6f\u4ef6\u5de5\u7a0b\u548c\u5b9e\u65f6\u7f51\u9875\u5bfc\u822a\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6210\u679c\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "Aime\u6846\u67b6\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u9002\u5e94\u6027\u548c\u4efb\u52a1\u6210\u529f\u7387\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u57fa\u7840\u3002"}}
{"id": "2507.11992", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11992", "abs": "https://arxiv.org/abs/2507.11992", "authors": ["Pranav Rajbhandari", "Abhi Veda", "Matthew Garratt", "Mandayam Srinivasan", "Sridhar Ravi"], "title": "Understanding visual attention beehind bee-inspired UAV navigation", "comment": null, "summary": "Bio-inspired design is often used in autonomous UAV navigation due to the\ncapacity of biological systems for flight and obstacle avoidance despite\nlimited sensory and computational capabilities. In particular, honeybees mainly\nuse the sensory input of optic flow, the apparent motion of objects in their\nvisual field, to navigate cluttered environments. In our work, we train a\nReinforcement Learning agent to navigate a tunnel with obstacles using only\noptic flow as sensory input. We inspect the attention patterns of trained\nagents to determine the regions of optic flow on which they primarily base\ntheir motor decisions. We find that agents trained in this way pay most\nattention to regions of discontinuity in optic flow, as well as regions with\nlarge optic flow magnitude. The trained agents appear to navigate a cluttered\ntunnel by avoiding the obstacles that produce large optic flow, while\nmaintaining a centered position in their environment, which resembles the\nbehavior seen in flying insects. This pattern persists across independently\ntrained agents, which suggests that this could be a good strategy for\ndeveloping a simple explicit control law for physical UAVs.", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u901a\u8fc7\u5173\u6ce8\u5149\u6d41\u7684\u4e0d\u8fde\u7eed\u533a\u57df\u548c\u9ad8\u5149\u6d41\u5e45\u5ea6\u533a\u57df\uff0c\u6210\u529f\u6a21\u4eff\u871c\u8702\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u884c\u4e3a\uff0c\u4e3a\u65e0\u4eba\u673a\u63a7\u5236\u5f8b\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u751f\u7269\u542f\u53d1\u5f0f\u8bbe\u8ba1\u5e38\u7528\u4e8e\u81ea\u4e3b\u65e0\u4eba\u673a\u5bfc\u822a\uff0c\u56e0\u4e3a\u751f\u7269\u7cfb\u7edf\u80fd\u591f\u98de\u884c\u548c\u907f\u969c\uff0c\u5373\u4f7f\u611f\u5b98\u548c\u8ba1\u7b97\u80fd\u529b\u6709\u9650\u3002\u871c\u8702\u4e3b\u8981\u5229\u7528\u5149\u6d41\uff08\u89c6\u89c9\u573a\u4e2d\u7269\u4f53\u7684\u8868\u89c2\u8fd0\u52a8\uff09\u7684\u611f\u89c9\u8f93\u5165\u6765\u5bfc\u822a\u6742\u4e71\u7684\u73af\u5883\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u667a\u80fd\u4f53\uff0c\u4ec5\u4f7f\u7528\u5149\u6d41\u4f5c\u4e3a\u611f\u89c9\u8f93\u5165\uff0c\u5728\u6709\u969c\u788d\u7269\u7684\u96a7\u9053\u4e2d\u5bfc\u822a\u3002", "result": "\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u4e3b\u8981\u5173\u6ce8\u5149\u6d41\u7684\u4e0d\u8fde\u7eed\u533a\u57df\u4ee5\u53ca\u5149\u6d41\u5e45\u5ea6\u5927\u7684\u533a\u57df\u3002", "conclusion": "\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u901a\u8fc7\u907f\u514d\u4ea7\u751f\u5927\u7684\u5149\u6d41\u7684\u969c\u788d\u7269\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u5728\u73af\u5883\u4e2d\u7684\u5c45\u4e2d\u4f4d\u7f6e\uff0c\u4ece\u800c\u5728\u6742\u4e71\u7684\u96a7\u9053\u4e2d\u5bfc\u822a\uff0c\u8fd9\u7c7b\u4f3c\u4e8e\u98de\u884c\u6606\u866b\u7684\u884c\u4e3a\u3002\u8fd9\u79cd\u6a21\u5f0f\u5728\u72ec\u7acb\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u4e2d\u6301\u7eed\u5b58\u5728\uff0c\u8fd9\u8868\u660e\u8fd9\u53ef\u80fd\u662f\u4e3a\u7269\u7406\u65e0\u4eba\u673a\u5f00\u53d1\u7b80\u5355\u7684\u663e\u5f0f\u63a7\u5236\u5f8b\u7684\u4e00\u4e2a\u597d\u7b56\u7565\u3002"}}
{"id": "2507.12110", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.12110", "abs": "https://arxiv.org/abs/2507.12110", "authors": ["Ye Han", "Lijun Zhang", "Dejian Meng", "Zhuang Zhang"], "title": "Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs", "comment": "16 pages, 16 figures", "summary": "The exploration-exploitation trade-off constitutes one of the fundamental\nchallenges in reinforcement learning (RL), which is exacerbated in multi-agent\nreinforcement learning (MARL) due to the exponential growth of joint\nstate-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)\nmethod for optimizing cooperative decision-making of connected and autonomous\nvehicles (CAVs) in mixed traffic. This work presents two primary contributions:\nFirst, we construct a game topology tensor for dynamic traffic flow,\neffectively compressing high-dimensional traffic state information and decrease\nthe search space for MARL algorithms. Second, building upon the designed game\ntopology tensor and using QMIX as the backbone RL algorithm, we establish a\ntopology-enhanced MARL framework incorporating visit counts and agent mutual\ninformation. Extensive simulations across varying traffic densities and CAV\npenetration rates demonstrate the effectiveness of TPE-MARL. Evaluations\nencompassing training dynamics, exploration patterns, macroscopic traffic\nperformance metrics, and microscopic vehicle behaviors reveal that TPE-MARL\nsuccessfully balances exploration and exploitation. Consequently, it exhibits\nsuperior performance in terms of traffic efficiency, safety, decision\nsmoothness, and task completion. Furthermore, the algorithm demonstrates\ndecision-making rationality comparable to or exceeding that of human drivers in\nboth mixed-autonomy and fully autonomous traffic scenarios. Code of our work is\navailable at\n\\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u62d3\u6251\u589e\u5f3a\u578b\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5(TPE-MARL)\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u6df7\u5408\u4ea4\u901a\u4e2d\u8054\u7f51\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u534f\u540c\u51b3\u7b56\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u63a2\u7d22-\u5229\u7528\u56f0\u5883\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u8054\u7f51\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u590d\u6742\u4ea4\u901a\u72b6\u6001\u65f6\uff0c\u6709\u6548\u964d\u4f4e\u641c\u7d22\u7a7a\u95f4\u3002", "method": "\u6784\u5efa\u6e38\u620f\u62d3\u6251\u5f20\u91cf\u538b\u7f29\u9ad8\u7ef4\u4ea4\u901a\u72b6\u6001\u4fe1\u606f\uff0c\u5e76\u7ed3\u5408QMIX\u7b97\u6cd5\uff0c\u5229\u7528\u8bbf\u95ee\u8ba1\u6570\u548c\u667a\u80fd\u4f53\u4e92\u4fe1\u606f\u5efa\u7acb\u62d3\u6251\u589e\u5f3a\u578bMARL\u6846\u67b6\u3002", "result": "TPE-MARL\u5728\u4e0d\u540c\u4ea4\u901a\u5bc6\u5ea6\u548cCAV\u6e17\u900f\u7387\u4e0b\u7684\u4eff\u771f\u5b9e\u9a8c\u4e2d\uff0c\u6210\u529f\u5e73\u8861\u4e86\u63a2\u7d22\u548c\u5229\u7528\uff0c\u63d0\u9ad8\u4e86\u4ea4\u901a\u6548\u7387\u3001\u5b89\u5168\u6027\u3001\u51b3\u7b56\u5e73\u6ed1\u6027\u548c\u4efb\u52a1\u5b8c\u6210\u5ea6\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u62d3\u6251\u589e\u5f3a\u578b\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5(TPE-MARL)\uff0c\u7528\u4e8e\u4f18\u5316\u6df7\u5408\u4ea4\u901a\u4e2d\u8054\u7f51\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u534f\u540c\u51b3\u7b56\uff0c\u5e76\u5728\u4ea4\u901a\u6548\u7387\u3001\u5b89\u5168\u6027\u548c\u51b3\u7b56\u5e73\u6ed1\u6027\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5176\u51b3\u7b56\u7406\u6027\u53ef\u4e0e\u4eba\u7c7b\u9a7e\u9a76\u5458\u76f8\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a\u3002"}}
{"id": "2507.12186", "categories": ["cs.AI", "I.2.8; I.2.9"], "pdf": "https://arxiv.org/pdf/2507.12186", "abs": "https://arxiv.org/abs/2507.12186", "authors": ["Edward Kim", "Hanna Kurniawati"], "title": "Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation", "comment": "8 pages, 2 tables, 3 figures. To be presented at International Joint\n  Conference on Artificial Intelligence 2025", "summary": "This paper proposes Partially Observable Reference Policy Programming, a\nnovel anytime online approximate POMDP solver which samples meaningful future\nhistories very deeply while simultaneously forcing a gradual policy update. We\nprovide theoretical guarantees for the algorithm's underlying scheme which say\nthat the performance loss is bounded by the average of the sampling\napproximation errors rather than the usual maximum, a crucial requirement given\nthe sampling sparsity of online planning. Empirical evaluations on two\nlarge-scale problems with dynamically evolving environments -- including a\nhelicopter emergency scenario in the Corsica region requiring approximately 150\nplanning steps -- corroborate the theoretical results and indicate that our\nsolver considerably outperforms current online benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u968f\u65f6\u5728\u7ebf\u8fd1\u4f3cPOMDP\u6c42\u89e3\u5668\uff0c\u5728\u5927\u578b\u52a8\u6001\u73af\u5883\u95ee\u9898\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5728\u7ebfPOMDP\u6c42\u89e3\u5668\u5728\u5904\u7406\u5927\u89c4\u6a21\u52a8\u6001\u73af\u5883\u95ee\u9898\u65f6\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "method": "\u8be5\u7b97\u6cd5\u901a\u8fc7\u5bf9\u6709\u610f\u4e49\u7684\u672a\u6765\u5386\u53f2\u8fdb\u884c\u6df1\u5165\u91c7\u6837\uff0c\u540c\u65f6\u5f3a\u5236\u6e10\u8fdb\u7b56\u7565\u66f4\u65b0\u6765\u5b9e\u73b0\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u7b97\u6cd5\u7684\u6027\u80fd\u635f\u5931\u53d7\u91c7\u6837\u8fd1\u4f3c\u8bef\u5dee\u5e73\u5747\u503c\u7684\u9650\u5236\uff0c\u800c\u4e0d\u662f\u6700\u5927\u503c\u7684\u9650\u5236\uff0c\u5e76\u4e14\u5728\u5904\u7406\u5927\u578b\u52a8\u6001\u73af\u5883\u95ee\u9898\uff08\u4f8b\u5982\u76f4\u5347\u673a\u7d27\u6025\u6551\u63f4\u573a\u666f\uff09\u65f6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u5728\u7ebf\u57fa\u51c6\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u968f\u65f6\u5728\u7ebf\u8fd1\u4f3cPOMDP\u6c42\u89e3\u5668\u2014\u2014\u90e8\u5206\u53ef\u89c2\u6d4b\u53c2\u8003\u7b56\u7565\u89c4\u5212(Partially Observable Reference Policy Programming)\uff0c\u8be5\u6c42\u89e3\u5668\u80fd\u591f\u5bf9\u6709\u610f\u4e49\u7684\u672a\u6765\u5386\u53f2\u8fdb\u884c\u975e\u5e38\u6df1\u5165\u7684\u91c7\u6837\uff0c\u540c\u65f6\u5f3a\u5236\u8fdb\u884c\u6e10\u8fdb\u7684\u7b56\u7565\u66f4\u65b0\u3002"}}
{"id": "2507.12207", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.12207", "abs": "https://arxiv.org/abs/2507.12207", "authors": ["Subin Lin", "Chuanbo Hua"], "title": "BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution", "comment": "ICML 2025 CO-Build Workshop Poster", "summary": "Accurate building energy forecasting is essential, yet traditional heuristics\noften lack precision, while advanced models can be opaque and struggle with\ngeneralization by neglecting physical principles. This paper introduces\nBuildEvo, a novel framework that uses Large Language Models (LLMs) to\nautomatically design effective and interpretable energy prediction heuristics.\nWithin an evolutionary process, BuildEvo guides LLMs to construct and enhance\nheuristics by systematically incorporating physical insights from building\ncharacteristics and operational data (e.g., from the Building Data Genome\nProject 2). Evaluations show BuildEvo achieves state-of-the-art performance on\nbenchmarks, offering improved generalization and transparent prediction logic.\nThis work advances the automated design of robust, physically grounded\nheuristics, promoting trustworthy models for complex energy systems.", "AI": {"tldr": "BuildEvo\u4f7f\u7528LLM\u81ea\u52a8\u8bbe\u8ba1\u53ef\u89e3\u91ca\u7684\u5efa\u7b51\u80fd\u6e90\u9884\u6d4b\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u51c6\u786e\u7684\u5efa\u7b51\u80fd\u6e90\u9884\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u5f80\u5f80\u7f3a\u4e4f\u7cbe\u5ea6\uff0c\u800c\u9ad8\u7ea7\u6a21\u578b\u53ef\u80fd\u4e0d\u900f\u660e\uff0c\u5e76\u4e14\u7531\u4e8e\u5ffd\u7565\u7269\u7406\u539f\u7406\u800c\u96be\u4ee5\u6cdb\u5316\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u81ea\u52a8\u8bbe\u8ba1\u6709\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u80fd\u6e90\u9884\u6d4b\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5728\u4e00\u4e2a\u8fdb\u5316\u8fc7\u7a0b\u4e2d\uff0cBuildEvo\u6307\u5bfcLLM\u901a\u8fc7\u7cfb\u7edf\u5730\u7ed3\u5408\u5efa\u7b51\u7279\u5f81\u548c\u8fd0\u884c\u6570\u636e\u7684\u7269\u7406\u89c1\u89e3\u6765\u6784\u5efa\u548c\u589e\u5f3a\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "result": "BuildEvo\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u900f\u660e\u7684\u9884\u6d4b\u903b\u8f91\u3002", "conclusion": "BuildEvo\u6846\u67b6\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u63d0\u9ad8\u4e86\u6cdb\u5316\u80fd\u529b\u548c\u9884\u6d4b\u903b\u8f91\u7684\u900f\u660e\u5ea6\uff0c\u63a8\u52a8\u4e86\u9c81\u68d2\u3001\u7269\u7406\u57fa\u7840\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u81ea\u52a8\u5316\u8bbe\u8ba1\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u590d\u6742\u80fd\u6e90\u7cfb\u7edf\u7684\u53ef\u4fe1\u8d56\u6a21\u578b\u3002"}}
{"id": "2507.12215", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.12215", "abs": "https://arxiv.org/abs/2507.12215", "authors": ["Yuhao Chen", "Shuochen Liu", "Yuanjie Lyu", "Chao Zhang", "Jiayao Shi", "Tong Xu"], "title": "Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning", "comment": "10 pages, 7 figures", "summary": "Game playing has long served as a fundamental benchmark for evaluating\nArtificial General Intelligence (AGI). While Large Language Models (LLMs) have\ndemonstrated impressive capabilities in general reasoning, their effectiveness\nin spatial strategic reasoning, which is critical for complex and fully\nobservable board games, remains insufficiently explored. In this work, we adopt\nChinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate\nrules and spatial complexity. To advance LLMs' strategic competence in such\nenvironments, we propose a training framework tailored to Xiangqi, built upon a\nlarge-scale dataset of five million board-move pairs enhanced with expert\nannotations and engine evaluations. Building on this foundation, we introduce\nXiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning\nfor legal move prediction to capture basic spatial rules, (2) incorporating\nstrategic annotations to improve decision-making, and (3) applying\nreinforcement learning via Group Relative Policy Optimization (GRPO) with\nmulti-dimensional reward signals to enhance reasoning stability. Our\nExperimental results indicate that, despite their size and power,\ngeneral-purpose LLMs struggle to achieve satisfactory performance in these\ntasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an\n18% rise in move legality and a 22% boost in analysis accuracy. Our results\npoint to a promising path for creating general strategic intelligence in\nspatially complex areas.", "AI": {"tldr": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u7b56\u7565\u63a8\u7406\u4e0a\u7684\u4e0d\u8db3\uff0c\u7814\u7a76\u8005\u63d0\u51faXiangqi-R1\u6a21\u578b\uff0c\u5728\u4e2d\u56fd\u8c61\u68cb\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u7a7a\u95f4\u7b56\u7565\u63a8\u7406\u65b9\u9762\u80fd\u529b\u4e0d\u8db3\uff0c\u4e2d\u56fd\u8c61\u68cb\u4f5c\u4e3a\u590d\u6742\u6e38\u620f\uff0c\u53ef\u4f5c\u4e3a\u8bc4\u4f30AGI\u7684\u826f\u597d\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4e2d\u56fd\u8c61\u68cb\u7684\u8bad\u7ec3\u6846\u67b6Xiangqi-R1\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e500\u4e07\u68cb\u5c40\u6570\u636e\uff0c\u7ed3\u5408\u4e13\u5bb6\u6807\u6ce8\u548c\u5f15\u64ce\u8bc4\u4f30\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff1a1)\u5fae\u8c03\u8fdb\u884c\u5408\u6cd5\u6027\u9884\u6d4b\uff1b2)\u878d\u5165\u7b56\u7565\u6807\u6ce8\uff1b3)\u4f7f\u7528\u57fa\u4e8e\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "Xiangqi-R1\u6a21\u578b\u5728\u5408\u6cd5\u6027\u9884\u6d4b\u548c\u5206\u6790\u51c6\u786e\u6027\u4e0a\u5206\u522b\u63d0\u9ad8\u4e8618%\u548c22%\uff0c\u663e\u8457\u4f18\u4e8e\u901a\u7528LLM\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u9700\u8981\u7a7a\u95f4\u7b56\u7565\u63a8\u7406\u7684\u590d\u6742\u6e38\u620f\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4e2d\u56fd\u8c61\u68cb\u7684\u8bad\u7ec3\u6846\u67b6Xiangqi-R1\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8bad\u7ec3\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u5408\u6cd5\u6027\u9884\u6d4b\u548c\u5206\u6790\u51c6\u786e\u6027\u65b9\u9762\u7684\u6027\u80fd\uff0c\u4e3a\u5728\u7a7a\u95f4\u590d\u6742\u9886\u57df\u521b\u5efa\u901a\u7528\u7b56\u7565\u667a\u80fd\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
