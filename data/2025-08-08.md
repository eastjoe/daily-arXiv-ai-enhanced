<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: LLM赋能的预测性维护系统，结合振动分析和多智能体信息检索，实现精准的故障诊断和维护建议生成。


<details>
  <summary>Details</summary>
Motivation: 及时维护工业机械以防止灾难性故障并优化运营效率。

Method: 该系统将轴承振动数据序列化为自然语言，利用LLM进行异常检测和故障分类，并结合多智能体组件处理维护手册和网络搜索结果，最终生成结构化的维护建议。

Result: 实验验证表明，该系统能够有效检测异常并提供相关的维护指导，在轴承振动数据集上取得了高精度。

Conclusion: 该论文提出了一种基于大型语言模型 (LLM) 的预测性维护智能系统，该系统结合轴承振动频率分析和多智能体生成，能够对工业机械故障进行准确检测并提供可操作的维护建议，弥合了状态监测和可操作维护规划之间的差距。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [2] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow 自动生成地理空间任务代理工作流程，提高效率并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有方法侧重于推理分解，而忽略了 API 选择，GeoFlow 通过提供详细的工具调用目标来改进。

Method: GeoFlow 方法通过为每个代理提供详细的工具调用目标来指导地理空间 API 的运行时调用。

Result: GeoFlow 将代理成功率提高了 6.8%，并将主要 LLM 系列的令牌使用量减少了多达四倍。

Conclusion: GeoFlow 是一种自动生成地理空间任务代理工作流程的方法，它通过为每个代理提供详细的工具调用目标来指导地理空间 API 的运行时调用，从而提高了代理的成功率并减少了令牌的使用。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [3] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 使用对抗性棋盘游戏评估大型语言模型，发现LLM适应性强但技能不稳定。


<details>
  <summary>Details</summary>
Motivation: 现有问答式基准方法存在数据依赖性限制，难以全面评估LLM的性能。对抗性棋盘游戏提供了一个评估策略推理和智能的理想环境。

Method: 构建了一个名为“Qi Town”的评估平台，支持五种棋盘游戏，并采用Elo评级系统和性能循环图（PLG）对LLM进行量化评估，同时捕捉游戏过程中的积极情绪评分（PSS）。

Result: 实验结果表明，大多数LLM在输赢方面都保持乐观，适应高压力对抗环境的能力强于人类。但PLG揭示了LLM技能的不稳定性。

Conclusion: 该论文提出了一种基于对抗性棋盘游戏评估大型语言模型（LLM）的基准测试框架，该框架弥补了主流问答式基准方法的数据依赖性限制。实验结果表明，LLM在高压力对抗环境中表现出比人类更强的适应性，但也暴露出其技能的不稳定性。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [4] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 小型语言模型在客户端的执行为自主式WebGIS提供了高准确率、高效率和高隐私的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的基于云的LLM的自主式WebGIS方案存在需要持续网络访问、隐私问题和可扩展性问题。

Method: 比较了三种实现自主式WebGIS的方法：(1) 基于云的LLM的完全自动化在线方法；(2) 使用经典机器学习分类器的半自动化离线方法；(3) 基于微调小型语言模型(SLM)的完全自主式离线客户端方法。

Result: 基于微调的T5-small模型的客户端方法在精确匹配准确率、Levenshtein相似度和ROUGE评分上均取得了最佳结果（准确率0.93，Levenshtein相似度0.99，ROUGE-1和ROUGE-L得分为0.98）。

Conclusion: 客户端执行的微型语言模型方法在自主式Web地理信息系统中取得了最高的准确率，消除了对服务器端推理的需求，提高了效率和隐私性。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [5] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 强化学习增强大型语言模型推理能力的研究存在局限性，在非理想场景下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽略了大型语言模型在现实非理想场景下的推理性能。

Method: 使用强化学习微调大型语言模型和视觉语言模型，并在八个公共数据集上进行评估。

Result: 强化学习微调提高了理想场景下的推理能力，但在非理想场景（摘要推理、细粒度噪声抑制和上下文过滤）下性能显著下降。

Conclusion: 当前强化学习增强大型语言模型推理能力的方法在非理想场景下效果显著下降，暴露出现有方法的局限性，需要进一步研究。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [6] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: Self-evolving AI agent HealthFlow surpasses existing methods in healthcare data analysis, showcasing the potential of self-improving task managers for scientific discovery.


<details>
  <summary>Details</summary>
Motivation: Addresses the limitation of static, predefined strategies in AI agents for healthcare research, aiming to improve strategic planning capabilities.

Method: Introduces a novel meta-level evolution mechanism for AI agents to autonomously refine high-level problem-solving policies by distilling procedural successes and failures.  Utilizes EHRFlowBench, a new benchmark with realistic health data analysis tasks.

Result: HealthFlow significantly outperforms existing methods.  EHRFlowBench benchmark facilitates reproducible evaluation.

Conclusion: HealthFlow, a self-evolving AI agent, significantly outperforms state-of-the-art agent frameworks in complex health data analysis tasks, demonstrating the effectiveness of self-evolving task-managers for scientific discovery.

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [7] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 利用博弈论框架和LoopPlay算法改进分子对接，提高了约10%的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有多任务学习模型在配体对接方面性能不如蛋白质口袋对接，这是由于配体和蛋白质的结构复杂性不同。

Method: 提出了一种名为“对接博弈”的二人博弈框架和LoopPlay算法，该算法通过两层循环迭代训练配体和蛋白质口袋对接模块，实现相互适应和动态优化。

Result: LoopPlay算法在预测准确结合模式方面比现有最先进方法提高了约10%。

Conclusion: 提出了一种新颖的博弈论框架LoopPlay，用于解决分子对接任务中配体对接和蛋白质口袋对接性能差异的问题，并在公共基准数据集上取得了大约10%的改进。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [8] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: LLM可用于空间数据整合，但需结合特征工程和迭代改进方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以处理空间数据整合中的各种边缘情况，而机器学习方法需要大量特定任务样本，因此研究LLM作为一种替代方案。

Method: 研究了LLM在空间数据整合中的应用，采用特征工程减少LLM对空间推理的依赖，并结合迭代改进方法修正错误。

Result: LLM在提供相关特征后能生成高性能结果，迭代改进方法能有效纠正错误，表明LLM具有作为自适应空间数据整合方法的潜力。

Conclusion: 大型语言模型(LLM)在整合大型、异构和嘈杂的城市空间数据集方面显示出潜力，虽然存在逻辑不一致的问题，但结合特征工程和迭代改进方法，LLM能生成高性能结果，为自适应空间数据整合提供了一种有前景的替代方案。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [9] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: CogniWeb: a dual-process web agent achieving high efficiency and competitive performance in WebArena.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of web navigation in AGI evaluation by effectively integrating offline imitation learning and online exploration.

Method: Developed CogniWeb, a modular agent architecture that integrates offline imitation learning and online exploration based on dual-process theory.

Result: CogniWeb achieves 43.96% success rate on WebArena with 75% reduction in token usage compared to existing methods.

Conclusion: CogniWeb, a modular web agent architecture inspired by dual-process theory, achieves competitive performance with higher efficiency by adaptively switching between fast intuitive processing and deliberate reasoning.

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [10] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: 提出MedMKEB基准，评估医疗多模态大型语言模型知识编辑能力，并揭示现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有医疗多模态大型语言模型难以有效更新过时或错误信息，缺乏系统性的多模态医疗知识编辑基准。

Method: 构建MedMKEB基准，包含反事实校正、语义泛化、知识迁移和对抗鲁棒性等编辑任务，并进行人工专家验证。在最先进的通用和医疗MLLM上进行单次和连续编辑实验。

Result: 揭示了现有基于知识的编辑方法在医学领域的局限性，证明了开发专门的编辑策略的必要性，并为开发值得信赖和高效的医疗知识编辑算法提供标准基准。

Conclusion: MedMKEB，一个用于评估医疗多模态大型语言模型知识编辑可靠性、通用性、局部性、可移植性和鲁棒性的综合基准，被提出用于解决现有模型难以有效更新过时或错误信息的问题。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [11] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize: 轻量级、通用的模拟电路门尺寸调整框架，显著减少人工干预和计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决模拟电路设计中耗时且依赖经验的门尺寸调整问题。

Method: EasySize利用性能指标的可达性（EOA）动态构建特定任务的损失函数，并结合全局差分进化（DE）和局部粒子群优化（PSO）算法进行高效启发式搜索。

Result: 在不同工艺节点（180nm、45nm、22nm）的5个运算放大器电路网表上取得了优异的性能，并在86.67%的任务中优于AutoCkt，同时减少了超过96.67%的仿真资源。

Conclusion: EasySize，一个基于微调Qwen3-8B模型的轻量级门尺寸调整框架，在跨工艺节点、设计规范和电路拓扑结构的通用适用性方面表现出色，并优于AutoCkt等现有方法。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [12] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: Socratic AI tutors improve student critical thinking;  study proposes scalable, orchestrated AI systems for education.


<details>
  <summary>Details</summary>
Motivation: To evaluate the impact of a Socratic AI tutor on student research question development and critical thinking, challenging narratives of de-skilling due to generative AI.

Method: Controlled experiment comparing a Socratic AI tutor with an uninstructed AI chatbot, involving 65 pre-service teacher students in Germany.

Result: Students using the Socratic AI tutor showed significantly greater support for critical, independent, and reflective thinking. The study proposes orchestrated multi-agent systems (MAS) for diverse learning trajectories.

Conclusion: This study provides empirical evidence and a conceptual roadmap for hybrid learning ecosystems incorporating human-AI co-agency and pedagogical alignment, showing that dialogic AI can enhance metacognitive engagement in students.  A cost-effectiveness analysis suggests scalability.

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [13] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 使用异构图神经网络模型有效填补流程挖掘中事件日志的缺失信息，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的流程日志重建方法要么需要过程模型，要么依赖机器学习/深度学习模型，而本文提出了一种基于异构图神经网络的模型，以更自然的方式表示复杂的多模态序列，从而提高了缺失信息填补的准确性和完整性。

Method: 开发了一种异构图神经网络模型，该模型能够处理编码为图的输入数据，并利用其优势处理流程挖掘中复杂的多模态序列执行轨迹。

Result: 该方法在两个合成日志和四个真实事件日志上进行了评估，结果表明该方法在重构所有不同事件属性方面具有良好的性能，优于现有的基于自动编码器的无模型方法。

Conclusion: 开发了一种基于异构图神经网络模型的方法，用于填补流程挖掘中事件日志中缺失的信息，并在合成日志和真实事件日志上进行了评估，结果表明该方法在重构所有不同事件属性方面具有良好的性能。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [14] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon是一个用于知识密集型VQA的动态RAG系统，通过多模态、多跳推理显著提升了问答准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法通常只从文本或图像中单独检索信息，难以处理需要多跳推理或最新事实知识的复杂查询。

Method: 提出了一种查询感知的动态RAG系统QA-Dragon，该系统包含领域路由器和搜索路由器，能够动态选择最优的检索策略，支持多模态、多轮和多跳推理。

Result: 在KDD Cup 2025的Meta CRAG-MM挑战赛中，QA-Dragon在单源任务、多源任务和多轮任务上分别提高了5.06%、6.35%和5.03%的准确率和知识重叠度。

Conclusion: QA-Dragon系统显著提升了知识密集型VQA任务的推理性能，在单源、多源和多轮任务上均取得了显著优于基线的成果。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [15] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 利用RDF图数据库和LLM构建框架，提升大型维护组织内部的沟通效率和精准度。


<details>
  <summary>Details</summary>
Motivation: 解决大型维护组织中识别主题专家和跨复杂实体关系管理沟通的挑战，例如信息过载和响应时间长等问题。

Method: 结合RDF图数据库和LLMs处理自然语言查询，实现精准的受众定位，并通过规划-协调架构提供透明的推理过程。

Result: 能够让沟通负责人使用直观的查询组合概念（如设备、制造商、维护工程师和设施），给出可解释的结果，提高沟通效率，并保持对系统的信任。

Conclusion: 提出了一种结合RDF图数据库和LLM的新框架，用于在大型维护组织中高效精准地定位主题专家并管理沟通，提高沟通效率，并保证系统透明性和可解释性。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [16] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 该论文提出一种混合神经符号推理架构，结合决策树和LLM，在多个基准测试中取得了显著的性能提升，并具有良好的可解释性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常松散地耦合符号和神经模块，该研究旨在构建一个更紧密集成符号和神经推理能力的系统，以提高推理性能和可解释性。

Method: 该研究提出了一种混合架构，将基于决策树的符号推理与大型语言模型 (LLM) 的生成能力集成在一个协调的多智能体框架中。决策树和随机森林作为可调用的预言机嵌入到统一的推理系统中，LLM 智能体负责溯因推理、泛化和交互式规划，中央协调器维护信念状态一致性并协调智能体和外部工具之间的通信。

Result: 在ProofWriter、GSM8k和ARC等推理基准测试中，该系统分别在蕴含一致性、多步数学问题求解和抽象精度方面取得了显著提升。

Conclusion: 该系统提供了一种强大、可解释且可扩展的通用神经符号推理解决方案，在推理基准测试中取得了显著成果，并在临床决策支持和科学发现等应用中展现了其优势。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [17] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: This paper proposes a new framework to clearly define 'AI agent' across multiple dimensions to improve research and policy.


<details>
  <summary>Details</summary>
Motivation: Ambiguity in the definition of 'agent' hinders research communication, system evaluation, reproducibility, and policy development.

Method: Historical analysis and contemporary usage patterns are used to propose a framework for defining AI agents.

Result: A framework defining minimum requirements for an AI agent is proposed, characterized by environmental interaction, learning, autonomy, goal complexity, and temporal coherence.  Recommendations for terminology standardization and framework adoption are provided.

Conclusion: The term 'agent' needs redefinition due to its ambiguity in AI, especially with large language models.  A new framework is proposed to clarify minimum requirements and characterize systems along multiple dimensions.

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>
