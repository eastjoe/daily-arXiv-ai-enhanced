<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Exploring Agentic Artificial Intelligence Systems: Towards a Typological Framework](https://arxiv.org/abs/2508.00844)
*Christopher Wissuchek,Patrick Zschech*

Main category: cs.AI

TL;DR: 该论文提出了一种新的AI系统类型系统，用于分类和比较自主AI系统。


<details>
  <summary>Details</summary>
Motivation: 缺乏对自主AI系统的结构化分类和比较框架。

Method: 使用多阶段方法构建和完善类型系统，并通过人机混合方法进行评估。

Result: 提出了一种包含八个维度的自主AI系统类型系统，能够分析AI系统中不同程度的自主性。

Conclusion: 该论文提出了一种对自主AI系统进行分类和比较的八维类型系统，并通过多阶段方法构建和完善了该系统，最终形成结构化的类型，有助于研究人员和实践者分析AI系统中不同程度的自主性，并预测未来自主AI的发展。

Abstract: Artificial intelligence (AI) systems are evolving beyond passive tools into
autonomous agents capable of reasoning, adapting, and acting with minimal human
intervention. Despite their growing presence, a structured framework is lacking
to classify and compare these systems. This paper develops a typology of
agentic AI systems, introducing eight dimensions that define their cognitive
and environmental agency in an ordinal structure. Using a multi-phase
methodological approach, we construct and refine this typology, which is then
evaluated through a human-AI hybrid approach and further distilled into
constructed types. The framework enables researchers and practitioners to
analyze varying levels of agency in AI systems. By offering a structured
perspective on the progression of AI capabilities, the typology provides a
foundation for assessing current systems and anticipating future developments
in agentic AI.

</details>


### [2] [A Formal Framework for the Definition of 'State': Hierarchical Representation and Meta-Universe Interpretation](https://arxiv.org/abs/2508.00853)
*Kei Itoh*

Main category: cs.AI

TL;DR: 提出一个新的元形式逻辑框架，统一了对‘状态’概念的理解，并为智能的定义提供了数学基础。


<details>
  <summary>Details</summary>
Motivation: 为了强化多元系统的理论基础，特别是智能的公理化定义，对长期以来缺乏共识和形式清晰度的'状态'概念进行形式化。

Method: 提出了分层状态网格和中间元宇宙 (IMU) 等概念，构建了一个统一的、适用于数学、物理和语言领域的符号系统。

Result: 建立了一个跨越时间、语言、主体和操作的元形式逻辑框架，扩展了跨宇宙理论，并增强了表达能力。

Conclusion: 该研究提出了一个基于“定义=状态”原则的元形式逻辑框架，为智能、形式逻辑和科学理论提供了数学基础。

Abstract: This study aims to reinforce the theoretical foundation for diverse
systems--including the axiomatic definition of intelligence--by introducing a
mathematically rigorous and unified formal structure for the concept of
'state,' which has long been used without consensus or formal clarity. First, a
'hierarchical state grid' composed of two axes--state depth and mapping
hierarchy--is proposed to provide a unified notational system applicable across
mathematical, physical, and linguistic domains. Next, the 'Intermediate
Meta-Universe (IMU)' is introduced to enable explicit descriptions of definers
(ourselves) and the languages we use, thereby allowing conscious meta-level
operations while avoiding self-reference and logical inconsistency. Building on
this meta-theoretical foundation, this study expands inter-universal theory
beyond mathematics to include linguistic translation and agent integration,
introducing the conceptual division between macrocosm-inter-universal and
microcosm-inter-universal operations for broader expressivity. Through these
contributions, this paper presents a meta-formal logical framework--grounded in
the principle of definition = state--that spans time, language, agents, and
operations, providing a mathematically robust foundation applicable to the
definition of intelligence, formal logic, and scientific theory at large.

</details>


### [3] [AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks](https://arxiv.org/abs/2508.00890)
*Fali Wang,Hui Liu,Zhenwei Dai,Jingying Zeng,Zhiwei Zhang,Zongyu Wu,Chen Luo,Zhen Li,Xianfeng Tang,Qi He,Suhang Wang*

Main category: cs.AI

TL;DR: 针对多阶段复杂任务的测试时计算最优缩放问题，提出AgentTTS框架，通过LLM-agent自主搜索计算最优分配，显著提升效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在单阶段任务的TTS，而实际问题多为多阶段复杂任务，每个子任务需要特定能力的LLM，因此研究多阶段复杂任务中的测试时计算最优缩放。

Method: 提出AgentTTS，一个基于LLM-agent的框架，通过迭代反馈驱动的交互自主搜索计算最优分配。

Result: AgentTTS在搜索效率方面显著优于传统方法和其它基于LLM的基线方法，并显示出对不同训练集大小的增强鲁棒性和更好的可解释性。

Conclusion: AgentTTS框架显著优于传统方法和其它基于LLM的基线方法，在搜索效率、对不同训练集大小的鲁棒性以及可解释性方面均有所提升。

Abstract: Test-time scaling (TTS) enhances the performance of large language models
(LLMs) by allocating additional compute resources during inference. However,
existing research primarily investigates TTS in single-stage tasks; while many
real-world problems are multi-stage complex tasks, composed of a sequence of
heterogeneous subtasks with each subtask requires LLM of specific capability.
Therefore, we study a novel problem: the test-time compute-optimal scaling in
multi-stage complex tasks, aiming to select suitable models and allocate
budgets per subtask to maximize overall performance. TTS in multi-stage tasks
introduces two fundamental challenges: (i) The combinatorial search space of
model and budget allocations, combined with the high cost of inference, makes
brute-force search impractical. (ii) The optimal model and budget allocations
across subtasks are interdependent, increasing the complexity of the
compute-optimal search. To address this gap, we conduct extensive pilot
experiments on four tasks across six datasets, deriving three empirical
insights characterizing the behavior of LLMs in multi-stage complex tasks.
Informed by these insights, we propose AgentTTS, an LLM-agent-based framework
that autonomously searches for compute-optimal allocations through iterative
feedback-driven interactions with the execution environment. Experimental
results demonstrate that AgentTTS significantly outperforms traditional and
other LLM-based baselines in search efficiency, and shows improved robustness
to varying training set sizes and enhanced interpretability.

</details>


### [4] [ff4ERA: A new Fuzzy Framework for Ethical Risk Assessment in AI](https://arxiv.org/abs/2508.00899)
*Abeer Dyoub,Ivan Letteri,Francesca A. Lisi*

Main category: cs.AI

TL;DR: 提出ff4ERA框架，利用模糊逻辑等方法量化伦理风险，辅助Symbiotic AI的伦理决策。


<details>
  <summary>Details</summary>
Motivation: Symbiotic AI (SAI)的出现给伦理决策带来了新的挑战，伦理风险评估(ERA)对于指导最大限度地减少此类风险的决策至关重要，但ERA受到不确定性、模糊性和信息不完整性的阻碍，因此需要一个灵活、透明且稳健的ERA框架。

Method: 该研究提出了一种名为ff4ERA的模糊框架，该框架集成了模糊逻辑、模糊层次分析法(FAHP)和确定性因子(CF)，通过每个风险类型的伦理风险评分(ERS)来量化伦理风险。最终的ERS结合了FAHP导出的权重、传播的CF和风险等级。

Result: 案例研究证实，ff4ERA产生了上下文相关的、具有伦理意义的风险评分，反映了专家输入和基于传感器的证据。风险评分随相关因素一致变化，同时对无关输入保持稳健。局部敏感性分析显示出可预测的、大部分单调的行为，全局Sobol分析突出了专家定义的权重和确定性因子的主导影响，验证了模型设计。

Conclusion: ff4ERA框架能够产生可解释、可追溯和风险感知的伦理评估，支持假设分析，并指导设计者校准隶属函数和专家判断，以实现可靠的伦理决策支持。

Abstract: The emergence of Symbiotic AI (SAI) introduces new challenges to ethical
decision-making as it deepens human-AI collaboration. As symbiosis grows, AI
systems pose greater ethical risks, including harm to human rights and trust.
Ethical Risk Assessment (ERA) thus becomes crucial for guiding decisions that
minimize such risks. However, ERA is hindered by uncertainty, vagueness, and
incomplete information, and morality itself is context-dependent and imprecise.
This motivates the need for a flexible, transparent, yet robust framework for
ERA. Our work supports ethical decision-making by quantitatively assessing and
prioritizing multiple ethical risks so that artificial agents can select
actions aligned with human values and acceptable risk levels. We introduce
ff4ERA, a fuzzy framework that integrates Fuzzy Logic, the Fuzzy Analytic
Hierarchy Process (FAHP), and Certainty Factors (CF) to quantify ethical risks
via an Ethical Risk Score (ERS) for each risk type. The final ERS combines the
FAHP-derived weight, propagated CF, and risk level. The framework offers a
robust mathematical approach for collaborative ERA modeling and systematic,
step-by-step analysis. A case study confirms that ff4ERA yields
context-sensitive, ethically meaningful risk scores reflecting both expert
input and sensor-based evidence. Risk scores vary consistently with relevant
factors while remaining robust to unrelated inputs. Local sensitivity analysis
shows predictable, mostly monotonic behavior across perturbations, and global
Sobol analysis highlights the dominant influence of expert-defined weights and
certainty factors, validating the model design. Overall, the results
demonstrate ff4ERA ability to produce interpretable, traceable, and risk-aware
ethical assessments, enabling what-if analyses and guiding designers in
calibrating membership functions and expert judgments for reliable ethical
decision support.

</details>


### [5] [An analysis of AI Decision under Risk: Prospect theory emerges in Large Language Models](https://arxiv.org/abs/2508.00902)
*Kenneth Payne*

Main category: cs.AI

TL;DR: LLM继承了人类的风险认知偏差，且这种偏差与语言情境密切相关。


<details>
  <summary>Details</summary>
Motivation: 检验前景理论在大型语言模型中的适用性，并探讨语言模型中风险偏好的来源。

Method: 对大型语言模型进行了一系列风险决策实验，测试了前景理论。

Result: LLM在风险决策中表现出与人类类似的前景理论偏差；情境（尤其是语言框架）对风险偏好有显著影响；军事场景的框架效应大于民用场景。

Conclusion: 大型语言模型(LLM)的风险偏好与人类相似，受情境影响，尤其军事场景比民用场景更容易产生框架效应。

Abstract: Judgment of risk is key to decision-making under uncertainty. As Daniel
Kahneman and Amos Tversky famously discovered, humans do so in a distinctive
way that departs from mathematical rationalism. Specifically, they demonstrated
experimentally that humans accept more risk when they feel themselves at risk
of losing something than when they might gain. I report the first tests of
Kahneman and Tversky's landmark 'prospect theory' with Large Language Models,
including today's state of the art chain-of-thought 'reasoners'.
  In common with humans, I find that prospect theory often anticipates how
these models approach risky decisions across a range of scenarios. I also
demonstrate that context is key to explaining much of the variance in risk
appetite. The 'frame' through which risk is apprehended appears to be embedded
within the language of the scenarios tackled by the models. Specifically, I
find that military scenarios generate far larger 'framing effects' than do
civilian settings, ceteris paribus. My research suggests, therefore, that
language models the world, capturing our human heuristics and biases. But also
that these biases are uneven - the idea of a 'frame' is richer than simple
gains and losses. Wittgenstein's notion of 'language games' explains the
contingent, localised biases activated by these scenarios. Finally, I use my
findings to reframe the ongoing debate about reasoning and memorisation in
LLMs.

</details>


### [6] [Knowledge Editing for Multi-Hop Question Answering Using Semantic Analysis](https://arxiv.org/abs/2508.00914)
*Dominic Simon,Rickard Ewetz*

Main category: cs.AI

TL;DR: 提出一种新的知识编辑器CHECK，通过语义分析提高多跳问题回答的准确性，平均提升22.8%。


<details>
  <summary>Details</summary>
Motivation: 现有的知识编辑方法难以处理需要组合推理的任务，例如多跳问题回答(MQA)，因为它们依赖分解技术，导致非逻辑推理过程。

Method: 提出了一种基于语义分析的MQA知识编辑器CHECK，该框架将推理链进行语义分析，类似于编译器编译源代码，以确保推理链的一致性，并通过逻辑优化和重新提示LLM模型来修正语义错误。

Result: 在四个数据集上平均提高了MQA准确率22.8%。

Conclusion: CHECK框架在四个数据集上平均提高了MQA准确率22.8%，优于其他五个最先进的框架。

Abstract: Large Language Models (LLMs) require lightweight avenues of updating stored
information that has fallen out of date. Knowledge Editing (KE) approaches have
been successful in updating model knowledge for simple factual queries but
struggle with handling tasks that require compositional reasoning such as
multi-hop question answering (MQA). We observe that existing knowledge editors
leverage decompositional techniques that result in illogical reasoning
processes. In this paper, we propose a knowledge editor for MQA based on
semantic analysis called CHECK. Our framework is based on insights from an
analogy between compilers and reasoning using LLMs. Similar to how source code
is first compiled before being executed, we propose to semantically analyze
reasoning chains before executing the chains to answer questions. Reasoning
chains with semantic errors are revised to ensure consistency through logic
optimization and re-prompting the LLM model at a higher temperature. We
evaluate the effectiveness of CHECK against five state-of-the-art frameworks on
four datasets and achieve an average 22.8% improved MQA accuracy.

</details>


### [7] [Cooperative Perception: A Resource-Efficient Framework for Multi-Drone 3D Scene Reconstruction Using Federated Diffusion and NeRF](https://arxiv.org/abs/2508.00967)
*Massoud Pourmandi*

Main category: cs.AI

TL;DR: 一种创新的无人机集群感知系统，通过联合学习和轻量级语义提取实现高效的3D/4D场景合成，解决了计算限制和低带宽通信问题。


<details>
  <summary>Details</summary>
Motivation: 解决无人机集群感知系统中计算限制、低带宽通信和实时场景重建等问题。

Method: 该框架通过联合学习共享扩散模型和YOLOv12轻量级语义提取以及局部NeRF更新，实现了高效的多智能体3D/4D场景合成，同时保持隐私和可扩展性。

Result: 该方法可以通过仿真和潜在的无人机测试平台上的实际部署进行验证，使其成为自主系统多智能体AI领域的一次突破性进展。

Conclusion: 该提案提出了一种创新的无人机集群感知系统，旨在解决计算限制、低带宽通信和实时场景重建等问题。

Abstract: The proposal introduces an innovative drone swarm perception system that aims
to solve problems related to computational limitations and low-bandwidth
communication, and real-time scene reconstruction. The framework enables
efficient multi-agent 3D/4D scene synthesis through federated learning of
shared diffusion model and YOLOv12 lightweight semantic extraction and local
NeRF updates while maintaining privacy and scalability. The framework redesigns
generative diffusion models for joint scene reconstruction, and improves
cooperative scene understanding, while adding semantic-aware compression
protocols. The approach can be validated through simulations and potential
real-world deployment on drone testbeds, positioning it as a disruptive
advancement in multi-agent AI for autonomous systems.

</details>


### [8] [AutoEDA: Enabling EDA Flow Automation through Microservice-Based LLM Agents](https://arxiv.org/abs/2508.01012)
*Yiyi Lu,Hoi Ian Au,Junyao Zhang,Jingyu Pan,Yiting Wang,Ang Li,Jianyi Zhang,Yiran Chen*

Main category: cs.AI

TL;DR: AutoEDA是一个开源的EDA自动化框架，利用并行学习和结构化提示工程提高效率和准确性，并提供改进的评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有的电子设计自动化(EDA)流程效率低下，依赖大量手动脚本和工具特定的交互。LLM虽然能实现自动化，但现有解决方案需要昂贵的微调，且缺乏标准化的集成和评估框架。

Method: AutoEDA框架利用模型上下文协议(MCP)实现并行学习，进行智能参数提取和任务分解，并通过结构化提示工程减少微调需求。

Result: 实验结果表明，与现有方法相比，AutoEDA在自动化准确性、效率和脚本质量方面均有所提高。

Conclusion: AutoEDA框架通过并行学习和结构化提示工程提高了EDA自动化流程的准确性和效率，并提供了一种扩展的CodeBLEU指标来评估TCL脚本的质量。

Abstract: Modern Electronic Design Automation (EDA) workflows, especially the
RTL-to-GDSII flow, require heavily manual scripting and demonstrate a multitude
of tool-specific interactions which limits scalability and efficiency. While
LLMs introduces strides for automation, existing LLM solutions require
expensive fine-tuning and do not contain standardized frameworks for
integration and evaluation. We introduce AutoEDA, a framework for EDA
automation that leverages paralleled learning through the Model Context
Protocol (MCP) specific for standardized and scalable natural language
experience across the entire RTL-to-GDSII flow. AutoEDA limits fine-tuning
through structured prompt engineering, implements intelligent parameter
extraction and task decomposition, and provides an extended CodeBLEU metric to
evaluate the quality of TCL scripts. Results from experiments over five
previously curated benchmarks show improvements in automation accuracy and
efficiency, as well as script quality when compared to existing methods.
AutoEDA is released open-sourced to support reproducibility and the EDA
community. Available at: https://github.com/AndyLu666/MCP-EDA-Server

</details>


### [9] [CADDesigner: Conceptual Design of CAD Models Based on General-Purpose Agent](https://arxiv.org/abs/2508.01031)
*Jingzhe Ni,Xiaolong Yin,Xintong Li,Xingyu Lu,Ji Wei,Ruofeng Tong,Min Tang,Peng Du*

Main category: cs.AI

TL;DR: 利用大型语言模型，通过交互式对话和迭代视觉反馈，实现高质量CAD代码自动生成，达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 降低CAD设计的准入门槛，提高设计效率。

Method: 该智能体基于新颖的上下文无关命令范式（CIP），利用大型语言模型（LLM）进行CAD概念设计，并结合迭代视觉反馈以提高模型质量。

Result: 该智能体能够根据抽象文本描述和手绘草图生成高质量的CAD建模代码，并通过与用户的交互式对话来改进和阐明设计需求。

Conclusion: 该方法在CAD代码生成方面达到了最先进的性能。

Abstract: Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing
but typically requires a high level of expertise from designers. To lower the
entry barrier and improve design efficiency, we present an agent for CAD
conceptual design powered by large language models (LLMs). The agent accepts
both abstract textual descriptions and freehand sketches as input, engaging in
interactive dialogue with users to refine and clarify design requirements
through comprehensive requirement analysis. Built upon a novel
Context-Independent Imperative Paradigm (CIP), the agent generates high-quality
CAD modeling code. During the generation process, the agent incorporates
iterative visual feedback to improve model quality. Generated design cases are
stored in a structured knowledge base, enabling continuous improvement of the
agent's code generation capabilities. Experimental results demonstrate that our
method achieves state-of-the-art performance in CAD code generation.

</details>


### [10] [REACT: A Real-Time Edge-AI Based V2X Framework for Accident Avoidance in Autonomous Driving System](https://arxiv.org/abs/2508.01057)
*Fengze Yang,Bo Yu,Yang Zhou,Xuewen Luo,Zhengzhong Tu,Chenxi Liu*

Main category: cs.AI

TL;DR: 轻量级VLM用于实时车端协同规划，语言引导的上下文推理提高了自动驾驶的安全性。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的V2X框架存在泛化能力有限、上下文推理浅显以及依赖单模态输入等问题。视觉语言模型(VLMs)虽然具有增强的推理和多模态集成能力，但在安全关键型应用中通常难以满足实时性能要求。

Method: REACT是一个基于微调轻量级视觉语言模型(VLM)的实时V2X集成轨迹优化框架，集成了处理多模态输入的一组专用模块，生成优化的风险感知轨迹，并结合边缘适应策略以降低模型复杂度和加快推理速度。

Result: 碰撞率降低77%，VPQ提高48.2%，推理延迟0.57秒。

Conclusion: REACT框架在DeepAccident基准测试中取得了最先进的性能，碰撞率降低了77%，VPQ提高了48.2%，推理延迟仅为0.57秒。消融研究验证了每个输入、模块和边缘适应策略的贡献。

Abstract: Collisions caused by human error are the most common type of multi-vehicle
crash, highlighting the critical need for autonomous driving (AD) systems to
leverage cooperative perception through Vehicle-to-Everything (V2X)
communication. This capability extends situational awareness beyond the
limitations of onboard sensors. However, current transformer-based V2X
frameworks suffer from limited generalization, shallow contextual reasoning,
and reliance on mono-modal inputs. Vision-Language Models (VLMs) offer enhanced
reasoning and multimodal integration but typically fall short of real-time
performance requirements in safety-critical applications. This paper presents
REACT, a real-time, V2X-integrated trajectory optimization framework built upon
a fine-tuned lightweight VLM. REACT integrates a set of specialized modules
that process multimodal inputs into optimized, risk-aware trajectories. To
ensure real-time performance on edge devices, REACT incorporates edge
adaptation strategies that reduce model complexity and accelerate inference.
Evaluated on the DeepAccident benchmark, REACT achieves state-of-the-art
performance, a 77% collision rate reduction, a 48.2% Video Panoptic Quality
(VPQ), and a 0.57-second inference latency on the Jetson AGX Orin. Ablation
studies validate the contribution of each input, module, and edge adaptation
strategy. These results demonstrate the feasibility of lightweight VLMs for
real-time edge-based cooperative planning and showcase the potential of
language-guided contextual reasoning to improve safety and responsiveness in
autonomous driving.

</details>


### [11] [gpuRDF2vec -- Scalable GPU-based RDF2vec](https://arxiv.org/abs/2508.01073)
*Martin Böckling,Heiko Paulheim*

Main category: cs.AI

TL;DR: gpuRDF2vec库利用GPU加速RDF2vec，显著提升了大规模知识图谱嵌入生成的效率。


<details>
  <summary>Details</summary>
Motivation: 现有技术生成web规模知识图谱嵌入仍然具有挑战性，RDF2vec兼具有效性和可扩展性，但仍需加速。

Method: 利用GPU和多节点执行加速RDF2vec流程的每个阶段，基于Pytorch Lightning实现可扩展的word2vec。

Result: gpuRDF2vec在合成图和真实基准测试中均实现了显著的加速，单节点设置下，其walk-extraction阶段显著优于pyRDF2vec、SparkKGML和jRDF2vec。

Conclusion: gpuRDF2vec库通过利用现代GPU和支持多节点执行，显著加速了RDF2vec流程的每个阶段，在大型图上生成高质量的知识图谱嵌入，并在单节点设置下优于现有方法。

Abstract: Generating Knowledge Graph (KG) embeddings at web scale remains challenging.
Among existing techniques, RDF2vec combines effectiveness with strong
scalability. We present gpuRDF2vec, an open source library that harnesses
modern GPUs and supports multi-node execution to accelerate every stage of the
RDF2vec pipeline. Extensive experiments on both synthetically generated graphs
and real-world benchmarks show that gpuRDF2vec achieves up to a substantial
speedup over the currently fastest alternative, i.e., jRDF2vec. In a
single-node setup, our walk-extraction phase alone outperforms pyRDF2vec,
SparkKGML, and jRDF2vec by a substantial margin using random walks on large/
dense graphs, and scales very well to longer walks, which typically lead to
better quality embeddings. Our implementation of gpuRDF2vec enables
practitioners and researchers to train high-quality KG embeddings on
large-scale graphs within practical time budgets and builds on top of Pytorch
Lightning for the scalable word2vec implementation.

</details>


### [12] [Multispin Physics of AI Tipping Points and Hallucinations](https://arxiv.org/abs/2508.01097)
*Neil F. Johnson,Frank Yingjie Huo*

Main category: cs.AI

TL;DR: 生成式AI存在隐蔽的错误模式，该研究通过建立数学模型解释了其原因，并提出了量化用户风险的方法。


<details>
  <summary>Details</summary>
Motivation: 生成式AI输出存在重复、偏差以及无察觉的从正确到错误的转变，造成巨大经济损失和人员伤亡。

Method: 建立生成式AI与多自旋热力学系统的数学映射，推导公式。

Result: 揭示了AI的“原子”（基本注意力机制）层面的倾翻不稳定性，导出了预测倾翻点的公式，解释了用户提示、AI训练偏差和多层架构的影响。

Conclusion: 揭示了生成式AI输出中一种隐藏的“倾翻”不稳定性，并导出了一个简单的公式来预测该点，解释了用户提示和AI训练偏差的影响，以及多层架构如何放大这种倾翻。

Abstract: Output from generative AI such as ChatGPT, can be repetitive and biased. But
more worrying is that this output can mysteriously tip mid-response from good
(correct) to bad (misleading or wrong) without the user noticing. In 2024
alone, this reportedly caused $67 billion in losses and several deaths.
Establishing a mathematical mapping to a multispin thermal system, we reveal a
hidden tipping instability at the scale of the AI's 'atom' (basic Attention
head). We derive a simple but essentially exact formula for this tipping point
which shows directly the impact of a user's prompt choice and the AI's training
bias. We then show how the output tipping can get amplified by the AI's
multilayer architecture. As well as helping improve AI transparency,
explainability and performance, our results open a path to quantifying users'
AI risk and legal liabilities.

</details>


### [13] [Platonic Representations for Poverty Mapping: Unified Vision-Language Codes or Agent-Induced Novelty?](https://arxiv.org/abs/2508.01109)
*Satiyabooshan Murugaboopathy,Connor T. Jerzak,Adel Daoud*

Main category: cs.AI

TL;DR: 融合卫星图像和多种文本数据能更准确预测非洲家庭财富，大型语言模型数据优于AI代理数据，并发布了一个大规模多模态数据集。


<details>
  <summary>Details</summary>
Motivation: 研究社会经济指标如何在卫星图像和互联网文本中留下可恢复的痕迹，并提高家庭财富预测的准确性和稳健性。

Method: 使用多模态框架，融合卫星图像、大型语言模型生成的文本和AI代理检索的网络文本，预测家庭财富（国际财富指数）。

Result: 融合视觉和文本数据提高了财富预测的准确性（例如，样本外分割的R平方从0.63提高到0.77），大型语言模型生成的文本比AI代理检索的文本更有效，模型在不同国家和时间段的泛化能力更强。部分表征收敛，视觉和语言模态的融合嵌入具有中等相关性。

Conclusion: 这项研究融合卫星图像和文本数据（包括大型语言模型生成的文本和AI代理检索的网络文本）预测非洲社区的家庭财富，发现融合视觉和文本数据优于仅使用视觉数据，大型语言模型生成的文本比AI代理检索的文本更有效，并构建了一个包含超过60,000个 DHS 集群的大规模多模态数据集。

Abstract: We investigate whether socio-economic indicators like household wealth leave
recoverable imprints in satellite imagery (capturing physical features) and
Internet-sourced text (reflecting historical/economic narratives). Using
Demographic and Health Survey (DHS) data from African neighborhoods, we pair
Landsat images with LLM-generated textual descriptions conditioned on
location/year and text retrieved by an AI search agent from web sources. We
develop a multimodal framework predicting household wealth (International
Wealth Index) through five pipelines: (i) vision model on satellite images,
(ii) LLM using only location/year, (iii) AI agent searching/synthesizing web
text, (iv) joint image-text encoder, (v) ensemble of all signals. Our framework
yields three contributions. First, fusing vision and agent/LLM text outperforms
vision-only baselines in wealth prediction (e.g., R-squared of 0.77 vs. 0.63 on
out-of-sample splits), with LLM-internal knowledge proving more effective than
agent-retrieved text, improving robustness to out-of-country and out-of-time
generalization. Second, we find partial representational convergence: fused
embeddings from vision/language modalities correlate moderately (median cosine
similarity of 0.60 after alignment), suggesting a shared latent code of
material well-being while retaining complementary details, consistent with the
Platonic Representation Hypothesis. Although LLM-only text outperforms
agent-retrieved data, challenging our Agent-Induced Novelty Hypothesis, modest
gains from combining agent data in some splits weakly support the notion that
agent-gathered information introduces unique representational structures not
fully captured by static LLM knowledge. Third, we release a large-scale
multimodal dataset comprising more than 60,000 DHS clusters linked to satellite
images, LLM-generated descriptions, and agent-retrieved texts.

</details>


### [14] [H2C: Hippocampal Circuit-inspired Continual Learning for Lifelong Trajectory Prediction in Autonomous Driving](https://arxiv.org/abs/2508.01158)
*Yunlong Lin,Zirui Li,Guodong Du,Xiaocong Zhao,Cheng Gong,Xinwei Wang,Chao Lu,Jianwei Gong*

Main category: cs.AI

TL;DR: 受海马体启发，提出H2C持续学习方法解决轨迹预测中的灾难性遗忘问题，实验表明有效。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在轨迹预测中存在灾难性遗忘问题，难以适应动态变化的环境。受神经科学中海马体电路在记忆重放中的作用启发，提出H2C方法解决此问题。

Method: 提出了一种受海马体电路启发的持续学习方法H2C，该方法通过两种互补策略选择代表已学习知识的样本子集，并通过记忆重放损失函数更新模型。

Result: 实验结果表明，H2C在无任务的情况下，平均减少了深度学习基线模型22.71%的灾难性遗忘。

Conclusion: H2C方法通过选择性地回忆少量学习样本，减少了深度学习基线模型平均22.71%的灾难性遗忘，无需手动告知分布变化。

Abstract: Deep learning (DL) has shown state-of-the-art performance in trajectory
prediction, which is critical to safe navigation in autonomous driving (AD).
However, most DL-based methods suffer from catastrophic forgetting, where
adapting to a new distribution may cause significant performance degradation in
previously learned ones. Such inability to retain learned knowledge limits
their applicability in the real world, where AD systems need to operate across
varying scenarios with dynamic distributions. As revealed by neuroscience, the
hippocampal circuit plays a crucial role in memory replay, effectively
reconstructing learned knowledge based on limited resources. Inspired by this,
we propose a hippocampal circuit-inspired continual learning method (H2C) for
trajectory prediction across varying scenarios. H2C retains prior knowledge by
selectively recalling a small subset of learned samples. First, two
complementary strategies are developed to select the subset to represent
learned knowledge. Specifically, one strategy maximizes inter-sample diversity
to represent the distinctive knowledge, and the other estimates the overall
knowledge by equiprobable sampling. Then, H2C updates via a memory replay loss
function calculated by these selected samples to retain knowledge while
learning new data. Experiments based on various scenarios from the INTERACTION
dataset are designed to evaluate H2C. Experimental results show that H2C
reduces catastrophic forgetting of DL baselines by 22.71% on average in a
task-free manner, without relying on manually informed distributional shifts.
The implementation is available at https://github.com/BIT-Jack/H2C-lifelong.

</details>


### [15] [Benchmarking and Bridging Emotion Conflicts for Multimodal Emotion Reasoning](https://arxiv.org/abs/2508.01181)
*Zhiyuan Han,Beier Zhu,Yanlong Xu,Peipei Song,Xun Yang*

Main category: cs.AI

TL;DR: 针对多模态情感冲突问题，提出MoSEAR框架，有效缓解模态偏差，提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型(MLLMs)在处理情感冲突场景时，容易忽略不同模态之间的情感冲突，本文旨在解决这一问题。

Method: 提出了一种参数高效的框架MoSEAR，包含两个模块：模态特定专家MoSE和注意力重新分配机制AR，以促进平衡的模态整合，减轻模态偏差。

Result: 在多个基准测试(包括MER2023, EMER, DFEW和CA-MER)上，MoSEAR取得了最先进的性能，特别是在模态冲突条件下。

Conclusion: MoSEAR框架在多模态情感冲突场景下取得了最先进的性能，尤其是在模态冲突条件下。

Abstract: Despite their strong performance in multimodal emotion reasoning, existing
Multimodal Large Language Models (MLLMs) often overlook the scenarios involving
emotion conflicts, where emotional cues from different modalities are
inconsistent. To fill this gap, we first introduce CA-MER, a new benchmark
designed to examine MLLMs under realistic emotion conflicts. It consists of
three subsets: video-aligned, audio-aligned, and consistent, where only one or
all modalities reflect the true emotion. However, evaluations on our CA-MER
reveal that current state-of-the-art emotion MLLMs systematically over-rely on
audio signal during emotion conflicts, neglecting critical cues from visual
modality. To mitigate this bias, we propose MoSEAR, a parameter-efficient
framework that promotes balanced modality integration. MoSEAR consists of two
modules: (1)MoSE, modality-specific experts with a regularized gating mechanism
that reduces modality bias in the fine-tuning heads; and (2)AR, an attention
reallocation mechanism that rebalances modality contributions in frozen
backbones during inference. Our framework offers two key advantages: it
mitigates emotion conflicts and improves performance on consistent
samples-without incurring a trade-off between audio and visual modalities.
Experiments on multiple benchmarks-including MER2023, EMER, DFEW, and our
CA-MER-demonstrate that MoSEAR achieves state-of-the-art performance,
particularly under modality conflict conditions.

</details>
