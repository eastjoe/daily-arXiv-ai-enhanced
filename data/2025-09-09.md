<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Attention of a Kiss: Exploring Attention Maps in Video Diffusion for XAIxArts](https://arxiv.org/abs/2509.05323)
*Adam Cole,Mick Grierson*

Main category: cs.AI

TL;DR: 本文探讨了视频扩散Transformer的注意力机制，提出了一种提取和可视化生成视频模型中交叉注意力图的方法，并将其应用于艺术创作。


<details>
  <summary>Details</summary>
Motivation: 受早期视频艺术家创作灵感的启发，旨在探索注意力机制在文本生成视频中的作用，并将其作为分析工具和艺术素材。

Method: 基于开源Wan模型，开发了一个工具来提取和可视化交叉注意力图，并通过探索性探测和艺术案例研究进行分析。

Result: 研究了注意力图作为分析工具和艺术素材的潜力，为艺术领域的XAI做出了贡献。

Conclusion: 注意力机制可被艺术家用作创造性媒介。

Abstract: This paper presents an artistic and technical investigation into the
attention mechanisms of video diffusion transformers. Inspired by early video
artists who manipulated analog video signals to create new visual aesthetics,
this study proposes a method for extracting and visualizing cross-attention
maps in generative video models. Built on the open-source Wan model, our tool
provides an interpretable window into the temporal and spatial behavior of
attention in text-to-video generation. Through exploratory probes and an
artistic case study, we examine the potential of attention maps as both
analytical tools and raw artistic material. This work contributes to the
growing field of Explainable AI for the Arts (XAIxArts), inviting artists to
reclaim the inner workings of AI as a creative medium.

</details>


### [2] [Perception Graph for Cognitive Attack Reasoning in Augmented Reality](https://arxiv.org/abs/2509.05324)
*Rongqian Chen,Shu Hong,Rifatul Islam,Mahdi Imani,G. Gary Tan,Tian Lan*

Main category: cs.AI

TL;DR: 该论文提出了一种名为“感知图”的新模型，用于检测和分析增强现实系统中认知攻击对人类感知的影响。


<details>
  <summary>Details</summary>
Motivation: 增强现实系统容易受到操纵用户感知的认知攻击，该论文旨在解决这一挑战。

Method: 该模型模拟人类解释增强现实环境中关键信息的过程，并使用语义结构表示结果，最终计算一个量化分数来反映感知扭曲的程度。

Result: 该模型提供了一种鲁棒且可衡量的方法来检测和分析认知攻击的影响。

Conclusion: 感知图模型为增强现实系统中认知攻击的检测和分析提供了一种有效的方法。

Abstract: Augmented reality (AR) systems are increasingly deployed in tactical
environments, but their reliance on seamless human-computer interaction makes
them vulnerable to cognitive attacks that manipulate a user's perception and
severely compromise user decision-making. To address this challenge, we
introduce the Perception Graph, a novel model designed to reason about human
perception within these systems. Our model operates by first mimicking the
human process of interpreting key information from an MR environment and then
representing the outcomes using a semantically meaningful structure. We
demonstrate how the model can compute a quantitative score that reflects the
level of perception distortion, providing a robust and measurable method for
detecting and analyzing the effects of such cognitive attacks.

</details>


### [3] [SynDelay: A Synthetic Dataset for Delivery Delay Prediction](https://arxiv.org/abs/2509.05325)
*Liming Xu,Yunbo Long,Alexandra Brintrup*

Main category: cs.AI

TL;DR: 合成数据集SynDelay用于改进递送延误预测


<details>
  <summary>Details</summary>
Motivation: 现有数据集稀缺、质量不高，阻碍递送延误预测模型的开发和基准测试

Method: 使用高级生成模型，基于真实数据生成合成数据集SynDelay，保留真实递送模式，同时保护隐私

Result: 提供了一个具有挑战性和实用性的测试平台，并提供了基准结果和评估指标

Conclusion: SynDelay公开可用，鼓励社区贡献数据集、模型和评估实践，以促进该领域的研究

Abstract: Artificial intelligence (AI) is transforming supply chain management, yet
progress in predictive tasks -- such as delivery delay prediction -- remains
constrained by the scarcity of high-quality, openly available datasets.
Existing datasets are often proprietary, small, or inconsistently maintained,
hindering reproducibility and benchmarking. We present SynDelay, a synthetic
dataset designed for delivery delay prediction. Generated using an advanced
generative model trained on real-world data, SynDelay preserves realistic
delivery patterns while ensuring privacy. Although not entirely free of noise
or inconsistencies, it provides a challenging and practical testbed for
advancing predictive modelling. To support adoption, we provide baseline
results and evaluation metrics as initial benchmarks, serving as reference
points rather than state-of-the-art claims. SynDelay is publicly available
through the Supply Chain Data Hub, an open initiative promoting dataset sharing
and benchmarking in supply chain AI. We encourage the community to contribute
datasets, models, and evaluation practices to advance research in this area.
All code is openly accessible at https://supplychaindatahub.org.

</details>


### [4] [MVRS: The Multimodal Virtual Reality Stimuli-based Emotion Recognition Dataset](https://arxiv.org/abs/2509.05330)
*Seyed Muhammad Hossein Mousavi,Atiye Ilanloo*

Main category: cs.AI

TL;DR: MVRS数据集收集了13名参与者在VR环境下情绪刺激下的多模态数据，包括眼动追踪、肢体动作、肌电和皮肤电反应，并进行了特征提取、融合和分类评估，为多模态情感计算研究提供了宝贵资源。


<details>
  <summary>Details</summary>
Motivation: 缺乏包含肢体运动和生理信号的多模态情感数据集限制了自动情感识别技术的发展。

Method: 收集了13名参与者在VR环境下观看情绪刺激视频时的多模态数据（眼动、肢体运动、肌电、皮肤电），采用早期和晚期融合技术融合特征，并使用分类器进行评估。

Result: 构建了MVRS数据集，并验证了其数据质量和情绪可分离性。

Conclusion: MVRS数据集为多模态情感计算研究提供了宝贵资源，有助于推动该领域的发展。

Abstract: Automatic emotion recognition has become increasingly important with the rise
of AI, especially in fields like healthcare, education, and automotive systems.
However, there is a lack of multimodal datasets, particularly involving body
motion and physiological signals, which limits progress in the field. To
address this, the MVRS dataset is introduced, featuring synchronized recordings
from 13 participants aged 12 to 60 exposed to VR based emotional stimuli
(relaxation, fear, stress, sadness, joy). Data were collected using eye
tracking (via webcam in a VR headset), body motion (Kinect v2), and EMG and GSR
signals (Arduino UNO), all timestamp aligned. Participants followed a unified
protocol with consent and questionnaires. Features from each modality were
extracted, fused using early and late fusion techniques, and evaluated with
classifiers to confirm the datasets quality and emotion separability, making
MVRS a valuable contribution to multimodal affective computing.

</details>


### [5] [Benchmarking Large Language Models for Personalized Guidance in AI-Enhanced Learning](https://arxiv.org/abs/2509.05346)
*Bo Yuan,Jiazi Hu*

Main category: cs.AI

TL;DR: 本研究实证比较了三个先进的大型语言模型(LLM)在模拟真实学习环境的辅导任务中的表现，结果表明GPT-4o表现最佳，其反馈更具信息性和结构性。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对大型语言模型在真实学习场景中个性化学习辅助作用的系统性评估。

Method: 使用包含学生答案及其正确性标签的数据集，比较三个LLM在分析测试、推断学生掌握情况和生成针对性指导方面的表现，并使用Gemini进行成对比较。

Result: GPT-4o总体表现最佳，DeepSeek-V3和GLM-4.5表现不稳定。

Conclusion: 该研究验证了将LLM作为高级教学助理的可行性，并为未来研究提供了方法指导。

Abstract: While Large Language Models (LLMs) are increasingly envisioned as intelligent
assistants for personalized learning, systematic head-to-head evaluations
within authentic learning scenarios remain limited. This study conducts an
empirical comparison of three state-of-the-art LLMs on a tutoring task that
simulates a realistic learning setting. Using a dataset comprising a student's
answers to ten questions of mixed formats with correctness labels, each LLM is
required to (i) analyze the quiz to identify underlying knowledge components,
(ii) infer the student's mastery profile, and (iii) generate targeted guidance
for improvement. To mitigate subjectivity and evaluator bias, we employ Gemini
as a virtual judge to perform pairwise comparisons along various dimensions:
accuracy, clarity, actionability, and appropriateness. Results analyzed via the
Bradley-Terry model indicate that GPT-4o is generally preferred, producing
feedback that is more informative and better structured than its counterparts,
while DeepSeek-V3 and GLM-4.5 demonstrate intermittent strengths but lower
consistency. These findings highlight the feasibility of deploying LLMs as
advanced teaching assistants for individualized support and provide
methodological guidance for future empirical research on LLM-driven
personalized learning.

</details>


### [6] [SasAgent: Multi-Agent AI System for Small-Angle Scattering Data Analysis](https://arxiv.org/abs/2509.05363)
*Lijie Ding,Changwoo Do*

Main category: cs.AI

TL;DR: SasAgent是一个基于大型语言模型的AI系统，自动化小角散射(SAS)数据分析。


<details>
  <summary>Details</summary>
Motivation: 简化SAS研究工作流程，提高自动化水平。

Method: 使用大型语言模型协调三个专业代理（SLD计算、合成数据生成和实验数据拟合），并通过Gradio界面进行用户交互。

Result: SasAgent能够解释复杂的提示，计算SLD，生成准确的散射数据，并高精度拟合实验数据集。

Conclusion: LLM驱动的AI系统在简化科学工作流程方面具有巨大潜力。

Abstract: We introduce SasAgent, a multi-agent AI system powered by large language
models (LLMs) that automates small-angle scattering (SAS) data analysis by
leveraging tools from the SasView software and enables user interaction via
text input. SasAgent features a coordinator agent that interprets user prompts
and delegates tasks to three specialized agents for scattering length density
(SLD) calculation, synthetic data generation, and experimental data fitting.
These agents utilize LLM-friendly tools to execute tasks efficiently. These
tools, including the model data tool, Retrieval-Augmented Generation (RAG)
documentation tool, bump fitting tool, and SLD calculator tool, are derived
from the SasView Python library. A user-friendly Gradio-based interface
enhances user accessibility. Through diverse examples, we demonstrate
SasAgent's ability to interpret complex prompts, calculate SLDs, generate
accurate scattering data, and fit experimental datasets with high precision.
This work showcases the potential of LLM-driven AI systems to streamline
scientific workflows and enhance automation in SAS research.

</details>


### [7] [Characterizing Fitness Landscape Structures in Prompt Engineering](https://arxiv.org/abs/2509.05375)
*Arend Hintze*

Main category: cs.AI

TL;DR: 研究发现提示工程的优化目标函数具有复杂拓扑结构，不同提示生成策略导致不同结构。


<details>
  <summary>Details</summary>
Motivation: 当前提示工程优化方法缺乏对目标函数结构的理解。

Method: 使用自相关分析和语义嵌入空间研究不同提示生成策略下的目标函数拓扑结构。

Result: 系统提示生成策略产生平滑衰减的自相关，而多样化策略产生非单调模式，表明多样化策略下的目标函数更复杂。

Conclusion: 该研究为理解提示工程优化复杂性提供了经验基础。

Abstract: While prompt engineering has emerged as a crucial technique for optimizing
large language model performance, the underlying optimization landscape remains
poorly understood. Current approaches treat prompt optimization as a black-box
problem, applying sophisticated search algorithms without characterizing the
landscape topology they navigate. We present a systematic analysis of fitness
landscape structures in prompt engineering using autocorrelation analysis
across semantic embedding spaces. Through experiments on error detection tasks
with two distinct prompt generation strategies -- systematic enumeration (1,024
prompts) and novelty-driven diversification (1,000 prompts) -- we reveal
fundamentally different landscape topologies. Systematic prompt generation
yields smoothly decaying autocorrelation, while diversified generation exhibits
non-monotonic patterns with peak correlation at intermediate semantic
distances, indicating rugged, hierarchically structured landscapes.
Task-specific analysis across 10 error detection categories reveals varying
degrees of ruggedness across different error types. Our findings provide an
empirical foundation for understanding the complexity of optimization in prompt
engineering landscapes.

</details>


### [8] [Code Like Humans: A Multi-Agent Solution for Medical Coding](https://arxiv.org/abs/2509.05378)
*Andreas Motzfeldt,Joakim Edin,Casper L. Christensen,Christian Hardmeier,Lars Maaløe,Anna Rogers*

Main category: cs.AI

TL;DR: 大型语言模型赋能医学编码，实现ICD-10编码系统全覆盖，对罕见病症编码效果最佳。


<details>
  <summary>Details</summary>
Motivation: 改进医学编码中专家将非结构化临床笔记映射到诊断和手术的字母数字代码的流程。

Method: 提出Code Like Humans框架，一个基于大型语言模型的医学编码框架，遵循人类专家使用的官方编码指南，支持ICD-10编码系统（7万多个标签）。

Result: 在罕见诊断代码上取得了最佳性能（高频代码仍受益于微调的判别式分类器）。

Conclusion: 分析了系统性能，并确定了其不足（系统性漏码代码）。

Abstract: In medical coding, experts map unstructured clinical notes to alphanumeric
codes for diagnoses and procedures. We introduce Code Like Humans: a new
agentic framework for medical coding with large language models. It implements
official coding guidelines for human experts, and it is the first solution that
can support the full ICD-10 coding system (+70K labels). It achieves the best
performance to date on rare diagnosis codes (fine-tuned discriminative
classifiers retain an advantage for high-frequency codes, to which they are
limited). Towards future work, we also contribute an analysis of system
performance and identify its `blind spots' (codes that are systematically
undercoded).

</details>


### [9] [Murphys Laws of AI Alignment: Why the Gap Always Wins](https://arxiv.org/abs/2509.05381)
*Madhava Gaikwad*

Main category: cs.AI

TL;DR: 这篇论文介绍了人工智能对齐中反复出现的失败模式，并提出了“对齐差距”的概念来解释这些模式，最终提出了MAPS框架作为实际的设计手段。


<details>
  <summary>Details</summary>
Motivation: 现有的基于反馈的强化学习方法（如RLHF）在人工智能对齐中存在一些不足，例如奖励作弊、谄媚、标注者漂移和泛化不足。

Method: 使用KL-tilting形式化方法，对齐差距概念，以及Murphys Laws of AI Alignment和Alignment Trilemma框架。

Result: 提出MAPS框架（Misspecification, Annotation, Pressure, Shift）作为实际设计杠杆，以应对对齐问题。

Conclusion: 该论文并非提出不可能定理，而是从结构性限制和权衡的角度重新构建了对齐问题的讨论，为未来的设计提供了更清晰的指导。

Abstract: Large language models are increasingly aligned to human preferences through
reinforcement learning from human feedback (RLHF) and related methods such as
Direct Preference Optimization (DPO), Constitutional AI, and RLAIF. While
effective, these methods exhibit recurring failure patterns i.e., reward
hacking, sycophancy, annotator drift, and misgeneralization. We introduce the
concept of the Alignment Gap, a unifying lens for understanding recurring
failures in feedback-based alignment. Using a KL-tilting formalism, we
illustrate why optimization pressure tends to amplify divergence between proxy
rewards and true human intent. We organize these failures into a catalogue of
Murphys Laws of AI Alignment, and propose the Alignment Trilemma as a way to
frame trade-offs among optimization strength, value capture, and
generalization. Small-scale empirical studies serve as illustrative support.
Finally, we propose the MAPS framework (Misspecification, Annotation, Pressure,
Shift) as practical design levers. Our contribution is not a definitive
impossibility theorem but a perspective that reframes alignment debates around
structural limits and trade-offs, offering clearer guidance for future design.

</details>


### [10] [From Image Generation to Infrastructure Design: a Multi-agent Pipeline for Street Design Generation](https://arxiv.org/abs/2509.05469)
*Chenguang Wang,Xiang Yan,Yilong Dai,Ziyi Wang,Susu Xu*

Main category: cs.AI

TL;DR: 利用多智能体系统直接编辑真实世界街景图像中的自行车设施，实现快速生成不同设计方案，提高公众参与度。


<details>
  <summary>Details</summary>
Motivation: 现有方法耗时长、需大量数据，限制了主动交通规划中的公众参与和协作决策。

Method: 开发了一个多智能体系统，集成了车道定位、提示优化、设计生成和自动评估等模块，直接在真实街景图像上编辑和重新设计自行车设施。

Result: 实验表明该系统能适应不同的道路几何形状和环境条件，生成视觉上连贯且符合指令的结果。

Conclusion: 该研究为将多智能体技术应用于交通基础设施规划和设施设计奠定了基础。

Abstract: Realistic visual renderings of street-design scenarios are essential for
public engagement in active transportation planning. Traditional approaches are
labor-intensive, hindering collective deliberation and collaborative
decision-making. While AI-assisted generative design shows transformative
potential by enabling rapid creation of design scenarios, existing generative
approaches typically require large amounts of domain-specific training data and
struggle to enable precise spatial variations of design/configuration in
complex street-view scenes. We introduce a multi-agent system that edits and
redesigns bicycle facilities directly on real-world street-view imagery. The
framework integrates lane localization, prompt optimization, design generation,
and automated evaluation to synthesize realistic, contextually appropriate
designs. Experiments across diverse urban scenarios demonstrate that the system
can adapt to varying road geometries and environmental conditions, consistently
yielding visually coherent and instruction-compliant results. This work
establishes a foundation for applying multi-agent pipelines to transportation
infrastructure planning and facility design.

</details>


### [11] [TreeGPT: A Novel Hybrid Architecture for Abstract Syntax Tree Processing with Global Parent-Child Aggregation](https://arxiv.org/abs/2509.05550)
*Zixi Li*

Main category: cs.AI

TL;DR: TreeGPT:一种结合Transformer和全局父子聚合机制的AST处理神经架构，在ARC Prize 2025数据集上取得96%的准确率，显著优于其他基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于顺序处理或图神经网络，TreeGPT结合了自注意力机制和树状前馈网络，以更好地处理AST。

Method: 提出了一种新的全局父子聚合机制，通过迭代信息传递建模分层树结构，并包含可选增强，如门控聚合、残差连接和双向传播。

Result: 在ARC Prize 2025数据集上达到96%的准确率，显著超过Transformer基线、Grok-4和SOAR等模型。消融实验表明边投影是最关键的组件。

Conclusion: TreeGPT是一种高效且有效的AST处理方法，其全局父子聚合机制和可选增强显著提升了性能。

Abstract: We introduce TreeGPT, a novel neural architecture that combines
transformer-based attention mechanisms with global parent-child aggregation for
processing Abstract Syntax Trees (ASTs) in neural program synthesis tasks.
Unlike traditional approaches that rely solely on sequential processing or
graph neural networks, TreeGPT employs a hybrid design that leverages both
self-attention for capturing local dependencies and a specialized Tree
Feed-Forward Network (TreeFFN) for modeling hierarchical tree structures
through iterative message passing.
  The core innovation lies in our Global Parent-Child Aggregation mechanism,
formalized as: $$h_i^{(t+1)} = \sigma \Big( h_i^{(0)} + W_{pc} \sum_{(p,c) \in
E_i} f(h_p^{(t)}, h_c^{(t)}) + b \Big)$$ where $h_i^{(t)}$ represents the
hidden state of node $i$ at iteration $t$, $E_i$ denotes all parent-child edges
involving node $i$, and $f(h_p, h_c)$ is an edge aggregation function. This
formulation enables each node to progressively aggregate information from the
entire tree structure through $T$ iterations.
  Our architecture integrates optional enhancements including gated aggregation
with learnable edge weights, residual connections for gradient stability, and
bidirectional propagation for capturing both bottom-up and top-down
dependencies. We evaluate TreeGPT on the ARC Prize 2025 dataset, a challenging
visual reasoning benchmark requiring abstract pattern recognition and rule
inference. Experimental results demonstrate that TreeGPT achieves 96\%
accuracy, significantly outperforming transformer baselines (1.3\%),
large-scale models like Grok-4 (15.9\%), and specialized program synthesis
methods like SOAR (52\%) while using only 1.5M parameters. Our comprehensive
ablation study reveals that edge projection is the most critical component,
with the combination of edge projection and gating achieving optimal
performance.

</details>


### [12] [OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision](https://arxiv.org/abs/2509.05578)
*Ruixun Liu,Lingyu Kong,Derun Li,Hang Zhao*

Main category: cs.AI

TL;DR: OccVLA框架将3D占用表示集成到多模态推理过程中，无需额外计算开销即可实现最先进的自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs缺乏鲁棒的3D空间理解能力，主要挑战在于构建有效的3D表示和缺乏大规模3D视觉语言预训练。

Method: 提出OccVLA框架，利用2D视觉输入学习细粒度的空间结构，将3D占用率作为预测输出和监督信号。

Result: 在nuScenes基准测试中取得了最先进的轨迹规划结果，并在3D视觉问答任务中表现出优越的性能。

Conclusion: OccVLA提供了一种可扩展、可解释且完全基于视觉的自动驾驶解决方案。

Abstract: Multimodal large language models (MLLMs) have shown strong vision-language
reasoning abilities but still lack robust 3D spatial understanding, which is
critical for autonomous driving. This limitation stems from two key challenges:
(1) the difficulty of constructing accessible yet effective 3D representations
without expensive manual annotations, and (2) the loss of fine-grained spatial
details in VLMs due to the absence of large-scale 3D vision-language
pretraining. To address these challenges, we propose OccVLA, a novel framework
that integrates 3D occupancy representations into a unified multimodal
reasoning process. Unlike prior approaches that rely on explicit 3D inputs,
OccVLA treats dense 3D occupancy as both a predictive output and a supervisory
signal, enabling the model to learn fine-grained spatial structures directly
from 2D visual inputs. The occupancy predictions are regarded as implicit
reasoning processes and can be skipped during inference without performance
degradation, thereby adding no extra computational overhead. OccVLA achieves
state-of-the-art results on the nuScenes benchmark for trajectory planning and
demonstrates superior performance on 3D visual question-answering tasks,
offering a scalable, interpretable, and fully vision-based solution for
autonomous driving.

</details>


### [13] [MSRFormer: Road Network Representation Learning using Multi-scale Feature Fusion of Heterogeneous Spatial Interactions](https://arxiv.org/abs/2509.05685)
*Jian Yang,Jiahui Wu,Li Fang,Hongchao Fan,Bianying Zhang,Huijie Zhao,Guangyi Yang,Rui Xin,Xiong You*

Main category: cs.AI

TL;DR: 该论文提出了一种新的道路网络表示学习框架MSRFormer，通过整合多尺度空间交互来解决城市道路网络的异构性和层次性问题，在两个实际数据集上取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效表示城市道路网络的异构性和层次性。

Method: 提出MSRFormer框架，集成多尺度空间交互，使用空间流卷积提取小尺度特征，识别尺度相关的空间交互区域，并利用图Transformer捕获复杂空间依赖性，最终使用对比学习算法得到道路网络表示。

Result: 在两个实际数据集上的两个道路网络分析任务中，MSRFormer的性能优于基线方法，尤其在复杂道路网络结构上提升显著（最高达16%）。

Conclusion: MSRFormer提供了一个有效的任务无关道路网络表示学习框架，并揭示了尺度效应和空间交互流异质性之间相互作用的独特关联模式。

Abstract: Transforming road network data into vector representations using deep
learning has proven effective for road network analysis. However, urban road
networks' heterogeneous and hierarchical nature poses challenges for accurate
representation learning. Graph neural networks, which aggregate features from
neighboring nodes, often struggle due to their homogeneity assumption and focus
on a single structural scale. To address these issues, this paper presents
MSRFormer, a novel road network representation learning framework that
integrates multi-scale spatial interactions by addressing their flow
heterogeneity and long-distance dependencies. It uses spatial flow convolution
to extract small-scale features from large trajectory datasets, and identifies
scale-dependent spatial interaction regions to capture the spatial structure of
road networks and flow heterogeneity. By employing a graph transformer,
MSRFormer effectively captures complex spatial dependencies across multiple
scales. The spatial interaction features are fused using residual connections,
which are fed to a contrastive learning algorithm to derive the final road
network representation. Validation on two real-world datasets demonstrates that
MSRFormer outperforms baseline methods in two road network analysis tasks. The
performance gains of MSRFormer suggest the traffic-related task benefits more
from incorporating trajectory data, also resulting in greater improvements in
complex road network structures with up to 16% improvements compared to the
most competitive baseline method. This research provides a practical framework
for developing task-agnostic road network representation models and highlights
distinct association patterns of the interplay between scale effects and flow
heterogeneity of spatial interactions.

</details>


### [14] [Towards Meta-Cognitive Knowledge Editing for Multimodal LLMs](https://arxiv.org/abs/2509.05714)
*Zhaoyu Fan,Kaihang Pan,Mingze Zhou,Bosheng Qin,Juncheng Li,Shengyu Zhang,Wenqiao Zhang,Siliang Tang,Fei Wu,Yueting Zhuang*

Main category: cs.AI

TL;DR: CogEdit基准测试评估MLLMs的元认知知识编辑能力，并提出MIND框架以改进元认知编辑。


<details>
  <summary>Details</summary>
Motivation: 现有基准侧重认知层面的修改，忽略了元认知过程。

Method: CogEdit基准测试涵盖反事实驱动编辑、边界约束编辑和噪声鲁棒编辑三个层面；MIND框架构建元知识记忆、利用博弈论交互和标签细化。

Result: MIND显著优于现有认知编辑方法，在传统和元认知知识编辑基准测试中均表现出色。

Conclusion: CogEdit和MIND框架为元认知知识编辑研究提供了新的方向和方法。

Abstract: Knowledge editing enables multimodal large language models (MLLMs) to
efficiently update outdated or incorrect information. However, existing
benchmarks primarily emphasize cognitive-level modifications while lacking a
focus on deeper meta-cognitive processes. To bridge this gap, we introduce
CogEdit, a novel benchmark designed to evaluate MLLMs' meta-cognitive knowledge
editing abilities across three levels: (1) Counterfactual-Driven Editing,
assessing self-awareness of knowledge correctness changes; (2) Boundary
Constraint Editing, ensuring appropriate generalization without unintended
interference; and (3) Noise-Robust Editing, promoting reflective evaluation of
uncertain information. To advance meta-cognitive editing, we propose MIND
(Meta-cognitive INtegrated Dynamic Knowledge Editing), a framework that
constructs a meta-knowledge memory for self-awareness, employs game-theoretic
interactions to monitor knowledge activation, and incorporates label refinement
for noise-robust updates. Extensive experiments show that MIND significantly
outperforms existing cognitive editing approaches, achieving strong performance
on both traditional and meta-cognitive knowledge editing benchmarks.

</details>


### [15] [Hyperbolic Large Language Models](https://arxiv.org/abs/2509.05757)
*Sarang Patil,Zeyong Zhang,Yiran Huang,Tengfei Ma,Mengjia Xu*

Main category: cs.AI

TL;DR: 本文综述了利用双曲几何增强语义表示学习和多尺度推理的大型语言模型 (HypLLMs) 的最新进展，并将其技术归纳为四类：基于指数/对数映射的HypLLMs、双曲微调模型、全双曲LLMs和双曲状态空间模型。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型难以有效学习非欧几里得数据中的语义蕴涵和层次关系，而双曲几何擅长建模树状层次结构，因此本文研究将双曲几何应用于LLMs。

Method: 对现有利用双曲几何的LLMs方法进行分类和综述，并探讨潜在应用和未来研究方向。

Result: 提出了HypLLMs的四类主要技术，并提供了一个包含关键论文、模型、数据集和代码实现的资源库。

Conclusion: 双曲几何为增强LLMs的语义表示学习和多尺度推理提供了有效途径，未来研究方向包括模型效率、可解释性和更广泛的应用。

Abstract: Large language models (LLMs) have achieved remarkable success and
demonstrated superior performance across various tasks, including natural
language processing (NLP), weather forecasting, biological protein folding,
text generation, and solving mathematical problems. However, many real-world
data exhibit highly non-Euclidean latent hierarchical anatomy, such as protein
networks, transportation networks, financial networks, brain networks, and
linguistic structures or syntactic trees in natural languages. Effectively
learning intrinsic semantic entailment and hierarchical relationships from
these raw, unstructured input data using LLMs remains an underexplored area.
Due to its effectiveness in modeling tree-like hierarchical structures,
hyperbolic geometry -- a non-Euclidean space -- has rapidly gained popularity
as an expressive latent representation space for complex data modeling across
domains such as graphs, images, languages, and multi-modal data. Here, we
provide a comprehensive and contextual exposition of recent advancements in
LLMs that leverage hyperbolic geometry as a representation space to enhance
semantic representation learning and multi-scale reasoning. Specifically, the
paper presents a taxonomy of the principal techniques of Hyperbolic LLMs
(HypLLMs) in terms of four main categories: (1) hyperbolic LLMs through exp/log
maps; (2) hyperbolic fine-tuned models; (3) fully hyperbolic LLMs, and (4)
hyperbolic state-space models. We also explore crucial potential applications
and outline future research directions. A repository of key papers, models,
datasets, and code implementations is available at
https://github.com/sarangp2402/Hyperbolic-LLM-Models/tree/main.

</details>


### [16] [DRF: LLM-AGENT Dynamic Reputation Filtering Framework](https://arxiv.org/abs/2509.05764)
*Yuwei Lou,Hao Hu,Shaocong Ma,Zongfei Zhang,Liang Wang,Jidong Ge,Xianping Tao*

Main category: cs.AI

TL;DR: DRF框架提高了多智能体系统中复杂任务的完成质量和协作效率


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统难以量化智能体性能和评估其可信度

Method: 构建交互式评分网络，设计信誉评分机制，集成基于UCB的策略

Result: 实验表明DRF显著提高了逻辑推理和代码生成任务的完成质量和协作效率

Conclusion: DRF为多智能体系统处理大规模任务提供了新方法

Abstract: With the evolution of generative AI, multi - agent systems leveraging large -
language models(LLMs) have emerged as a powerful tool for complex tasks.
However, these systems face challenges in quantifying agent performance and
lack mechanisms to assess agent credibility. To address these issues, we
introduce DRF, a dynamic reputation filtering framework. DRF constructs an
interactive rating network to quantify agent performance, designs a reputation
scoring mechanism to measure agent honesty and capability, and integrates an
Upper Confidence Bound - based strategy to enhance agent selection efficiency.
Experiments show that DRF significantly improves task completion quality and
collaboration efficiency in logical reasoning and code - generation tasks,
offering a new approach for multi - agent systems to handle large - scale
tasks.

</details>
