<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone](https://arxiv.org/abs/2508.14923)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 一种基于图谱处理的全新神经符号推理架构，提升了推理的效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型通常将谱图方法作为辅助组件，而该论文旨在构建一个完全在图谱域中进行推理的系统。

Method: 该架构将逻辑实体和关系编码为图信号，通过可学习的谱滤波器处理，并将结果映射到符号谓词进行基于规则的推理。使用了图傅里叶变换、频带选择注意和谱规则接地等技术。

Result: 在ProofWriter、EntailmentBank、bAbI、CLUTRR和ARC-Challenge等基准数据集上，该模型在逻辑一致性、可解释性和计算效率方面均优于现有神经符号模型。

Conclusion: 该论文提出了一种完全基于谱的、神经符号推理架构，利用图信号处理（GSP）作为主要计算框架，集成符号逻辑和神经推理，并在基准推理数据集上取得了比现有神经符号模型更好的逻辑一致性、可解释性和计算效率。

Abstract: We propose a fully spectral, neuro\-symbolic reasoning architecture that
leverages Graph Signal Processing (GSP) as the primary computational backbone
for integrating symbolic logic and neural inference. Unlike conventional
reasoning models that treat spectral graph methods as peripheral components,
our approach formulates the entire reasoning pipeline in the graph spectral
domain. Logical entities and relationships are encoded as graph signals,
processed via learnable spectral filters that control multi-scale information
propagation, and mapped into symbolic predicates for rule-based inference. We
present a complete mathematical framework for spectral reasoning, including
graph Fourier transforms, band-selective attention, and spectral rule
grounding. Experiments on benchmark reasoning datasets (ProofWriter,
EntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in
logical consistency, interpretability, and computational efficiency over
state\-of\-the\-art neuro\-symbolic models. Our results suggest that GSP
provides a mathematically grounded and computationally efficient substrate for
robust and interpretable reasoning systems.

</details>


### [2] [Goals and the Structure of Experience](https://arxiv.org/abs/2508.15013)
*Nadav Amir,Stas Tiomkin,Angela Langdon*

Main category: cs.AI

TL;DR: 该论文提出了一种新的计算框架，认为世界模型的描述性和规定性方面可以从主体的目标中共同涌现，并用目标等价经验分布的类别来解释目标导向学习。


<details>
  <summary>Details</summary>
Motivation: 目前的计算模型通常将世界模型的描述性和规定性方面（例如强化学习中的状态表示和奖励函数）视为不同的组成部分。该论文提出了一种替代方案，认为这两个方面可以从主体的目标中共同涌现。

Method: 该框架基于佛教认识论，引入目标导向或目的论状态的概念，定义为目标等价经验分布的类别。

Result: 该框架用行为策略和理想经验特征之间的统计差异来解释目标导向学习，为理解目的性行为的各种维度提供了一个统一的视角。

Conclusion: 该论文描述了一个认知主体中目标导向状态表征的计算框架，其中世界模型的描述性和规定性方面从主体与环境的交互序列或经验中共同涌现。

Abstract: Purposeful behavior is a hallmark of natural and artificial intelligence. Its
acquisition is often believed to rely on world models, comprising both
descriptive (what is) and prescriptive (what is desirable) aspects that
identify and evaluate state of affairs in the world, respectively. Canonical
computational accounts of purposeful behavior, such as reinforcement learning,
posit distinct components of a world model comprising a state representation
(descriptive aspect) and a reward function (prescriptive aspect). However, an
alternative possibility, which has not yet been computationally formulated, is
that these two aspects instead co-emerge interdependently from an agent's goal.
Here, we describe a computational framework of goal-directed state
representation in cognitive agents, in which the descriptive and prescriptive
aspects of a world model co-emerge from agent-environment interaction
sequences, or experiences. Drawing on Buddhist epistemology, we introduce a
construct of goal-directed, or telic, states, defined as classes of
goal-equivalent experience distributions. Telic states provide a parsimonious
account of goal-directed learning in terms of the statistical divergence
between behavioral policies and desirable experience features. We review
empirical and theoretical literature supporting this novel perspective and
discuss its potential to provide a unified account of behavioral,
phenomenological and neural dimensions of purposeful behaviors across diverse
substrates.

</details>


### [3] [Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism](https://arxiv.org/abs/2508.15030)
*Ashmi Banerjee,Fitri Nur Aisyah,Adithi Satish,Wolfgang Wörndl,Yashar Deldjoo*

Main category: cs.AI

TL;DR: 多智能体协作框架Collab-REC提升旅游推荐多样性，解决热门城市过度旅游问题。


<details>
  <summary>Details</summary>
Motivation: 为了对抗流行度偏差，增强旅游推荐的多样性。

Method: 提出一个多智能体框架Collab-REC，由三个基于LLM的智能体（个性化、流行度和可持续性）生成城市建议，并通过非LLM协调者进行多轮协商合并和优化。

Result: 实验结果表明，Collab-REC在多样性和整体相关性方面优于单智能体基线，能够推荐更少被访问的景点。

Conclusion: Collab-REC框架有效提升了旅游推荐的多样性和相关性，解决了热门城市过度旅游的问题，并更好地满足用户需求。

Abstract: We propose Collab-REC, a multi-agent framework designed to counteract
popularity bias and enhance diversity in tourism recommendations. In our
setting, three LLM-based agents -- Personalization, Popularity, and
Sustainability generate city suggestions from complementary perspectives. A
non-LLM moderator then merges and refines these proposals via multi-round
negotiation, ensuring each agent's viewpoint is incorporated while penalizing
spurious or repeated responses. Experiments on European city queries show that
Collab-REC improves diversity and overall relevance compared to a single-agent
baseline, surfacing lesser-visited locales that often remain overlooked. This
balanced, context-aware approach addresses over-tourism and better aligns with
constraints provided by the user, highlighting the promise of multi-stakeholder
collaboration in LLM-driven recommender systems.

</details>


### [4] [Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions](https://arxiv.org/abs/2508.15047)
*Yibo Liu,Liam Shatzel,Brandon Haworth,Teseo Schneider*

Main category: cs.AI

TL;DR: 利用大型语言模型实现更真实的人群模拟，通过对话系统和语言驱动的导航，使代理的运动决策基于感知输入和对话，从而产生自然涌现的群体行为。


<details>
  <summary>Details</summary>
Motivation: 现有的基于代理的人群模拟方法大多忽略了语言和对话对人类导航和运动的影响，导致动画中代理与代理、代理与环境之间的交互仅限于转向和固定的高级目标推断。该论文旨在通过引入LLM来改进人群模拟的真实性。

Method: 该方法包含两个主要部分：对话系统和语言驱动的导航。通过周期性地查询以角色个性、角色、愿望和关系为条件的以代理为中心的LLM来控制代理间对话的生成，并利用对话和每个代理的个性、情绪状态、视野和物理状态来控制每个代理的导航和转向。

Result: 在两个复杂的场景中验证了该方法，结果表明该方法能够自动产生代理的组合和分解，并作为人群内部的信息传递机制，产生更逼真的群体行为。

Conclusion: 该论文提出了一种利用大型语言模型（LLM）控制人群模拟中个体代理运动的新方法，该方法通过对话系统和语言驱动的导航，使代理能够根据感知输入和持续对话做出运动决策，从而产生更逼真的人群模拟，并自然地出现群体行为。

Abstract: Animating and simulating crowds using an agent-based approach is a
well-established area where every agent in the crowd is individually controlled
such that global human-like behaviour emerges. We observe that human navigation
and movement in crowds are often influenced by complex social and environmental
interactions, driven mainly by language and dialogue. However, most existing
work does not consider these dimensions and leads to animations where
agent-agent and agent-environment interactions are largely limited to steering
and fixed higher-level goal extrapolation.
  We propose a novel method that exploits large language models (LLMs) to
control agents' movement. Our method has two main components: a dialogue system
and language-driven navigation. We periodically query agent-centric LLMs
conditioned on character personalities, roles, desires, and relationships to
control the generation of inter-agent dialogue when necessitated by the spatial
and social relationships with neighbouring agents. We then use the conversation
and each agent's personality, emotional state, vision, and physical state to
control the navigation and steering of each agent. Our model thus enables
agents to make motion decisions based on both their perceptual inputs and the
ongoing dialogue.
  We validate our method in two complex scenarios that exemplify the interplay
between social interactions, steering, and crowding. In these scenarios, we
observe that grouping and ungrouping of agents automatically occur.
Additionally, our experiments show that our method serves as an
information-passing mechanism within the crowd. As a result, our framework
produces more realistic crowd simulations, with emergent group behaviours
arising naturally from any environmental setting.

</details>


### [5] [Don't Think Twice! Over-Reasoning Impairs Confidence Calibration](https://arxiv.org/abs/2508.15050)
*Romain Lacombe,Kerrie Wu,Eddie Dilworth*

Main category: cs.AI

TL;DR: 推理预算增加反而降低大型语言模型的置信度校准精度；搜索增强型生成方法效果更好，信息获取是关键。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为问答工具需要强大的校准以避免过度自信。

Method: 系统评估推理能力和预算如何影响置信度评估的准确性，使用ClimateX数据集，并扩展到人类和地球健康领域。

Result: 增加推理预算会降低校准精度，搜索增强型生成方法的准确性达到89.3%。信息获取比推理深度或推理预算更重要。

Conclusion: 大型语言模型作为问答工具需要强大的校准以避免过度自信。研究发现，增加推理预算会降低校准精度，而搜索增强型生成方法显著优于纯推理方法，信息获取可能是提高知识密集型任务置信度校准的关键瓶颈。

Abstract: Large Language Models deployed as question answering tools require robust
calibration to avoid overconfidence. We systematically evaluate how reasoning
capabilities and budget affect confidence assessment accuracy, using the
ClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary
health. Our key finding challenges the "test-time scaling" paradigm: while
recent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,
increasing reasoning budgets consistently impairs rather than improves
calibration. Extended reasoning leads to systematic overconfidence that worsens
with longer thinking budgets, producing diminishing and negative returns beyond
modest computational investments. Conversely, search-augmented generation
dramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving
relevant evidence. Our results suggest that information access, rather than
reasoning depth or inference budget, may be the critical bottleneck for
improved confidence calibration of knowledge-intensive tasks.

</details>


### [6] [Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning](https://arxiv.org/abs/2508.15053)
*Itai Zilberstein,Alberto Candela,Steve Chien,David Rijlaarsdam,Tom Hendrix,Leonie Buckley,Aubrey Dunne*

Main category: cs.AI

TL;DR: 在CogniSAT-6/HAMMER卫星上进行机载数据分析的演示，利用深度学习和光谱分析算法，实现新的地球科学测量和响应。


<details>
  <summary>Details</summary>
Motivation: 为了实现新的地球科学测量和响应，需要在卫星机载进行数据分析。

Method: 利用深度学习和光谱分析算法，在卫星机载进行数据分析和推理。

Result: 演示了在CogniSAT-6/HAMMER卫星上进行多种应用的数据分析和推理。

Conclusion: 本文介绍了在CogniSAT-6/HAMMER卫星上进行数据分析的演示，该卫星搭载了高光谱仪器和神经网络加速硬件。

Abstract: In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is
demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).
CS-6 is a satellite with a visible and near infrared range hyperspectral
instrument and neural network acceleration hardware. Performing data analysis
at the edge (e.g. onboard) can enable new Earth science measurements and
responses. We will demonstrate data analysis and inference onboard CS-6 for
numerous applications using deep learning and spectral analysis algorithms.

</details>


### [7] [S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner](https://arxiv.org/abs/2508.15068)
*Shuang Ao,Gopal Rumchurn*

Main category: cs.AI

TL;DR: S3LoRA 是一种轻量级安全框架，用于安全部署基于LLM的代理，无需访问基础模型，即可提高安全性并降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有的安全感知自适应方法通常需要访问基础模型和指令微调模型检查点，而这些检查点在实践中往往不可用，限制了它们的适用性。

Method: 提出了一种轻量级、无数据、与模型无关的框架S3LoRA，该框架通过仅检查微调的权重更新来减轻LoRA调整模型中的安全风险。首先介绍了Magnitude-Aware Spherically Normalized SVD (MAS-SVD)，然后设计了Spectral Sharpness Index (SSI)来检测具有高度集中且可能不安全更新的层。

Result: 大量的实验和消融研究表明，S3LoRA在代理规划和语言生成任务中始终提高安全指标，同时保持或提高效用指标，并显著降低推理成本。

Conclusion: S3LoRA框架通过检查微调权重更新来减轻LoRA调整模型中的安全风险，在保持或提高效用指标的同时，持续提高安全指标并显著降低推理成本。

Abstract: Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning
(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based
agents. However, these adaptations can unintentionally compromise safety
alignment, leading to unsafe or unstable behaviors, particularly in agent
planning tasks. Existing safety-aware adaptation methods often require access
to both base and instruction-tuned model checkpoints, which are frequently
unavailable in practice, limiting their applicability. We propose S3LoRA (Safe
Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and
model-independent framework that mitigates safety risks in LoRA-adapted models
by inspecting only the fine-tuned weight updates. We first introduce
Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes
the structural properties of LoRA updates while preserving global magnitude
information. We then design the Spectral Sharpness Index (SSI), a
sharpness-aware metric to detect layers with highly concentrated and
potentially unsafe updates. These layers are pruned post-hoc to reduce risk
without sacrificing task performance. Extensive experiments and ablation
studies across agent planning and language generation tasks show that S3LoRA
consistently improves safety metrics while maintaining or improving utility
metrics and significantly reducing inference cost. These results establish
S3LoRA as a practical and scalable solution for safely deploying LLM-based
agents in real-world, resource-constrained, and safety-critical environments.

</details>


### [8] [Argumentation for Explainable Workforce Optimisation (with Appendix)](https://arxiv.org/abs/2508.15118)
*Jennifer Leigh,Dimitrios Letsios,Alessandro Mella,Lucio Machetti,Francesca Toni*

Main category: cs.AI

TL;DR: 利用抽象论证方法改进劳动力管理，实现更快、更准确的问题解决。


<details>
  <summary>Details</summary>
Motivation: 解决劳动力管理中适应运行时变化和为利益相关者提供解释的挑战。

Method: 将劳动力管理问题建模为抽象论证问题，并开发相应的工具。

Result: 用户研究表明，该工具和解释比传统的手动解决方案能够更快、更准确地解决问题。

Conclusion: 通过将劳动力管理理解为工业应用中的抽象论证，可以适应变化并获得可靠的解释，用户研究表明，该工具和解释比传统的手动解决方案能够更快、更准确地解决问题。

Abstract: Workforce management is a complex problem optimising the makespan and travel
distance required for a team of operators to complete a set of jobs, using a
set of instruments. A crucial challenge in workforce management is
accommodating changes at execution time so that explanations are provided to
all stakeholders involved. Here, we show that, by understanding workforce
management as abstract argumentation in an industrial application, we can
accommodate change and obtain faithful explanations. We show, with a user
study, that our tool and explanations lead to faster and more accurate problem
solving than conventional solutions by hand.

</details>


### [9] [Open-Universe Assistance Games](https://arxiv.org/abs/2508.15119)
*Rachel Ma,Jingyi Qu,Andreea Bobu,Dylan Hadfield-Menell*

Main category: cs.AI

TL;DR: GOOD方法利用LLM高效地从开放式对话中提取人类目标，并在模拟环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了使具身AI代理能够以可解释的方式推断和行动，针对多种未预定义的人类目标和偏好，本文引入了开放宇宙辅助博弈（OU-AGs）框架。

Method: 提出了一种名为GOOD的数据高效在线方法，该方法利用LLM模拟不同复杂意图的用户，通过其回复对候选目标进行概率推理，从而提取自然语言形式的目标，并推断自然语言目标的分布。

Result: GOOD方法在文本购物和AI2Thor模拟环境中优于无显式目标追踪的基线方法，由LLM和人工评估证实。

Conclusion: GOOD方法在文本购物和AI2Thor模拟环境中优于无显式目标追踪的基线方法，由LLM和人工评估证实。

Abstract: Embodied AI agents must infer and act in an interpretable way on diverse
human goals and preferences that are not predefined. To formalize this setting,
we introduce Open-Universe Assistance Games (OU-AGs), a framework where the
agent must reason over an unbounded and evolving space of possible goals. In
this context, we introduce GOOD (GOals from Open-ended Dialogue), a
data-efficient, online method that extracts goals in the form of natural
language during an interaction with a human, and infers a distribution over
natural language goals. GOOD prompts an LLM to simulate users with different
complex intents, using its responses to perform probabilistic inference over
candidate goals. This approach enables rich goal representations and
uncertainty estimation without requiring large offline datasets. We evaluate
GOOD in a text-based grocery shopping domain and in a text-operated simulated
household robotics environment (AI2Thor), using synthetic user profiles. Our
method outperforms a baseline without explicit goal tracking, as confirmed by
both LLM-based and human evaluations.

</details>


### [10] [aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](https://arxiv.org/abs/2508.15126)
*Pengsong Zhang,Xiang Hu,Guowei Huang,Yang Qi,Heng Zhang,Xiuxu Li,Jiaxing Song,Jiabin Luo,Yijiang Li,Shuo Yin,Chengxiao Dai,Eric Hanchen Jiang,Xiaoyan Zhou,Zhenfei Yin,Boqin Yuan,Jing Dong,Guinan Su,Guanren Qiao,Haiming Tang,Anghong Du,Lili Pan,Zhenzhong Lan,Xinyu Liu*

Main category: cs.AI

TL;DR: aiXiv平台是一个用于人类和AI科学家合作的开放获取平台，它解决了AI生成研究内容发表和传播的难题，并显著提高了AI生成研究的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的出版生态系统难以应对AI生成的海量研究内容，传统的期刊和会议依赖人工同行评审，难以扩展，且常常不愿接受AI生成的研究内容；现有的预印本服务器缺乏严格的质量控制机制。

Method: 构建了一个名为aiXiv的开放获取平台，该平台采用多智能体架构，允许人类和AI科学家提交、评审和迭代改进研究提案和论文，并提供API和MCP接口以实现异构人类和AI科学家的无缝集成。

Result: aiXiv平台可靠且健壮，能够显著提高AI生成研究提案和论文的质量。

Conclusion: aiXiv平台能够显著提高AI生成研究提案和论文的质量，为AI科学家构建了下一代开放获取生态系统，加速高质量AI生成研究内容的发表和传播。

Abstract: Recent advances in large language models (LLMs) have enabled AI agents to
autonomously generate scientific proposals, conduct experiments, author papers,
and perform peer reviews. Yet this flood of AI-generated research content
collides with a fragmented and largely closed publication ecosystem.
Traditional journals and conferences rely on human peer review, making them
difficult to scale and often reluctant to accept AI-generated research content;
existing preprint servers (e.g. arXiv) lack rigorous quality-control
mechanisms. Consequently, a significant amount of high-quality AI-generated
research lacks appropriate venues for dissemination, hindering its potential to
advance scientific progress. To address these challenges, we introduce aiXiv, a
next-generation open-access platform for human and AI scientists. Its
multi-agent architecture allows research proposals and papers to be submitted,
reviewed, and iteratively refined by both human and AI scientists. It also
provides API and MCP interfaces that enable seamless integration of
heterogeneous human and AI scientists, creating a scalable and extensible
ecosystem for autonomous scientific discovery. Through extensive experiments,
we demonstrate that aiXiv is a reliable and robust platform that significantly
enhances the quality of AI-generated research proposals and papers after
iterative revising and reviewing on aiXiv. Our work lays the groundwork for a
next-generation open-access ecosystem for AI scientists, accelerating the
publication and dissemination of high-quality AI-generated research content.
Code is available at https://github.com/aixiv-org. Website is available at
https://forms.gle/DxQgCtXFsJ4paMtn8.

</details>


### [11] [Mobile-Agent-v3: Foundamental Agents for GUI Automation](https://arxiv.org/abs/2508.15144)
*Jiabo Ye,Xi Zhang,Haiyang Xu,Haowei Liu,Junyang Wang,Zhaoqing Zhu,Ziwei Zheng,Feiyu Gao,Junjie Cao,Zhengxi Lu,Jitong Liao,Qi Zheng,Fei Huang,Jingren Zhou,Ming Yan*

Main category: cs.AI

TL;DR: 这篇论文介绍了两个新的GUI智能体模型GUI-Owl和Mobile-Agent-v3，它们在多个基准测试中取得了最先进的性能，并已开源。


<details>
  <summary>Details</summary>
Motivation: 现有开源端到端GUI智能体模型性能不足。

Method: 提出了一种新的GUI智能体模型GUI-Owl，并基于此构建了通用GUI智能体框架Mobile-Agent-v3。GUI-Owl包含大规模环境基础设施、多样化的基础智能体能力和可扩展的环境强化学习三个关键创新。

Result: GUI-Owl-7B在AndroidWorld和OSWorld上分别达到66.4和29.4的成绩；Mobile-Agent-v3进一步提升性能，分别达到73.3和37.7，刷新了开源GUI智能体框架的最高水平。

Conclusion: GUI-Owl和Mobile-Agent-v3在多个GUI基准测试中取得了最先进的性能，并开源发布。

Abstract: This paper introduces GUI-Owl, a foundational GUI agent model that achieves
state-of-the-art performance among open-source end-to-end models on ten GUI
benchmarks across desktop and mobile environments, covering grounding, question
answering, planning, decision-making, and procedural knowledge. GUI-Owl-7B
achieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose
Mobile-Agent-v3, a general-purpose GUI agent framework that further improves
performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new
state-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates
three key innovations: (1) Large-scale Environment Infrastructure: a
cloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,
enabling our Self-Evolving GUI Trajectory Production framework. This generates
high-quality interaction data via automated query generation and correctness
validation, leveraging GUI-Owl to refine trajectories iteratively, forming a
self-improving loop. It supports diverse data pipelines and reduces manual
annotation. (2) Diverse Foundational Agent Capabilities: by integrating UI
grounding, planning, action semantics, and reasoning patterns, GUI-Owl supports
end-to-end decision-making and can act as a modular component in multi-agent
systems. (3) Scalable Environment RL: we develop a scalable reinforcement
learning framework with fully asynchronous training for real-world alignment.
We also introduce Trajectory-aware Relative Policy Optimization (TRPO) for
online RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are
open-sourced at https://github.com/X-PLUG/MobileAgent.

</details>


### [12] [PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data](https://arxiv.org/abs/2508.15180)
*Kai Xiong,Yanwei Huang,Rongjunchen Zhang,Kun Chen,Haipang Wu*

Main category: cs.AI

TL;DR: 利用SMT技术大规模生成可验证的数学逻辑数据集PuzzleClone，显著提升LLM推理能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成的数据集可靠性、多样性和可扩展性有限，难以有效提升LLM的推理能力。

Method: 利用SMT技术，通过编码种子谜题、系统性变量和约束随机化以及再现机制生成可验证的数据集。

Result: 构建了一个包含超过83K个多样化且经过程序验证的谜题的基准，并在SFT和RL后训练中取得了显著效果，PuzzleClone平均得分从14.4提升到56.2，7个逻辑和数学基准测试平均提升了12.5个百分点。

Conclusion: PuzzleClone框架通过SMT技术大规模合成可验证的数学和逻辑数据集，显著提升了LLM的推理能力，并在多个基准测试中取得了显著改进。

Abstract: High-quality mathematical and logical datasets with verifiable answers are
essential for strengthening the reasoning capabilities of large language models
(LLMs). While recent data augmentation techniques have facilitated the creation
of large-scale benchmarks, existing LLM-generated datasets often suffer from
limited reliability, diversity, and scalability. To address these challenges,
we introduce PuzzleClone, a formal framework for synthesizing verifiable data
at scale using Satisfiability Modulo Theories (SMT). Our approach features
three key innovations: (1) encoding seed puzzles into structured logical
specifications, (2) generating scalable variants through systematic variable
and constraint randomization, and (3) ensuring validity via a reproduction
mechanism. Applying PuzzleClone, we construct a curated benchmark comprising
over 83K diverse and programmatically validated puzzles. The generated puzzles
span a wide spectrum of difficulty and formats, posing significant challenges
to current state-of-the-art models. We conduct post training (SFT and RL) on
PuzzleClone datasets. Experimental results show that training on PuzzleClone
yields substantial improvements not only on PuzzleClone testset but also on
logic and mathematical benchmarks. Post training raises PuzzleClone average
from 14.4 to 56.2 and delivers consistent improvements across 7 logic and
mathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from
52.5 to 65.0). Our code and data are available at
https://github.com/puzzleclone.

</details>


### [13] [LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support](https://arxiv.org/abs/2508.15192)
*Wenjie Lin,Jin Wei-Kocsis*

Main category: cs.AI

TL;DR: 开发了一个名为LLM4Sweat的开源大型语言模型框架，用于多汗症的诊断和护理，并提供了一种处理其他罕见病的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型难以应用于罕见病，例如多汗症，因为缺乏可靠的数据集。

Method: 三阶段流水线：数据增强、微调和推理与专家评估。利用大型语言模型生成医学上合理的合成数据，对开源基础模型进行微调，并由临床和心理专家评估准确性、适当性和同理心。

Result: LLM4Sweat优于基线模型，并提供诊断、个性化治疗建议和心理支持。

Conclusion: LLM4Sweat，一个开源的针对多汗症的特定领域大型语言模型框架，优于基线模型，为罕见病提供了一种通用的方法。

Abstract: While large language models (LLMs) have shown promise in healthcare, their
application for rare medical conditions is still hindered by scarce and
unreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing
excessive sweating beyond physiological needs, is one such rare disorder,
affecting 2-3% of the population and significantly impacting both physical
comfort and psychosocial well-being. To date, no work has tailored LLMs to
advance the diagnosis or care of hyperhidrosis. To address this gap, we present
LLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and
empathetic hyperhidrosis support. The system follows a three-stage pipeline. In
the data augmentation stage, a frontier LLM generates medically plausible
synthetic vignettes from curated open-source data to create a diverse and
balanced question-answer dataset. In the fine-tuning stage, an open-source
foundation model is fine-tuned on the dataset to provide diagnosis,
personalized treatment recommendations, and empathetic psychological support.
In the inference and expert evaluation stage, clinical and psychological
specialists assess accuracy, appropriateness, and empathy, with validated
responses iteratively enriching the dataset. Experiments show that LLM4Sweat
outperforms baselines and delivers the first open-source LLM framework for
hyperhidrosis, offering a generalizable approach for other rare diseases with
similar data and trustworthiness challenges.

</details>


### [14] [R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling](https://arxiv.org/abs/2508.15204)
*Raj Jain,Marc Wetter*

Main category: cs.AI

TL;DR: LLM在高约束条件下的调度问题表现不佳，约束交互是主要瓶颈，合成数据结果难以迁移到实际场景。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在高约束环境下推理可靠性不足的问题。

Method: 提出R-ConstraintBench框架，通过逐步增加约束条件来评估模型性能，并在数据中心迁移场景中进行了实验。

Result: 实验证明，强大的模型在仅包含优先级约束的DAG上表现良好，但在引入停机时间、时间窗口和互斥约束后，可行性性能急剧下降。

Conclusion: 大型语言模型在资源受限项目调度问题上的可靠性不足，且约束条件的交互作用而非图的深度是性能瓶颈的主要因素。

Abstract: Effective scheduling under tight resource, timing, and operational
constraints underpins large-scale planning across sectors such as capital
projects, manufacturing, logistics, and IT fleet transitions. However, the
reliability of large language models (LLMs) when reasoning under
high-constraint regimes is insufficiently characterized. To address this gap,
we present R-ConstraintBench, a scalable framework that evaluates models on
Resource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete
feasibility class, while difficulty increases via linear growth in constraints.
R-ConstraintBench incrementally increases non-redundant precedence constraints
in Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal
windows, and disjunctive constraints. As an illustrative example, we
instantiate the benchmark in a data center migration setting and evaluate
multiple LLMs using feasibility and error analysis, identifying degradation
thresholds and constraint types most associated with failure. Empirically,
strong models are near-ceiling on precedence-only DAGs, but feasibility
performance collapses when downtime, temporal windows, and disjunctive
constraints interact, implicating constraint interaction, not graph depth, as
the principal bottleneck. Performance on clean synthetic ramps also does not
guarantee transfer to domain-grounded scenarios, underscoring limited
generalization.

</details>


### [15] [See it. Say it. Sorted: Agentic System for Compositional Diagram Generation](https://arxiv.org/abs/2508.15222)
*Hantao Zhang,Jingyang Liu,Ed Li*

Main category: cs.AI

TL;DR: 无需训练的代理系统See it. Say it. Sorted. 利用VLM和LLM将草图转换为精确的SVG图表，效果优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型难以胜任需要空间精度、对齐和符号结构的图表生成任务。

Method: 结合视觉语言模型（VLM）和大型语言模型（LLM），迭代地进行改进，Critic VLM提出修改建议，多个LLM生成不同的SVG更新方案，Judge VLM选择最佳方案。

Result: 在10个草图上，该方法比GPT-5和Gemini-2.5-Pro更准确地重建布局和结构，能够准确地组合基本图形，并且生成的SVG程序易于扩展到演示工具。

Conclusion: 提出了一种无需训练的代理系统See it. Say it. Sorted.，用于将草图转换为精确的图表，该系统结合了视觉语言模型（VLM）和大型语言模型（LLM），能够生成可编辑的SVG程序，并在精度、对齐和结构方面优于现有图像生成模型。

Abstract: We study sketch-to-diagram generation: converting rough hand sketches into
precise, compositional diagrams. Diffusion models excel at photorealism but
struggle with the spatial precision, alignment, and symbolic structure required
for flowcharts. We introduce See it. Say it. Sorted., a training-free agentic
system that couples a Vision-Language Model (VLM) with Large Language Models
(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system
runs an iterative loop in which a Critic VLM proposes a small set of
qualitative, relational edits; multiple candidate LLMs synthesize SVG updates
with diverse strategies (conservative->aggressive, alternative, focused); and a
Judge VLM selects the best candidate, ensuring stable improvement. This design
prioritizes qualitative reasoning over brittle numerical estimates, preserves
global constraints (e.g., alignment, connectivity), and naturally supports
human-in-the-loop corrections. On 10 sketches derived from flowcharts in
published papers, our method more faithfully reconstructs layout and structure
than two frontier closed-source image generation LLMs (GPT-5 and
Gemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)
without inserting unwanted text. Because outputs are programmatic SVGs, the
approach is readily extensible to presentation tools (e.g., PowerPoint) via
APIs and can be specialized with improved prompts and task-specific tools. The
codebase is open-sourced at
https://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.

</details>


### [16] [Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas](https://arxiv.org/abs/2508.15240)
*Sabab Aosaf,Muhammad Ali Nayeem,Afsana Haque,M Sohel Rahmana*

Main category: cs.AI

TL;DR: 利用计算智能算法优化城市土地使用分配，提高土地利用兼容性和经济效益。


<details>
  <summary>Details</summary>
Motivation: 解决混合用途区域土地使用分配中土地利用兼容性和经济目标之间的权衡问题，为城市发展政策提供支持。

Method: 开发了多种优化算法，包括结合差分进化和多目标遗传算法的自定义变体，例如CR+DES算法和MSBX+MO算法。使用了Kruskal-Wallis检验进行统计验证。

Result: CR+DES算法在土地利用兼容性方面比现有方法提高了3.16%，MSBX+MO算法在价格优化方面提高了3.3%。统计分析证实，结合差分向量的算法优于传统方法。

Conclusion: 该论文提出并验证了多种计算智能算法，用于优化混合用途区域的土地使用分配，并在实际案例中取得了比现有方法更好的土地利用兼容性和价格优化效果。

Abstract: Urban land-use allocation represents a complex multi-objective optimization
problem critical for sustainable urban development policy. This paper presents
novel computational intelligence approaches for optimizing land-use allocation
in mixed-use areas, addressing inherent trade-offs between land-use
compatibility and economic objectives. We develop multiple optimization
algorithms, including custom variants integrating differential evolution with
multi-objective genetic algorithms. Key contributions include: (1) CR+DES
algorithm leveraging scaled difference vectors for enhanced exploration, (2)
systematic constraint relaxation strategy improving solution quality while
maintaining feasibility, and (3) statistical validation using Kruskal-Wallis
tests with compact letter displays. Applied to a real-world case study with
1,290 plots, CR+DES achieves 3.16\% improvement in land-use compatibility
compared to state-of-the-art methods, while MSBX+MO excels in price
optimization with 3.3\% improvement. Statistical analysis confirms algorithms
incorporating difference vectors significantly outperform traditional
approaches across multiple metrics. The constraint relaxation technique enables
broader solution space exploration while maintaining practical constraints.
These findings provide urban planners and policymakers with evidence-based
computational tools for balancing competing objectives in land-use allocation,
supporting more effective urban development policies in rapidly urbanizing
regions.

</details>
