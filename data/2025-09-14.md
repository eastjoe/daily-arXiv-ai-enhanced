<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [An Interval Type-2 Version of Bayes Theorem Derived from Interval Probability Range Estimates Provided by Subject Matter Experts](https://arxiv.org/abs/2509.08834)
*John T. Rickard,William A. Dembski,James Rickards*

Main category: cs.AI

TL;DR: 本文提出了一种区间二型贝叶斯定理，用于处理专家提供的区间概率估计，并提供了一种将区间编码到区间二型模糊隶属函数的新算法。


<details>
  <summary>Details</summary>
Motivation: 传统的贝叶斯推理假设输入值精确，这在实际应用中不切实际。本文旨在扩展贝叶斯定理以处理区间概率估计。

Method: 开发了一种区间二型贝叶斯定理和一种将专家提供的区间编码到区间二型模糊隶属函数的算法。

Result: 提出了一种新的区间二型贝叶斯定理和一种区间编码算法，解决了输入区间概率的不确定性问题。

Conclusion: 本文提出的方法能够更有效地处理实际应用中的不确定性，扩展了贝叶斯定理的应用范围。

Abstract: Bayesian inference is widely used in many different fields to test hypotheses
against observations. In most such applications, an assumption is made of
precise input values to produce a precise output value. However, this is
unrealistic for real-world applications. Often the best available information
from subject matter experts (SMEs) in a given field is interval range estimates
of the input probabilities involved in Bayes Theorem. This paper provides two
key contributions to extend Bayes Theorem to an interval type-2 (IT2) version.
First, we develop an IT2 version of Bayes Theorem that uses a novel and
conservative method to avoid potential inconsistencies in the input IT2 MFs
that otherwise might produce invalid output results. We then describe a novel
and flexible algorithm for encoding SME-provided intervals into IT2 fuzzy
membership functions (MFs), which we can use to specify the input probabilities
in Bayes Theorem. Our algorithm generalizes and extends previous work on this
problem that primarily addressed the encoding of intervals into word MFs for
Computing with Words applications.

</details>


### [2] [Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs](https://arxiv.org/abs/2509.08847)
*Amna Hassan*

Main category: cs.AI

TL;DR: 该论文提出一个新框架，利用自然语言处理和大型语言模型将游戏设计文档自动转换为Unity游戏原型。


<details>
  <summary>Details</summary>
Motivation: 简化游戏开发流程，缩短设计到实现的周期。

Method: 使用微调的LLaMA-3模型解析游戏设计文档，提取结构化游戏规范，生成Unity兼容的C#代码。

Result: 生成的原型与游戏设计文档高度一致，在编译成功率、文档遵循度、最佳实践采用和代码模块化等方面均表现优异(平均得分4.8/5.0)。

Conclusion: 该系统有效地解决了AI辅助游戏开发中的关键问题，证明大型语言模型是简化游戏开发流程的宝贵工具。

Abstract: This paper presents a novel framework for automated game template generation
by transforming Game Design Documents (GDDs) into functional Unity game
prototypes using Natural Language Processing (NLP) and multi-modal Large
Language Models (LLMs). We introduce an end-to-end system that parses GDDs,
extracts structured game specifications, and synthesizes Unity-compatible C#
code that implements the core mechanics, systems, and architecture defined in
the design documentation. Our approach combines a fine-tuned LLaMA-3 model
specialized for Unity code generation with a custom Unity integration package
that streamlines the implementation process. Evaluation results demonstrate
significant improvements over baseline models, with our fine-tuned model
achieving superior performance (4.8/5.0 average score) compared to
state-of-the-art LLMs across compilation success, GDD adherence, best practices
adoption, and code modularity metrics. The generated templates demonstrate high
adherence to GDD specifications across multiple game genres. Our system
effectively addresses critical gaps in AI-assisted game development,
positioning LLMs as valuable tools in streamlining the transition from game
design to implementation.

</details>


### [3] [Global Constraint LLM Agents for Text-to-Model Translation](https://arxiv.org/abs/2509.08970)
*Junyang Cai,Serdar Kadioglu,Bistra Dilkina*

Main category: cs.AI

TL;DR: 利用多个大型语言模型(LLM) agent分解建模任务，提高将自然语言描述的优化或满意度问题转换为MiniZinc模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 将自然语言描述转换为MiniZinc模型需要逻辑推理和约束编程专业知识，该框架旨在解决这一难题。

Method: 采用Agentic方法，多个专门的LLM agent根据全局约束类型分解建模任务，最终组装agent整合约束代码片段到完整的MiniZinc模型。

Result: 实验表明，该方法优于一次性提示和思维链提示等基线方法。

Conclusion: 该框架为自然语言到MiniZinc模型的转换提供了一种有效方法，未来工作将进一步改进和完善。

Abstract: Natural language descriptions of optimization or satisfaction problems are
challenging to translate into correct MiniZinc models, as this process demands
both logical reasoning and constraint programming expertise. We introduce a
framework that addresses this challenge with an agentic approach: multiple
specialized large language model (LLM) agents decompose the modeling task by
global constraint type. Each agent is dedicated to detecting and generating
code for a specific class of global constraint, while a final assembler agent
integrates these constraint snippets into a complete MiniZinc model. By
dividing the problem into smaller, well-defined sub-tasks, each LLM handles a
simpler reasoning challenge, potentially reducing overall complexity. We
conduct initial experiments with several LLMs and show better performance
against baselines such as one-shot prompting and chain-of-thought prompting.
Finally, we outline a comprehensive roadmap for future work, highlighting
potential enhancements and directions for improvement.

</details>


### [4] [ForTIFAI: Fending Off Recursive Training Induced Failure for AI Models](https://arxiv.org/abs/2509.08972)
*Soheil Zibakhsh Shabgahi,Pedram Aghazadeh,Azalia Mirhosseini,Farinaz Koushanfar*

Main category: cs.AI

TL;DR: 合成数据训练导致模型崩溃，本文提出一种新的置信度感知损失函数TCE，有效延缓模型崩溃，提升模型保真度。


<details>
  <summary>Details</summary>
Motivation: 随着合成数据增多，模型崩溃问题日益严重，现有缓解策略有限。

Method: 提出一种新的截断交叉熵损失函数(TCE)，降低模型对高置信度预测的依赖。

Result: TCE显著延缓模型崩溃，将模型保真度区间延长2.3倍以上，且方法具有模型无关性，适用于多种模态。

Conclusion: 损失函数设计是解决合成数据训练中模型崩溃问题的一种有效方法。

Abstract: The increasing reliance on generative AI models has accelerated the
generation rate of synthetic data, with some projections suggesting that most
available new data for training could be machine-generated by 2030. This shift
to a mainly synthetic content presents a critical challenge: repeated training
in synthetic data leads to a phenomenon known as model collapse, where model
performance degrades over generations of training, eventually rendering the
models ineffective. Although prior studies have explored the causes and
detection of model collapse, existing mitigation strategies remain limited.
  In this paper, we identify model overconfidence in their self-generated data
as a key driver of collapse. Building on this observation, we propose a
confidence-aware loss function that downweights high-confidence predictions
during training. We introduce a novel loss function we call Truncated Cross
Entropy (TCE). We demonstrate that TCE significantly delays model collapse in
recursive training.
  We provide a model-agnostic framework that links the loss function design to
model collapse mitigation and validate our approach both theoretically and
empirically, showing that it can extend the model's fidelity interval before
collapse by more than 2.3x. Finally, we show that our method generalizes across
modalities. These findings suggest that the design of loss functions provides a
simple yet powerful tool for preserving the quality of generative models in the
era of increasing synthetic data.

</details>


### [5] [Uncertainty Awareness and Trust in Explainable AI- On Trust Calibration using Local and Global Explanations](https://arxiv.org/abs/2509.08989)
*Carina Newen,Daniel Bodemer,Sonja Glantz,Emmanuel Müller,Magdalena Wischnewski,Lenka Schnaubert*

Main category: cs.AI

TL;DR: 研究者提出关于可解释AI（XAI）的通用指导方针，关注经常被忽略的全局不确定性解释，并测试算法在校准信任和提升用户满意度方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有XAI研究多关注局部解释，忽略全局不确定性解释。

Method: 选择同时涵盖不确定性、稳健性和全局XAI的算法，测试其校准信任和提升用户满意度的能力。

Result: 评估算法在提供直观视觉理解方面的效果，以及提升用户满意度和人机可解释性方面的能力。

Conclusion: 研究结果为XAI的通用指导方针提供了依据，并强调了全局不确定性解释和用户满意度的重要性。

Abstract: Explainable AI has become a common term in the literature, scrutinized by
computer scientists and statisticians and highlighted by psychological or
philosophical researchers. One major effort many researchers tackle is
constructing general guidelines for XAI schemes, which we derived from our
study. While some areas of XAI are well studied, we focus on uncertainty
explanations and consider global explanations, which are often left out. We
chose an algorithm that covers various concepts simultaneously, such as
uncertainty, robustness, and global XAI, and tested its ability to calibrate
trust. We then checked whether an algorithm that aims to provide more of an
intuitive visual understanding, despite being complicated to understand, can
provide higher user satisfaction and human interpretability.

</details>


### [6] [Instructional Prompt Optimization for Few-Shot LLM-Based Recommendations on Cold-Start Users](https://arxiv.org/abs/2509.09066)
*Haowei Yang,Yushang Zhao,Sitao Min,Bo Su,Chao Yao,Wei Xu*

Main category: cs.AI

TL;DR: 本文提出一种基于上下文条件的提示词构建方法，用于解决推荐系统中的冷启动用户问题，实验证明该方法能显著提高模型的推荐精度。


<details>
  <summary>Details</summary>
Motivation: 冷启动用户问题限制了推荐系统的有效性，现有方法难以利用少量用户数据进行有效推荐。

Method: 提出一种上下文条件的提示词构建方法P(u, Ds) → R

，其中u是冷启动用户资料，Ds是精选的支持集，R是预测的项目排序列表。利用基于transformer的自回归LLM（BioGPT, LLaMA-2, GPT-4）进行实验，并使用token级对齐和嵌入空间正则化以提高语义保真度。

Result: 实验证明，优化的示例注入和指令结构可以显著提高模型在低数据环境下的precision@k和NDCG分数，表明及时的提示词构建不仅具有句法意义，也具有功能意义，因为它直接控制注意力机制和解码器的行为。

Conclusion: 基于提示词的自适应方法可以有效解决LLM推荐系统中的冷启动问题。

Abstract: The cold-start user issue further compromises the effectiveness of
recommender systems in limiting access to the historical behavioral
information. It is an effective pipeline to optimize instructional prompts on a
few-shot large language model (LLM) used in recommender tasks. We introduce a
context-conditioned prompt formulation method P(u,\ Ds)\ \rightarrow\
R\widehat, where u is a cold-start user profile, Ds is a curated support set,
and R\widehat is the predicted ranked list of items. Based on systematic
experimentation with transformer-based autoregressive LLMs (BioGPT, LLaMA-2,
GPT-4), we provide empirical evidence that optimal exemplar injection and
instruction structuring can significantly improve the precision@k and NDCG
scores of such models in low-data settings. The pipeline uses token-level
alignments and embedding space regularization with a greater semantic fidelity.
Our findings not only show that timely composition is not merely syntactic but
also functional as it is in direct control of attention scales and decoder
conduct through inference. This paper shows that prompt-based adaptation may be
considered one of the ways to address cold-start recommendation issues in
LLM-based pipelines.

</details>


### [7] [Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games](https://arxiv.org/abs/2509.09071)
*Crystal Qian,Kehang Zhu,John Horton,Benjamin S. Manning,Vivian Tsai,James Wexler,Nithum Thain*

Main category: cs.AI

TL;DR: 本文比较了人类、大型语言模型（LLM）和贝叶斯Agent在动态协商环境下的表现，发现虽然LLM和人类的整体收益相似，但行为策略差异显著：LLM保守、让步，人类更策略化、冒险且注重公平。


<details>
  <summary>Details</summary>
Motivation: 评估自主Agent在动态多Agent环境中的协商过程，比较不同类型Agent的优劣。

Method: 在动态协商环境中，比较人类（N=216）、LLM（GPT-4o, Gemini 1.5 Pro）和贝叶斯Agent的表现，分析结果和行为动态。

Result: 贝叶斯Agent收益最高，但拒绝交易频繁；LLM和人类收益相似，但LLM保守让步，人类更策略化、冒险且注重公平。

Conclusion: Agent评估需关注过程和一致性，而不仅仅是性能。

Abstract: Coordination tasks traditionally performed by humans are increasingly being
delegated to autonomous agents. As this pattern progresses, it becomes critical
to evaluate not only these agents' performance but also the processes through
which they negotiate in dynamic, multi-agent environments. Furthermore,
different agents exhibit distinct advantages: traditional statistical agents,
such as Bayesian models, may excel under well-specified conditions, whereas
large language models (LLMs) can generalize across contexts. In this work, we
compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in
a dynamic negotiation setting that enables direct, identical-condition
comparisons across populations, capturing both outcomes and behavioral
dynamics. Bayesian agents extract the highest surplus through aggressive
optimization, at the cost of frequent trade rejections. Humans and LLMs can
achieve similar overall surplus, but through distinct behaviors: LLMs favor
conservative, concessionary trades with few rejections, while humans employ
more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find
that performance parity -- a common benchmark in agent evaluation -- can
conceal fundamental differences in process and alignment, which are critical
for practical deployment in real-world coordination tasks.

</details>


### [8] [Anti-Money Laundering Machine Learning Pipelines; A Technical Analysis on Identifying High-risk Bank Clients with Supervised Learning](https://arxiv.org/abs/2509.09127)
*Khashayar Namdar,Pin-Chien Wang,Tushar Raju,Steven Zheng,Fiona Li,Safwat Tahmin Khan*

Main category: cs.AI

TL;DR: 该论文提出一种利用机器学习识别高风险银行客户的综合方法，并在多伦多大学IMI竞赛中获得第二名，AUROC达到0.961。


<details>
  <summary>Details</summary>
Motivation: 改进反洗钱措施，利用机器学习识别高风险银行客户。

Method: 构建16步的机器学习流水线，包括数据预处理、特征工程（基于SQL）、模型训练和XAI模块。

Result: AUROC达到0.961，标准差0.005，在竞赛中获得第二名。

Conclusion: 该论文提出的机器学习流水线有效且高效地识别高风险银行客户，为反洗钱工作提供了新的方法。

Abstract: Anti-money laundering (AML) actions and measurements are among the priorities
of financial institutions, for which machine learning (ML) has shown to have a
high potential. In this paper, we propose a comprehensive and systematic
approach for developing ML pipelines to identify high-risk bank clients in a
dataset curated for Task 1 of the University of Toronto 2023-2024 Institute for
Management and Innovation (IMI) Big Data and Artificial Intelligence
Competition. The dataset included 195,789 customer IDs, and we employed a
16-step design and statistical analysis to ensure the final pipeline was
robust. We also framed the data in a SQLite database, developed SQL-based
feature engineering algorithms, connected our pre-trained model to the
database, and made it inference-ready, and provided explainable artificial
intelligence (XAI) modules to derive feature importance. Our pipeline achieved
a mean area under the receiver operating characteristic curve (AUROC) of 0.961
with a standard deviation (SD) of 0.005. The proposed pipeline achieved second
place in the competition.

</details>


### [9] [Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective](https://arxiv.org/abs/2509.09154)
*Bui Duc Manh,Soumyaratna Debnath,Zetong Zhang,Shriram Damodaran,Arvind Kumar,Yueyi Zhang,Lu Mi,Erik Cambria,Lin Wang*

Main category: cs.AI

TL;DR: 本文探究了赋能空间智能的计算框架，该框架受到神经科学的启发，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统空间推理能力有限，本文旨在弥合AI与人类空间智能之间的差距。

Method: 提出一个基于神经科学原理的计算框架，包含六个核心模块：生物启发的多模态感知、多感官整合、自我中心-异中心转换、人工认知地图、空间记忆和空间推理。并对现有方法和基准进行了分析。

Result: 提出一个包含六个核心模块的计算框架，并分析了现有方法和基准，指出了未来研究方向。

Conclusion: 该框架为在虚拟和物理环境中实现智能体空间推理能力提供了新的视角，并为未来的研究提供了有前景的路线图。

Abstract: Recent advances in agentic AI have led to systems capable of autonomous task
execution and language-based reasoning, yet their spatial reasoning abilities
remain limited and underexplored, largely constrained to symbolic and
sequential processing. In contrast, human spatial intelligence, rooted in
integrated multisensory perception, spatial memory, and cognitive maps, enables
flexible, context-aware decision-making in unstructured environments.
Therefore, bridging this gap is critical for advancing Agentic Spatial
Intelligence toward better interaction with the physical 3D world. To this end,
we first start from scrutinizing the spatial neural models as studied in
computational neuroscience, and accordingly introduce a novel computational
framework grounded in neuroscience principles. This framework maps core
biological functions to six essential computation modules: bio-inspired
multimodal sensing, multi-sensory integration, egocentric-allocentric
conversion, an artificial cognitive map, spatial memory, and spatial reasoning.
Together, these modules form a perspective landscape for agentic spatial
reasoning capability across both virtual and physical environments. On top, we
conduct a framework-guided analysis of recent methods, evaluating their
relevance to each module and identifying critical gaps that hinder the
development of more neuroscience-grounded spatial reasoning modules. We further
examine emerging benchmarks and datasets and explore potential application
domains ranging from virtual to embodied systems, such as robotics. Finally, we
outline potential research directions, emphasizing the promising roadmap that
can generalize spatial reasoning across dynamic or unstructured environments.
We hope this work will benefit the research community with a
neuroscience-grounded perspective and a structured pathway. Our project page
can be found at Github.

</details>


### [10] [ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent Motion Forecasting](https://arxiv.org/abs/2509.09210)
*Xing Gao,Zherui Huang,Weiyao Lin,Xiao Sun*

Main category: cs.AI

TL;DR: 该论文提出了一种名为ProgD的渐进式多尺度解码策略，用于提高多智能体运动预测的准确性，并在INTERACTION和Argoverse 2基准测试中取得了最优结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了多智能体交互的动态演变特性，该论文旨在对此进行改进。

Method: 采用动态异构图对场景进行建模，并设计了一种分步式架构来处理时空依赖关系，逐步消除未来运动的不确定性，同时结合多尺度解码过程。

Result: 在INTERACTION和Argoverse 2基准测试中取得了最优结果。

Conclusion: ProgD策略有效提高了多智能体运动预测的准确性，为自动驾驶的安全规划提供了重要支持。

Abstract: Accurate motion prediction of surrounding agents is crucial for the safe
planning of autonomous vehicles. Recent advancements have extended prediction
techniques from individual agents to joint predictions of multiple interacting
agents, with various strategies to address complex interactions within future
motions of agents. However, these methods overlook the evolving nature of these
interactions. To address this limitation, we propose a novel progressive
multi-scale decoding strategy, termed ProgD, with the help of dynamic
heterogeneous graph-based scenario modeling. In particular, to explicitly and
comprehensively capture the evolving social interactions in future scenarios,
given their inherent uncertainty, we design a progressive modeling of scenarios
with dynamic heterogeneous graphs. With the unfolding of such dynamic
heterogeneous graphs, a factorized architecture is designed to process the
spatio-temporal dependencies within future scenarios and progressively
eliminate uncertainty in future motions of multiple agents. Furthermore, a
multi-scale decoding procedure is incorporated to improve on the future
scenario modeling and consistent prediction of agents' future motion. The
proposed ProgD achieves state-of-the-art performance on the INTERACTION
multi-agent prediction benchmark, ranking $1^{st}$, and the Argoverse 2
multi-world forecasting benchmark.

</details>


### [11] [Enabling Regulatory Multi-Agent Collaboration: Architecture, Challenges, and Solutions](https://arxiv.org/abs/2509.09215)
*Qinnan Hu,Yuntao Wang,Yuan Gao,Zhou Su,Linkang Du*

Main category: cs.AI

TL;DR: 本论文提出一种基于区块链的分层架构，用于规范大型语言模型驱动自主代理的协作，以解决其行为不可预测和能力异构带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型驱动的自主代理带来了机遇，但也带来了治理和问责方面的挑战。

Method: 提出一种基于区块链的分层架构，包含代理层、区块链数据层和监管应用层，并设计了三个模块：代理行为追踪与仲裁、动态声誉评估和恶意行为预测。

Result: 建立了用于大规模代理生态系统中值得信赖、有弹性和可扩展的监管机制的系统性基础。

Conclusion: 讨论了区块链赋能的监管框架在多代理系统中的未来研究方向。

Abstract: Large language models (LLMs)-empowered autonomous agents are transforming
both digital and physical environments by enabling adaptive, multi-agent
collaboration. While these agents offer significant opportunities across
domains such as finance, healthcare, and smart manufacturing, their
unpredictable behaviors and heterogeneous capabilities pose substantial
governance and accountability challenges. In this paper, we propose a
blockchain-enabled layered architecture for regulatory agent collaboration,
comprising an agent layer, a blockchain data layer, and a regulatory
application layer. Within this framework, we design three key modules: (i) an
agent behavior tracing and arbitration module for automated accountability,
(ii) a dynamic reputation evaluation module for trust assessment in
collaborative scenarios, and (iii) a malicious behavior forecasting module for
early detection of adversarial activities. Our approach establishes a
systematic foundation for trustworthy, resilient, and scalable regulatory
mechanisms in large-scale agent ecosystems. Finally, we discuss the future
research directions for blockchain-enabled regulatory frameworks in multi-agent
systems.

</details>


### [12] [Jupiter: Enhancing LLM Data Analysis Capabilities via Notebook and Inference-Time Value-Guided Search](https://arxiv.org/abs/2509.09245)
*Shuocheng Li,Yihao Liu,Silin Du,Wenxuan Zeng,Zhe Xu,Mengyu Zhou,Yeye He,Haoyu Dong,Shi Han,Dongmei Zhang*

Main category: cs.AI

TL;DR: 大型语言模型(LLM)在自动化数据科学工作流程方面显示出巨大潜力，但现有模型在多步骤推理和工具使用方面仍存在不足。本文提出一个可扩展的流程，从真实世界中的Jupyter笔记本和相关数据文件中提取高质量的基于工具的数据分析任务及其可执行的多步骤解决方案，构建NbQA数据集，并提出Jupiter框架，通过蒙特卡洛树搜索(MCTS)生成多种解决方案轨迹，以提高多步骤推理能力。实验结果表明，该方法在多步骤推理任务中取得了显著成果，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在复杂数据分析任务中受多步骤推理和工具使用限制，本文旨在构建一个能够解决此问题的可扩展流程和数据集。

Method: 提出一个可扩展的数据分析任务和解决方案提取流程，构建NbQA数据集，并提出Jupiter框架，利用MCTS进行多步骤解决方案搜索和价值模型学习。

Result: Qwen2.5-7B和14B-Instruct模型在NbQA数据集上分别解决了77.82%和86.38%的任务，匹配或超过了GPT-4o和先进的agent框架。在各种多步骤推理任务中，该方法展现出改进的泛化能力和更强的工具使用推理能力。

Conclusion: 本文提出的流程和框架有效地提高了LLM在多步骤数据分析任务中的性能，为自动化数据科学工作流程提供了新的思路。

Abstract: Large language models (LLMs) have shown great promise in automating data
science workflows, but existing models still struggle with multi-step reasoning
and tool use, which limits their effectiveness on complex data analysis tasks.
To address this, we propose a scalable pipeline that extracts high-quality,
tool-based data analysis tasks and their executable multi-step solutions from
real-world Jupyter notebooks and associated data files. Using this pipeline, we
introduce NbQA, a large-scale dataset of standardized task-solution pairs that
reflect authentic tool-use patterns in practical data science scenarios. To
further enhance multi-step reasoning, we present Jupiter, a framework that
formulates data analysis as a search problem and applies Monte Carlo Tree
Search (MCTS) to generate diverse solution trajectories for value model
learning. During inference, Jupiter combines the value model and node visit
counts to efficiently collect executable multi-step plans with minimal search
steps. Experimental results show that Qwen2.5-7B and 14B-Instruct models on
NbQA solve 77.82% and 86.38% of tasks on InfiAgent-DABench,
respectively-matching or surpassing GPT-4o and advanced agent frameworks.
Further evaluations demonstrate improved generalization and stronger tool-use
reasoning across diverse multi-step reasoning tasks.

</details>


### [13] [Fusing Knowledge and Language: A Comparative Study of Knowledge Graph-Based Question Answering with LLMs](https://arxiv.org/abs/2509.09272)
*Vaibhav Chaudhary,Neha Soni,Narotam Singh,Amita Kapoor*

Main category: cs.AI

TL;DR: 本文比较了三种构建知识图谱并将其与大型语言模型集成用于问答的方法：spaCy、Stanford CoreNLP-OpenIE和GraphRAG，实验结果表明OpenIE覆盖范围最广，GraphRAG推理能力最强。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG方法在处理复杂的长文本时存在局限性，需要对文本和上下文进行更深入的分析，知识图谱可以增强问答系统。

Method: 比较三种构建知识图谱的方法(spaCy, Stanford CoreNLP-OpenIE, GraphRAG)并将其与LLM集成用于问答，评估其有效性、可行性和适应性。

Result: OpenIE提供最全面的三元组覆盖，GraphRAG表现出优越的推理能力。

Conclusion: 讨论了每种方法的优缺点，并指出了未来改进知识图谱问答的建议。

Abstract: Knowledge graphs, a powerful tool for structuring information through
relational triplets, have recently become the new front-runner in enhancing
question-answering systems. While traditional Retrieval Augmented Generation
(RAG) approaches are proficient in fact-based and local context-based
extraction from concise texts, they encounter limitations when addressing the
thematic and holistic understanding of complex, extensive texts, requiring a
deeper analysis of both text and context. This paper presents a comprehensive
technical comparative study of three different methodologies for constructing
knowledge graph triplets and integrating them with Large Language Models (LLMs)
for question answering: spaCy, Stanford CoreNLP-OpenIE, and GraphRAG, all
leveraging open source technologies. We evaluate the effectiveness,
feasibility, and adaptability of these methods by analyzing their capabilities,
state of development, and their impact on the performance of LLM-based question
answering. Experimental results indicate that while OpenIE provides the most
comprehensive coverage of triplets, GraphRAG demonstrates superior reasoning
abilities among the three. We conclude with a discussion on the strengths and
limitations of each method and provide insights into future directions for
improving knowledge graph-based question answering.

</details>


### [14] [Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning](https://arxiv.org/abs/2509.09284)
*Bingning Huang,Tu Nguyen,Matthieu Zimmer*

Main category: cs.AI

TL;DR: 本文探索了如何将蒙特卡洛树搜索(MCTS)生成的轨迹用于改进基于偏好的强化学习中的策略优化，特别是针对群体相对策略优化(GRPO)算法。


<details>
  <summary>Details</summary>
Motivation: MCTS在大型语言模型推理中已被证明有效，本文尝试将其应用于基于偏好的强化学习策略优化。

Method: 提出了一种分阶段的GRPO训练范式，利用MCTS rollout生成中间轨迹，并进行树结构优势估计。

Result: 初步结果表明，结构化优势估计可以稳定更新并更好地反映组合推理质量，但也存在优势饱和和奖励信号崩溃等挑战。

Conclusion: 本文提出了一些启发式和统计方法来缓解这些问题，并讨论了在分阶段或树状奖励结构下学习的开放性挑战。

Abstract: Recent advances in reasoning with large language models (LLMs) have shown the
effectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality
intermediate trajectories, particularly in math and symbolic domains. Inspired
by this, we explore how MCTS-derived trajectories, traditionally used for
training value or reward models, can be repurposed to improve policy
optimization in preference-based reinforcement learning (RL). Specifically, we
focus on Group Relative Policy Optimization (GRPO), a recent algorithm that
enables preference-consistent policy learning without value networks. We
propose a staged GRPO training paradigm where completions are derived from
partially revealed MCTS rollouts, introducing a novel tree-structured setting
for advantage estimation. This leads to a rich class of prefix-conditioned
reward signals, which we analyze theoretically and empirically. Our initial
results indicate that while structured advantage estimation can stabilize
updates and better reflect compositional reasoning quality, challenges such as
advantage saturation and reward signal collapse remain. We propose heuristic
and statistical solutions to mitigate these issues and discuss open challenges
for learning under staged or tree-like reward structures.

</details>


### [15] [LightAgent: Production-level Open-source Agentic AI Framework](https://arxiv.org/abs/2509.09292)
*Weige Cai,Tong Zhu,Jinyi Niu,Ruiqi Hu,Lingyao Li,Tenglong Wang,Xiaowu Dai,Weining Shen,Liwen Zhang*

Main category: cs.AI

TL;DR: LightAgent是一个轻量级、功能强大的多智能体系统框架，它在灵活性与简易性之间取得了平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体系统框架在灵活性与简易性之间存在权衡，LightAgent旨在解决这一问题。

Method: LightAgent集成了内存、工具和思维树等核心功能，并具有轻量级的结构，易于与主流聊天平台集成。

Result: LightAgent是一个完全开源的解决方案，方便开发者构建自学习智能体。

Conclusion: LightAgent为多智能体系统的开发提供了一个高效且灵活的平台。

Abstract: With the rapid advancement of large language models (LLMs), Multi-agent
Systems (MAS) have achieved significant progress in various application
scenarios. However, substantial challenges remain in designing versatile,
robust, and efficient platforms for agent deployment. To address these
limitations, we propose \textbf{LightAgent}, a lightweight yet powerful agentic
framework, effectively resolving the trade-off between flexibility and
simplicity found in existing frameworks. LightAgent integrates core
functionalities such as Memory (mem0), Tools, and Tree of Thought (ToT), while
maintaining an extremely lightweight structure. As a fully open-source
solution, it seamlessly integrates with mainstream chat platforms, enabling
developers to easily build self-learning agents. We have released LightAgent at
\href{https://github.com/wxai-space/LightAgent}{https://github.com/wxai-space/LightAgent}

</details>


### [16] [Explaining Tournament Solutions with Minimal Supports](https://arxiv.org/abs/2509.09312)
*Clément Contet,Umberto Grandi,Jérôme Mengin*

Main category: cs.AI

TL;DR: 本文研究了在各种锦标赛规则下，解释候选人获胜原因的方法，通过识别最小支持子锦标赛来实现。


<details>
  <summary>Details</summary>
Motivation: 为锦标赛获胜结果提供可认证的解释。

Method: 识别最小支持子锦标赛，即候选人在其中必胜的最小子图。研究了多种锦标赛解决方案，包括Top Cycle、Uncovered Set、Copeland规则、Borda规则、Maximin规则和加权Uncovered Set。

Result: 确定了最小支持的大小，并为除加权Uncovered Set外的所有规则设计了多项式时间算法。加权Uncovered Set问题被证明是NP完全的。

Conclusion: 最小支持可以用于生成简洁、可认证且直观的解释。

Abstract: Tournaments are widely used models to represent pairwise dominance between
candidates, alternatives, or teams. We study the problem of providing certified
explanations for why a candidate appears among the winners under various
tournament rules. To this end, we identify minimal supports, minimal
sub-tournaments in which the candidate is guaranteed to win regardless of how
the rest of the tournament is completed (that is, the candidate is a necessary
winner of the sub-tournament). This notion corresponds to an abductive
explanation for the question,"Why does the winner win the tournament", a
central concept in formal explainable AI. We focus on common tournament
solutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule,
the maximin rule, and the weighted uncovered set. For each rule we determine
the size of the smallest minimal supports, and we present polynomial-time
algorithms to compute them for all but the weighted uncovered set, for which
the problem is NP-complete. Finally, we show how minimal supports can serve to
produce compact, certified, and intuitive explanations.

</details>
