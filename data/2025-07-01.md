<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents](https://arxiv.org/abs/2506.21669)
*Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang*

Main category: cs.AI

TL;DR: SEEA-R1是一个新的强化学习框架，它通过Tree-GRPO和MGRM提高了 embodied agents 的自我进化能力，并在ALFWorld基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 为了使 embodied agents能够自主改进其推理和行为，从而实现自我进化。现有的强化学习微调方法在多模态交互的 embodied intelligence 中的应用仍未得到充分探索。

Method: 提出了一种新的强化学习微调框架SEEA-R1，该框架结合了基于树的群体相对策略优化(Tree-GRPO)和多模态生成奖励模型(MGRM)，以解决多步骤推理任务中奖励稀疏和泛化能力差的问题。

Result: 在ALFWorld基准测试中，SEEA-R1取得了85.07%（文本）和36.19%（多模态）的得分，超过了现有技术水平。即使在没有环境奖励的情况下，其得分也达到80.3%，超过所有开源基线。

Conclusion: SEEA-R1框架在ALFWorld基准测试中取得了最先进的结果，超过了包括GPT-4o在内的现有模型，并在没有环境奖励的情况下也取得了优异的成绩，突出了其作为自我进化实体智能体的可扩展性。

Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning
and behavior, is essential for the embodied domain with long-horizon,
real-world tasks. Despite current advancements in reinforcement fine-tuning
(RFT) showing strong performance in enhancing reasoning in LLMs, its potential
to enable self-evolving embodied intelligence with multi-modal interactions
remains largely unexplored. Specifically, reinforcement fine-tuning faces two
fundamental obstacles in embodied settings: (i) the lack of accessible
intermediate rewards in multi-step reasoning tasks limits effective learning
signals, and (ii) reliance on hand-crafted reward functions restricts
generalization to novel tasks and environments. To address these challenges, we
present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework
designed for enabling the self-evolving capabilities of embodied agents.
Specifically, to convert sparse delayed rewards into denser intermediate
signals that improve multi-step reasoning, we propose Tree-based group relative
policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into
GRPO. To generalize reward estimation across tasks and scenes, supporting
autonomous adaptation and reward-driven self-evolution, we further introduce
Multi-modal Generative Reward Model (MGRM). To holistically evaluate the
effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing
state-of-the-art methods with scores of 85.07% (textual) and 36.19%
(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also
achieves scores of 80.3% without environmental reward, surpassing all
open-source baselines and highlighting its scalability as a self-evolving
embodied agent. Additional experiments and qualitative analysis further support
the potential of SEEA-R1 for future research in scalable embodied intelligence.

</details>


### [2] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
*Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori*

Main category: cs.AI

TL;DR: HRM模型是一种高效、稳定的新型推理模型，在复杂推理任务上取得突破性进展，具有显著的效率和性能优势。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型(LLM)主要采用思维链(CoT)技术，存在任务分解脆弱、数据需求量大、延迟高等问题。

Method: 提出了一种新的递归架构——分层推理模型（HRM），该模型通过两个相互依赖的递归模块（高层模块和低层模块）执行顺序推理任务。

Result: HRM模型仅用2700万个参数，在复杂推理任务上取得了优异的性能，在具有挑战性的任务（例如复杂的数独谜题和大型迷宫中的最优路径查找）中达到了近乎完美的性能，并且在抽象和推理语料库(ARC)上优于参数更多、上下文窗口更长的模型。

Conclusion: HRM模型在复杂推理任务中取得了优异性能，展现了其在通用计算和通用推理系统方面的巨大潜力。

Abstract: Reasoning, the process of devising and executing complex goal-oriented action
sequences, remains a critical challenge in AI. Current large language models
(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from
brittle task decomposition, extensive data requirements, and high latency.
Inspired by the hierarchical and multi-timescale processing in the human brain,
we propose the Hierarchical Reasoning Model (HRM), a novel recurrent
architecture that attains significant computational depth while maintaining
both training stability and efficiency. HRM executes sequential reasoning tasks
in a single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level module
responsible for slow, abstract planning, and a low-level module handling rapid,
detailed computations. With only 27 million parameters, HRM achieves
exceptional performance on complex reasoning tasks using only 1000 training
samples. The model operates without pre-training or CoT data, yet achieves
nearly perfect performance on challenging tasks including complex Sudoku
puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms
much larger models with significantly longer context windows on the Abstraction
and Reasoning Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and general-purpose
reasoning systems.

</details>


### [3] [THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?](https://arxiv.org/abs/2506.21763)
*Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu*

Main category: cs.AI

TL;DR: THE-Tree框架通过构建科学文献进化树，有效验证AI生成的科学命题，并在多个任务中显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以快速有效地验证LLM生成的科学命题，缺乏结构化、可验证且因果关联的科学演化历史数据。

Method: 提出了一种名为THE-Tree的计算框架，该框架利用LLM提出潜在的科学进展并进行验证，结合自然语言推理机制确保每一步的逻辑连贯性和证据支持。

Result: 在图完成任务中，THE-Tree将hit@1指标提高了8%到14%；在预测未来科学发展方面，hit@1指标提高了近10%；与其他方法结合使用时，评估重要科学论文的性能提升了近100%。构建并验证了88个THE-Tree，并发布了一个包含多达71000个事实验证和27000篇论文的基准数据集。

Conclusion: THE-Tree框架通过构建领域特定进化树，有效提高了对AI生成科学命题的新颖性和准确性的验证效率，并在图完成和预测未来科学发展方面均取得了显著改进。

Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but
rigorously evaluating these numerous, often superficial, AI-generated
propositions for novelty and factual accuracy is a critical bottleneck; manual
verification is too slow.Existing validation methods are inadequate: LLMs as
standalone verifiers may hallucinate and lack domain knowledge (our findings
show ~60\% unawareness of relevant papers in specific domains), while
traditional citation networks lack explicit causality and narrative surveys are
unstructured.This underscores a core challenge: the absence of structured,
verifiable, and causally-linked historical data of scientific evolution.To
address this,we introduce \textbf{THE-Tree} (\textbf{T}echnology
\textbf{H}istory \textbf{E}volution Tree), a computational framework that
constructs such domain-specific evolution trees from scientific
literature.THE-Tree employs a search algorithm to explore evolutionary paths.
During its node expansion, it utilizes a novel "Think-Verbalize-Cite-Verify"
process: an LLM proposes potential advancements and cites supporting
literature. Critically, each proposed evolutionary link is then validated for
logical coherence and evidential support by a recovered natural language
inference mechanism that interrogates the cited literature, ensuring that each
step is grounded.We construct and validate 88 THE-Trees across diverse domains
and release a benchmark dataset including up to 71k fact verifications covering
27k papers to foster further research.Experiments demonstrate that i) in graph
completion, our THE-Tree improves hit@1 by 8\% to 14\% across multiple models
compared to traditional citation networks; ii) for predicting future scientific
developments, it improves hit@1 metric by nearly 10\%; and iii) when combined
with other methods, it boosts the performance of evaluating important
scientific papers by almost 100\%.

</details>


### [4] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

Main category: cs.AI

TL;DR: MobiVerse是一个高效、可定制的交通模拟平台，能够模拟大规模人群出行并适应动态环境变化。


<details>
  <summary>Details</summary>
Motivation: 现有交通模拟平台在数据收集、模型校准、适应动态环境和计算效率方面存在不足。

Method: 提出了一种名为MobiVerse的混合框架，该框架结合了轻量级领域特定生成器和LLMs，用于生成和动态调整大规模人群的活动链。

Result: 在洛杉矶Westwood地区进行了案例研究，成功模拟了约53,000个代理人的出行行为，并能够响应道路封闭、大型活动等环境反馈。

Conclusion: MobiVerse框架有效地结合了轻量级领域特定生成器和LLM的适应性，解决了传统交通模拟平台的局限性，能够高效、逼真地模拟大规模人群出行行为，并适应动态环境变化。

Abstract: Understanding and modeling human mobility patterns is crucial for effective
transportation planning and urban development. Despite significant advances in
mobility research, there remains a critical gap in simulation platforms that
allow for algorithm development, policy implementation, and comprehensive
evaluation at scale. Traditional activity-based models require extensive data
collection and manual calibration, machine learning approaches struggle with
adaptation to dynamic conditions, and treding agent-based Large Language Models
(LLMs) implementations face computational constraints with large-scale
simulations. To address these challenges, we propose MobiVerse, a hybrid
framework leverages the efficiency of lightweight domain-specific generator for
generating base activity chains with the adaptability of LLMs for context-aware
modifications. A case study was conducted in Westwood, Los Angeles, where we
efficiently generated and dynamically adjusted schedules for the whole
population of approximately 53,000 agents on a standard PC. Our experiments
demonstrate that MobiVerse successfully enables agents to respond to
environmental feedback, including road closures, large gathering events like
football games, and congestion, through our hybrid framework. Its modular
design facilitates testing various mobility algorithms at both transportation
system and agent levels. Results show our approach maintains computational
efficiency while enhancing behavioral realism. MobiVerse bridges the gap in
mobility simulation by providing a customizable platform for mobility systems
planning and operations with benchmark algorithms. Code and videos are
available at https://github.com/ucla-mobility/MobiVerse.

</details>


### [5] [CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation](https://arxiv.org/abs/2506.21805)
*Nicolas Bougie,Narimasa Watanabe*

Main category: cs.AI

TL;DR: CitySim是一个利用大型语言模型模拟城市人类行为的仿真器，结果表明其更贴近真实人类行为，并可用于预测城市现象。


<details>
  <summary>Details</summary>
Motivation: 模拟城市环境中的人类行为对于社会科学、行为学研究和城市规划至关重要。以往工作依赖于僵化的、手工制作的规则，限制了它们模拟细致的意图、计划和适应性行为的能力。

Method: CitySim 使用递归价值驱动的方法，结合强制性活动、个人习惯和情境因素，生成代理人的日常计划。代理人拥有信念、长期目标和空间记忆用于导航。

Result: CitySim 在模拟数万个代理人和评估他们在各种现实场景下的集体行为方面进行了有见地的实验，包括估计人群密度、预测地点受欢迎程度和评估福祉。

Conclusion: CitySim 能够比以往工作更贴近真实人类行为，并在微观和宏观层面都取得了良好的效果。它是一个可扩展、灵活的测试平台，用于理解和预测城市现象。

Abstract: Modeling human behavior in urban environments is fundamental for social
science, behavioral studies, and urban planning. Prior work often rely on
rigid, hand-crafted rules, limiting their ability to simulate nuanced
intentions, plans, and adaptive behaviors. Addressing these challenges, we
envision an urban simulator (CitySim), capitalizing on breakthroughs in
human-level intelligence exhibited by large language models. In CitySim, agents
generate realistic daily schedules using a recursive value-driven approach that
balances mandatory activities, personal habits, and situational factors. To
enable long-term, lifelike simulations, we endow agents with beliefs, long-term
goals, and spatial memory for navigation. CitySim exhibits closer alignment
with real humans than prior work, both at micro and macro levels. Additionally,
we conduct insightful experiments by modeling tens of thousands of agents and
evaluating their collective behaviors under various real-world scenarios,
including estimating crowd density, predicting place popularity, and assessing
well-being. Our results highlight CitySim as a scalable, flexible testbed for
understanding and forecasting urban phenomena.

</details>


### [6] [Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds](https://arxiv.org/abs/2506.21887)
*Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.AI

TL;DR: Active-MoSH框架通过交互式局部全局方法，结合概率偏好学习和多目标敏感性分析，帮助决策者在高风险场景下做出更有效的多目标决策。


<details>
  <summary>Details</summary>
Motivation: 高风险决策（例如放射治疗）中，需要在多个相互竞争的目标之间取得平衡，且评估成本高昂。现有方法难以有效处理多方面偏好结构，且难以建立决策者对最终决策的信任。

Method: Active-MoSH是一个交互式局部-全局框架，其局部组件整合了软硬边界和概率偏好学习，自适应地细化Pareto子集；全局组件T-MoSH利用多目标敏感性分析识别潜在的被忽略的高价值点。

Result: Active-MoSH在合成和真实世界应用中都表现出性能优势，用户研究也验证了其在提高收敛性、增强决策者信任度和表达偏好方面的能力。

Conclusion: Active-MoSH框架通过结合概率偏好学习和多目标敏感性分析，有效解决了高风险决策中多目标优化的问题，提高了决策效率和决策者信任度。

Abstract: High-stakes decision-making involves navigating multiple competing objectives
with expensive evaluations. For instance, in brachytherapy, clinicians must
balance maximizing tumor coverage (e.g., an aspirational target or soft bound
of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard
bound of <601 cGy to the bladder), with each plan evaluation being
resource-intensive. Selecting Pareto-optimal solutions that match implicit
preferences is challenging, as exhaustive Pareto frontier exploration is
computationally and cognitively prohibitive, necessitating interactive
frameworks to guide users. While decision-makers (DMs) often possess domain
knowledge to narrow the search via such soft-hard bounds, current methods often
lack systematic approaches to iteratively refine these multi-faceted preference
structures. Critically, DMs must trust their final decision, confident they
haven't missed superior alternatives; this trust is paramount in
high-consequence scenarios. We present Active-MoSH, an interactive local-global
framework designed for this process. Its local component integrates soft-hard
bounds with probabilistic preference learning, maintaining distributions over
DM preferences and bounds for adaptive Pareto subset refinement. This is guided
by an active sampling strategy optimizing exploration-exploitation while
minimizing cognitive burden. To build DM trust, Active-MoSH's global component,
T-MoSH, leverages multi-objective sensitivity analysis to identify potentially
overlooked, high-value points beyond immediate feedback. We demonstrate
Active-MoSH's performance benefits through diverse synthetic and real-world
applications. A user study on AI-generated image selection further validates
our hypotheses regarding the framework's ability to improve convergence,
enhance DM trust, and provide expressive preference articulation, enabling more
effective DMs.

</details>


### [7] [AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms](https://arxiv.org/abs/2506.21996)
*Raphaël Boige,Amine Boumaza,Bruno Scherrer*

Main category: cs.AI

TL;DR: 新模型分析博弈算法，更贴近实际，AlphaBeta算法效率不如Scout算法


<details>
  <summary>Details</summary>
Motivation: 传统的博弈树分析模型忽略了博弈的结构复杂性，本文旨在通过一个新的模型来解决这个问题，从而更准确地评估算法性能。

Method: 本文提出了一种新的概率模型，该模型通过强制祖先依赖性来构建博弈树，并对AlphaBeta和Scout算法的平均情况复杂度进行了分析，推导了相应的递归公式。

Result: 本文提出的模型能够生成具有可调难度的博弈树，并对AlphaBeta和Scout算法的平均情况复杂度进行了比较，结果表明AlphaBeta算法在实际应用中效率较低。

Conclusion: 本文介绍了一种新的概率模型来分析确定性博弈求解算法，该模型通过引入祖先依赖性来生成具有可调难度的博弈树，并对AlphaBeta和Scout等算法的平均情况复杂度进行了分析，结果表明尽管渐近情况下所有算法都收敛到相同的branching factor，但在深度有限的博弈树中，AlphaBeta算法的常数乘法因子显著大于Scout算法，导致实际运行速度变慢。

Abstract: Deterministic game-solving algorithms are conventionally analyzed in the
light of their average-case complexity against a distribution of random
game-trees, where leaf values are independently sampled from a fixed
distribution. This simplified model enables uncluttered mathematical analysis,
revealing two key properties: root value distributions asymptotically collapse
to a single fixed value for finite-valued trees, and all reasonable algorithms
achieve global optimality. However, these findings are artifacts of the model's
design-its long criticized independence assumption strips games of structural
complexity, producing trivial instances where no algorithm faces meaningful
challenges. To address this limitation, we introduce a new probabilistic model
that incrementally constructs game-trees using a fixed level-wise conditional
distribution. By enforcing ancestor dependency, a critical structural feature
of real-world games, our framework generates problems with adjustable
difficulty while retaining some form of analytical tractability. For several
algorithms, including AlphaBeta and Scout, we derive recursive formulas
characterizing their average-case complexities under this model. These allow us
to rigorously compare algorithms on deep game-trees, where Monte-Carlo
simulations are no longer feasible. While asymptotically, all algorithms seem
to converge to identical branching factor (a result analogous to those of
independence-based models), deep finite trees reveal stark differences:
AlphaBeta incurs a significantly larger constant multiplicative factor compared
to algorithms like Scout, leading to a substantial practical slowdown. Our
framework sheds new light on classical game-solving algorithms, offering
rigorous evidence and analytical tools to advance the understanding of these
methods under a more realistic, challenging, and yet tractable model.

</details>


### [8] [LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving](https://arxiv.org/abs/2506.22005)
*Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda*

Main category: cs.AI

TL;DR: 利用LLM自动生成Lean 4数学猜想，解决了数据稀缺问题，并增强了定理证明能力。


<details>
  <summary>Details</summary>
Motivation: 解决形式化定理证明中的数据稀缺性挑战，并增强定理证明能力。

Method: 结合基于规则的上下文提取和基于 LLM 的定理陈述生成。

Result: 生成了 12289 个猜想，其中 3776 个被识别为句法有效且非平凡的，平均每个种子文件生成 103.25 个新猜想。验证了拓扑学中几个非平凡的定理。

Conclusion: LeanConjecturer，一个利用大型语言模型 (LLM) 自动生成 Lean 4 中大学水平数学猜想的 pipeline，通过结合基于规则的上下文提取和基于 LLM 的定理陈述生成，解决了形式化定理证明中的数据稀缺性挑战。该系统从 40 个 Mathlib 种子文件中生成了 12289 个猜想，其中 3776 个被识别为句法有效且非平凡的。

Abstract: We introduce LeanConjecturer, a pipeline for automatically generating
university-level mathematical conjectures in Lean 4 using Large Language Models
(LLMs). Our hybrid approach combines rule-based context extraction with
LLM-based theorem statement generation, addressing the data scarcity challenge
in formal theorem proving. Through iterative generation and evaluation,
LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with
3,776 identified as syntactically valid and non-trivial, that is, cannot be
proven by \texttt{aesop} tactic. We demonstrate the utility of these generated
conjectures for reinforcement learning through Group Relative Policy
Optimization (GRPO), showing that targeted training on domain-specific
conjectures can enhance theorem proving capabilities. Our approach generates
103.25 novel conjectures per seed file on average, providing a scalable
solution for creating training data for theorem proving systems. Our system
successfully verified several non-trivial theorems in topology, including
properties of semi-open, alpha-open, and pre-open sets, demonstrating its
potential for mathematical discovery beyond simple variations of existing
results.

</details>


### [9] [Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/abs/2506.22056)
*Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong*

Main category: cs.AI

TL;DR: 提出一种新的多模态轨迹检索框架GAE-Retriever，并在基准数据集上取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 弥合通用检索和以代理为中心的轨迹建模之间的差距，解决轨迹数据表示建模的挑战。

Method: 构建了统一代理轨迹数据集（UATD），并提出了GAE-Retriever，该框架采用视觉语言模型，并通过令牌选择和GradCache机制结合优化的对比学习。

Result: GAE-Retriever在多个数据集上的综合评估表明，其检索召回率始终优于强基线。

Conclusion: GAE-Retriever，一个多模态检索框架，在检索召回率方面持续优于强基线，有效地促进了多模态轨迹检索。

Abstract: Trajectory data, capturing human actions and environmental states across
various modalities, holds significant potential for enhancing AI agent
capabilities, particularly in GUI environments. However, how to model the
representation of trajectory-level data presents a significant challenge that
has not been systematically addressed amid explosive trajectory data growth. In
this work, we introduce Multimodal Trajectory Retrieval, bridging the gap
between universal retrieval and agent-centric trajectory modeling. We construct
the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and
states across diverse real-world scenarios. Based on this, we present
GAE-Bench, a benchmark containing a large number of trajectory-based retrieval
pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework
that adopts vision-language models and incorporates optimized contrastive
learning through a token selection and the GradCache mechanism. Comprehensive
evaluations across multiple datasets show that GAE-Retriever consistently
outperforms strong baselines in retrieval recall, highlighting its
effectiveness in advancing multimodal trajectory retrieval.

</details>


### [10] [Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](https://arxiv.org/abs/2506.22068)
*Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang*

Main category: cs.AI

TL;DR: 新方法QaT和ESN利用逻辑查询和ASP解决智能交通数据碎片化问题，提升测试效率和安全性，并提出验证驱动开发VDD。


<details>
  <summary>Details</summary>
Motivation: Address the fragmented and incompatible data ecosystems in intelligent transportation, improving testing methods for autonomous driving systems.

Method: Proposes Query as Test (QaT) and Extensible Scenarios Notations (ESN) based on Answer Set Programming (ASP).

Result: Introduces QaT and ESN, demonstrating advantages in semantic data fusion, flexible querying, interpretability, and privacy.  Proposes VDD for accelerated development.

Conclusion: This paper introduces Query as Test (QaT) and Extensible Scenarios Notations (ESN) to address the fragmented and incompatible data ecosystems in intelligent transportation.  ESN, based on Answer Set Programming (ASP), enables semantic fusion of multimodal data, supporting complex querying, interpretability, and fine-grained privacy protection. QaT transforms functional validation and safety checks into logical queries against ESN, enhancing testing rigor.  Validation-Driven Development (VDD) is proposed to accelerate development using logical validation.

Abstract: With the deep penetration of Artificial Intelligence (AI) in the
transportation sector, intelligent cockpits, autonomous driving, and
intelligent road networks are developing at an unprecedented pace. However, the
data ecosystems of these three key areas are increasingly fragmented and
incompatible. Especially, existing testing methods rely on data stacking, fail
to cover all edge cases, and lack flexibility. To address this issue, this
paper introduces the concept of "Query as Test" (QaT). This concept shifts the
focus from rigid, prescripted test cases to flexible, on-demand logical queries
against a unified data representation. Specifically, we identify the need for a
fundamental improvement in data storage and representation, leading to our
proposal of "Extensible Scenarios Notations" (ESN). ESN is a novel declarative
data framework based on Answer Set Programming (ASP), which uniformly
represents heterogeneous multimodal data from the cockpit, vehicle, and road as
a collection of logical facts and rules. This approach not only achieves deep
semantic fusion of data, but also brings three core advantages: (1) supports
complex and flexible semantic querying through logical reasoning; (2) provides
natural interpretability for decision-making processes; (3) allows for
on-demand data abstraction through logical rules, enabling fine-grained privacy
protection. We further elaborate on the QaT paradigm, transforming the
functional validation and safety compliance checks of autonomous driving
systems into logical queries against the ESN database, significantly enhancing
the expressiveness and formal rigor of the testing. Finally, we introduce the
concept of "Validation-Driven Development" (VDD), which suggests to guide
developments by logical validation rather than quantitative testing in the era
of Large Language Models, in order to accelerating the iteration and
development process.

</details>


### [11] [A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety](https://arxiv.org/abs/2506.22183)
*Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon*

Main category: cs.AI

TL;DR: 开放性增强AI安全性，但仍需更多研究，尤其在多模态、多语言基准，以及针对自主系统攻击的防御方面。


<details>
  <summary>Details</summary>
Motivation: 开放权重和开源基础模型的快速兴起，使得保障AI系统安全的需求更加迫切。

Method: 参与式、面向解决方案的流程，包括研讨会和为期六周的准备计划。

Result: 提出了一个关于安全和开源AI交叉点的研究议程；对现有的和所需的干预措施和开源工具进行了梳理，以安全和负责任地在AI开发工作流程中部署开放的基础模型；对内容安全过滤器生态系统进行了梳理，并提出了未来研发路线图。

Conclusion: 开放性（透明的权重、可互操作的工具和公共治理）可以增强安全性，但仍存在差距，例如缺乏多模态和多语言基准、针对自主系统的提示注入和组合攻击的防御有限，以及参与机制不足。

Abstract: The rapid rise of open-weight and open-source foundation models is
intensifying the obligation and reshaping the opportunity to make AI systems
safe. This paper reports outcomes from the Columbia Convening on AI Openness
and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme
involving more than forty-five researchers, engineers, and policy leaders from
academia, industry, civil society, and government. Using a participatory,
solutions-oriented process, the working groups produced (i) a research agenda
at the intersection of safety and open source AI; (ii) a mapping of existing
and needed technical interventions and open source tools to safely and
responsibly deploy open foundation models across the AI development workflow;
and (iii) a mapping of the content safety filter ecosystem with a proposed
roadmap for future research and development. We find that openness --
understood as transparent weights, interoperable tooling, and public governance
-- can enhance safety by enabling independent scrutiny, decentralized
mitigation, and culturally plural oversight. However, significant gaps persist:
scarce multimodal and multilingual benchmarks, limited defenses against
prompt-injection and compositional attacks in agentic systems, and insufficient
participatory mechanisms for communities most affected by AI harms. The paper
concludes with a roadmap of five priority research directions, emphasizing
participatory inputs, future-proof content filters, ecosystem-wide safety
infrastructure, rigorous agentic safeguards, and expanded harm taxonomies.
These recommendations informed the February 2025 French AI Action Summit and
lay groundwork for an open, plural, and accountable AI safety discipline.

</details>


### [12] [Breaking Rank Bottlenecks in Knowledge Graph Completion](https://arxiv.org/abs/2506.22271)
*Samy Badreddine,Emile van Krieken,Luciano Serafini*

Main category: cs.AI

TL;DR: 秩瓶颈限制KGC模型表达能力，KGE-MoS通过混合输出层有效解决了此问题，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 许多KGC模型使用简单的向量-矩阵乘法来评分，存在秩瓶颈问题，限制了模型表达能力。

Method: 理论分析和实证研究相结合，提出KGE-MoS模型，该模型使用基于混合的输出层。

Result: KGE-MoS提高了KGC模型的性能和概率拟合，参数成本低。

Conclusion: 本文探究了知识图谱补全(KGC)模型中秩瓶颈对模型表达能力的影响，并提出了一种基于混合的输出层KGE-MoS来解决此问题。实验结果表明，KGE-MoS在提高KGC模型性能和概率拟合方面具有显著效果。

Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful
encoders, rely on a simple vector-matrix multiplication to score queries
against candidate object entities. When the number of entities is larger than
the model's embedding dimension, which in practical scenarios is often by
several orders of magnitude, we have a linear output layer with a rank
bottleneck. Such bottlenecked layers limit model expressivity. We investigate
both theoretically and empirically how rank bottlenecks affect KGC models. We
find that, by limiting the set of feasible predictions, rank bottlenecks hurt
ranking accuracy and the distribution fidelity of scores. Inspired by the
language modelling literature, we propose KGE-MoS, a mixture-based output layer
to break rank bottlenecks in many KGC models. Our experiments on four datasets
show that KGE-MoS improves performance and probabilistic fit of KGC models for
a low parameter cost.

</details>


### [13] [Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates](https://arxiv.org/abs/2506.22276)
*Reuth Mirsky*

Main category: cs.AI

TL;DR: 论文主张赋予合作AI系统"智能不服从"能力，使其能够自主贡献，并探讨了其实现方法和边界。


<details>
  <summary>Details</summary>
Motivation: 当前大多数合作AI系统 rigidly obedient，即使这样做可能适得其反或不安全。

Method: 该论文介绍了AI代理级别量表，并用实例阐述了将AI自主性作为合作环境中独立研究重点的重要性。

Result: 提出智能不服从作为AI代理核心能力，并提出初步边界和研究方向。

Conclusion: 该论文认为，合作AI系统应该具备"智能不服从"的能力，能够自主做出贡献，并在不同自主级别上体现这种能力，并提出初步边界和研究方向。

Abstract: Artificial intelligence has made remarkable strides in recent years,
achieving superhuman performance across a wide range of tasks. Yet despite
these advances, most cooperative AI systems remain rigidly obedient, designed
to follow human instructions without question and conform to user expectations,
even when doing so may be counterproductive or unsafe. This paper argues for
expanding the agency of AI teammates to include \textit{intelligent
disobedience}, empowering them to make meaningful and autonomous contributions
within human-AI teams. It introduces a scale of AI agency levels and uses
representative examples to highlight the importance and growing necessity of
treating AI autonomy as an independent research focus in cooperative settings.
The paper then explores how intelligent disobedience manifests across different
autonomy levels and concludes by proposing initial boundaries and
considerations for studying disobedience as a core capability of artificial
agents.

</details>


### [14] [Conceptual Topic Aggregation](https://arxiv.org/abs/2506.22309)
*Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme*

Main category: cs.AI

TL;DR: FAT-CAT利用形式概念分析增强主题建模的可解释性，提供更有效的主题聚合和可视化。


<details>
  <summary>Details</summary>
Motivation: 传统人工检查方法已无法应对海量数据的挑战，主题建模方法的可解释性不足，难以深入理解数据结构和内容。

Method: 提出FAT-CAT方法，利用形式概念分析对主题进行聚合和可视化。

Result: 在ETYNTKE数据集上的案例研究表明，基于FCA的聚合方法比现有的主题建模技术能提供更有意义、更易解释的数据集构成见解。

Conclusion: FAT-CAT方法，基于形式概念分析（FCA），通过构建概念格，提供了一种更有效、更易解释的数据集主题聚合和可视化方法，优于现有的主题建模技术。

Abstract: The vast growth of data has rendered traditional manual inspection
infeasible, necessitating the adoption of computational methods for efficient
data exploration. Topic modeling has emerged as a powerful tool for analyzing
large-scale textual datasets, enabling the extraction of latent semantic
structures. However, existing methods for topic modeling often struggle to
provide interpretable representations that facilitate deeper insights into data
structure and content. In this paper, we propose FAT-CAT, an approach based on
Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and
visualization of discovered topics. Our approach can handle diverse topics and
file types -- grouped by directories -- to construct a concept lattice that
offers a structured, hierarchical representation of their topic distribution.
In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our
approach against other representation methods to demonstrate that FCA-based
aggregation provides more meaningful and interpretable insights into dataset
composition than existing topic modeling techniques.

</details>


### [15] [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
*Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik*

Main category: cs.AI

TL;DR: 具身AI智能体通过世界模型更好地感知、学习和与环境及用户互动。


<details>
  <summary>Details</summary>
Motivation: 使AI智能体更像人类一样学习和与环境互动。

Method: 研究具身AI智能体，关注世界模型的构建。

Result: 提出世界模型对具身AI智能体的推理和规划至关重要，并建议学习用户的思维模型以增强人机协作。

Conclusion: 该论文研究具身AI智能体，包括虚拟化身、可穿戴设备和机器人，使其能够感知、学习和行动，并通过世界模型理解和预测环境及用户意图，从而自主完成复杂任务。

Abstract: This paper describes our research on AI agents embodied in visual, virtual or
physical forms, enabling them to interact with both users and their
environments. These agents, which include virtual avatars, wearable devices,
and robots, are designed to perceive, learn and act within their surroundings,
which makes them more similar to how humans learn and interact with the
environments as compared to disembodied agents. We propose that the development
of world models is central to reasoning and planning of embodied AI agents,
allowing these agents to understand and predict their environment, to
understand user intentions and social contexts, thereby enhancing their ability
to perform complex tasks autonomously. World modeling encompasses the
integration of multimodal perception, planning through reasoning for action and
control, and memory to create a comprehensive understanding of the physical
world. Beyond the physical world, we also propose to learn the mental world
model of users to enable better human-agent collaboration.

</details>


### [16] [AI Model Passport: Data and System Traceability Framework for Transparent AI in Health](https://arxiv.org/abs/2506.22358)
*Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou,The ProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: AI模型护照提升医疗AI系统透明度、可重复性和合规性。


<details>
  <summary>Details</summary>
Motivation: 现有框架缺乏可扩展性、可比性和机器可解释性，难以确保AI模型的可追溯性和真实性。

Method: 提出了一种结构化和标准化的文档框架——AI模型护照，并通过AIPassport工具实现，该工具自动化元数据收集、版本控制等。

Result: 实现了AI模型护照框架，并通过一个病灶分割的案例展示了其有效性，降低了人工成本，提高了透明度和可重复性。

Conclusion: 本文介绍了AI模型护照的概念及其在医疗影像应用中的实现，旨在提高AI系统的透明度、可重复性和合规性。

Abstract: The increasing integration of Artificial Intelligence (AI) into health and
biomedical systems necessitates robust frameworks for transparency,
accountability, and ethical compliance. Existing frameworks often rely on
human-readable, manual documentation which limits scalability, comparability,
and machine interpretability across projects and platforms. They also fail to
provide a unique, verifiable identity for AI models to ensure their provenance
and authenticity across systems and use cases, limiting reproducibility and
stakeholder trust. This paper introduces the concept of the AI Model Passport,
a structured and standardized documentation framework that acts as a digital
identity and verification tool for AI models. It captures essential metadata to
uniquely identify, verify, trace and monitor AI models across their lifecycle -
from data acquisition and preprocessing to model design, development and
deployment. In addition, an implementation of this framework is presented
through AIPassport, an MLOps tool developed within the ProCAncer-I EU project
for medical imaging applications. AIPassport automates metadata collection,
ensures proper versioning, decouples results from source scripts, and
integrates with various development environments. Its effectiveness is
showcased through a lesion segmentation use case using data from the
ProCAncer-I dataset, illustrating how the AI Model Passport enhances
transparency, reproducibility, and regulatory readiness while reducing manual
effort. This approach aims to set a new standard for fostering trust and
accountability in AI-driven healthcare solutions, aspiring to serve as the
basis for developing transparent and regulation compliant AI systems across
domains.

</details>
