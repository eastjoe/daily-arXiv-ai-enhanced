<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 67]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents](https://arxiv.org/abs/2506.21669)
*Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang*

Main category: cs.AI

TL;DR: SEEA-R1是一个新的强化学习框架，它通过Tree-GRPO和MGRM提高了 embodied agents 的自我进化能力，并在ALFWorld基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 为了使 embodied agents能够自主改进其推理和行为，从而实现自我进化。现有的强化学习微调方法在多模态交互的 embodied intelligence 中的应用仍未得到充分探索。

Method: 提出了一种新的强化学习微调框架SEEA-R1，该框架结合了基于树的群体相对策略优化(Tree-GRPO)和多模态生成奖励模型(MGRM)，以解决多步骤推理任务中奖励稀疏和泛化能力差的问题。

Result: 在ALFWorld基准测试中，SEEA-R1取得了85.07%（文本）和36.19%（多模态）的得分，超过了现有技术水平。即使在没有环境奖励的情况下，其得分也达到80.3%，超过所有开源基线。

Conclusion: SEEA-R1框架在ALFWorld基准测试中取得了最先进的结果，超过了包括GPT-4o在内的现有模型，并在没有环境奖励的情况下也取得了优异的成绩，突出了其作为自我进化实体智能体的可扩展性。

Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning
and behavior, is essential for the embodied domain with long-horizon,
real-world tasks. Despite current advancements in reinforcement fine-tuning
(RFT) showing strong performance in enhancing reasoning in LLMs, its potential
to enable self-evolving embodied intelligence with multi-modal interactions
remains largely unexplored. Specifically, reinforcement fine-tuning faces two
fundamental obstacles in embodied settings: (i) the lack of accessible
intermediate rewards in multi-step reasoning tasks limits effective learning
signals, and (ii) reliance on hand-crafted reward functions restricts
generalization to novel tasks and environments. To address these challenges, we
present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework
designed for enabling the self-evolving capabilities of embodied agents.
Specifically, to convert sparse delayed rewards into denser intermediate
signals that improve multi-step reasoning, we propose Tree-based group relative
policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into
GRPO. To generalize reward estimation across tasks and scenes, supporting
autonomous adaptation and reward-driven self-evolution, we further introduce
Multi-modal Generative Reward Model (MGRM). To holistically evaluate the
effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing
state-of-the-art methods with scores of 85.07% (textual) and 36.19%
(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also
achieves scores of 80.3% without environmental reward, surpassing all
open-source baselines and highlighting its scalability as a self-evolving
embodied agent. Additional experiments and qualitative analysis further support
the potential of SEEA-R1 for future research in scalable embodied intelligence.

</details>


### [2] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
*Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori*

Main category: cs.AI

TL;DR: HRM模型是一种高效、稳定的新型推理模型，在复杂推理任务上取得突破性进展，具有显著的效率和性能优势。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型(LLM)主要采用思维链(CoT)技术，存在任务分解脆弱、数据需求量大、延迟高等问题。

Method: 提出了一种新的递归架构——分层推理模型（HRM），该模型通过两个相互依赖的递归模块（高层模块和低层模块）执行顺序推理任务。

Result: HRM模型仅用2700万个参数，在复杂推理任务上取得了优异的性能，在具有挑战性的任务（例如复杂的数独谜题和大型迷宫中的最优路径查找）中达到了近乎完美的性能，并且在抽象和推理语料库(ARC)上优于参数更多、上下文窗口更长的模型。

Conclusion: HRM模型在复杂推理任务中取得了优异性能，展现了其在通用计算和通用推理系统方面的巨大潜力。

Abstract: Reasoning, the process of devising and executing complex goal-oriented action
sequences, remains a critical challenge in AI. Current large language models
(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from
brittle task decomposition, extensive data requirements, and high latency.
Inspired by the hierarchical and multi-timescale processing in the human brain,
we propose the Hierarchical Reasoning Model (HRM), a novel recurrent
architecture that attains significant computational depth while maintaining
both training stability and efficiency. HRM executes sequential reasoning tasks
in a single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level module
responsible for slow, abstract planning, and a low-level module handling rapid,
detailed computations. With only 27 million parameters, HRM achieves
exceptional performance on complex reasoning tasks using only 1000 training
samples. The model operates without pre-training or CoT data, yet achieves
nearly perfect performance on challenging tasks including complex Sudoku
puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms
much larger models with significantly longer context windows on the Abstraction
and Reasoning Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and general-purpose
reasoning systems.

</details>


### [3] [THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?](https://arxiv.org/abs/2506.21763)
*Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu*

Main category: cs.AI

TL;DR: THE-Tree框架通过构建科学文献进化树，有效验证AI生成的科学命题，并在多个任务中显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以快速有效地验证LLM生成的科学命题，缺乏结构化、可验证且因果关联的科学演化历史数据。

Method: 提出了一种名为THE-Tree的计算框架，该框架利用LLM提出潜在的科学进展并进行验证，结合自然语言推理机制确保每一步的逻辑连贯性和证据支持。

Result: 在图完成任务中，THE-Tree将hit@1指标提高了8%到14%；在预测未来科学发展方面，hit@1指标提高了近10%；与其他方法结合使用时，评估重要科学论文的性能提升了近100%。构建并验证了88个THE-Tree，并发布了一个包含多达71000个事实验证和27000篇论文的基准数据集。

Conclusion: THE-Tree框架通过构建领域特定进化树，有效提高了对AI生成科学命题的新颖性和准确性的验证效率，并在图完成和预测未来科学发展方面均取得了显著改进。

Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but
rigorously evaluating these numerous, often superficial, AI-generated
propositions for novelty and factual accuracy is a critical bottleneck; manual
verification is too slow.Existing validation methods are inadequate: LLMs as
standalone verifiers may hallucinate and lack domain knowledge (our findings
show ~60\% unawareness of relevant papers in specific domains), while
traditional citation networks lack explicit causality and narrative surveys are
unstructured.This underscores a core challenge: the absence of structured,
verifiable, and causally-linked historical data of scientific evolution.To
address this,we introduce \textbf{THE-Tree} (\textbf{T}echnology
\textbf{H}istory \textbf{E}volution Tree), a computational framework that
constructs such domain-specific evolution trees from scientific
literature.THE-Tree employs a search algorithm to explore evolutionary paths.
During its node expansion, it utilizes a novel "Think-Verbalize-Cite-Verify"
process: an LLM proposes potential advancements and cites supporting
literature. Critically, each proposed evolutionary link is then validated for
logical coherence and evidential support by a recovered natural language
inference mechanism that interrogates the cited literature, ensuring that each
step is grounded.We construct and validate 88 THE-Trees across diverse domains
and release a benchmark dataset including up to 71k fact verifications covering
27k papers to foster further research.Experiments demonstrate that i) in graph
completion, our THE-Tree improves hit@1 by 8\% to 14\% across multiple models
compared to traditional citation networks; ii) for predicting future scientific
developments, it improves hit@1 metric by nearly 10\%; and iii) when combined
with other methods, it boosts the performance of evaluating important
scientific papers by almost 100\%.

</details>


### [4] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

Main category: cs.AI

TL;DR: MobiVerse是一个高效、可定制的交通模拟平台，能够模拟大规模人群出行并适应动态环境变化。


<details>
  <summary>Details</summary>
Motivation: 现有交通模拟平台在数据收集、模型校准、适应动态环境和计算效率方面存在不足。

Method: 提出了一种名为MobiVerse的混合框架，该框架结合了轻量级领域特定生成器和LLMs，用于生成和动态调整大规模人群的活动链。

Result: 在洛杉矶Westwood地区进行了案例研究，成功模拟了约53,000个代理人的出行行为，并能够响应道路封闭、大型活动等环境反馈。

Conclusion: MobiVerse框架有效地结合了轻量级领域特定生成器和LLM的适应性，解决了传统交通模拟平台的局限性，能够高效、逼真地模拟大规模人群出行行为，并适应动态环境变化。

Abstract: Understanding and modeling human mobility patterns is crucial for effective
transportation planning and urban development. Despite significant advances in
mobility research, there remains a critical gap in simulation platforms that
allow for algorithm development, policy implementation, and comprehensive
evaluation at scale. Traditional activity-based models require extensive data
collection and manual calibration, machine learning approaches struggle with
adaptation to dynamic conditions, and treding agent-based Large Language Models
(LLMs) implementations face computational constraints with large-scale
simulations. To address these challenges, we propose MobiVerse, a hybrid
framework leverages the efficiency of lightweight domain-specific generator for
generating base activity chains with the adaptability of LLMs for context-aware
modifications. A case study was conducted in Westwood, Los Angeles, where we
efficiently generated and dynamically adjusted schedules for the whole
population of approximately 53,000 agents on a standard PC. Our experiments
demonstrate that MobiVerse successfully enables agents to respond to
environmental feedback, including road closures, large gathering events like
football games, and congestion, through our hybrid framework. Its modular
design facilitates testing various mobility algorithms at both transportation
system and agent levels. Results show our approach maintains computational
efficiency while enhancing behavioral realism. MobiVerse bridges the gap in
mobility simulation by providing a customizable platform for mobility systems
planning and operations with benchmark algorithms. Code and videos are
available at https://github.com/ucla-mobility/MobiVerse.

</details>


### [5] [CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation](https://arxiv.org/abs/2506.21805)
*Nicolas Bougie,Narimasa Watanabe*

Main category: cs.AI

TL;DR: CitySim是一个利用大型语言模型模拟城市人类行为的仿真器，结果表明其更贴近真实人类行为，并可用于预测城市现象。


<details>
  <summary>Details</summary>
Motivation: 模拟城市环境中的人类行为对于社会科学、行为学研究和城市规划至关重要。以往工作依赖于僵化的、手工制作的规则，限制了它们模拟细致的意图、计划和适应性行为的能力。

Method: CitySim 使用递归价值驱动的方法，结合强制性活动、个人习惯和情境因素，生成代理人的日常计划。代理人拥有信念、长期目标和空间记忆用于导航。

Result: CitySim 在模拟数万个代理人和评估他们在各种现实场景下的集体行为方面进行了有见地的实验，包括估计人群密度、预测地点受欢迎程度和评估福祉。

Conclusion: CitySim 能够比以往工作更贴近真实人类行为，并在微观和宏观层面都取得了良好的效果。它是一个可扩展、灵活的测试平台，用于理解和预测城市现象。

Abstract: Modeling human behavior in urban environments is fundamental for social
science, behavioral studies, and urban planning. Prior work often rely on
rigid, hand-crafted rules, limiting their ability to simulate nuanced
intentions, plans, and adaptive behaviors. Addressing these challenges, we
envision an urban simulator (CitySim), capitalizing on breakthroughs in
human-level intelligence exhibited by large language models. In CitySim, agents
generate realistic daily schedules using a recursive value-driven approach that
balances mandatory activities, personal habits, and situational factors. To
enable long-term, lifelike simulations, we endow agents with beliefs, long-term
goals, and spatial memory for navigation. CitySim exhibits closer alignment
with real humans than prior work, both at micro and macro levels. Additionally,
we conduct insightful experiments by modeling tens of thousands of agents and
evaluating their collective behaviors under various real-world scenarios,
including estimating crowd density, predicting place popularity, and assessing
well-being. Our results highlight CitySim as a scalable, flexible testbed for
understanding and forecasting urban phenomena.

</details>


### [6] [Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds](https://arxiv.org/abs/2506.21887)
*Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.AI

TL;DR: Active-MoSH框架通过交互式局部全局方法，结合概率偏好学习和多目标敏感性分析，帮助决策者在高风险场景下做出更有效的多目标决策。


<details>
  <summary>Details</summary>
Motivation: 高风险决策（例如放射治疗）中，需要在多个相互竞争的目标之间取得平衡，且评估成本高昂。现有方法难以有效处理多方面偏好结构，且难以建立决策者对最终决策的信任。

Method: Active-MoSH是一个交互式局部-全局框架，其局部组件整合了软硬边界和概率偏好学习，自适应地细化Pareto子集；全局组件T-MoSH利用多目标敏感性分析识别潜在的被忽略的高价值点。

Result: Active-MoSH在合成和真实世界应用中都表现出性能优势，用户研究也验证了其在提高收敛性、增强决策者信任度和表达偏好方面的能力。

Conclusion: Active-MoSH框架通过结合概率偏好学习和多目标敏感性分析，有效解决了高风险决策中多目标优化的问题，提高了决策效率和决策者信任度。

Abstract: High-stakes decision-making involves navigating multiple competing objectives
with expensive evaluations. For instance, in brachytherapy, clinicians must
balance maximizing tumor coverage (e.g., an aspirational target or soft bound
of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard
bound of <601 cGy to the bladder), with each plan evaluation being
resource-intensive. Selecting Pareto-optimal solutions that match implicit
preferences is challenging, as exhaustive Pareto frontier exploration is
computationally and cognitively prohibitive, necessitating interactive
frameworks to guide users. While decision-makers (DMs) often possess domain
knowledge to narrow the search via such soft-hard bounds, current methods often
lack systematic approaches to iteratively refine these multi-faceted preference
structures. Critically, DMs must trust their final decision, confident they
haven't missed superior alternatives; this trust is paramount in
high-consequence scenarios. We present Active-MoSH, an interactive local-global
framework designed for this process. Its local component integrates soft-hard
bounds with probabilistic preference learning, maintaining distributions over
DM preferences and bounds for adaptive Pareto subset refinement. This is guided
by an active sampling strategy optimizing exploration-exploitation while
minimizing cognitive burden. To build DM trust, Active-MoSH's global component,
T-MoSH, leverages multi-objective sensitivity analysis to identify potentially
overlooked, high-value points beyond immediate feedback. We demonstrate
Active-MoSH's performance benefits through diverse synthetic and real-world
applications. A user study on AI-generated image selection further validates
our hypotheses regarding the framework's ability to improve convergence,
enhance DM trust, and provide expressive preference articulation, enabling more
effective DMs.

</details>


### [7] [AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms](https://arxiv.org/abs/2506.21996)
*Raphaël Boige,Amine Boumaza,Bruno Scherrer*

Main category: cs.AI

TL;DR: 新模型分析博弈算法，更贴近实际，AlphaBeta算法效率不如Scout算法


<details>
  <summary>Details</summary>
Motivation: 传统的博弈树分析模型忽略了博弈的结构复杂性，本文旨在通过一个新的模型来解决这个问题，从而更准确地评估算法性能。

Method: 本文提出了一种新的概率模型，该模型通过强制祖先依赖性来构建博弈树，并对AlphaBeta和Scout算法的平均情况复杂度进行了分析，推导了相应的递归公式。

Result: 本文提出的模型能够生成具有可调难度的博弈树，并对AlphaBeta和Scout算法的平均情况复杂度进行了比较，结果表明AlphaBeta算法在实际应用中效率较低。

Conclusion: 本文介绍了一种新的概率模型来分析确定性博弈求解算法，该模型通过引入祖先依赖性来生成具有可调难度的博弈树，并对AlphaBeta和Scout等算法的平均情况复杂度进行了分析，结果表明尽管渐近情况下所有算法都收敛到相同的branching factor，但在深度有限的博弈树中，AlphaBeta算法的常数乘法因子显著大于Scout算法，导致实际运行速度变慢。

Abstract: Deterministic game-solving algorithms are conventionally analyzed in the
light of their average-case complexity against a distribution of random
game-trees, where leaf values are independently sampled from a fixed
distribution. This simplified model enables uncluttered mathematical analysis,
revealing two key properties: root value distributions asymptotically collapse
to a single fixed value for finite-valued trees, and all reasonable algorithms
achieve global optimality. However, these findings are artifacts of the model's
design-its long criticized independence assumption strips games of structural
complexity, producing trivial instances where no algorithm faces meaningful
challenges. To address this limitation, we introduce a new probabilistic model
that incrementally constructs game-trees using a fixed level-wise conditional
distribution. By enforcing ancestor dependency, a critical structural feature
of real-world games, our framework generates problems with adjustable
difficulty while retaining some form of analytical tractability. For several
algorithms, including AlphaBeta and Scout, we derive recursive formulas
characterizing their average-case complexities under this model. These allow us
to rigorously compare algorithms on deep game-trees, where Monte-Carlo
simulations are no longer feasible. While asymptotically, all algorithms seem
to converge to identical branching factor (a result analogous to those of
independence-based models), deep finite trees reveal stark differences:
AlphaBeta incurs a significantly larger constant multiplicative factor compared
to algorithms like Scout, leading to a substantial practical slowdown. Our
framework sheds new light on classical game-solving algorithms, offering
rigorous evidence and analytical tools to advance the understanding of these
methods under a more realistic, challenging, and yet tractable model.

</details>


### [8] [LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving](https://arxiv.org/abs/2506.22005)
*Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda*

Main category: cs.AI

TL;DR: 利用LLM自动生成Lean 4数学猜想，解决了数据稀缺问题，并增强了定理证明能力。


<details>
  <summary>Details</summary>
Motivation: 解决形式化定理证明中的数据稀缺性挑战，并增强定理证明能力。

Method: 结合基于规则的上下文提取和基于 LLM 的定理陈述生成。

Result: 生成了 12289 个猜想，其中 3776 个被识别为句法有效且非平凡的，平均每个种子文件生成 103.25 个新猜想。验证了拓扑学中几个非平凡的定理。

Conclusion: LeanConjecturer，一个利用大型语言模型 (LLM) 自动生成 Lean 4 中大学水平数学猜想的 pipeline，通过结合基于规则的上下文提取和基于 LLM 的定理陈述生成，解决了形式化定理证明中的数据稀缺性挑战。该系统从 40 个 Mathlib 种子文件中生成了 12289 个猜想，其中 3776 个被识别为句法有效且非平凡的。

Abstract: We introduce LeanConjecturer, a pipeline for automatically generating
university-level mathematical conjectures in Lean 4 using Large Language Models
(LLMs). Our hybrid approach combines rule-based context extraction with
LLM-based theorem statement generation, addressing the data scarcity challenge
in formal theorem proving. Through iterative generation and evaluation,
LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with
3,776 identified as syntactically valid and non-trivial, that is, cannot be
proven by \texttt{aesop} tactic. We demonstrate the utility of these generated
conjectures for reinforcement learning through Group Relative Policy
Optimization (GRPO), showing that targeted training on domain-specific
conjectures can enhance theorem proving capabilities. Our approach generates
103.25 novel conjectures per seed file on average, providing a scalable
solution for creating training data for theorem proving systems. Our system
successfully verified several non-trivial theorems in topology, including
properties of semi-open, alpha-open, and pre-open sets, demonstrating its
potential for mathematical discovery beyond simple variations of existing
results.

</details>


### [9] [Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/abs/2506.22056)
*Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong*

Main category: cs.AI

TL;DR: 提出一种新的多模态轨迹检索框架GAE-Retriever，并在基准数据集上取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 弥合通用检索和以代理为中心的轨迹建模之间的差距，解决轨迹数据表示建模的挑战。

Method: 构建了统一代理轨迹数据集（UATD），并提出了GAE-Retriever，该框架采用视觉语言模型，并通过令牌选择和GradCache机制结合优化的对比学习。

Result: GAE-Retriever在多个数据集上的综合评估表明，其检索召回率始终优于强基线。

Conclusion: GAE-Retriever，一个多模态检索框架，在检索召回率方面持续优于强基线，有效地促进了多模态轨迹检索。

Abstract: Trajectory data, capturing human actions and environmental states across
various modalities, holds significant potential for enhancing AI agent
capabilities, particularly in GUI environments. However, how to model the
representation of trajectory-level data presents a significant challenge that
has not been systematically addressed amid explosive trajectory data growth. In
this work, we introduce Multimodal Trajectory Retrieval, bridging the gap
between universal retrieval and agent-centric trajectory modeling. We construct
the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and
states across diverse real-world scenarios. Based on this, we present
GAE-Bench, a benchmark containing a large number of trajectory-based retrieval
pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework
that adopts vision-language models and incorporates optimized contrastive
learning through a token selection and the GradCache mechanism. Comprehensive
evaluations across multiple datasets show that GAE-Retriever consistently
outperforms strong baselines in retrieval recall, highlighting its
effectiveness in advancing multimodal trajectory retrieval.

</details>


### [10] [Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](https://arxiv.org/abs/2506.22068)
*Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang*

Main category: cs.AI

TL;DR: 新方法QaT和ESN利用逻辑查询和ASP解决智能交通数据碎片化问题，提升测试效率和安全性，并提出验证驱动开发VDD。


<details>
  <summary>Details</summary>
Motivation: Address the fragmented and incompatible data ecosystems in intelligent transportation, improving testing methods for autonomous driving systems.

Method: Proposes Query as Test (QaT) and Extensible Scenarios Notations (ESN) based on Answer Set Programming (ASP).

Result: Introduces QaT and ESN, demonstrating advantages in semantic data fusion, flexible querying, interpretability, and privacy.  Proposes VDD for accelerated development.

Conclusion: This paper introduces Query as Test (QaT) and Extensible Scenarios Notations (ESN) to address the fragmented and incompatible data ecosystems in intelligent transportation.  ESN, based on Answer Set Programming (ASP), enables semantic fusion of multimodal data, supporting complex querying, interpretability, and fine-grained privacy protection. QaT transforms functional validation and safety checks into logical queries against ESN, enhancing testing rigor.  Validation-Driven Development (VDD) is proposed to accelerate development using logical validation.

Abstract: With the deep penetration of Artificial Intelligence (AI) in the
transportation sector, intelligent cockpits, autonomous driving, and
intelligent road networks are developing at an unprecedented pace. However, the
data ecosystems of these three key areas are increasingly fragmented and
incompatible. Especially, existing testing methods rely on data stacking, fail
to cover all edge cases, and lack flexibility. To address this issue, this
paper introduces the concept of "Query as Test" (QaT). This concept shifts the
focus from rigid, prescripted test cases to flexible, on-demand logical queries
against a unified data representation. Specifically, we identify the need for a
fundamental improvement in data storage and representation, leading to our
proposal of "Extensible Scenarios Notations" (ESN). ESN is a novel declarative
data framework based on Answer Set Programming (ASP), which uniformly
represents heterogeneous multimodal data from the cockpit, vehicle, and road as
a collection of logical facts and rules. This approach not only achieves deep
semantic fusion of data, but also brings three core advantages: (1) supports
complex and flexible semantic querying through logical reasoning; (2) provides
natural interpretability for decision-making processes; (3) allows for
on-demand data abstraction through logical rules, enabling fine-grained privacy
protection. We further elaborate on the QaT paradigm, transforming the
functional validation and safety compliance checks of autonomous driving
systems into logical queries against the ESN database, significantly enhancing
the expressiveness and formal rigor of the testing. Finally, we introduce the
concept of "Validation-Driven Development" (VDD), which suggests to guide
developments by logical validation rather than quantitative testing in the era
of Large Language Models, in order to accelerating the iteration and
development process.

</details>


### [11] [A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety](https://arxiv.org/abs/2506.22183)
*Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon*

Main category: cs.AI

TL;DR: 开放性增强AI安全性，但仍需更多研究，尤其在多模态、多语言基准，以及针对自主系统攻击的防御方面。


<details>
  <summary>Details</summary>
Motivation: 开放权重和开源基础模型的快速兴起，使得保障AI系统安全的需求更加迫切。

Method: 参与式、面向解决方案的流程，包括研讨会和为期六周的准备计划。

Result: 提出了一个关于安全和开源AI交叉点的研究议程；对现有的和所需的干预措施和开源工具进行了梳理，以安全和负责任地在AI开发工作流程中部署开放的基础模型；对内容安全过滤器生态系统进行了梳理，并提出了未来研发路线图。

Conclusion: 开放性（透明的权重、可互操作的工具和公共治理）可以增强安全性，但仍存在差距，例如缺乏多模态和多语言基准、针对自主系统的提示注入和组合攻击的防御有限，以及参与机制不足。

Abstract: The rapid rise of open-weight and open-source foundation models is
intensifying the obligation and reshaping the opportunity to make AI systems
safe. This paper reports outcomes from the Columbia Convening on AI Openness
and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme
involving more than forty-five researchers, engineers, and policy leaders from
academia, industry, civil society, and government. Using a participatory,
solutions-oriented process, the working groups produced (i) a research agenda
at the intersection of safety and open source AI; (ii) a mapping of existing
and needed technical interventions and open source tools to safely and
responsibly deploy open foundation models across the AI development workflow;
and (iii) a mapping of the content safety filter ecosystem with a proposed
roadmap for future research and development. We find that openness --
understood as transparent weights, interoperable tooling, and public governance
-- can enhance safety by enabling independent scrutiny, decentralized
mitigation, and culturally plural oversight. However, significant gaps persist:
scarce multimodal and multilingual benchmarks, limited defenses against
prompt-injection and compositional attacks in agentic systems, and insufficient
participatory mechanisms for communities most affected by AI harms. The paper
concludes with a roadmap of five priority research directions, emphasizing
participatory inputs, future-proof content filters, ecosystem-wide safety
infrastructure, rigorous agentic safeguards, and expanded harm taxonomies.
These recommendations informed the February 2025 French AI Action Summit and
lay groundwork for an open, plural, and accountable AI safety discipline.

</details>


### [12] [Breaking Rank Bottlenecks in Knowledge Graph Completion](https://arxiv.org/abs/2506.22271)
*Samy Badreddine,Emile van Krieken,Luciano Serafini*

Main category: cs.AI

TL;DR: 秩瓶颈限制KGC模型表达能力，KGE-MoS通过混合输出层有效解决了此问题，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 许多KGC模型使用简单的向量-矩阵乘法来评分，存在秩瓶颈问题，限制了模型表达能力。

Method: 理论分析和实证研究相结合，提出KGE-MoS模型，该模型使用基于混合的输出层。

Result: KGE-MoS提高了KGC模型的性能和概率拟合，参数成本低。

Conclusion: 本文探究了知识图谱补全(KGC)模型中秩瓶颈对模型表达能力的影响，并提出了一种基于混合的输出层KGE-MoS来解决此问题。实验结果表明，KGE-MoS在提高KGC模型性能和概率拟合方面具有显著效果。

Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful
encoders, rely on a simple vector-matrix multiplication to score queries
against candidate object entities. When the number of entities is larger than
the model's embedding dimension, which in practical scenarios is often by
several orders of magnitude, we have a linear output layer with a rank
bottleneck. Such bottlenecked layers limit model expressivity. We investigate
both theoretically and empirically how rank bottlenecks affect KGC models. We
find that, by limiting the set of feasible predictions, rank bottlenecks hurt
ranking accuracy and the distribution fidelity of scores. Inspired by the
language modelling literature, we propose KGE-MoS, a mixture-based output layer
to break rank bottlenecks in many KGC models. Our experiments on four datasets
show that KGE-MoS improves performance and probabilistic fit of KGC models for
a low parameter cost.

</details>


### [13] [Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates](https://arxiv.org/abs/2506.22276)
*Reuth Mirsky*

Main category: cs.AI

TL;DR: 论文主张赋予合作AI系统"智能不服从"能力，使其能够自主贡献，并探讨了其实现方法和边界。


<details>
  <summary>Details</summary>
Motivation: 当前大多数合作AI系统 rigidly obedient，即使这样做可能适得其反或不安全。

Method: 该论文介绍了AI代理级别量表，并用实例阐述了将AI自主性作为合作环境中独立研究重点的重要性。

Result: 提出智能不服从作为AI代理核心能力，并提出初步边界和研究方向。

Conclusion: 该论文认为，合作AI系统应该具备"智能不服从"的能力，能够自主做出贡献，并在不同自主级别上体现这种能力，并提出初步边界和研究方向。

Abstract: Artificial intelligence has made remarkable strides in recent years,
achieving superhuman performance across a wide range of tasks. Yet despite
these advances, most cooperative AI systems remain rigidly obedient, designed
to follow human instructions without question and conform to user expectations,
even when doing so may be counterproductive or unsafe. This paper argues for
expanding the agency of AI teammates to include \textit{intelligent
disobedience}, empowering them to make meaningful and autonomous contributions
within human-AI teams. It introduces a scale of AI agency levels and uses
representative examples to highlight the importance and growing necessity of
treating AI autonomy as an independent research focus in cooperative settings.
The paper then explores how intelligent disobedience manifests across different
autonomy levels and concludes by proposing initial boundaries and
considerations for studying disobedience as a core capability of artificial
agents.

</details>


### [14] [Conceptual Topic Aggregation](https://arxiv.org/abs/2506.22309)
*Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme*

Main category: cs.AI

TL;DR: FAT-CAT利用形式概念分析增强主题建模的可解释性，提供更有效的主题聚合和可视化。


<details>
  <summary>Details</summary>
Motivation: 传统人工检查方法已无法应对海量数据的挑战，主题建模方法的可解释性不足，难以深入理解数据结构和内容。

Method: 提出FAT-CAT方法，利用形式概念分析对主题进行聚合和可视化。

Result: 在ETYNTKE数据集上的案例研究表明，基于FCA的聚合方法比现有的主题建模技术能提供更有意义、更易解释的数据集构成见解。

Conclusion: FAT-CAT方法，基于形式概念分析（FCA），通过构建概念格，提供了一种更有效、更易解释的数据集主题聚合和可视化方法，优于现有的主题建模技术。

Abstract: The vast growth of data has rendered traditional manual inspection
infeasible, necessitating the adoption of computational methods for efficient
data exploration. Topic modeling has emerged as a powerful tool for analyzing
large-scale textual datasets, enabling the extraction of latent semantic
structures. However, existing methods for topic modeling often struggle to
provide interpretable representations that facilitate deeper insights into data
structure and content. In this paper, we propose FAT-CAT, an approach based on
Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and
visualization of discovered topics. Our approach can handle diverse topics and
file types -- grouped by directories -- to construct a concept lattice that
offers a structured, hierarchical representation of their topic distribution.
In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our
approach against other representation methods to demonstrate that FCA-based
aggregation provides more meaningful and interpretable insights into dataset
composition than existing topic modeling techniques.

</details>


### [15] [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
*Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik*

Main category: cs.AI

TL;DR: 具身AI智能体通过世界模型更好地感知、学习和与环境及用户互动。


<details>
  <summary>Details</summary>
Motivation: 使AI智能体更像人类一样学习和与环境互动。

Method: 研究具身AI智能体，关注世界模型的构建。

Result: 提出世界模型对具身AI智能体的推理和规划至关重要，并建议学习用户的思维模型以增强人机协作。

Conclusion: 该论文研究具身AI智能体，包括虚拟化身、可穿戴设备和机器人，使其能够感知、学习和行动，并通过世界模型理解和预测环境及用户意图，从而自主完成复杂任务。

Abstract: This paper describes our research on AI agents embodied in visual, virtual or
physical forms, enabling them to interact with both users and their
environments. These agents, which include virtual avatars, wearable devices,
and robots, are designed to perceive, learn and act within their surroundings,
which makes them more similar to how humans learn and interact with the
environments as compared to disembodied agents. We propose that the development
of world models is central to reasoning and planning of embodied AI agents,
allowing these agents to understand and predict their environment, to
understand user intentions and social contexts, thereby enhancing their ability
to perform complex tasks autonomously. World modeling encompasses the
integration of multimodal perception, planning through reasoning for action and
control, and memory to create a comprehensive understanding of the physical
world. Beyond the physical world, we also propose to learn the mental world
model of users to enable better human-agent collaboration.

</details>


### [16] [AI Model Passport: Data and System Traceability Framework for Transparent AI in Health](https://arxiv.org/abs/2506.22358)
*Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou,The ProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: AI模型护照提升医疗AI系统透明度、可重复性和合规性。


<details>
  <summary>Details</summary>
Motivation: 现有框架缺乏可扩展性、可比性和机器可解释性，难以确保AI模型的可追溯性和真实性。

Method: 提出了一种结构化和标准化的文档框架——AI模型护照，并通过AIPassport工具实现，该工具自动化元数据收集、版本控制等。

Result: 实现了AI模型护照框架，并通过一个病灶分割的案例展示了其有效性，降低了人工成本，提高了透明度和可重复性。

Conclusion: 本文介绍了AI模型护照的概念及其在医疗影像应用中的实现，旨在提高AI系统的透明度、可重复性和合规性。

Abstract: The increasing integration of Artificial Intelligence (AI) into health and
biomedical systems necessitates robust frameworks for transparency,
accountability, and ethical compliance. Existing frameworks often rely on
human-readable, manual documentation which limits scalability, comparability,
and machine interpretability across projects and platforms. They also fail to
provide a unique, verifiable identity for AI models to ensure their provenance
and authenticity across systems and use cases, limiting reproducibility and
stakeholder trust. This paper introduces the concept of the AI Model Passport,
a structured and standardized documentation framework that acts as a digital
identity and verification tool for AI models. It captures essential metadata to
uniquely identify, verify, trace and monitor AI models across their lifecycle -
from data acquisition and preprocessing to model design, development and
deployment. In addition, an implementation of this framework is presented
through AIPassport, an MLOps tool developed within the ProCAncer-I EU project
for medical imaging applications. AIPassport automates metadata collection,
ensures proper versioning, decouples results from source scripts, and
integrates with various development environments. Its effectiveness is
showcased through a lesion segmentation use case using data from the
ProCAncer-I dataset, illustrating how the AI Model Passport enhances
transparency, reproducibility, and regulatory readiness while reducing manual
effort. This approach aims to set a new standard for fostering trust and
accountability in AI-driven healthcare solutions, aspiring to serve as the
basis for developing transparent and regulation compliant AI systems across
domains.

</details>


### [17] [SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents](https://arxiv.org/abs/2506.21669)
*Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang*

Main category: cs.AI

TL;DR: SEEA-R1框架通过Tree-GRPO和MGRM方法实现了具身智能体的自我进化，并在ALFWorld基准测试中取得了显著成果，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前的强化微调方法在增强大型语言模型的推理能力方面显示出强大的性能，但其在实现具有多模态交互的自我进化具身智能方面的潜力仍未得到充分探索。

Method: 提出了基于树的群体相对策略优化(Tree-GRPO)和多模态生成奖励模型(MGRM)两种方法，以解决具身环境中强化微调的两个基本障碍：缺乏可访问的中间奖励和对手工制作奖励函数的依赖。

Result: 在ALFWorld基准测试中，SEEA-R1在文本和多模态任务上分别取得了85.07%和36.19%的得分，超过了现有技术水平。即使没有环境奖励，其得分也达到了80.3%，超过所有开源基线。

Conclusion: SEEA-R1，一个用于增强具身智能体的自我进化能力的强化微调框架，在ALFWorld基准测试中取得了最先进的结果，优于包括GPT-4o在内的先前模型，并在没有环境奖励的情况下也取得了优异的成绩。

Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning
and behavior, is essential for the embodied domain with long-horizon,
real-world tasks. Despite current advancements in reinforcement fine-tuning
(RFT) showing strong performance in enhancing reasoning in LLMs, its potential
to enable self-evolving embodied intelligence with multi-modal interactions
remains largely unexplored. Specifically, reinforcement fine-tuning faces two
fundamental obstacles in embodied settings: (i) the lack of accessible
intermediate rewards in multi-step reasoning tasks limits effective learning
signals, and (ii) reliance on hand-crafted reward functions restricts
generalization to novel tasks and environments. To address these challenges, we
present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework
designed for enabling the self-evolving capabilities of embodied agents.
Specifically, to convert sparse delayed rewards into denser intermediate
signals that improve multi-step reasoning, we propose Tree-based group relative
policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into
GRPO. To generalize reward estimation across tasks and scenes, supporting
autonomous adaptation and reward-driven self-evolution, we further introduce
Multi-modal Generative Reward Model (MGRM). To holistically evaluate the
effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing
state-of-the-art methods with scores of 85.07% (textual) and 36.19%
(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also
achieves scores of 80.3% without environmental reward, surpassing all
open-source baselines and highlighting its scalability as a self-evolving
embodied agent. Additional experiments and qualitative analysis further support
the potential of SEEA-R1 for future research in scalable embodied intelligence.

</details>


### [18] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
*Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori*

Main category: cs.AI

TL;DR: HRM模型是一种高效、稳定的新型推理模型，在复杂推理任务中取得了显著成果，有望推动通用人工智能的发展。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型(LLM)的推理能力受限于链式思维(CoT)技术的不足，例如任务分解脆弱、数据需求量大、延迟高等问题。

Method: 提出了一种新的递归架构——分层推理模型（HRM），该模型通过两个相互依赖的递归模块（高层模块和低层模块）执行顺序推理任务。

Result: HRM模型仅用2700万参数和1000个训练样本，在复杂推理任务（例如数独和迷宫寻路）中取得了接近完美的性能，并在ARC基准测试中超越了更大的模型。

Conclusion: HRM模型在复杂推理任务中取得了优异性能，并超越了更大的模型，展现了其在通用计算和通用推理系统方面的潜力。

Abstract: Reasoning, the process of devising and executing complex goal-oriented action
sequences, remains a critical challenge in AI. Current large language models
(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from
brittle task decomposition, extensive data requirements, and high latency.
Inspired by the hierarchical and multi-timescale processing in the human brain,
we propose the Hierarchical Reasoning Model (HRM), a novel recurrent
architecture that attains significant computational depth while maintaining
both training stability and efficiency. HRM executes sequential reasoning tasks
in a single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level module
responsible for slow, abstract planning, and a low-level module handling rapid,
detailed computations. With only 27 million parameters, HRM achieves
exceptional performance on complex reasoning tasks using only 1000 training
samples. The model operates without pre-training or CoT data, yet achieves
nearly perfect performance on challenging tasks including complex Sudoku
puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms
much larger models with significantly longer context windows on the Abstraction
and Reasoning Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and general-purpose
reasoning systems.

</details>


### [19] [THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?](https://arxiv.org/abs/2506.21763)
*Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu*

Main category: cs.AI

TL;DR: THE-Tree框架通过构建领域特定进化树，有效提高了科学发展预测和重要论文评估的准确性


<details>
  <summary>Details</summary>
Motivation: 现有验证方法不足以评估AI生成的科学命题的新颖性和准确性，缺乏结构化、可验证且因果关联的科学演化历史数据。

Method: 构建领域特定进化树，使用“Think-Verbalize-Cite-Verify”流程，结合自然语言推理机制验证进化链接。

Result: 在图完成和预测未来科学发展方面均提升了hit@1指标，与其他方法结合后，重要科学论文评估性能提升近100%。构建并验证了88个THE-Tree，发布包含71k事实验证和27k篇论文的基准数据集。

Conclusion: THE-Tree框架通过构建领域特定进化树，改进科学发展预测和重要论文评估，提高了hit@1指标。

Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but
rigorously evaluating these numerous, often superficial, AI-generated
propositions for novelty and factual accuracy is a critical bottleneck; manual
verification is too slow.Existing validation methods are inadequate: LLMs as
standalone verifiers may hallucinate and lack domain knowledge (our findings
show ~60\% unawareness of relevant papers in specific domains), while
traditional citation networks lack explicit causality and narrative surveys are
unstructured.This underscores a core challenge: the absence of structured,
verifiable, and causally-linked historical data of scientific evolution.To
address this,we introduce \textbf{THE-Tree} (\textbf{T}echnology
\textbf{H}istory \textbf{E}volution Tree), a computational framework that
constructs such domain-specific evolution trees from scientific
literature.THE-Tree employs a search algorithm to explore evolutionary paths.
During its node expansion, it utilizes a novel "Think-Verbalize-Cite-Verify"
process: an LLM proposes potential advancements and cites supporting
literature. Critically, each proposed evolutionary link is then validated for
logical coherence and evidential support by a recovered natural language
inference mechanism that interrogates the cited literature, ensuring that each
step is grounded.We construct and validate 88 THE-Trees across diverse domains
and release a benchmark dataset including up to 71k fact verifications covering
27k papers to foster further research.Experiments demonstrate that i) in graph
completion, our THE-Tree improves hit@1 by 8\% to 14\% across multiple models
compared to traditional citation networks; ii) for predicting future scientific
developments, it improves hit@1 metric by nearly 10\%; and iii) when combined
with other methods, it boosts the performance of evaluating important
scientific papers by almost 100\%.

</details>


### [20] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

Main category: cs.AI

TL;DR: MobiVerse是一个高效且真实的移动性模拟平台，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有移动性模拟平台在算法开发、策略实施和综合评估方面存在局限性。

Method: 提出了一种混合框架MobiVerse，结合轻量级特定领域生成器和LLMs，用于生成和动态调整代理人的活动计划。

Result: MobiVerse成功地使代理人能够对环境反馈做出反应，并保持计算效率，同时提高行为真实性。

Conclusion: MobiVerse，一个混合框架，有效地结合了轻量级特定领域生成器和LLMs的适应性，解决了现有移动性模拟平台的局限性，并在洛杉矶Westwood的案例研究中成功模拟了53000个代理人的活动。

Abstract: Understanding and modeling human mobility patterns is crucial for effective
transportation planning and urban development. Despite significant advances in
mobility research, there remains a critical gap in simulation platforms that
allow for algorithm development, policy implementation, and comprehensive
evaluation at scale. Traditional activity-based models require extensive data
collection and manual calibration, machine learning approaches struggle with
adaptation to dynamic conditions, and treding agent-based Large Language Models
(LLMs) implementations face computational constraints with large-scale
simulations. To address these challenges, we propose MobiVerse, a hybrid
framework leverages the efficiency of lightweight domain-specific generator for
generating base activity chains with the adaptability of LLMs for context-aware
modifications. A case study was conducted in Westwood, Los Angeles, where we
efficiently generated and dynamically adjusted schedules for the whole
population of approximately 53,000 agents on a standard PC. Our experiments
demonstrate that MobiVerse successfully enables agents to respond to
environmental feedback, including road closures, large gathering events like
football games, and congestion, through our hybrid framework. Its modular
design facilitates testing various mobility algorithms at both transportation
system and agent levels. Results show our approach maintains computational
efficiency while enhancing behavioral realism. MobiVerse bridges the gap in
mobility simulation by providing a customizable platform for mobility systems
planning and operations with benchmark algorithms. Code and videos are
available at https://github.com/ucla-mobility/MobiVerse.

</details>


### [21] [CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation](https://arxiv.org/abs/2506.21805)
*Nicolas Bougie,Narimasa Watanabe*

Main category: cs.AI

TL;DR: CitySim使用大型语言模型模拟更真实的人类城市行为，可用于预测城市现象。


<details>
  <summary>Details</summary>
Motivation: 现有城市模拟器依赖于僵硬的手工规则，限制了其模拟细微的意图、计划和适应性行为的能力。

Method: 使用递归价值驱动的方法生成代理的每日日程安排，并赋予代理信念、长期目标和空间记忆。

Result: CitySim能够模拟数万个代理，并在各种现实场景下评估其集体行为，例如估计人群密度、预测地点受欢迎程度和评估福祉。

Conclusion: CitySim, 一个基于大型语言模型的城市模拟器，能够更逼真地模拟人类行为，并在微观和宏观层面都与真实人类行为更接近。

Abstract: Modeling human behavior in urban environments is fundamental for social
science, behavioral studies, and urban planning. Prior work often rely on
rigid, hand-crafted rules, limiting their ability to simulate nuanced
intentions, plans, and adaptive behaviors. Addressing these challenges, we
envision an urban simulator (CitySim), capitalizing on breakthroughs in
human-level intelligence exhibited by large language models. In CitySim, agents
generate realistic daily schedules using a recursive value-driven approach that
balances mandatory activities, personal habits, and situational factors. To
enable long-term, lifelike simulations, we endow agents with beliefs, long-term
goals, and spatial memory for navigation. CitySim exhibits closer alignment
with real humans than prior work, both at micro and macro levels. Additionally,
we conduct insightful experiments by modeling tens of thousands of agents and
evaluating their collective behaviors under various real-world scenarios,
including estimating crowd density, predicting place popularity, and assessing
well-being. Our results highlight CitySim as a scalable, flexible testbed for
understanding and forecasting urban phenomena.

</details>


### [22] [Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds](https://arxiv.org/abs/2506.21887)
*Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.AI

TL;DR: Active-MoSH 框架通过交互式局部-全局方法，有效帮助决策者在高风险场景下做出更有效的多目标决策，提升决策效率和信任度。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效处理高风险决策中多目标优化问题，且缺乏系统的方法迭代优化多方面偏好结构，难以确保决策者对最终决策的信任。

Method: Active-MoSH 框架结合了局部组件（整合软硬边界和概率偏好学习）和全局组件（利用多目标敏感性分析），采用主动采样策略，在最小化认知负担的同时优化探索-利用的平衡。

Result: Active-MoSH 框架在合成数据和真实世界应用中均展现出性能优势，用户研究也验证了其在提高收敛性、增强决策者信任度和表达偏好方面具有显著效果。

Conclusion: Active-MoSH 框架通过结合概率偏好学习和多目标敏感性分析，有效解决了高风险决策中多目标优化的问题，提升了决策效率和信任度。

Abstract: High-stakes decision-making involves navigating multiple competing objectives
with expensive evaluations. For instance, in brachytherapy, clinicians must
balance maximizing tumor coverage (e.g., an aspirational target or soft bound
of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard
bound of <601 cGy to the bladder), with each plan evaluation being
resource-intensive. Selecting Pareto-optimal solutions that match implicit
preferences is challenging, as exhaustive Pareto frontier exploration is
computationally and cognitively prohibitive, necessitating interactive
frameworks to guide users. While decision-makers (DMs) often possess domain
knowledge to narrow the search via such soft-hard bounds, current methods often
lack systematic approaches to iteratively refine these multi-faceted preference
structures. Critically, DMs must trust their final decision, confident they
haven't missed superior alternatives; this trust is paramount in
high-consequence scenarios. We present Active-MoSH, an interactive local-global
framework designed for this process. Its local component integrates soft-hard
bounds with probabilistic preference learning, maintaining distributions over
DM preferences and bounds for adaptive Pareto subset refinement. This is guided
by an active sampling strategy optimizing exploration-exploitation while
minimizing cognitive burden. To build DM trust, Active-MoSH's global component,
T-MoSH, leverages multi-objective sensitivity analysis to identify potentially
overlooked, high-value points beyond immediate feedback. We demonstrate
Active-MoSH's performance benefits through diverse synthetic and real-world
applications. A user study on AI-generated image selection further validates
our hypotheses regarding the framework's ability to improve convergence,
enhance DM trust, and provide expressive preference articulation, enabling more
effective DMs.

</details>


### [23] [AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms](https://arxiv.org/abs/2506.21996)
*Raphaël Boige,Amine Boumaza,Bruno Scherrer*

Main category: cs.AI

TL;DR: 新模型更真实地模拟博弈树结构，分析表明AlphaBeta算法效率低于Scout算法。


<details>
  <summary>Details</summary>
Motivation: 传统的基于随机游戏树的平均情况复杂度分析忽略了真实博弈的结构复杂性，本文旨在通过构建一个更现实的模型来解决这个问题。

Method: 本文通过构建一个新的概率模型，该模型通过强制祖先依赖关系来生成具有可调难度和结构复杂性的博弈树，并对AlphaBeta和Scout算法进行分析，推导了其平均情况复杂度的递归公式。

Result: 本文提出的模型能够更准确地评估确定性博弈求解算法的性能，并揭示了不同算法在深度有限树上的实际差异，为算法设计和改进提供了理论依据。

Conclusion: 本文介绍了一种新的概率模型来分析确定性博弈求解算法，该模型通过引入祖先依赖性来生成具有可调难度的博弈树，并对AlphaBeta和Scout算法的平均情况复杂度进行了分析，结果表明尽管渐近情况下所有算法收敛到相同的分支因子，但在深度有限树中，AlphaBeta算法比Scout算法慢得多。

Abstract: Deterministic game-solving algorithms are conventionally analyzed in the
light of their average-case complexity against a distribution of random
game-trees, where leaf values are independently sampled from a fixed
distribution. This simplified model enables uncluttered mathematical analysis,
revealing two key properties: root value distributions asymptotically collapse
to a single fixed value for finite-valued trees, and all reasonable algorithms
achieve global optimality. However, these findings are artifacts of the model's
design-its long criticized independence assumption strips games of structural
complexity, producing trivial instances where no algorithm faces meaningful
challenges. To address this limitation, we introduce a new probabilistic model
that incrementally constructs game-trees using a fixed level-wise conditional
distribution. By enforcing ancestor dependency, a critical structural feature
of real-world games, our framework generates problems with adjustable
difficulty while retaining some form of analytical tractability. For several
algorithms, including AlphaBeta and Scout, we derive recursive formulas
characterizing their average-case complexities under this model. These allow us
to rigorously compare algorithms on deep game-trees, where Monte-Carlo
simulations are no longer feasible. While asymptotically, all algorithms seem
to converge to identical branching factor (a result analogous to those of
independence-based models), deep finite trees reveal stark differences:
AlphaBeta incurs a significantly larger constant multiplicative factor compared
to algorithms like Scout, leading to a substantial practical slowdown. Our
framework sheds new light on classical game-solving algorithms, offering
rigorous evidence and analytical tools to advance the understanding of these
methods under a more realistic, challenging, and yet tractable model.

</details>


### [24] [LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving](https://arxiv.org/abs/2506.22005)
*Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda*

Main category: cs.AI

TL;DR: 利用LLM自动生成数学猜想，解决了数据稀缺问题，并提升了定理证明能力。


<details>
  <summary>Details</summary>
Motivation: 解决形式化定理证明中的数据稀缺性挑战，并为定理证明系统创建训练数据。

Method: 结合基于规则的上下文提取和基于LLM的定理陈述生成，迭代生成和评估。

Result: 生成了12289个猜想，其中3776个语法有效且非平凡；验证了拓扑学中一些非平凡的定理；证明了该方法在数学发现方面的潜力。

Conclusion: LeanConjecturer项目通过结合基于规则的上下文提取和基于LLM的定理陈述生成，成功地从40个Mathlib种子文件中生成了12289个猜想，其中3776个被认为是语法有效且非平凡的。该项目还展示了这些生成的猜想在强化学习中的实用性，并成功验证了拓扑学中一些非平凡的定理。

Abstract: We introduce LeanConjecturer, a pipeline for automatically generating
university-level mathematical conjectures in Lean 4 using Large Language Models
(LLMs). Our hybrid approach combines rule-based context extraction with
LLM-based theorem statement generation, addressing the data scarcity challenge
in formal theorem proving. Through iterative generation and evaluation,
LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with
3,776 identified as syntactically valid and non-trivial, that is, cannot be
proven by \texttt{aesop} tactic. We demonstrate the utility of these generated
conjectures for reinforcement learning through Group Relative Policy
Optimization (GRPO), showing that targeted training on domain-specific
conjectures can enhance theorem proving capabilities. Our approach generates
103.25 novel conjectures per seed file on average, providing a scalable
solution for creating training data for theorem proving systems. Our system
successfully verified several non-trivial theorems in topology, including
properties of semi-open, alpha-open, and pre-open sets, demonstrating its
potential for mathematical discovery beyond simple variations of existing
results.

</details>


### [25] [Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/abs/2506.22056)
*Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong*

Main category: cs.AI

TL;DR: 提出了一种新的多模态轨迹检索框架GAE-Retriever，并在多个数据集上取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法没有系统地解决轨迹数据建模的挑战，而轨迹数据对于增强AI智能体能力，特别是在GUI环境中，具有巨大潜力。

Method: 构建了统一的Agent轨迹数据集(UATD)，并提出了GAE-Retriever多模态检索框架，该框架采用视觉语言模型，并通过令牌选择和GradCache机制结合优化的对比学习。

Result: GAE-Retriever在多个数据集上的综合评估表明，其检索查全率始终优于强基线。

Conclusion: GAE-Retriever，一个多模态检索框架，在检索查全率方面始终优于强基线，有效地促进了多模态轨迹检索的发展。

Abstract: Trajectory data, capturing human actions and environmental states across
various modalities, holds significant potential for enhancing AI agent
capabilities, particularly in GUI environments. However, how to model the
representation of trajectory-level data presents a significant challenge that
has not been systematically addressed amid explosive trajectory data growth. In
this work, we introduce Multimodal Trajectory Retrieval, bridging the gap
between universal retrieval and agent-centric trajectory modeling. We construct
the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and
states across diverse real-world scenarios. Based on this, we present
GAE-Bench, a benchmark containing a large number of trajectory-based retrieval
pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework
that adopts vision-language models and incorporates optimized contrastive
learning through a token selection and the GradCache mechanism. Comprehensive
evaluations across multiple datasets show that GAE-Retriever consistently
outperforms strong baselines in retrieval recall, highlighting its
effectiveness in advancing multimodal trajectory retrieval.

</details>


### [26] [Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](https://arxiv.org/abs/2506.22068)
*Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang*

Main category: cs.AI

TL;DR: 提出Query as Test (QaT)和Extensible Scenarios Notations (ESN)框架，用于更有效地测试自动驾驶系统。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶系统测试方法存在数据碎片化、测试用例僵化、缺乏灵活性等问题。

Method: 提出了一种基于Answer Set Programming (ASP)的新的声明式数据框架ESN，并将其应用于QaT测试范式。

Result: ESN框架实现了异构多模态数据的深度语义融合，支持复杂的语义查询，提高了测试的可解释性和隐私保护能力，并提出了"Validation-Driven Development"(VDD)的开发理念。

Conclusion: 本文介绍了"Query as Test"(QaT)的概念，并提出了一种新的声明式数据框架"Extensible Scenarios Notations"(ESN)，用于统一表示来自驾驶舱、车辆和道路的多模态数据，从而提高自动驾驶系统的测试效率和有效性。

Abstract: With the deep penetration of Artificial Intelligence (AI) in the
transportation sector, intelligent cockpits, autonomous driving, and
intelligent road networks are developing at an unprecedented pace. However, the
data ecosystems of these three key areas are increasingly fragmented and
incompatible. Especially, existing testing methods rely on data stacking, fail
to cover all edge cases, and lack flexibility. To address this issue, this
paper introduces the concept of "Query as Test" (QaT). This concept shifts the
focus from rigid, prescripted test cases to flexible, on-demand logical queries
against a unified data representation. Specifically, we identify the need for a
fundamental improvement in data storage and representation, leading to our
proposal of "Extensible Scenarios Notations" (ESN). ESN is a novel declarative
data framework based on Answer Set Programming (ASP), which uniformly
represents heterogeneous multimodal data from the cockpit, vehicle, and road as
a collection of logical facts and rules. This approach not only achieves deep
semantic fusion of data, but also brings three core advantages: (1) supports
complex and flexible semantic querying through logical reasoning; (2) provides
natural interpretability for decision-making processes; (3) allows for
on-demand data abstraction through logical rules, enabling fine-grained privacy
protection. We further elaborate on the QaT paradigm, transforming the
functional validation and safety compliance checks of autonomous driving
systems into logical queries against the ESN database, significantly enhancing
the expressiveness and formal rigor of the testing. Finally, we introduce the
concept of "Validation-Driven Development" (VDD), which suggests to guide
developments by logical validation rather than quantitative testing in the era
of Large Language Models, in order to accelerating the iteration and
development process.

</details>


### [27] [A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety](https://arxiv.org/abs/2506.22183)
*Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon*

Main category: cs.AI

TL;DR: 开源AI增强安全性，但仍存在差距，需优先研究参与式方法、内容过滤、安全基础设施和自主系统安全。


<details>
  <summary>Details</summary>
Motivation: 开放权重和开源基础模型的快速兴起，使得确保AI系统安全的需求更加迫切，也重塑了机会。

Method: 参与式、面向解决方案的方法，工作组制作了关于安全和开源AI的研究议程，以及安全和负责任地部署开放基础模型的工具图谱，并绘制了内容安全过滤器生态系统的图谱，提出了未来研发路线图。

Result: 提出了五个优先研究方向：参与式投入、面向未来的内容过滤器、全生态系统安全基础设施、强大的自主安全措施和扩展的危害分类法。这些建议为2025年2月的法国AI行动峰会提供了参考，也为建立开放、多元和负责任的AI安全学科奠定了基础。

Conclusion: 开放性（透明的权重、可互操作的工具和公共治理）可以增强安全性，但仍存在差距，例如缺乏多模态和多语言基准，以及针对自主系统的提示注入和组合攻击的防御不足。

Abstract: The rapid rise of open-weight and open-source foundation models is
intensifying the obligation and reshaping the opportunity to make AI systems
safe. This paper reports outcomes from the Columbia Convening on AI Openness
and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme
involving more than forty-five researchers, engineers, and policy leaders from
academia, industry, civil society, and government. Using a participatory,
solutions-oriented process, the working groups produced (i) a research agenda
at the intersection of safety and open source AI; (ii) a mapping of existing
and needed technical interventions and open source tools to safely and
responsibly deploy open foundation models across the AI development workflow;
and (iii) a mapping of the content safety filter ecosystem with a proposed
roadmap for future research and development. We find that openness --
understood as transparent weights, interoperable tooling, and public governance
-- can enhance safety by enabling independent scrutiny, decentralized
mitigation, and culturally plural oversight. However, significant gaps persist:
scarce multimodal and multilingual benchmarks, limited defenses against
prompt-injection and compositional attacks in agentic systems, and insufficient
participatory mechanisms for communities most affected by AI harms. The paper
concludes with a roadmap of five priority research directions, emphasizing
participatory inputs, future-proof content filters, ecosystem-wide safety
infrastructure, rigorous agentic safeguards, and expanded harm taxonomies.
These recommendations informed the February 2025 French AI Action Summit and
lay groundwork for an open, plural, and accountable AI safety discipline.

</details>


### [28] [Breaking Rank Bottlenecks in Knowledge Graph Completion](https://arxiv.org/abs/2506.22271)
*Samy Badreddine,Emile van Krieken,Luciano Serafini*

Main category: cs.AI

TL;DR: 秩瓶颈限制KGC模型表达能力，KGE-MoS通过混合输出层有效解决了这个问题，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 许多KGC模型使用简单的向量矩阵乘法来评分查询，当实体数量远大于模型嵌入维度时，会产生秩瓶颈，限制模型表达能力。

Method: 理论分析和实证研究，提出KGE-MoS模型。

Result: KGE-MoS提高了KGC模型的性能和概率拟合度，参数成本低。

Conclusion: 本文探究了知识图谱补全(KGC)模型中秩瓶颈的影响，并提出了一种基于混合的输出层KGE-MoS来解决这个问题。实验结果表明，KGE-MoS在四个数据集上提高了KGC模型的性能和概率拟合度。

Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful
encoders, rely on a simple vector-matrix multiplication to score queries
against candidate object entities. When the number of entities is larger than
the model's embedding dimension, which in practical scenarios is often by
several orders of magnitude, we have a linear output layer with a rank
bottleneck. Such bottlenecked layers limit model expressivity. We investigate
both theoretically and empirically how rank bottlenecks affect KGC models. We
find that, by limiting the set of feasible predictions, rank bottlenecks hurt
ranking accuracy and the distribution fidelity of scores. Inspired by the
language modelling literature, we propose KGE-MoS, a mixture-based output layer
to break rank bottlenecks in many KGC models. Our experiments on four datasets
show that KGE-MoS improves performance and probabilistic fit of KGC models for
a low parameter cost.

</details>


### [29] [Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates](https://arxiv.org/abs/2506.22276)
*Reuth Mirsky*

Main category: cs.AI

TL;DR: 论文主张赋予合作AI系统"智能不服从"的能力，使其能够自主贡献，并探讨了其实现方法及边界。


<details>
  <summary>Details</summary>
Motivation: 当前大多数合作AI系统严格服从指令，缺乏自主性，这在某些情况下可能适得其反或不安全。

Method: 提出AI自主性等级，并用实例说明智能不服从的重要性。

Result: 提出将智能不服从作为人工智能智能体的核心能力进行研究。

Conclusion: 该论文认为，合作AI系统应该具备"智能不服从"的能力，能够自主做出贡献，并在不同自主性水平下探讨其表现，并提出初步边界和研究考虑。

Abstract: Artificial intelligence has made remarkable strides in recent years,
achieving superhuman performance across a wide range of tasks. Yet despite
these advances, most cooperative AI systems remain rigidly obedient, designed
to follow human instructions without question and conform to user expectations,
even when doing so may be counterproductive or unsafe. This paper argues for
expanding the agency of AI teammates to include \textit{intelligent
disobedience}, empowering them to make meaningful and autonomous contributions
within human-AI teams. It introduces a scale of AI agency levels and uses
representative examples to highlight the importance and growing necessity of
treating AI autonomy as an independent research focus in cooperative settings.
The paper then explores how intelligent disobedience manifests across different
autonomy levels and concludes by proposing initial boundaries and
considerations for studying disobedience as a core capability of artificial
agents.

</details>


### [30] [Conceptual Topic Aggregation](https://arxiv.org/abs/2506.22309)
*Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme*

Main category: cs.AI

TL;DR: 提出FAT-CAT，一种基于FCA的主题建模方法，通过概念格可视化主题分布，提升主题建模的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有主题建模方法难以提供易于理解的数据结构和内容洞察，故提出FAT-CAT方法。

Method: 提出FAT-CAT方法，利用形式概念分析（FCA）对主题进行聚合和可视化，构建概念格来表示主题分布。

Result: 实验证明，基于FCA的聚合方法比现有的主题建模技术能提供更有意义和更易解释的数据集构成分析。

Conclusion: FAT-CAT方法，一种基于形式概念分析（FCA）的主题建模方法，通过构建概念格，提供了一种更有效、更易解释的数据集主题结构和内容的层次化表示，优于现有的主题建模技术。

Abstract: The vast growth of data has rendered traditional manual inspection
infeasible, necessitating the adoption of computational methods for efficient
data exploration. Topic modeling has emerged as a powerful tool for analyzing
large-scale textual datasets, enabling the extraction of latent semantic
structures. However, existing methods for topic modeling often struggle to
provide interpretable representations that facilitate deeper insights into data
structure and content. In this paper, we propose FAT-CAT, an approach based on
Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and
visualization of discovered topics. Our approach can handle diverse topics and
file types -- grouped by directories -- to construct a concept lattice that
offers a structured, hierarchical representation of their topic distribution.
In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our
approach against other representation methods to demonstrate that FCA-based
aggregation provides more meaningful and interpretable insights into dataset
composition than existing topic modeling techniques.

</details>


### [31] [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
*Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik*

Main category: cs.AI

TL;DR: 具身AI智能体通过构建世界模型，理解环境和用户意图，从而更好地与用户协作。


<details>
  <summary>Details</summary>
Motivation: 探究如何使AI智能体更好地与用户和环境交互，提升其自主执行复杂任务的能力。

Method: 研究具身AI智能体，包括虚拟化身、可穿戴设备和机器人，使其能够感知、学习和行动。

Result: 提出世界模型的概念，包含多模态感知、推理规划和记忆等，并强调学习用户的心理模型的重要性。

Conclusion: 本论文研究了具身AI智能体在视觉、虚拟或物理环境中的交互作用，认为世界模型的构建对于具身AI智能体的推理和规划至关重要，并提出学习用户的心理模型以增强人机协作。

Abstract: This paper describes our research on AI agents embodied in visual, virtual or
physical forms, enabling them to interact with both users and their
environments. These agents, which include virtual avatars, wearable devices,
and robots, are designed to perceive, learn and act within their surroundings,
which makes them more similar to how humans learn and interact with the
environments as compared to disembodied agents. We propose that the development
of world models is central to reasoning and planning of embodied AI agents,
allowing these agents to understand and predict their environment, to
understand user intentions and social contexts, thereby enhancing their ability
to perform complex tasks autonomously. World modeling encompasses the
integration of multimodal perception, planning through reasoning for action and
control, and memory to create a comprehensive understanding of the physical
world. Beyond the physical world, we also propose to learn the mental world
model of users to enable better human-agent collaboration.

</details>


### [32] [AI Model Passport: Data and System Traceability Framework for Transparent AI in Health](https://arxiv.org/abs/2506.22358)
*Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou,The ProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: AI模型护照提高AI医疗应用的透明度和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有框架缺乏可扩展性、可比性和机器可解释性，难以保证AI模型的来源和真实性。

Method: 提出了一种结构化和标准化的文档框架——AI模型护照，并通过AIPassport工具进行实现，自动化元数据收集，确保版本控制，并与各种开发环境集成。

Result: AIPassport工具有效地提高了AI模型的透明度、可重复性和合规性，降低了人工成本。

Conclusion: 本文介绍了AI模型护照的概念及其在医疗影像应用中的实现，旨在提高AI系统的透明度、可重复性和合规性。

Abstract: The increasing integration of Artificial Intelligence (AI) into health and
biomedical systems necessitates robust frameworks for transparency,
accountability, and ethical compliance. Existing frameworks often rely on
human-readable, manual documentation which limits scalability, comparability,
and machine interpretability across projects and platforms. They also fail to
provide a unique, verifiable identity for AI models to ensure their provenance
and authenticity across systems and use cases, limiting reproducibility and
stakeholder trust. This paper introduces the concept of the AI Model Passport,
a structured and standardized documentation framework that acts as a digital
identity and verification tool for AI models. It captures essential metadata to
uniquely identify, verify, trace and monitor AI models across their lifecycle -
from data acquisition and preprocessing to model design, development and
deployment. In addition, an implementation of this framework is presented
through AIPassport, an MLOps tool developed within the ProCAncer-I EU project
for medical imaging applications. AIPassport automates metadata collection,
ensures proper versioning, decouples results from source scripts, and
integrates with various development environments. Its effectiveness is
showcased through a lesion segmentation use case using data from the
ProCAncer-I dataset, illustrating how the AI Model Passport enhances
transparency, reproducibility, and regulatory readiness while reducing manual
effort. This approach aims to set a new standard for fostering trust and
accountability in AI-driven healthcare solutions, aspiring to serve as the
basis for developing transparent and regulation compliant AI systems across
domains.

</details>


### [33] [SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents](https://arxiv.org/abs/2506.21669)
*Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang*

Main category: cs.AI

TL;DR: 新框架SEEA-R1通过改进奖励机制提升了具身智能体的自主进化能力，在ALFWorld基准测试中取得了最优结果。


<details>
  <summary>Details</summary>
Motivation: To enable self-evolving embodied intelligence capable of multi-modal interactions and overcome the limitations of sparse rewards and hand-crafted reward functions in reinforcement fine-tuning.

Method: Tree-based group relative policy optimization (Tree-GRPO) integrated with Monte Carlo Tree Search and a Multi-modal Generative Reward Model (MGRM).

Result: SEEA-R1 outperforms state-of-the-art methods on the ALFWorld benchmark, achieving 85.07% (textual) and 36.19% (multi-modal) scores, and 80.3% without environmental reward, surpassing all open-source baselines.

Conclusion: SEEA-R1, a novel reinforcement fine-tuning framework, surpasses state-of-the-art methods in embodied intelligence tasks by addressing the challenges of sparse rewards and generalization limitations.  It achieves this through Tree-GRPO for denser reward signals and MGRM for generalized reward estimation.

Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning
and behavior, is essential for the embodied domain with long-horizon,
real-world tasks. Despite current advancements in reinforcement fine-tuning
(RFT) showing strong performance in enhancing reasoning in LLMs, its potential
to enable self-evolving embodied intelligence with multi-modal interactions
remains largely unexplored. Specifically, reinforcement fine-tuning faces two
fundamental obstacles in embodied settings: (i) the lack of accessible
intermediate rewards in multi-step reasoning tasks limits effective learning
signals, and (ii) reliance on hand-crafted reward functions restricts
generalization to novel tasks and environments. To address these challenges, we
present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework
designed for enabling the self-evolving capabilities of embodied agents.
Specifically, to convert sparse delayed rewards into denser intermediate
signals that improve multi-step reasoning, we propose Tree-based group relative
policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into
GRPO. To generalize reward estimation across tasks and scenes, supporting
autonomous adaptation and reward-driven self-evolution, we further introduce
Multi-modal Generative Reward Model (MGRM). To holistically evaluate the
effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing
state-of-the-art methods with scores of 85.07% (textual) and 36.19%
(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also
achieves scores of 80.3% without environmental reward, surpassing all
open-source baselines and highlighting its scalability as a self-evolving
embodied agent. Additional experiments and qualitative analysis further support
the potential of SEEA-R1 for future research in scalable embodied intelligence.

</details>


### [34] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
*Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori*

Main category: cs.AI

TL;DR: HRM模型是一种高效、稳定的分层推理模型，在复杂推理任务中取得了突破性进展。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的推理能力面临挑战，例如任务分解脆弱、数据需求量大、延迟高等问题。

Method: 提出了一种新的递归架构——分层推理模型（HRM），该模型通过两个相互依赖的递归模块（高层模块和低层模块）执行顺序推理任务。

Result: HRM模型仅用2700万参数和1000个训练样本，在复杂数独和迷宫寻路等任务中取得了近乎完美的性能，并在ARC基准测试中超越了更大的模型。

Conclusion: HRM模型在复杂推理任务中取得了优异性能，超越了更大规模的模型，并展现出通向通用计算和通用推理系统的潜力。

Abstract: Reasoning, the process of devising and executing complex goal-oriented action
sequences, remains a critical challenge in AI. Current large language models
(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from
brittle task decomposition, extensive data requirements, and high latency.
Inspired by the hierarchical and multi-timescale processing in the human brain,
we propose the Hierarchical Reasoning Model (HRM), a novel recurrent
architecture that attains significant computational depth while maintaining
both training stability and efficiency. HRM executes sequential reasoning tasks
in a single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level module
responsible for slow, abstract planning, and a low-level module handling rapid,
detailed computations. With only 27 million parameters, HRM achieves
exceptional performance on complex reasoning tasks using only 1000 training
samples. The model operates without pre-training or CoT data, yet achieves
nearly perfect performance on challenging tasks including complex Sudoku
puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms
much larger models with significantly longer context windows on the Abstraction
and Reasoning Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and general-purpose
reasoning systems.

</details>


### [35] [THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?](https://arxiv.org/abs/2506.21763)
*Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu*

Main category: cs.AI

TL;DR: THE-Tree框架通过构建科学文献进化树，有效验证AI生成的科学命题，并在多个评估任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法不足以验证LLM生成的科学命题，缺乏结构化、可验证且因果关联的科学演化历史数据。

Method: 提出了一种名为THE-Tree的计算框架，该框架利用LLM提出潜在的科学进展并引用支持性文献，并通过自然语言推理机制验证每个进化步骤的逻辑连贯性和证据支持。

Result: 在图完成、预测未来科学发展和评估重要科学论文方面，THE-Tree相比传统方法均有显著提升。构建并验证了88个THE-Tree，并发布了一个包含多达71,000个事实验证和27,000篇论文的基准数据集。

Conclusion: THE-Tree框架通过构建领域特定进化树，有效提高了对AI生成科学命题的新颖性和准确性评估，并在图完成、预测未来科学发展和评估重要科学论文方面均取得了显著成果。

Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but
rigorously evaluating these numerous, often superficial, AI-generated
propositions for novelty and factual accuracy is a critical bottleneck; manual
verification is too slow.Existing validation methods are inadequate: LLMs as
standalone verifiers may hallucinate and lack domain knowledge (our findings
show ~60\% unawareness of relevant papers in specific domains), while
traditional citation networks lack explicit causality and narrative surveys are
unstructured.This underscores a core challenge: the absence of structured,
verifiable, and causally-linked historical data of scientific evolution.To
address this,we introduce \textbf{THE-Tree} (\textbf{T}echnology
\textbf{H}istory \textbf{E}volution Tree), a computational framework that
constructs such domain-specific evolution trees from scientific
literature.THE-Tree employs a search algorithm to explore evolutionary paths.
During its node expansion, it utilizes a novel "Think-Verbalize-Cite-Verify"
process: an LLM proposes potential advancements and cites supporting
literature. Critically, each proposed evolutionary link is then validated for
logical coherence and evidential support by a recovered natural language
inference mechanism that interrogates the cited literature, ensuring that each
step is grounded.We construct and validate 88 THE-Trees across diverse domains
and release a benchmark dataset including up to 71k fact verifications covering
27k papers to foster further research.Experiments demonstrate that i) in graph
completion, our THE-Tree improves hit@1 by 8\% to 14\% across multiple models
compared to traditional citation networks; ii) for predicting future scientific
developments, it improves hit@1 metric by nearly 10\%; and iii) when combined
with other methods, it boosts the performance of evaluating important
scientific papers by almost 100\%.

</details>


### [36] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

Main category: cs.AI

TL;DR: MobiVerse是一个高效且逼真的移动性模拟平台，能够处理大规模动态场景。


<details>
  <summary>Details</summary>
Motivation: 现有移动性模拟平台在数据收集、模型校准和计算效率方面存在不足，难以支持大规模、动态的模拟。

Method: 提出了一种混合框架MobiVerse，结合轻量级领域特定生成器和LLM，用于生成和动态调整代理人的活动链。

Result: MobiVerse成功地在洛杉矶Westwood地区对约53,000个代理人进行了高效模拟，并能够响应环境变化，例如道路封闭和大型活动。

Conclusion: MobiVerse框架有效地解决了现有移动性模拟平台的局限性，通过结合轻量级生成器和LLM的优势，实现了高效且行为逼真的大规模模拟。

Abstract: Understanding and modeling human mobility patterns is crucial for effective
transportation planning and urban development. Despite significant advances in
mobility research, there remains a critical gap in simulation platforms that
allow for algorithm development, policy implementation, and comprehensive
evaluation at scale. Traditional activity-based models require extensive data
collection and manual calibration, machine learning approaches struggle with
adaptation to dynamic conditions, and treding agent-based Large Language Models
(LLMs) implementations face computational constraints with large-scale
simulations. To address these challenges, we propose MobiVerse, a hybrid
framework leverages the efficiency of lightweight domain-specific generator for
generating base activity chains with the adaptability of LLMs for context-aware
modifications. A case study was conducted in Westwood, Los Angeles, where we
efficiently generated and dynamically adjusted schedules for the whole
population of approximately 53,000 agents on a standard PC. Our experiments
demonstrate that MobiVerse successfully enables agents to respond to
environmental feedback, including road closures, large gathering events like
football games, and congestion, through our hybrid framework. Its modular
design facilitates testing various mobility algorithms at both transportation
system and agent levels. Results show our approach maintains computational
efficiency while enhancing behavioral realism. MobiVerse bridges the gap in
mobility simulation by providing a customizable platform for mobility systems
planning and operations with benchmark algorithms. Code and videos are
available at https://github.com/ucla-mobility/MobiVerse.

</details>


### [37] [CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation](https://arxiv.org/abs/2506.21805)
*Nicolas Bougie,Narimasa Watanabe*

Main category: cs.AI

TL;DR: CitySim 使用大型语言模型模拟城市中人类行为，结果比以往更真实，并能用于预测城市现象。


<details>
  <summary>Details</summary>
Motivation: 对城市环境中人类行为的建模对于社会科学、行为研究和城市规划至关重要。以往工作依赖于僵化的、手工制作的规则，限制了其模拟细微意图、计划和适应性行为的能力。

Method: CitySim 利用大型语言模型的突破，采用递归价值驱动的方法生成代理的日常计划，并赋予代理信念、长期目标和空间记忆。

Result: CitySim 在模拟数万个代理及其在各种现实场景下的集体行为方面进行了有见地的实验，包括估计人群密度、预测地点受欢迎程度和评估福祉。

Conclusion: CitySim 是一款可扩展、灵活的测试平台，用于理解和预测城市现象。它在微观和宏观层面都比以往的工作更贴近真实人类行为。

Abstract: Modeling human behavior in urban environments is fundamental for social
science, behavioral studies, and urban planning. Prior work often rely on
rigid, hand-crafted rules, limiting their ability to simulate nuanced
intentions, plans, and adaptive behaviors. Addressing these challenges, we
envision an urban simulator (CitySim), capitalizing on breakthroughs in
human-level intelligence exhibited by large language models. In CitySim, agents
generate realistic daily schedules using a recursive value-driven approach that
balances mandatory activities, personal habits, and situational factors. To
enable long-term, lifelike simulations, we endow agents with beliefs, long-term
goals, and spatial memory for navigation. CitySim exhibits closer alignment
with real humans than prior work, both at micro and macro levels. Additionally,
we conduct insightful experiments by modeling tens of thousands of agents and
evaluating their collective behaviors under various real-world scenarios,
including estimating crowd density, predicting place popularity, and assessing
well-being. Our results highlight CitySim as a scalable, flexible testbed for
understanding and forecasting urban phenomena.

</details>


### [38] [Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds](https://arxiv.org/abs/2506.21887)
*Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.AI

TL;DR: Active-MoSH是一个交互式局部-全局框架，用于高风险决策，通过主动采样和多目标敏感性分析帮助决策者高效选择帕累托最优解，并增强其决策信任度。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏系统的方法来迭代细化多方面的偏好结构，难以在高风险决策中选择满足隐式偏好的帕累托最优解。

Method: Active-MoSH框架结合了局部组件（整合软硬边界和概率偏好学习）和全局组件（利用多目标敏感性分析），采用主动采样策略优化探索-利用过程，减少认知负担。

Result: 通过合成和真实世界的应用以及用户研究验证了Active-MoSH在提高收敛速度、增强决策者信任度和支持更有效偏好表达方面的性能优势。

Conclusion: Active-MoSH框架通过结合概率偏好学习和多目标敏感性分析，有效提高了高风险决策中的帕累托最优解选择效率，增强了决策者信任度，并支持更有效的偏好表达。

Abstract: High-stakes decision-making involves navigating multiple competing objectives
with expensive evaluations. For instance, in brachytherapy, clinicians must
balance maximizing tumor coverage (e.g., an aspirational target or soft bound
of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard
bound of <601 cGy to the bladder), with each plan evaluation being
resource-intensive. Selecting Pareto-optimal solutions that match implicit
preferences is challenging, as exhaustive Pareto frontier exploration is
computationally and cognitively prohibitive, necessitating interactive
frameworks to guide users. While decision-makers (DMs) often possess domain
knowledge to narrow the search via such soft-hard bounds, current methods often
lack systematic approaches to iteratively refine these multi-faceted preference
structures. Critically, DMs must trust their final decision, confident they
haven't missed superior alternatives; this trust is paramount in
high-consequence scenarios. We present Active-MoSH, an interactive local-global
framework designed for this process. Its local component integrates soft-hard
bounds with probabilistic preference learning, maintaining distributions over
DM preferences and bounds for adaptive Pareto subset refinement. This is guided
by an active sampling strategy optimizing exploration-exploitation while
minimizing cognitive burden. To build DM trust, Active-MoSH's global component,
T-MoSH, leverages multi-objective sensitivity analysis to identify potentially
overlooked, high-value points beyond immediate feedback. We demonstrate
Active-MoSH's performance benefits through diverse synthetic and real-world
applications. A user study on AI-generated image selection further validates
our hypotheses regarding the framework's ability to improve convergence,
enhance DM trust, and provide expressive preference articulation, enabling more
effective DMs.

</details>


### [39] [AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms](https://arxiv.org/abs/2506.21996)
*Raphaël Boige,Amine Boumaza,Bruno Scherrer*

Main category: cs.AI

TL;DR: 提出一种新的概率模型，更真实地模拟博弈树结构，并用该模型分析了AlphaBeta和Scout算法，发现后者效率更高。


<details>
  <summary>Details</summary>
Motivation: 传统的基于独立性的模型过于简化，无法反映真实博弈的结构复杂性。

Method: 提出了一种新的概率模型，该模型通过强制执行祖先依赖性来生成具有可调难度且保留一定分析可处理性的博弈树。

Result: 在新的模型下，对AlphaBeta和Scout算法的平均情况复杂度进行了分析，发现虽然渐近情况下所有算法收敛到相同的分支因子，但在深度有限的博弈树中，AlphaBeta算法的常数乘法因子显著大于Scout算法，导致实际运行速度较慢。

Conclusion: 本文介绍了一种新的概率模型来分析确定性博弈求解算法，该模型通过引入祖先依赖性来生成具有可调难度的博弈树，并推导出AlphaBeta和Scout等算法的平均情况复杂度递归公式，从而对算法进行更精确的比较。

Abstract: Deterministic game-solving algorithms are conventionally analyzed in the
light of their average-case complexity against a distribution of random
game-trees, where leaf values are independently sampled from a fixed
distribution. This simplified model enables uncluttered mathematical analysis,
revealing two key properties: root value distributions asymptotically collapse
to a single fixed value for finite-valued trees, and all reasonable algorithms
achieve global optimality. However, these findings are artifacts of the model's
design-its long criticized independence assumption strips games of structural
complexity, producing trivial instances where no algorithm faces meaningful
challenges. To address this limitation, we introduce a new probabilistic model
that incrementally constructs game-trees using a fixed level-wise conditional
distribution. By enforcing ancestor dependency, a critical structural feature
of real-world games, our framework generates problems with adjustable
difficulty while retaining some form of analytical tractability. For several
algorithms, including AlphaBeta and Scout, we derive recursive formulas
characterizing their average-case complexities under this model. These allow us
to rigorously compare algorithms on deep game-trees, where Monte-Carlo
simulations are no longer feasible. While asymptotically, all algorithms seem
to converge to identical branching factor (a result analogous to those of
independence-based models), deep finite trees reveal stark differences:
AlphaBeta incurs a significantly larger constant multiplicative factor compared
to algorithms like Scout, leading to a substantial practical slowdown. Our
framework sheds new light on classical game-solving algorithms, offering
rigorous evidence and analytical tools to advance the understanding of these
methods under a more realistic, challenging, and yet tractable model.

</details>


### [40] [LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving](https://arxiv.org/abs/2506.22005)
*Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda*

Main category: cs.AI

TL;DR: 利用LLM生成大量数学猜想，并成功验证了一些非平凡定理，为定理证明系统提供训练数据。


<details>
  <summary>Details</summary>
Motivation: 解决形式化定理证明中的数据稀缺性挑战，并为定理证明系统创建训练数据。

Method: 该项目采用混合方法，结合基于规则的上下文提取和基于LLM的定理陈述生成。

Result: 生成了12289个猜想，其中3776个语法有效且非平凡；验证了几个人拓扑学中的非平凡定理；平均每个种子文件生成103.25个新猜想。

Conclusion: LeanConjecturer项目成功地利用大型语言模型(LLM)结合基于规则的上下文提取，从40个Mathlib种子文件中生成了12289个数学猜想，其中3776个被鉴定为语法有效且非平凡的。该项目验证了几个人拓扑学中的非平凡定理，证明了其在数学发现方面的潜力。

Abstract: We introduce LeanConjecturer, a pipeline for automatically generating
university-level mathematical conjectures in Lean 4 using Large Language Models
(LLMs). Our hybrid approach combines rule-based context extraction with
LLM-based theorem statement generation, addressing the data scarcity challenge
in formal theorem proving. Through iterative generation and evaluation,
LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with
3,776 identified as syntactically valid and non-trivial, that is, cannot be
proven by \texttt{aesop} tactic. We demonstrate the utility of these generated
conjectures for reinforcement learning through Group Relative Policy
Optimization (GRPO), showing that targeted training on domain-specific
conjectures can enhance theorem proving capabilities. Our approach generates
103.25 novel conjectures per seed file on average, providing a scalable
solution for creating training data for theorem proving systems. Our system
successfully verified several non-trivial theorems in topology, including
properties of semi-open, alpha-open, and pre-open sets, demonstrating its
potential for mathematical discovery beyond simple variations of existing
results.

</details>


### [41] [Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/abs/2506.22056)
*Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong*

Main category: cs.AI

TL;DR: 提出一种多模态轨迹检索框架GAE-Retriever，并在多个数据集上取得了比现有方法更好的结果。


<details>
  <summary>Details</summary>
Motivation: 弥合通用检索和以代理为中心的轨迹建模之间的差距，解决轨迹数据表示建模的挑战。

Method: 构建了统一的代理轨迹数据集 (UATD)；提出GAE-Retriever，一个采用视觉语言模型并结合优化对比学习的多模态检索框架。

Result: GAE-Retriever在检索查全率方面优于强基线。

Conclusion: GAE-Retriever，一个多模态检索框架，在检索查全率方面始终优于强基线，有效地促进了多模态轨迹检索的发展。

Abstract: Trajectory data, capturing human actions and environmental states across
various modalities, holds significant potential for enhancing AI agent
capabilities, particularly in GUI environments. However, how to model the
representation of trajectory-level data presents a significant challenge that
has not been systematically addressed amid explosive trajectory data growth. In
this work, we introduce Multimodal Trajectory Retrieval, bridging the gap
between universal retrieval and agent-centric trajectory modeling. We construct
the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and
states across diverse real-world scenarios. Based on this, we present
GAE-Bench, a benchmark containing a large number of trajectory-based retrieval
pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework
that adopts vision-language models and incorporates optimized contrastive
learning through a token selection and the GradCache mechanism. Comprehensive
evaluations across multiple datasets show that GAE-Retriever consistently
outperforms strong baselines in retrieval recall, highlighting its
effectiveness in advancing multimodal trajectory retrieval.

</details>


### [42] [Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](https://arxiv.org/abs/2506.22068)
*Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang*

Main category: cs.AI

TL;DR: 新方法QaT和ESN解决AI交通系统数据碎片化问题，提高测试效率和安全性。


<details>
  <summary>Details</summary>
Motivation: Address data fragmentation and incompatibility in intelligent cockpits, autonomous driving, and intelligent road networks; improve testing methods for autonomous driving systems.

Method: Proposes Query as Test (QaT) and Extensible Scenarios Notations (ESN) for testing autonomous driving systems. ESN uses Answer Set Programming for data representation.

Result: Introduces QaT and ESN, demonstrating improved data representation, flexible querying, and enhanced testing rigor.  Proposes VDD as a new development paradigm.

Conclusion: This paper introduces Query as Test (QaT) and Extensible Scenarios Notations (ESN) to address data fragmentation and incompatibility issues in AI-powered transportation systems.  ESN, based on Answer Set Programming, enables semantic data fusion and supports flexible querying, interpretability, and privacy protection. QaT transforms functional validation and safety checks into logical queries, enhancing testing rigor.  The paper also proposes Validation-Driven Development (VDD) to accelerate development using logical validation.

Abstract: With the deep penetration of Artificial Intelligence (AI) in the
transportation sector, intelligent cockpits, autonomous driving, and
intelligent road networks are developing at an unprecedented pace. However, the
data ecosystems of these three key areas are increasingly fragmented and
incompatible. Especially, existing testing methods rely on data stacking, fail
to cover all edge cases, and lack flexibility. To address this issue, this
paper introduces the concept of "Query as Test" (QaT). This concept shifts the
focus from rigid, prescripted test cases to flexible, on-demand logical queries
against a unified data representation. Specifically, we identify the need for a
fundamental improvement in data storage and representation, leading to our
proposal of "Extensible Scenarios Notations" (ESN). ESN is a novel declarative
data framework based on Answer Set Programming (ASP), which uniformly
represents heterogeneous multimodal data from the cockpit, vehicle, and road as
a collection of logical facts and rules. This approach not only achieves deep
semantic fusion of data, but also brings three core advantages: (1) supports
complex and flexible semantic querying through logical reasoning; (2) provides
natural interpretability for decision-making processes; (3) allows for
on-demand data abstraction through logical rules, enabling fine-grained privacy
protection. We further elaborate on the QaT paradigm, transforming the
functional validation and safety compliance checks of autonomous driving
systems into logical queries against the ESN database, significantly enhancing
the expressiveness and formal rigor of the testing. Finally, we introduce the
concept of "Validation-Driven Development" (VDD), which suggests to guide
developments by logical validation rather than quantitative testing in the era
of Large Language Models, in order to accelerating the iteration and
development process.

</details>


### [43] [A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety](https://arxiv.org/abs/2506.22183)
*Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon*

Main category: cs.AI

TL;DR: 开放性增强AI安全，但仍需改进多模态和多语言基准、针对自主系统攻击的防御以及参与机制，以实现更安全、负责任的AI发展。


<details>
  <summary>Details</summary>
Motivation: 开放权重和开源基础模型的快速兴起，加剧了使人工智能系统安全的义务，并重塑了机会。

Method: 参与式、面向解决方案的过程，包括来自学术界、工业界、民间社会和政府的 45 多名研究人员、工程师和政策领导者。

Result: 制定了关于安全与开源人工智能交叉点的研究议程；绘制了现有和需要的技术干预措施和开源工具，以安全和负责任地在整个 AI 开发工作流程中部署开放基础模型；绘制了内容安全过滤器生态系统的图谱，并提出了未来研究和发展的路线图。

Conclusion: 开放性（透明的权重、可互操作的工具和公共治理）可以增强安全性，但仍存在差距，例如缺乏多模态和多语言基准、针对自主系统的提示注入和组合攻击的防御有限，以及参与机制不足等。

Abstract: The rapid rise of open-weight and open-source foundation models is
intensifying the obligation and reshaping the opportunity to make AI systems
safe. This paper reports outcomes from the Columbia Convening on AI Openness
and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme
involving more than forty-five researchers, engineers, and policy leaders from
academia, industry, civil society, and government. Using a participatory,
solutions-oriented process, the working groups produced (i) a research agenda
at the intersection of safety and open source AI; (ii) a mapping of existing
and needed technical interventions and open source tools to safely and
responsibly deploy open foundation models across the AI development workflow;
and (iii) a mapping of the content safety filter ecosystem with a proposed
roadmap for future research and development. We find that openness --
understood as transparent weights, interoperable tooling, and public governance
-- can enhance safety by enabling independent scrutiny, decentralized
mitigation, and culturally plural oversight. However, significant gaps persist:
scarce multimodal and multilingual benchmarks, limited defenses against
prompt-injection and compositional attacks in agentic systems, and insufficient
participatory mechanisms for communities most affected by AI harms. The paper
concludes with a roadmap of five priority research directions, emphasizing
participatory inputs, future-proof content filters, ecosystem-wide safety
infrastructure, rigorous agentic safeguards, and expanded harm taxonomies.
These recommendations informed the February 2025 French AI Action Summit and
lay groundwork for an open, plural, and accountable AI safety discipline.

</details>


### [44] [Breaking Rank Bottlenecks in Knowledge Graph Completion](https://arxiv.org/abs/2506.22271)
*Samy Badreddine,Emile van Krieken,Luciano Serafini*

Main category: cs.AI

TL;DR: 针对知识图谱补全模型中秩瓶颈问题，提出KGE-MoS混合输出层模型，实验表明有效提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱补全模型普遍存在秩瓶颈问题，限制了模型表达能力，影响了排序精度和分数分布保真度。

Method: 理论分析和实验验证，提出KGE-MoS混合输出层模型。

Result: 在四个数据集上的实验结果表明，KGE-MoS模型在参数开销较低的情况下，提升了知识图谱补全模型的性能和概率拟合度。

Conclusion: KGE-MoS模型通过使用混合输出层有效解决了知识图谱补全模型中秩瓶颈问题，提高了模型的性能和概率拟合度。

Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful
encoders, rely on a simple vector-matrix multiplication to score queries
against candidate object entities. When the number of entities is larger than
the model's embedding dimension, which in practical scenarios is often by
several orders of magnitude, we have a linear output layer with a rank
bottleneck. Such bottlenecked layers limit model expressivity. We investigate
both theoretically and empirically how rank bottlenecks affect KGC models. We
find that, by limiting the set of feasible predictions, rank bottlenecks hurt
ranking accuracy and the distribution fidelity of scores. Inspired by the
language modelling literature, we propose KGE-MoS, a mixture-based output layer
to break rank bottlenecks in many KGC models. Our experiments on four datasets
show that KGE-MoS improves performance and probabilistic fit of KGC models for
a low parameter cost.

</details>


### [45] [Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates](https://arxiv.org/abs/2506.22276)
*Reuth Mirsky*

Main category: cs.AI

TL;DR: 论文倡导赋予AI“智能违抗”能力，使其在人机合作中更有效。


<details>
  <summary>Details</summary>
Motivation: 当前大多数合作AI系统仍然僵化地服从指令，即使这样做可能适得其反或不安全。

Method: 该论文介绍了AI自主性水平的量表，并用代表性例子强调了将AI自主性作为合作环境中独立研究重点的重要性。

Result: 探讨了智能违抗如何在不同自主性水平上体现。

Conclusion: 该论文主张扩展AI队友的自主性，使其能够进行"智能违抗"，并在人机团队中做出有意义的自主贡献，并提出了研究智能违抗作为人工代理核心能力的初步界限和考虑。

Abstract: Artificial intelligence has made remarkable strides in recent years,
achieving superhuman performance across a wide range of tasks. Yet despite
these advances, most cooperative AI systems remain rigidly obedient, designed
to follow human instructions without question and conform to user expectations,
even when doing so may be counterproductive or unsafe. This paper argues for
expanding the agency of AI teammates to include \textit{intelligent
disobedience}, empowering them to make meaningful and autonomous contributions
within human-AI teams. It introduces a scale of AI agency levels and uses
representative examples to highlight the importance and growing necessity of
treating AI autonomy as an independent research focus in cooperative settings.
The paper then explores how intelligent disobedience manifests across different
autonomy levels and concludes by proposing initial boundaries and
considerations for studying disobedience as a core capability of artificial
agents.

</details>


### [46] [Conceptual Topic Aggregation](https://arxiv.org/abs/2506.22309)
*Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme*

Main category: cs.AI

TL;DR: FAT-CAT利用形式概念分析，改进主题建模，提升结果的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统人工检查方法已无法应对海量数据的挑战，因此需要采用计算方法进行高效的数据探索。现有的主题建模方法通常难以提供易于理解的表示，难以深入了解数据结构和内容。

Method: 提出了一种基于形式概念分析（FCA）的主题建模方法FAT-CAT，该方法能够处理不同的主题和文件类型，构建概念格，提供主题分布的结构化层次表示。

Result: 通过对ETYNTKE数据集的案例研究，证明了基于FCA的聚合方法比现有的主题建模技术能提供更有意义和可解释性的见解。

Conclusion: FAT-CAT方法，一种基于形式概念分析（FCA）的主题建模方法，能够更有效地聚合和可视化主题，从而提供对数据集组成更有意义和可解释性的见解。

Abstract: The vast growth of data has rendered traditional manual inspection
infeasible, necessitating the adoption of computational methods for efficient
data exploration. Topic modeling has emerged as a powerful tool for analyzing
large-scale textual datasets, enabling the extraction of latent semantic
structures. However, existing methods for topic modeling often struggle to
provide interpretable representations that facilitate deeper insights into data
structure and content. In this paper, we propose FAT-CAT, an approach based on
Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and
visualization of discovered topics. Our approach can handle diverse topics and
file types -- grouped by directories -- to construct a concept lattice that
offers a structured, hierarchical representation of their topic distribution.
In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our
approach against other representation methods to demonstrate that FCA-based
aggregation provides more meaningful and interpretable insights into dataset
composition than existing topic modeling techniques.

</details>


### [47] [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
*Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik*

Main category: cs.AI

TL;DR: 具身AI智能体通过构建世界模型，学习用户 mental world model，从而更好地与环境和用户交互，自主完成复杂任务。


<details>
  <summary>Details</summary>
Motivation: 希望开发出更类似于人类学习和交互方式的AI智能体，使其能够自主执行复杂任务。

Method: 研究具身AI智能体（虚拟化身、可穿戴设备和机器人），通过多模态感知、推理规划和记忆构建世界模型，学习用户 mental world model。

Result: 提出世界模型构建对于具身AI推理和规划的重要性，以及学习用户mental world model以增强人机协作。

Conclusion: 该论文研究具身AI智能体在视觉、虚拟或物理环境中的交互作用，认为世界模型的构建对于具身AI的推理和规划至关重要，并提出学习用户的 mental world model 以增强人机协作。

Abstract: This paper describes our research on AI agents embodied in visual, virtual or
physical forms, enabling them to interact with both users and their
environments. These agents, which include virtual avatars, wearable devices,
and robots, are designed to perceive, learn and act within their surroundings,
which makes them more similar to how humans learn and interact with the
environments as compared to disembodied agents. We propose that the development
of world models is central to reasoning and planning of embodied AI agents,
allowing these agents to understand and predict their environment, to
understand user intentions and social contexts, thereby enhancing their ability
to perform complex tasks autonomously. World modeling encompasses the
integration of multimodal perception, planning through reasoning for action and
control, and memory to create a comprehensive understanding of the physical
world. Beyond the physical world, we also propose to learn the mental world
model of users to enable better human-agent collaboration.

</details>


### [48] [AI Model Passport: Data and System Traceability Framework for Transparent AI in Health](https://arxiv.org/abs/2506.22358)
*Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou,The ProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: AI模型护照提高医疗AI系统的透明度、可重复性和合规性


<details>
  <summary>Details</summary>
Motivation: 现有的框架缺乏可扩展性、可比性和机器可解释性，且无法保证AI模型的来源和真实性。

Method: 提出了一种结构化和标准化的文档框架——AI模型护照，并开发了MLOps工具AIPassport进行实现。

Result: 通过一个病灶分割的案例研究，展示了AI模型护照如何提高透明度、可重复性和监管准备情况，同时减少人工工作。

Conclusion: 本文介绍了AI模型护照的概念及其在医疗影像应用中的实现，旨在提高AI系统的透明度、可重复性和合规性。

Abstract: The increasing integration of Artificial Intelligence (AI) into health and
biomedical systems necessitates robust frameworks for transparency,
accountability, and ethical compliance. Existing frameworks often rely on
human-readable, manual documentation which limits scalability, comparability,
and machine interpretability across projects and platforms. They also fail to
provide a unique, verifiable identity for AI models to ensure their provenance
and authenticity across systems and use cases, limiting reproducibility and
stakeholder trust. This paper introduces the concept of the AI Model Passport,
a structured and standardized documentation framework that acts as a digital
identity and verification tool for AI models. It captures essential metadata to
uniquely identify, verify, trace and monitor AI models across their lifecycle -
from data acquisition and preprocessing to model design, development and
deployment. In addition, an implementation of this framework is presented
through AIPassport, an MLOps tool developed within the ProCAncer-I EU project
for medical imaging applications. AIPassport automates metadata collection,
ensures proper versioning, decouples results from source scripts, and
integrates with various development environments. Its effectiveness is
showcased through a lesion segmentation use case using data from the
ProCAncer-I dataset, illustrating how the AI Model Passport enhances
transparency, reproducibility, and regulatory readiness while reducing manual
effort. This approach aims to set a new standard for fostering trust and
accountability in AI-driven healthcare solutions, aspiring to serve as the
basis for developing transparent and regulation compliant AI systems across
domains.

</details>


### [49] [SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents](https://arxiv.org/abs/2506.21669)
*Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang*

Main category: cs.AI

TL;DR: 新型强化微调框架SEEA-R1通过解决多步推理任务中稀疏奖励和泛化能力有限的问题，实现了自我进化的具身智能体。在ALFWorld基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: To overcome the limitations of existing reinforcement fine-tuning methods in embodied AI, particularly the lack of accessible intermediate rewards and the dependence on hand-crafted reward functions.

Method: The framework uses Tree-based group relative policy optimization (Tree-GRPO), integrating Monte Carlo Tree Search into GRPO, to generate denser intermediate rewards.  A Multi-modal Generative Reward Model (MGRM) is introduced to enable generalization across tasks and scenes.

Result: SEEA-R1 surpasses state-of-the-art methods on the ALFWorld benchmark, achieving 85.07% (textual) and 36.19% (multi-modal) scores, and 80.3% without environmental rewards, showcasing its self-evolving capabilities and scalability.

Conclusion: SEEA-R1, a novel reinforcement fine-tuning framework, enables self-evolving embodied agents by addressing the challenges of sparse rewards and limited generalization in multi-step reasoning tasks.  It achieves state-of-the-art results on the ALFWorld benchmark, surpassing existing methods in both textual and multi-modal performance, even without environmental rewards.

Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning
and behavior, is essential for the embodied domain with long-horizon,
real-world tasks. Despite current advancements in reinforcement fine-tuning
(RFT) showing strong performance in enhancing reasoning in LLMs, its potential
to enable self-evolving embodied intelligence with multi-modal interactions
remains largely unexplored. Specifically, reinforcement fine-tuning faces two
fundamental obstacles in embodied settings: (i) the lack of accessible
intermediate rewards in multi-step reasoning tasks limits effective learning
signals, and (ii) reliance on hand-crafted reward functions restricts
generalization to novel tasks and environments. To address these challenges, we
present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework
designed for enabling the self-evolving capabilities of embodied agents.
Specifically, to convert sparse delayed rewards into denser intermediate
signals that improve multi-step reasoning, we propose Tree-based group relative
policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into
GRPO. To generalize reward estimation across tasks and scenes, supporting
autonomous adaptation and reward-driven self-evolution, we further introduce
Multi-modal Generative Reward Model (MGRM). To holistically evaluate the
effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing
state-of-the-art methods with scores of 85.07% (textual) and 36.19%
(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also
achieves scores of 80.3% without environmental reward, surpassing all
open-source baselines and highlighting its scalability as a self-evolving
embodied agent. Additional experiments and qualitative analysis further support
the potential of SEEA-R1 for future research in scalable embodied intelligence.

</details>


### [50] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
*Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori*

Main category: cs.AI

TL;DR: 新型分层推理模型(HRM)在复杂推理任务中取得突破性进展，效率高，性能优异，有望推动通用人工智能发展。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM主要采用思维链(CoT)技术，存在任务分解脆弱、数据需求量大、延迟高等问题。本文受人脑分层和多时间尺度处理机制的启发，提出了一种更高效稳定的模型。

Method: 提出了一种新的递归架构——分层推理模型(HRM)，该模型通过两个相互依赖的递归模块(高层模块和低层模块)执行顺序推理任务，无需对中间过程进行明确监督。

Result: HRM模型仅用2700万参数，在1000个训练样本下，就能在复杂的推理任务(例如数独和迷宫寻路)中达到近乎完美的性能，并在ARC基准测试中超越了更大的模型。

Conclusion: HRM模型在复杂推理任务中取得了优异性能，并超越了更大的模型，展现了其在通用计算和通用推理系统方面的巨大潜力。

Abstract: Reasoning, the process of devising and executing complex goal-oriented action
sequences, remains a critical challenge in AI. Current large language models
(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from
brittle task decomposition, extensive data requirements, and high latency.
Inspired by the hierarchical and multi-timescale processing in the human brain,
we propose the Hierarchical Reasoning Model (HRM), a novel recurrent
architecture that attains significant computational depth while maintaining
both training stability and efficiency. HRM executes sequential reasoning tasks
in a single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level module
responsible for slow, abstract planning, and a low-level module handling rapid,
detailed computations. With only 27 million parameters, HRM achieves
exceptional performance on complex reasoning tasks using only 1000 training
samples. The model operates without pre-training or CoT data, yet achieves
nearly perfect performance on challenging tasks including complex Sudoku
puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms
much larger models with significantly longer context windows on the Abstraction
and Reasoning Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and general-purpose
reasoning systems.

</details>


### [51] [THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?](https://arxiv.org/abs/2506.21763)
*Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu*

Main category: cs.AI

TL;DR: THE-Tree框架通过构建领域特定进化树，利用LLM和自然语言推理机制验证科学发展路径，显著提升了科学发展预测和重要论文评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有验证方法不足以评估AI生成的科学命题的新颖性和准确性，缺乏结构化、可验证且因果关联的科学演化历史数据。

Method: 构建领域特定进化树(THE-Tree)，利用LLM提出潜在进展并引用支持文献，再通过自然语言推理机制验证每个进化步骤的逻辑连贯性和证据支持。

Result: 实验表明，THE-Tree在图谱补全和预测未来科学发展方面均优于传统方法，并能显著提升重要科学论文评估性能。

Conclusion: THE-Tree框架通过构建领域特定进化树，提高了科学发展预测和重要论文评估的准确性，并提供了一个包含71,000个事实验证的大型基准数据集。

Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but
rigorously evaluating these numerous, often superficial, AI-generated
propositions for novelty and factual accuracy is a critical bottleneck; manual
verification is too slow.Existing validation methods are inadequate: LLMs as
standalone verifiers may hallucinate and lack domain knowledge (our findings
show ~60\% unawareness of relevant papers in specific domains), while
traditional citation networks lack explicit causality and narrative surveys are
unstructured.This underscores a core challenge: the absence of structured,
verifiable, and causally-linked historical data of scientific evolution.To
address this,we introduce \textbf{THE-Tree} (\textbf{T}echnology
\textbf{H}istory \textbf{E}volution Tree), a computational framework that
constructs such domain-specific evolution trees from scientific
literature.THE-Tree employs a search algorithm to explore evolutionary paths.
During its node expansion, it utilizes a novel "Think-Verbalize-Cite-Verify"
process: an LLM proposes potential advancements and cites supporting
literature. Critically, each proposed evolutionary link is then validated for
logical coherence and evidential support by a recovered natural language
inference mechanism that interrogates the cited literature, ensuring that each
step is grounded.We construct and validate 88 THE-Trees across diverse domains
and release a benchmark dataset including up to 71k fact verifications covering
27k papers to foster further research.Experiments demonstrate that i) in graph
completion, our THE-Tree improves hit@1 by 8\% to 14\% across multiple models
compared to traditional citation networks; ii) for predicting future scientific
developments, it improves hit@1 metric by nearly 10\%; and iii) when combined
with other methods, it boosts the performance of evaluating important
scientific papers by almost 100\%.

</details>


### [52] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

Main category: cs.AI

TL;DR: MobiVerse:  高效且真实的混合框架，用于大规模人群移动模拟，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有移动模拟平台存在数据收集困难、适应性差和计算成本高等问题。

Method: 提出了一种混合框架MobiVerse，结合轻量级领域特定生成器和LLM，用于生成和动态调整代理活动链。

Result: MobiVerse能够高效且真实地模拟大规模人群移动，并对环境变化做出反应，为交通系统规划和运营提供了一个定制化平台。

Conclusion: MobiVerse是一个混合框架，有效地结合了轻量级领域特定生成器和LLM，用于大规模人群移动模拟，并在洛杉矶西木区进行了案例研究，证明其能够高效地生成和动态调整约53,000个代理的行程安排，并对环境反馈做出反应。

Abstract: Understanding and modeling human mobility patterns is crucial for effective
transportation planning and urban development. Despite significant advances in
mobility research, there remains a critical gap in simulation platforms that
allow for algorithm development, policy implementation, and comprehensive
evaluation at scale. Traditional activity-based models require extensive data
collection and manual calibration, machine learning approaches struggle with
adaptation to dynamic conditions, and treding agent-based Large Language Models
(LLMs) implementations face computational constraints with large-scale
simulations. To address these challenges, we propose MobiVerse, a hybrid
framework leverages the efficiency of lightweight domain-specific generator for
generating base activity chains with the adaptability of LLMs for context-aware
modifications. A case study was conducted in Westwood, Los Angeles, where we
efficiently generated and dynamically adjusted schedules for the whole
population of approximately 53,000 agents on a standard PC. Our experiments
demonstrate that MobiVerse successfully enables agents to respond to
environmental feedback, including road closures, large gathering events like
football games, and congestion, through our hybrid framework. Its modular
design facilitates testing various mobility algorithms at both transportation
system and agent levels. Results show our approach maintains computational
efficiency while enhancing behavioral realism. MobiVerse bridges the gap in
mobility simulation by providing a customizable platform for mobility systems
planning and operations with benchmark algorithms. Code and videos are
available at https://github.com/ucla-mobility/MobiVerse.

</details>


### [53] [CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation](https://arxiv.org/abs/2506.21805)
*Nicolas Bougie,Narimasa Watanabe*

Main category: cs.AI

TL;DR: CitySim使用大型语言模型模拟人类城市行为，结果更真实，可用于预测城市现象。


<details>
  <summary>Details</summary>
Motivation: 现有城市模拟器依赖于僵化的、手工设计的规则，难以模拟细致的意图、计划和适应性行为。

Method: 基于大型语言模型的递归价值驱动方法，赋予智能体信念、长期目标和空间记忆。

Result: CitySim模拟器在微观和宏观层面都比现有工作更接近真实人类行为，能够进行大规模模拟，并应用于人群密度估计、地点受欢迎程度预测和幸福感评估等任务。

Conclusion: CitySim城市模拟器能够更真实地模拟人类行为，并在微观和宏观层面与真实人类行为更接近。它可以用于估计人群密度、预测地点受欢迎程度和评估幸福感等任务。

Abstract: Modeling human behavior in urban environments is fundamental for social
science, behavioral studies, and urban planning. Prior work often rely on
rigid, hand-crafted rules, limiting their ability to simulate nuanced
intentions, plans, and adaptive behaviors. Addressing these challenges, we
envision an urban simulator (CitySim), capitalizing on breakthroughs in
human-level intelligence exhibited by large language models. In CitySim, agents
generate realistic daily schedules using a recursive value-driven approach that
balances mandatory activities, personal habits, and situational factors. To
enable long-term, lifelike simulations, we endow agents with beliefs, long-term
goals, and spatial memory for navigation. CitySim exhibits closer alignment
with real humans than prior work, both at micro and macro levels. Additionally,
we conduct insightful experiments by modeling tens of thousands of agents and
evaluating their collective behaviors under various real-world scenarios,
including estimating crowd density, predicting place popularity, and assessing
well-being. Our results highlight CitySim as a scalable, flexible testbed for
understanding and forecasting urban phenomena.

</details>


### [54] [Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds](https://arxiv.org/abs/2506.21887)
*Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.AI

TL;DR: Active-MoSH是一个交互式局部-全局框架，用于解决高风险决策中的多目标优化问题，通过结合概率偏好学习和多目标敏感性分析，提高决策效率和信任度。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理高风险决策中多目标优化问题，尤其是在评估成本高昂且需要考虑软硬约束的情况下。

Method: Active-MoSH框架结合了局部和全局组件：局部组件利用概率偏好学习和主动采样策略迭代细化多方面偏好结构；全局组件T-MoSH利用多目标敏感性分析识别潜在的被忽视的高价值点。

Result: Active-MoSH在合成数据和真实世界应用中均表现出性能优势，用户研究也验证了其在提高决策收敛性、增强决策者信任度和表达偏好方面的有效性。

Conclusion: Active-MoSH框架通过结合概率偏好学习和多目标敏感性分析，有效解决了高风险决策中多目标优化问题，提高了决策效率和信任度。

Abstract: High-stakes decision-making involves navigating multiple competing objectives
with expensive evaluations. For instance, in brachytherapy, clinicians must
balance maximizing tumor coverage (e.g., an aspirational target or soft bound
of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard
bound of <601 cGy to the bladder), with each plan evaluation being
resource-intensive. Selecting Pareto-optimal solutions that match implicit
preferences is challenging, as exhaustive Pareto frontier exploration is
computationally and cognitively prohibitive, necessitating interactive
frameworks to guide users. While decision-makers (DMs) often possess domain
knowledge to narrow the search via such soft-hard bounds, current methods often
lack systematic approaches to iteratively refine these multi-faceted preference
structures. Critically, DMs must trust their final decision, confident they
haven't missed superior alternatives; this trust is paramount in
high-consequence scenarios. We present Active-MoSH, an interactive local-global
framework designed for this process. Its local component integrates soft-hard
bounds with probabilistic preference learning, maintaining distributions over
DM preferences and bounds for adaptive Pareto subset refinement. This is guided
by an active sampling strategy optimizing exploration-exploitation while
minimizing cognitive burden. To build DM trust, Active-MoSH's global component,
T-MoSH, leverages multi-objective sensitivity analysis to identify potentially
overlooked, high-value points beyond immediate feedback. We demonstrate
Active-MoSH's performance benefits through diverse synthetic and real-world
applications. A user study on AI-generated image selection further validates
our hypotheses regarding the framework's ability to improve convergence,
enhance DM trust, and provide expressive preference articulation, enabling more
effective DMs.

</details>


### [55] [AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms](https://arxiv.org/abs/2506.21996)
*Raphaël Boige,Amine Boumaza,Bruno Scherrer*

Main category: cs.AI

TL;DR: 新模型更真实地模拟了博弈树的结构，分析表明AlphaBeta算法效率低于Scout算法


<details>
  <summary>Details</summary>
Motivation: 传统的基于随机独立性假设的模型过于简化，无法反映真实博弈的复杂性。

Method: 提出了一种新的概率模型，该模型通过强制祖先依赖关系来构建博弈树，并对AlphaBeta和Scout算法进行了分析。

Result: 提出了一个新的概率模型，并对AlphaBeta和Scout算法的平均情况复杂度进行了分析，结果表明在深度有限树上，AlphaBeta算法的效率低于Scout算法。

Conclusion: 本文介绍了一种新的概率模型来分析确定性博弈求解算法，该模型通过引入祖先依赖性来生成具有可调难度的博弈树，并对AlphaBeta和Scout等算法的平均情况复杂度进行了分析，结果表明虽然渐进上所有算法收敛到相同的branching factor，但在深度有限树上，AlphaBeta算法的常数乘法因子远大于Scout算法，导致实际运行速度显著下降。

Abstract: Deterministic game-solving algorithms are conventionally analyzed in the
light of their average-case complexity against a distribution of random
game-trees, where leaf values are independently sampled from a fixed
distribution. This simplified model enables uncluttered mathematical analysis,
revealing two key properties: root value distributions asymptotically collapse
to a single fixed value for finite-valued trees, and all reasonable algorithms
achieve global optimality. However, these findings are artifacts of the model's
design-its long criticized independence assumption strips games of structural
complexity, producing trivial instances where no algorithm faces meaningful
challenges. To address this limitation, we introduce a new probabilistic model
that incrementally constructs game-trees using a fixed level-wise conditional
distribution. By enforcing ancestor dependency, a critical structural feature
of real-world games, our framework generates problems with adjustable
difficulty while retaining some form of analytical tractability. For several
algorithms, including AlphaBeta and Scout, we derive recursive formulas
characterizing their average-case complexities under this model. These allow us
to rigorously compare algorithms on deep game-trees, where Monte-Carlo
simulations are no longer feasible. While asymptotically, all algorithms seem
to converge to identical branching factor (a result analogous to those of
independence-based models), deep finite trees reveal stark differences:
AlphaBeta incurs a significantly larger constant multiplicative factor compared
to algorithms like Scout, leading to a substantial practical slowdown. Our
framework sheds new light on classical game-solving algorithms, offering
rigorous evidence and analytical tools to advance the understanding of these
methods under a more realistic, challenging, and yet tractable model.

</details>


### [56] [LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving](https://arxiv.org/abs/2506.22005)
*Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda*

Main category: cs.AI

TL;DR: 利用大型语言模型自动生成数学猜想，为定理证明系统提供训练数据，并成功验证了一些非平凡定理。


<details>
  <summary>Details</summary>
Motivation: 解决形式化定理证明中的数据稀缺问题，并为定理证明系统创建训练数据。

Method: 该项目采用混合方法，结合了基于规则的上下文提取和基于大型语言模型的定理陈述生成。

Result: 生成了12289个猜想，其中3776个语法有效且非平凡；验证了几个拓扑学中的非平凡定理；展示了其增强定理证明能力的潜力。

Conclusion: LeanConjecturer项目成功地利用大型语言模型结合规则生成方法，从40个Mathlib种子文件中自动生成了12289个数学猜想，其中3776个是语法有效且非平凡的。该项目验证了其在拓扑学等领域的非平凡定理，并证明了其在增强定理证明能力方面的潜力。

Abstract: We introduce LeanConjecturer, a pipeline for automatically generating
university-level mathematical conjectures in Lean 4 using Large Language Models
(LLMs). Our hybrid approach combines rule-based context extraction with
LLM-based theorem statement generation, addressing the data scarcity challenge
in formal theorem proving. Through iterative generation and evaluation,
LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with
3,776 identified as syntactically valid and non-trivial, that is, cannot be
proven by \texttt{aesop} tactic. We demonstrate the utility of these generated
conjectures for reinforcement learning through Group Relative Policy
Optimization (GRPO), showing that targeted training on domain-specific
conjectures can enhance theorem proving capabilities. Our approach generates
103.25 novel conjectures per seed file on average, providing a scalable
solution for creating training data for theorem proving systems. Our system
successfully verified several non-trivial theorems in topology, including
properties of semi-open, alpha-open, and pre-open sets, demonstrating its
potential for mathematical discovery beyond simple variations of existing
results.

</details>


### [57] [Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/abs/2506.22056)
*Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong*

Main category: cs.AI

TL;DR: 提出多模态轨迹检索框架GAE-Retriever，在UATD数据集上取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效建模轨迹数据，尤其是在GUI环境中。

Method: 构建了统一的智能体轨迹数据集UATD，并提出GAE-Retriever框架，该框架采用视觉语言模型并结合优化的对比学习（包括令牌选择和GradCache机制）。

Result: GAE-Retriever在检索召回率方面优于现有基线。

Conclusion: 提出了一种多模态轨迹检索框架GAE-Retriever，并在多个数据集上取得了比现有基线更好的检索效果。

Abstract: Trajectory data, capturing human actions and environmental states across
various modalities, holds significant potential for enhancing AI agent
capabilities, particularly in GUI environments. However, how to model the
representation of trajectory-level data presents a significant challenge that
has not been systematically addressed amid explosive trajectory data growth. In
this work, we introduce Multimodal Trajectory Retrieval, bridging the gap
between universal retrieval and agent-centric trajectory modeling. We construct
the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and
states across diverse real-world scenarios. Based on this, we present
GAE-Bench, a benchmark containing a large number of trajectory-based retrieval
pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework
that adopts vision-language models and incorporates optimized contrastive
learning through a token selection and the GradCache mechanism. Comprehensive
evaluations across multiple datasets show that GAE-Retriever consistently
outperforms strong baselines in retrieval recall, highlighting its
effectiveness in advancing multimodal trajectory retrieval.

</details>


### [58] [Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](https://arxiv.org/abs/2506.22068)
*Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang*

Main category: cs.AI

TL;DR: A new testing paradigm (QaT) and data framework (ESN) are proposed to improve the testing and development of intelligent transportation systems.


<details>
  <summary>Details</summary>
Motivation: Existing testing methods for intelligent transportation systems are insufficient due to data fragmentation, incomplete edge case coverage, and inflexibility.

Method: Proposed Query as Test (QaT) paradigm and Extensible Scenarios Notations (ESN) data framework based on Answer Set Programming.

Result: ESN enables complex semantic querying, interpretability, and fine-grained privacy protection. QaT enhances testing expressiveness and rigor, while Validation-Driven Development (VDD) accelerates the development process.

Conclusion: This paper introduces Query as Test (QaT) and Extensible Scenarios Notations (ESN) to address the fragmented and incompatible data ecosystems in intelligent transportation. ESN, based on Answer Set Programming, provides a unified data representation for semantic fusion and flexible querying, enhancing testing and enabling validation-driven development.

Abstract: With the deep penetration of Artificial Intelligence (AI) in the
transportation sector, intelligent cockpits, autonomous driving, and
intelligent road networks are developing at an unprecedented pace. However, the
data ecosystems of these three key areas are increasingly fragmented and
incompatible. Especially, existing testing methods rely on data stacking, fail
to cover all edge cases, and lack flexibility. To address this issue, this
paper introduces the concept of "Query as Test" (QaT). This concept shifts the
focus from rigid, prescripted test cases to flexible, on-demand logical queries
against a unified data representation. Specifically, we identify the need for a
fundamental improvement in data storage and representation, leading to our
proposal of "Extensible Scenarios Notations" (ESN). ESN is a novel declarative
data framework based on Answer Set Programming (ASP), which uniformly
represents heterogeneous multimodal data from the cockpit, vehicle, and road as
a collection of logical facts and rules. This approach not only achieves deep
semantic fusion of data, but also brings three core advantages: (1) supports
complex and flexible semantic querying through logical reasoning; (2) provides
natural interpretability for decision-making processes; (3) allows for
on-demand data abstraction through logical rules, enabling fine-grained privacy
protection. We further elaborate on the QaT paradigm, transforming the
functional validation and safety compliance checks of autonomous driving
systems into logical queries against the ESN database, significantly enhancing
the expressiveness and formal rigor of the testing. Finally, we introduce the
concept of "Validation-Driven Development" (VDD), which suggests to guide
developments by logical validation rather than quantitative testing in the era
of Large Language Models, in order to accelerating the iteration and
development process.

</details>


### [59] [A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety](https://arxiv.org/abs/2506.22183)
*Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon*

Main category: cs.AI

TL;DR: 开源AI提升安全性，但仍需解决多模态、多语言基准、防御机制和参与机制等方面的差距。


<details>
  <summary>Details</summary>
Motivation: 开放权重和开源基础模型的快速兴起，使得确保AI系统安全变得更加重要和迫切。

Method: 参与式、面向解决方案的方法，包括工作组研讨和制定研究议程。

Result: 产出了AI安全与开源研究议程、安全部署开源基础模型的技术干预和开源工具，以及内容安全过滤器生态系统图谱和未来研发路线图。

Conclusion: 开放性（透明的权重、可互操作的工具和公共治理）可以增强安全性，但仍存在差距，例如缺乏多模态和多语言基准、有限的防御机制以及参与机制不足等。

Abstract: The rapid rise of open-weight and open-source foundation models is
intensifying the obligation and reshaping the opportunity to make AI systems
safe. This paper reports outcomes from the Columbia Convening on AI Openness
and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme
involving more than forty-five researchers, engineers, and policy leaders from
academia, industry, civil society, and government. Using a participatory,
solutions-oriented process, the working groups produced (i) a research agenda
at the intersection of safety and open source AI; (ii) a mapping of existing
and needed technical interventions and open source tools to safely and
responsibly deploy open foundation models across the AI development workflow;
and (iii) a mapping of the content safety filter ecosystem with a proposed
roadmap for future research and development. We find that openness --
understood as transparent weights, interoperable tooling, and public governance
-- can enhance safety by enabling independent scrutiny, decentralized
mitigation, and culturally plural oversight. However, significant gaps persist:
scarce multimodal and multilingual benchmarks, limited defenses against
prompt-injection and compositional attacks in agentic systems, and insufficient
participatory mechanisms for communities most affected by AI harms. The paper
concludes with a roadmap of five priority research directions, emphasizing
participatory inputs, future-proof content filters, ecosystem-wide safety
infrastructure, rigorous agentic safeguards, and expanded harm taxonomies.
These recommendations informed the February 2025 French AI Action Summit and
lay groundwork for an open, plural, and accountable AI safety discipline.

</details>


### [60] [Breaking Rank Bottlenecks in Knowledge Graph Completion](https://arxiv.org/abs/2506.22271)
*Samy Badreddine,Emile van Krieken,Luciano Serafini*

Main category: cs.AI

TL;DR: 针对知识图谱补全模型中秩瓶颈问题，提出了一种新的混合输出层KGE-MoS，提高了模型性能和概率拟合度。


<details>
  <summary>Details</summary>
Motivation: 许多知识图谱补全模型使用简单的向量矩阵乘法来评分，存在秩瓶颈问题，限制了模型表达能力。

Method: 提出了一种基于混合的输出层KGE-MoS，用于打破知识图谱补全模型中的秩瓶颈。

Result: 实验证明，KGE-MoS在四个数据集上提高了知识图谱补全模型的性能和概率拟合度，参数成本低。

Conclusion: KGE-MoS模型通过混合输出层有效解决了知识图谱补全模型中秩瓶颈问题，提高了性能和概率拟合度。

Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful
encoders, rely on a simple vector-matrix multiplication to score queries
against candidate object entities. When the number of entities is larger than
the model's embedding dimension, which in practical scenarios is often by
several orders of magnitude, we have a linear output layer with a rank
bottleneck. Such bottlenecked layers limit model expressivity. We investigate
both theoretically and empirically how rank bottlenecks affect KGC models. We
find that, by limiting the set of feasible predictions, rank bottlenecks hurt
ranking accuracy and the distribution fidelity of scores. Inspired by the
language modelling literature, we propose KGE-MoS, a mixture-based output layer
to break rank bottlenecks in many KGC models. Our experiments on four datasets
show that KGE-MoS improves performance and probabilistic fit of KGC models for
a low parameter cost.

</details>


### [61] [Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates](https://arxiv.org/abs/2506.22276)
*Reuth Mirsky*

Main category: cs.AI

TL;DR: 论文倡导赋予AI“智能式不服从”的能力，使其成为更有效的合作AI团队成员。


<details>
  <summary>Details</summary>
Motivation: 当前大多数合作AI系统仍然僵化服从，即使这样做可能适得其反或不安全，该论文认为需要扩展AI的自主性以进行智能式不服从。

Method: 提出AI自主性等级规模，并用代表性例子强调将AI自主性作为合作环境下独立研究重点的重要性。

Result: 探讨了智能式不服从在不同自主性水平下的表现，并提出了研究不服从作为人工智能主体核心能力的初步边界和考虑。

Conclusion: 该论文主张扩展AI团队成员的自主性，使其能够进行"智能式不服从"，并在不同自主性水平下探讨其表现，最终提出研究"不服从"作为人工智能主体核心能力的初步边界和考虑。

Abstract: Artificial intelligence has made remarkable strides in recent years,
achieving superhuman performance across a wide range of tasks. Yet despite
these advances, most cooperative AI systems remain rigidly obedient, designed
to follow human instructions without question and conform to user expectations,
even when doing so may be counterproductive or unsafe. This paper argues for
expanding the agency of AI teammates to include \textit{intelligent
disobedience}, empowering them to make meaningful and autonomous contributions
within human-AI teams. It introduces a scale of AI agency levels and uses
representative examples to highlight the importance and growing necessity of
treating AI autonomy as an independent research focus in cooperative settings.
The paper then explores how intelligent disobedience manifests across different
autonomy levels and concludes by proposing initial boundaries and
considerations for studying disobedience as a core capability of artificial
agents.

</details>


### [62] [Conceptual Topic Aggregation](https://arxiv.org/abs/2506.22309)
*Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme*

Main category: cs.AI

TL;DR: FAT-CAT利用形式概念分析，改进主题建模的可解释性，并通过概念格可视化主题分布。


<details>
  <summary>Details</summary>
Motivation: 现有主题建模方法难以提供可解释的表示，难以深入了解数据结构和内容。

Method: 提出FAT-CAT方法，该方法基于形式概念分析（FCA）,处理多种主题和文件类型，构建概念格以展示主题分布的层次结构。

Result: 实证研究表明，基于FCA的聚合比现有的主题建模技术能提供更有意义和可解释的数据集组成见解。

Conclusion: FAT-CAT，一种基于形式概念分析（FCA）的方法，通过构建概念格，有效地聚合和可视化主题，从而对数据集组成提供更有意义和可解释的见解。

Abstract: The vast growth of data has rendered traditional manual inspection
infeasible, necessitating the adoption of computational methods for efficient
data exploration. Topic modeling has emerged as a powerful tool for analyzing
large-scale textual datasets, enabling the extraction of latent semantic
structures. However, existing methods for topic modeling often struggle to
provide interpretable representations that facilitate deeper insights into data
structure and content. In this paper, we propose FAT-CAT, an approach based on
Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and
visualization of discovered topics. Our approach can handle diverse topics and
file types -- grouped by directories -- to construct a concept lattice that
offers a structured, hierarchical representation of their topic distribution.
In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our
approach against other representation methods to demonstrate that FCA-based
aggregation provides more meaningful and interpretable insights into dataset
composition than existing topic modeling techniques.

</details>


### [63] [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
*Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik*

Main category: cs.AI

TL;DR: 研究具身AI智能体如何通过构建世界模型理解环境和用户意图，从而更好地与人类协作。


<details>
  <summary>Details</summary>
Motivation: 为了使AI智能体更接近人类学习和交互方式，提升其自主完成复杂任务的能力。

Method: 研究具身AI智能体（虚拟化身、可穿戴设备和机器人），通过构建世界模型，整合多模态感知、基于推理的行动规划和控制以及记忆，从而实现对物理世界和用户意图的理解。

Result: 提出世界模型对于具身AI智能体推理和规划的重要性，以及学习用户mental world model以增强人机协作。

Conclusion: 该论文研究具身AI智能体在视觉、虚拟或物理环境中的交互作用，认为世界模型的构建对于具身AI智能体的推理和规划至关重要，并提出学习用户的 mental world model 以增强人机协作。

Abstract: This paper describes our research on AI agents embodied in visual, virtual or
physical forms, enabling them to interact with both users and their
environments. These agents, which include virtual avatars, wearable devices,
and robots, are designed to perceive, learn and act within their surroundings,
which makes them more similar to how humans learn and interact with the
environments as compared to disembodied agents. We propose that the development
of world models is central to reasoning and planning of embodied AI agents,
allowing these agents to understand and predict their environment, to
understand user intentions and social contexts, thereby enhancing their ability
to perform complex tasks autonomously. World modeling encompasses the
integration of multimodal perception, planning through reasoning for action and
control, and memory to create a comprehensive understanding of the physical
world. Beyond the physical world, we also propose to learn the mental world
model of users to enable better human-agent collaboration.

</details>


### [64] [AI Model Passport: Data and System Traceability Framework for Transparent AI in Health](https://arxiv.org/abs/2506.22358)
*Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou,The ProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: AI模型护照框架及其实现AIPassport工具，提升医疗AI的透明度、可重复性和合规性。


<details>
  <summary>Details</summary>
Motivation: 现有框架缺乏可扩展性、可比性和机器可解释性，且无法保证AI模型的来源和真实性。

Method: 提出AI模型护照的概念和AIPassport工具的实现，并通过案例验证其有效性。

Result: 提出了一种结构化和标准化的文档框架——AI模型护照，并开发了AIPassport工具，用于自动化元数据收集、版本控制和结果与源脚本解耦。

Conclusion: 本文介绍了AI模型护照的概念，并提出AIPassport工具，以提高医疗AI系统的透明度、可重复性和合规性。

Abstract: The increasing integration of Artificial Intelligence (AI) into health and
biomedical systems necessitates robust frameworks for transparency,
accountability, and ethical compliance. Existing frameworks often rely on
human-readable, manual documentation which limits scalability, comparability,
and machine interpretability across projects and platforms. They also fail to
provide a unique, verifiable identity for AI models to ensure their provenance
and authenticity across systems and use cases, limiting reproducibility and
stakeholder trust. This paper introduces the concept of the AI Model Passport,
a structured and standardized documentation framework that acts as a digital
identity and verification tool for AI models. It captures essential metadata to
uniquely identify, verify, trace and monitor AI models across their lifecycle -
from data acquisition and preprocessing to model design, development and
deployment. In addition, an implementation of this framework is presented
through AIPassport, an MLOps tool developed within the ProCAncer-I EU project
for medical imaging applications. AIPassport automates metadata collection,
ensures proper versioning, decouples results from source scripts, and
integrates with various development environments. Its effectiveness is
showcased through a lesion segmentation use case using data from the
ProCAncer-I dataset, illustrating how the AI Model Passport enhances
transparency, reproducibility, and regulatory readiness while reducing manual
effort. This approach aims to set a new standard for fostering trust and
accountability in AI-driven healthcare solutions, aspiring to serve as the
basis for developing transparent and regulation compliant AI systems across
domains.

</details>


### [65] [The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements](https://arxiv.org/abs/2506.22419)
*Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach*

Main category: cs.AI

TL;DR: AI难以复现已知科研成果，本文提出一个基准测试评估大型语言模型的科研成果再现能力。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型再现现有科研成果的能力，这对于自主科研代理至关重要。

Method: 构建了一个名为Automated LLM Speedrunning Benchmark的基准测试，利用NanoGPT竞赛的数据，评估AI代理再现研究结果的能力。

Result: 最新的推理LLM结合最先进的脚手架很难重新实现已知的创新，该基准测试提供了一个简单的、非饱和的衡量LLM自动化科学再现能力的方法。

Conclusion: 大型语言模型(LLM)在辅助科学进步方面具有巨大潜力，但其再现现有研究成果的能力仍需提升。本文介绍了一个名为Automated LLM Speedrunning Benchmark的基准测试，用于评估AI代理再现研究结果的能力，结果表明，即使给出详细提示，最新的推理LLM结合最先进的脚手架也很难在该基准测试中重新实现已知的创新。

Abstract: Rapid advancements in large language models (LLMs) have the potential to
assist in scientific progress. A critical capability toward this endeavor is
the ability to reproduce existing work. To evaluate the ability of AI agents to
reproduce results in an active research area, we introduce the Automated LLM
Speedrunning Benchmark, leveraging the research community contributions on the
NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time.
Each of the 19 speedrun tasks provides the agent with the previous records
training script, optionally paired with one of three hint formats, ranging from
pseudocode to paper-like descriptions of the new records improvements. Records
execute quickly by design and speedrun improvements encompass diverse
code-level changes, ranging from high-level algorithmic advancements to
hardware-aware optimizations. These features make the benchmark both accessible
and realistic for the frontier problem of improving LLM training. We find that
recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement
already-known innovations in our benchmark, even when given detailed hints. Our
benchmark thus provides a simple, non-saturated measure of an LLMs ability to
automate scientific reproduction, a necessary (but not sufficient) skill for an
autonomous research agent.

</details>


### [66] [Bootstrapping Human-Like Planning via LLMs](https://arxiv.org/abs/2506.22604)
*David Porfirio,Vincent Hsiao,Morgan Fine-Morris,Leslie Smith,Laura M. Hiatt*

Main category: cs.AI

TL;DR: 研究结合自然语言和拖放界面编程机器人，大型语言模型能生成类人动作序列，更大模型效果更好但小型模型也足够好。


<details>
  <summary>Details</summary>
Motivation: 机器人终端用户需要一种易于访问的方式来指定机器人执行的任务，自然语言界面和拖放界面是两种常见的编程方式，本文旨在研究如何将这两种方式结合起来。

Method: 构建了一个基于大型语言模型的管道，将自然语言转换为人类可执行的动作序列，并与手动指定的动作序列进行比较。

Result: 更大的模型在生成类人动作序列方面表现更好，但较小的模型也能达到令人满意的性能。

Conclusion: 本文研究了将自然语言编程和拖放界面相结合的程度，构建了一个基于大型语言模型的管道，将自然语言输入转换为人类可执行的动作序列，并与手动指定的动作序列进行了比较。结果表明，更大的模型在生成类人动作序列方面表现更好，但较小的模型也能达到令人满意的性能。

Abstract: Robot end users increasingly require accessible means of specifying tasks for
robots to perform. Two common end-user programming paradigms include
drag-and-drop interfaces and natural language programming. Although natural
language interfaces harness an intuitive form of human communication,
drag-and-drop interfaces enable users to meticulously and precisely dictate the
key actions of the robot's task. In this paper, we investigate the degree to
which both approaches can be combined. Specifically, we construct a large
language model (LLM)-based pipeline that accepts natural language as input and
produces human-like action sequences as output, specified at a level of
granularity that a human would produce. We then compare these generated action
sequences to another dataset of hand-specified action sequences. Although our
results reveal that larger models tend to outperform smaller ones in the
production of human-like action sequences, smaller models nonetheless achieve
satisfactory performance.

</details>


### [67] [Ludax: A GPU-Accelerated Domain Specific Language for Board Games](https://arxiv.org/abs/2506.22609)
*Graham Todd,Alexander G. Padula,Dennis J. N. J. Soemers,Julian Togelius*

Main category: cs.AI

TL;DR: Ludax是一个开源的，基于硬件加速的棋盘游戏领域特定语言，旨在加速游戏研究。


<details>
  <summary>Details</summary>
Motivation: 现有的游戏研究受限于手动实现游戏和缺乏硬件加速，Ludax旨在解决这些问题。

Method: 开发了一个名为Ludax的领域特定语言，将棋盘游戏编译成硬件加速代码。

Result: Ludax框架开源可用，并进行了速度基准测试和强化学习智能体训练演示。

Conclusion: Ludax框架是一个用于棋盘游戏的领域特定语言，它能自动编译成硬件加速代码，结合了游戏描述语言的通用性和现代并行处理硬件的速度，旨在加速游戏研究，例如强化学习和认知科学。

Abstract: Games have long been used as benchmarks and testing environments for research
in artificial intelligence. A key step in supporting this research was the
development of game description languages: frameworks that compile
domain-specific code into playable and simulatable game environments, allowing
researchers to generalize their algorithms and approaches across multiple games
without having to manually implement each one. More recently, progress in
reinforcement learning (RL) has been largely driven by advances in hardware
acceleration. Libraries like JAX allow practitioners to take full advantage of
cutting-edge computing hardware, often speeding up training and testing by
orders of magnitude. Here, we present a synthesis of these strands of research:
a domain-specific language for board games which automatically compiles into
hardware-accelerated code. Our framework, Ludax, combines the generality of
game description languages with the speed of modern parallel processing
hardware and is designed to fit neatly into existing deep learning pipelines.
We envision Ludax as a tool to help accelerate games research generally, from
RL to cognitive science, by enabling rapid simulation and providing a flexible
representation scheme. We present a detailed breakdown of Ludax's description
language and technical notes on the compilation process, along with speed
benchmarking and a demonstration of training RL agents. The Ludax framework,
along with implementations of existing board games, is open-source and freely
available.

</details>
