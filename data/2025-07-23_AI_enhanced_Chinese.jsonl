{"id": "2507.15865", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15865", "abs": "https://arxiv.org/abs/2507.15865", "authors": ["Shai Shalev-Shwartz", "Amnon Shashua"], "title": "From Reasoning to Super-Intelligence: A Search-Theoretic Perspective", "comment": null, "summary": "Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing\nthe problem-solving capabilities of large language models (LLMs). However, the\ntheoretical foundations of learning from CoT data remain underdeveloped, and\nexisting approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement\nLearning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --\noften fail on complex reasoning tasks. In this work, we identify core obstacles\nthat hinder effective CoT learning, including distribution drift, lack of\nembedded search, and exponential inference costs. We introduce the Diligent\nLearner, a new learning paradigm that explicitly models reasoning as a\ndepth-first search guided by a validator and supports backtracking upon\nfailure. Under two mild and realistic assumptions, we prove that the Diligent\nLearner can efficiently learn from CoT data while existing methods fail to do\nso. This framework offers a path toward building scalable and reliable\nreasoning systems trained on naturally occurring, incomplete data -- paving the\nway for the development of Large Reasoning Models (LRMs) with robust,\ninterpretable problem-solving abilities.", "AI": {"tldr": "\u63d0\u51faDiligent Learner\uff0c\u4e00\u79cd\u65b0\u7684CoT\u5b66\u4e60\u8303\u5f0f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u4e0d\u8db3\uff0c\u5e76\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684CoT\u5b66\u4e60\u65b9\u6cd5\uff08\u5982SFT\u3001RL\u3001ToT\u548cMCTS\uff09\u5728\u590d\u6742\u7684\u63a8\u7406\u4efb\u52a1\u4e0a\u5e38\u5e38\u5931\u8d25\uff0c\u4e3b\u8981\u969c\u788d\u5305\u62ec\u5206\u5e03\u6f02\u79fb\u3001\u7f3a\u4e4f\u5d4c\u5165\u5f0f\u641c\u7d22\u548c\u6307\u6570\u63a8\u7406\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u8303\u5f0fDiligent Learner\uff0c\u5b83\u5c06\u63a8\u7406\u5efa\u6a21\u4e3a\u7531\u9a8c\u8bc1\u5668\u5f15\u5bfc\u7684\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\uff0c\u5e76\u5728\u5931\u8d25\u65f6\u652f\u6301\u56de\u6eaf\u3002", "result": "\u8bc1\u660eDiligent Learner\u53ef\u4ee5\u5728\u4e24\u4e2a\u6e29\u548c\u4e14\u73b0\u5b9e\u7684\u5047\u8bbe\u4e0b\u6709\u6548\u5730\u4eceCoT\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u5374\u65e0\u6cd5\u505a\u5230\u3002", "conclusion": "Diligent Learner\uff0c\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5668\u5f15\u5bfc\u7684\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u5bf9\u63a8\u7406\u5efa\u6a21\uff0c\u5e76\u5728\u5931\u8d25\u65f6\u652f\u6301\u56de\u6eaf\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u4eceCoT\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u5374\u65e0\u6cd5\u505a\u5230\u3002"}}
{"id": "2507.15866", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15866", "abs": "https://arxiv.org/abs/2507.15866", "authors": ["Marek Vlk", "Premysl Sucha", "Jaroslaw Rudy", "Radoslaw Idzikowski"], "title": "Purchase and Production Optimization in a Meat Processing Plant", "comment": "25 pages, 5 figures", "summary": "The food production industry, especially the meat production sector, faces\nmany challenges that have even escalated due to the recent outbreak of the\nenergy crisis in the European Union. Therefore, efficient use of input\nmaterials is an essential aspect affecting the profit of such companies. This\npaper addresses an optimization problem concerning the purchase and subsequent\nmaterial processing we solved for a meat processing company. Unlike the\nmajority of existing papers, we do not concentrate on how this problem concerns\nsupply chain management, but we focus purely on the production stage. The\nproblem involves the concept of alternative ways of material processing, stock\nof material with different expiration dates, and extra constraints widely\nneglected in the current literature, namely, the minimum order quantity and the\nminimum percentage in alternatives. We prove that each of these two constraints\nmakes the problem \\mbox{$\\mathcal{NP}$-hard}, and hence we design a simple\niterative approach based on integer linear programming that allows us to solve\nreal-life instances even using an open-source integer linear programming\nsolver. Another advantage of this approach is that it mitigates numerical\nissues, caused by the extensive range of data values, we experienced with a\ncommercial solver. The results obtained using real data from the meat\nprocessing company showed that our algorithm can find the optimum solution in a\nfew seconds for all considered use cases.", "AI": {"tldr": "\u9488\u5bf9\u8089\u7c7b\u52a0\u5de5\u7684\u7269\u6599\u91c7\u8d2d\u548c\u52a0\u5de5\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u7684\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u53ef\u5728\u51e0\u79d2\u5185\u6c42\u89e3\u5b9e\u9645\u6848\u4f8b\u3002", "motivation": "\u63d0\u9ad8\u8089\u7c7b\u52a0\u5de5\u884c\u4e1a\u7684\u751f\u4ea7\u6548\u7387\u548c\u76c8\u5229\u80fd\u529b\uff0c\u89e3\u51b3\u7269\u6599\u91c7\u8d2d\u548c\u52a0\u5de5\u8fc7\u7a0b\u4e2d\u7684\u4f18\u5316\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\u7684\u8fed\u4ee3\u65b9\u6cd5", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u51e0\u79d2\u949f\u5185\u4e3a\u6240\u6709\u8003\u8651\u7684\u7528\u4f8b\u627e\u5230\u6700\u4f18\u89e3\uff0c\u5e76\u6709\u6548\u7f13\u89e3\u6570\u503c\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u9488\u5bf9\u8089\u7c7b\u52a0\u5de5\u516c\u53f8\u4e2d\u7269\u6599\u91c7\u8d2d\u548c\u52a0\u5de5\u7684\u4f18\u5316\u95ee\u9898\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5b9e\u9645\u6848\u4f8b\uff0c\u5e76\u5728\u51e0\u79d2\u949f\u5185\u627e\u5230\u6700\u4f18\u89e3\u3002"}}
{"id": "2507.15874", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15874", "abs": "https://arxiv.org/abs/2507.15874", "authors": ["Yin Wu", "Daniel Slieter", "Vivek Subramanian", "Ahmed Abouelazm", "Robin Bohn", "J. Marius Z\u00f6llner"], "title": "Why Braking? Scenario Extraction and Reasoning Utilizing LLM", "comment": null, "summary": "The growing number of ADAS-equipped vehicles has led to a dramatic increase\nin driving data, yet most of them capture routine driving behavior. Identifying\nand understanding safety-critical corner cases within this vast dataset remains\na significant challenge. Braking events are particularly indicative of\npotentially hazardous situations, motivating the central question of our\nresearch: Why does a vehicle brake? Existing approaches primarily rely on\nrule-based heuristics to retrieve target scenarios using predefined condition\nfilters. While effective in simple environments such as highways, these methods\nlack generalization in complex urban settings. In this paper, we propose a\nnovel framework that leverages Large Language Model (LLM) for scenario\nunderstanding and reasoning. Our method bridges the gap between low-level\nnumerical signals and natural language descriptions, enabling LLM to interpret\nand classify driving scenarios. We propose a dual-path scenario retrieval that\nsupports both category-based search for known scenarios and embedding-based\nretrieval for unknown Out-of-Distribution (OOD) scenarios. To facilitate\nevaluation, we curate scenario annotations on the Argoverse 2 Sensor Dataset.\nExperimental results show that our method outperforms rule-based baselines and\ngeneralizes well to OOD scenarios.", "AI": {"tldr": "\u5229\u7528LLM\u5206\u6790ADAS\u6570\u636e\u4e2d\u7684\u5239\u8f66\u4e8b\u4ef6\uff0c\u4ee5\u8bc6\u522b\u5b89\u5168\u5173\u952e\u7684\u6781\u7aef\u60c5\u51b5\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u89c4\u5219\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5728\u590d\u6742\u7684\u57ce\u5e02\u73af\u5883\u4e2d\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u6b64\u672c\u6587\u63d0\u51fa\u5229\u7528LLM\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u8be5\u65b9\u6cd5\u6865\u63a5\u4e86\u4f4e\u7ea7\u6570\u503c\u4fe1\u53f7\u548c\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4f7fLLM\u80fd\u591f\u89e3\u91ca\u548c\u5206\u7c7b\u9a7e\u9a76\u573a\u666f\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u8def\u5f84\u573a\u666f\u68c0\u7d22\u65b9\u6cd5\uff0c\u652f\u6301\u57fa\u4e8e\u7c7b\u522b\u7684\u5df2\u77e5\u573a\u666f\u641c\u7d22\u548c\u57fa\u4e8e\u5d4c\u5165\u7684\u672a\u77e5\u573a\u666f\u68c0\u7d22\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u5f88\u597d\u5730\u6cdb\u5316\u5230OOD\u573a\u666f\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u8fdb\u884c\u573a\u666f\u7406\u89e3\u548c\u63a8\u7406\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522b\u548c\u7406\u89e3\u81ea\u52a8\u9a7e\u9a76\u8f85\u52a9\u7cfb\u7edf (ADAS) \u6570\u636e\u4e2d\u5b89\u5168\u5173\u952e\u7684\u6781\u7aef\u60c5\u51b5\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u5f88\u597d\u5730\u6cdb\u5316\u5230\u672a\u77e5\u573a\u666f\u3002"}}
{"id": "2507.15875", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.15875", "abs": "https://arxiv.org/abs/2507.15875", "authors": ["Jerry Li", "Timothy Oh", "Joseph Hoang", "Vardhit Veeramachaneni"], "title": "Differential Multimodal Transformers", "comment": null, "summary": "Small language models have gained significant popularity due to their\nefficiency and growing capabilities. However, incorporating additional\nmodalities, such as vision, can exacerbate the challenge of limited context\nwindows by introducing noise. Recent studies have highlighted that Transformer\nattention mechanisms often disproportionately focus on irrelevant contexts. In\nthis work, we extend the Differential Attention mechanism, originally designed\nfor text-only models, to the text-vision model PaliGemma. Our aim is to\nevaluate its ability to mitigate noisy information retrieval and reduce\nhallucinations. To this end, we fine-tuned the PaliGemma 3B model using LoRA,\nincorporating Differential Attention, and experimented with various parameter\nsettings and configurations. We demonstrate that Differential Attention can be\nadapted and integrated into the fine-tuning of existing models to enhance noisy\ninformation retrieval and question-answering capabilities.", "AI": {"tldr": "\u5c06Differential Attention\u5e94\u7528\u4e8e\u6587\u672c\u89c6\u89c9\u6a21\u578bPaliGemma\uff0c\u6709\u6548\u51cf\u5c11\u566a\u58f0\u548c\u5e7b\u89c9\uff0c\u63d0\u5347\u4e86\u4fe1\u606f\u68c0\u7d22\u548c\u95ee\u7b54\u6027\u80fd\u3002", "motivation": "\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u6709\u9650\uff0c\u7ed3\u5408\u89c6\u89c9\u7b49\u591a\u6a21\u6001\u4fe1\u606f\u4f1a\u52a0\u5267\u8fd9\u4e2a\u95ee\u9898\uff0cTransformer\u6ce8\u610f\u529b\u673a\u5236\u5bb9\u6613\u5173\u6ce8\u65e0\u5173\u4e0a\u4e0b\u6587\u3002", "method": "\u5fae\u8c03PaliGemma 3B\u6a21\u578b\uff0c\u4f7f\u7528LoRA\u5e76\u7ed3\u5408Differential Attention\u673a\u5236\uff0c\u5b9e\u9a8c\u4e0d\u540c\u7684\u53c2\u6570\u8bbe\u7f6e\u548c\u914d\u7f6e\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eDifferential Attention\u53ef\u4ee5\u589e\u5f3a\u566a\u58f0\u4fe1\u606f\u68c0\u7d22\u548c\u95ee\u7b54\u80fd\u529b\u3002", "conclusion": "Differential Attention\u673a\u5236\u53ef\u4ee5\u6709\u6548\u5e94\u7528\u4e8e\u6587\u672c\u89c6\u89c9\u6a21\u578bPaliGemma\uff0c\u4ee5\u51cf\u8f7b\u566a\u58f0\u4fe1\u606f\u68c0\u7d22\u548c\u51cf\u5c11\u5e7b\u89c9\u3002"}}
{"id": "2507.15876", "categories": ["cs.AI", "q-fin.PR", "q-fin.ST", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2507.15876", "abs": "https://arxiv.org/abs/2507.15876", "authors": ["Eric Benhamou", "Jean-Jacques Ohana", "Alban Etienne", "B\u00e9atrice Guez", "Ethan Setrouk", "Thomas Jacquot"], "title": "Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach", "comment": "13 pages", "summary": "Commodity Trading Advisors (CTAs) have historically relied on trend-following\nrules that operate on vastly different horizons from long-term breakouts that\ncapture major directional moves to short-term momentum signals that thrive in\nfast-moving markets. Despite a large body of work on trend following, the\nrelative merits and interactions of short-versus long-term trend systems remain\ncontroversial. This paper adds to the debate by (i) dynamically decomposing CTA\nreturns into short-term trend, long-term trend and market beta factors using a\nBayesian graphical model, and (ii) showing how the blend of horizons shapes the\nstrategy's risk-adjusted performance.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u8d1d\u53f6\u65af\u56fe\u6a21\u578b\u5206\u6790CTA\u7b56\u7565\u4e2d\u77ed\u671f\u548c\u957f\u671f\u8d8b\u52bf\u7684\u98ce\u9669\u8c03\u6574\u540e\u7ee9\u6548\uff0c\u53d1\u73b0\u4e24\u8005\u878d\u5408\u65b9\u5f0f\u5f71\u54cd\u6700\u7ec8\u7ed3\u679c", "motivation": "\u63a2\u8ba8\u77ed\u671f\u548c\u957f\u671f\u8d8b\u52bf\u7cfb\u7edf\u5728CTA\u7b56\u7565\u4e2d\u7684\u76f8\u5bf9\u4f18\u52a3\u52bf\u53ca\u76f8\u4e92\u4f5c\u7528\uff0c\u5c1a\u5b58\u5728\u4e89\u8bae\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u56fe\u6a21\u578b\u52a8\u6001\u5206\u89e3CTA\u6536\u76ca\u4e3a\u77ed\u671f\u8d8b\u52bf\u3001\u957f\u671f\u8d8b\u52bf\u548c\u5e02\u573aBeta\u56e0\u7d20\u3002", "result": "\u4e0d\u540c\u65f6\u95f4\u8303\u56f4\u8d8b\u52bf\u7684\u878d\u5408\u4f1a\u5f71\u54cd\u7b56\u7565\u7684\u98ce\u9669\u8c03\u6574\u540e\u7ee9\u6548\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u8d1d\u53f6\u65af\u56fe\u6a21\u578b\u52a8\u6001\u5206\u89e3CTA\u6536\u76ca\uff0c\u63a2\u8ba8\u4e86\u77ed\u671f\u548c\u957f\u671f\u8d8b\u52bf\u7cfb\u7edf\u5728\u98ce\u9669\u8c03\u6574\u540e\u7684\u7ee9\u6548\u4e2d\u7684\u76f8\u5bf9\u4f18\u52a3\u52bf\u53ca\u76f8\u4e92\u4f5c\u7528\uff0c\u7ed3\u679c\u8868\u660e\u4e0d\u540c\u65f6\u95f4\u8303\u56f4\u8d8b\u52bf\u7684\u878d\u5408\u4f1a\u5f71\u54cd\u7b56\u7565\u7684\u98ce\u9669\u8c03\u6574\u540e\u7ee9\u6548\u3002"}}
{"id": "2507.15877", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15877", "abs": "https://arxiv.org/abs/2507.15877", "authors": ["Simon Ouellette"], "title": "Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning", "comment": null, "summary": "We run a controlled compositional generalization experiment in the ARC-AGI\ndomain: an open-world problem domain in which the ability to generalize\nout-of-distribution is, by design, an essential characteristic for success. We\ncompare neural program synthesis and test-time fine-tuning approaches on this\nexperiment. We find that execution-guided neural program synthesis outperforms\nall reference algorithms in its ability to compose novel solutions. Our\nempirical findings also suggest that the success of TTFT on ARC-AGI lies mainly\nin eliciting in-distribution knowledge that the LLM otherwise fails to rely on\ndirectly.", "AI": {"tldr": "\u6267\u884c\u5f15\u5bfc\u7684\u795e\u7ecf\u7a0b\u5e8f\u5408\u6210\u5728ARC-AGI\u7ec4\u5408\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u6d4b\u8bd5\u65f6\u5fae\u8c03\u4e3b\u8981\u4f9d\u8d56\u5206\u5e03\u5185\u77e5\u8bc6\u3002", "motivation": "\u7814\u7a76\u5728ARC-AGI\u5f00\u653e\u5f0f\u95ee\u9898\u9886\u57df\u4e2d\uff0c\u6a21\u578b\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u53d7\u63a7\u7ec4\u5408\u6cdb\u5316\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u795e\u7ecf\u7a0b\u5e8f\u5408\u6210\u548c\u6d4b\u8bd5\u65f6\u5fae\u8c03\u65b9\u6cd5\u3002", "result": "\u6267\u884c\u5f15\u5bfc\u7684\u795e\u7ecf\u7a0b\u5e8f\u5408\u6210\u4f18\u4e8e\u5176\u4ed6\u7b97\u6cd5\uff1b\u6d4b\u8bd5\u65f6\u5fae\u8c03\u4e3b\u8981\u5229\u7528\u5206\u5e03\u5185\u77e5\u8bc6\u3002", "conclusion": "\u6267\u884c\u5f15\u5bfc\u7684\u795e\u7ecf\u7a0b\u5e8f\u5408\u6210\u5728\u7ec4\u5408\u65b0\u9896\u89e3\u51b3\u65b9\u6848\u7684\u80fd\u529b\u65b9\u9762\u4f18\u4e8e\u6240\u6709\u53c2\u8003\u7b97\u6cd5\u3002\u6d4b\u8bd5\u65f6\u5fae\u8c03\u5728ARC-AGI\u4e0a\u7684\u6210\u529f\u4e3b\u8981\u5728\u4e8e\u5f15\u51faLLM\u539f\u672c\u65e0\u6cd5\u76f4\u63a5\u4f9d\u8d56\u7684\u5206\u5e03\u5185\u77e5\u8bc6\u3002"}}
{"id": "2507.15880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15880", "abs": "https://arxiv.org/abs/2507.15880", "authors": ["Andy E. Williams"], "title": "The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture", "comment": null, "summary": "Intelligence-biological, artificial, or collective-requires structural\ncoherence across recursive reasoning processes to scale effectively. As complex\nsystems grow, coherence becomes fragile unless a higher-order structure ensures\nsemantic consistency. This paper introduces the Recursive Coherence Principle\n(RCP): a foundational constraint stating that for any reasoning system of order\nN, composed of systems operating over conceptual spaces of order N-1, semantic\ncoherence is preserved only by a recursively evaluable generalization operator\nthat spans and aligns those lower-order conceptual spaces. Crucially, this\ncoherence enables structural alignment. Without recursive coherence, no system\ncan reliably preserve goals, meanings, or reasoning consistency at scale. We\nformally define the Functional Model of Intelligence (FMI) as the only known\noperator capable of satisfying the RCP at any scale. The FMI is a minimal,\ncomposable architecture with internal functions (evaluation, modeling,\nadaptation, stability, decomposition, bridging) and external functions\n(storage, recall, System 1 and System 2 reasoning) vital for preserving\nsemantic structure across inference and coordination layers. We prove that any\nsystem lacking the FMI will experience recursive coherence breakdown as it\nscales, arguing that common AI issues like misalignment, hallucination, and\ninstability are symptoms of this structural coherence loss. Unlike other\nfoundational principles, RCP uniquely captures the internal, recursive dynamics\nneeded for coherent, alignable intelligence, modeling semantic coherence under\nrecursion. This work significantly impacts AI alignment, advocating a shift\nfrom behavioral constraints to structural coherence, and offers a pathway for\nsafely generalizable, robustly coherent AI at scale.", "AI": {"tldr": "\u8981\u6784\u5efa\u53ef\u6269\u5c55\u3001\u4e00\u81f4\u7684\u4eba\u5de5\u667a\u80fd\uff0c\u9700\u8981\u6ee1\u8db3\u9012\u5f52\u4e00\u81f4\u6027\u539f\u7406 (RCP)\uff0c\u800c\u529f\u80fd\u667a\u80fd\u6a21\u578b (FMI) \u662f\u6ee1\u8db3\u8be5\u539f\u7406\u7684\u552f\u4e00\u5df2\u77e5\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5728\u6269\u5c55\u6027\u3001\u4e00\u81f4\u6027\u548c\u5bf9\u9f50\u6027\u65b9\u9762\u7684\u95ee\u9898\u3002", "method": "\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u9012\u5f52\u4e00\u81f4\u6027\u539f\u7406 (RCP) \u548c\u529f\u80fd\u667a\u80fd\u6a21\u578b (FMI)\uff0c\u5e76\u8bc1\u660e\u4e86\u4efb\u4f55\u7f3a\u4e4f FMI \u7684\u7cfb\u7edf\u90fd\u4f1a\u968f\u7740\u89c4\u6a21\u7684\u6269\u5927\u800c\u51fa\u73b0\u9012\u5f52\u4e00\u81f4\u6027\u5d29\u6e83\u3002", "result": "\u63d0\u51fa\u4e86\u9012\u5f52\u4e00\u81f4\u6027\u539f\u7406 (RCP) \u548c\u529f\u80fd\u667a\u80fd\u6a21\u578b (FMI)\uff0c\u4e3a\u6784\u5efa\u5b89\u5168\u3001\u53ef\u6cdb\u5316\u3001\u9c81\u68d2\u4e00\u81f4\u7684\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u9014\u5f84\u3002", "conclusion": "\u9012\u5f52\u4e00\u81f4\u6027\u539f\u7406 (RCP) \u662f\u6784\u5efa\u53ef\u6269\u5c55\u3001\u4e00\u81f4\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u57fa\u7840\u7ea6\u675f\uff0c\u7f3a\u4e4fRCP\u4f1a\u5bfc\u81f4\u9519\u4f4d\u3001\u5e7b\u89c9\u548c\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002\u529f\u80fd\u667a\u80fd\u6a21\u578b (FMI) \u662f\u552f\u4e00\u5df2\u77e5\u7684\u80fd\u591f\u6ee1\u8db3RCP\u7684\u7b97\u5b50\u3002"}}
{"id": "2507.15885", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15885", "abs": "https://arxiv.org/abs/2507.15885", "authors": ["Pierluca D'Oro", "Caley Drooff", "Joy Chen", "Joseph Tighe"], "title": "ADEPTS: A Capability Framework for Human-Centered Agent Design", "comment": null, "summary": "Large language models have paved the way to powerful and flexible AI agents,\nassisting humans by increasingly integrating into their daily life. This\nflexibility, potential, and growing adoption demands a holistic and\ncross-disciplinary approach to developing, monitoring and discussing the\ncapabilities required for agent-driven user experiences. However, current\nguidance on human-centered AI agent development is scattered: UX heuristics\nfocus on interface behaviors, engineering taxonomies describe internal\npipelines, and ethics checklists address high-level governance. There is no\nconcise, user-facing vocabulary that tells teams what an agent should\nfundamentally be able to do. We introduce ADEPTS, a capability framework\ndefining a set of core user-facing capabilities to provide unified guidance\naround the development of AI agents. ADEPTS is based on six principles for\nhuman-centered agent design, that express the minimal, user-facing capabilities\nan AI agent should demonstrate to be understandable, controllable and\ntrustworthy in everyday use. ADEPTS complements existing frameworks and\ntaxonomies; differently from them, it sits at the interface between technical\nand experience development. By presenting ADEPTS, we aim to condense complex\nAI-UX requirements into a compact framework that is actionable guidance for AI\nresearchers, designers, engineers, and policy reviewers alike. We believe\nADEPTS has the potential of accelerating the improvement of user-relevant agent\ncapabilities, of easing the design of experiences that take advantage of those\ncapabilities, and of providing a shared language to track and discuss progress\naround the development of AI agents.", "AI": {"tldr": "\u63d0\u51faADEPTS\u6846\u67b6\uff0c\u7528\u4e8e\u6307\u5bfcAI\u4ee3\u7406\u5f00\u53d1\uff0c\u4f7f\u5176\u66f4\u6613\u4e8e\u7406\u89e3\u3001\u63a7\u5236\u548c\u4fe1\u4efb\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u5f00\u53d1\u7684\u6307\u5bfc\u5206\u6563\u4e14\u7f3a\u4e4f\u7edf\u4e00\u7684\u7528\u6237\u89c6\u89d2\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aADEPTS\u7684\u80fd\u529b\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aADEPTS\u7684\u80fd\u529b\u6846\u67b6\uff0c\u4ee5\u5e2e\u52a9\u5f00\u53d1\u4eba\u5458\u6784\u5efa\u66f4\u6613\u7406\u89e3\u3001\u53ef\u63a7\u548c\u503c\u5f97\u4fe1\u8d56\u7684AI\u4ee3\u7406\u3002", "conclusion": "\u4ecb\u7ecd\u4e86ADEPTS\uff0c\u4e00\u4e2a\u5b9a\u4e49\u6838\u5fc3\u7528\u6237\u80fd\u529b\u7684\u6846\u67b6\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u7684\u5f00\u53d1\u63d0\u4f9b\u7edf\u4e00\u6307\u5bfc\uff0c\u5f25\u5408\u4e86\u6280\u672f\u548c\u4f53\u9a8c\u5f00\u53d1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2507.15895", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15895", "abs": "https://arxiv.org/abs/2507.15895", "authors": ["Lisa Dargasz"], "title": "Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture", "comment": "Master's thesis, April 2025, 122 pages", "summary": "Reinforcement Learning is a machine learning methodology that has\ndemonstrated strong performance across a variety of tasks. In particular, it\nplays a central role in the development of artificial autonomous agents. As\nthese agents become increasingly capable, market readiness is rapidly\napproaching, which means those agents, for example taking the form of humanoid\nrobots or autonomous cars, are poised to transition from laboratory prototypes\nto autonomous operation in real-world environments. This transition raises\nconcerns leading to specific requirements for these systems - among them, the\nrequirement that they are designed to behave ethically. Crucially, research\ndirected toward building agents that fulfill the requirement to behave\nethically - referred to as artificial moral agents(AMAs) - has to address a\nrange of challenges at the intersection of computer science and philosophy.\nThis study explores the development of reason-based artificial moral agents\n(RBAMAs). RBAMAs are build on an extension of the reinforcement learning\narchitecture to enable moral decision-making based on sound normative\nreasoning, which is achieved by equipping the agent with the capacity to learn\na reason-theory - a theory which enables it to process morally relevant\npropositions to derive moral obligations - through case-based feedback. They\nare designed such that they adapt their behavior to ensure conformance to these\nobligations while they pursue their designated tasks. These features contribute\nto the moral justifiability of the their actions, their moral robustness, and\ntheir moral trustworthiness, which proposes the extended architecture as a\nconcrete and deployable framework for the development of AMAs that fulfills key\nethical desiderata. This study presents a first implementation of an RBAMA and\ndemonstrates the potential of RBAMAs in initial experiments.", "AI": {"tldr": "This paper introduces RBAMAs, which use reinforcement learning and normative reasoning to create ethically behaving AI agents, demonstrating a first implementation and its potential.", "motivation": "The increasing capability of artificial autonomous agents necessitates the development of ethically behaving agents, addressing challenges at the intersection of computer science and philosophy.", "method": "The study extends the reinforcement learning architecture to enable moral decision-making based on normative reasoning, using case-based feedback to learn a reason-theory for processing morally relevant propositions and deriving moral obligations.", "result": "The developed RBAMA adapts its behavior to conform to moral obligations while pursuing tasks, contributing to moral justifiability, robustness, and trustworthiness.", "conclusion": "This study presents a first implementation of a Reason-Based Artificial Moral Agent (RBAMA) and demonstrates its potential in initial experiments."}}
{"id": "2507.15901", "categories": ["cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15901", "abs": "https://arxiv.org/abs/2507.15901", "authors": ["Joydeep Chandra", "Satyam Kumar Navneet"], "title": "Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation", "comment": null, "summary": "The implementation of Artificial Intelligence (AI) in household environments,\nespecially in the form of proactive autonomous agents, brings about\npossibilities of comfort and attention as well as it comes with intra or\nextramural ethical challenges. This article analyzes agentic AI and its\napplications, focusing on its move from reactive to proactive autonomy,\nprivacy, fairness and user control. We review responsible innovation\nframeworks, human-centered design principles, and governance practices to\ndistill practical guidance for ethical smart home systems. Vulnerable user\ngroups such as elderly individuals, children, and neurodivergent who face\nhigher risks of surveillance, bias, and privacy risks were studied in detail in\ncontext of Agentic AI. Design imperatives are highlighted such as tailored\nexplainability, granular consent mechanisms, and robust override controls,\nsupported by participatory and inclusive methodologies. It was also explored\nhow data-driven insights, including social media analysis via Natural Language\nProcessing(NLP), can inform specific user needs and ethical concerns. This\nsurvey aims to provide both a conceptual foundation and suggestions for\ndeveloping transparent, inclusive, and trustworthy agentic AI in household\nautomation.", "AI": {"tldr": "Ethical smart home systems need tailored explainability, granular consent, and robust override controls to protect vulnerable users from surveillance and bias.", "motivation": "To provide a conceptual foundation and suggestions for developing transparent, inclusive, and trustworthy agentic AI in household automation, addressing ethical concerns for vulnerable user groups.", "method": "Review of responsible innovation frameworks, human-centered design principles, governance practices, and data-driven insights (including social media analysis via NLP).", "result": "Design imperatives such as tailored explainability, granular consent mechanisms, and robust override controls are highlighted, supported by participatory and inclusive methodologies.", "conclusion": "This article analyzes the ethical challenges of proactive autonomous AI agents in household environments, focusing on privacy, fairness, and user control, and offers practical guidance for developing ethical smart home systems."}}
{"id": "2507.15974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15974", "abs": "https://arxiv.org/abs/2507.15974", "authors": ["Tong Wu", "Chong Xiang", "Jiachen T. Wang", "Weichen Yu", "Chawin Sitawarin", "Vikash Sehwag", "Prateek Mittal"], "title": "Does More Inference-Time Compute Really Help Robustness?", "comment": "Preprint", "summary": "Recently, Zaremba et al. demonstrated that increasing inference-time\ncomputation improves robustness in large proprietary reasoning LLMs. In this\npaper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1,\nQwen3, Phi-reasoning) can also benefit from inference-time scaling using a\nsimple budget forcing strategy. More importantly, we reveal and critically\nexamine an implicit assumption in prior work: intermediate reasoning steps are\nhidden from adversaries. By relaxing this assumption, we identify an important\nsecurity risk, intuitively motivated and empirically verified as an inverse\nscaling law: if intermediate reasoning steps become explicitly accessible,\nincreased inference-time computation consistently reduces model robustness.\nFinally, we discuss practical scenarios where models with hidden reasoning\nchains are still vulnerable to attacks, such as models with tool-integrated\nreasoning and advanced reasoning extraction attacks. Our findings collectively\ndemonstrate that the robustness benefits of inference-time scaling depend\nheavily on the adversarial setting and deployment context. We urge\npractitioners to carefully weigh these subtle trade-offs before applying\ninference-time scaling in security-sensitive, real-world applications.", "AI": {"tldr": "\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u4f46\u524d\u63d0\u662f\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u9690\u85cf\uff1b\u5426\u5219\uff0c\u53cd\u800c\u964d\u4f4e\u9c81\u68d2\u6027\u3002", "motivation": "\u5148\u524d\u5de5\u4f5c\u8868\u660e\u589e\u52a0\u63a8\u7406\u65f6\u95f4\u8ba1\u7b97\u53ef\u4ee5\u63d0\u9ad8\u5927\u578b\u4e13\u6709\u63a8\u7406LLM\u7684\u9c81\u68d2\u6027\uff0c\u672c\u6587\u7814\u7a76\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u662f\u5426\u4e5f\u9002\u7528\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u53ef\u89c1\u6027\u5bf9\u6a21\u578b\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u3002", "method": "\u9996\u5148\u9a8c\u8bc1\u4e86\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u4e5f\u80fd\u4ece\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u4e2d\u83b7\u76ca\uff1b\u7136\u540e\uff0c\u901a\u8fc7\u653e\u5bbd\u5148\u524d\u5de5\u4f5c\u4e2d\u5173\u4e8e\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u9690\u85cf\u7684\u5047\u8bbe\uff0c\u63ed\u793a\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u9006\u5411\u7f29\u653e\u89c4\u5f8b\uff1a\u5982\u679c\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u53ef\u8bbf\u95ee\uff0c\u5219\u589e\u52a0\u63a8\u7406\u65f6\u95f4\u8ba1\u7b97\u4f1a\u964d\u4f4e\u6a21\u578b\u9c81\u68d2\u6027\uff1b\u6700\u540e\uff0c\u8ba8\u8bba\u4e86\u5177\u6709\u9690\u85cf\u63a8\u7406\u94fe\u7684\u6a21\u578b\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u653b\u51fb\u7684\u60c5\u51b5\u3002", "result": "\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u540c\u6837\u53d7\u76ca\u4e8e\u63a8\u7406\u65f6\u95f4\u6269\u5c55\uff1b\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u53ef\u89c1\u6027\u4f1a\u964d\u4f4e\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u5e26\u6765\u7684\u9c81\u68d2\u6027\u63d0\u5347\uff1b\u5177\u6709\u5de5\u5177\u96c6\u6210\u63a8\u7406\u548c\u9ad8\u7ea7\u63a8\u7406\u63d0\u53d6\u653b\u51fb\u7684\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u653b\u51fb\u3002", "conclusion": "\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u5bf9\u6a21\u578b\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u53d6\u51b3\u4e8e\u5bf9\u6297\u73af\u5883\u548c\u90e8\u7f72\u73af\u5883\uff0c\u5728\u5b89\u5168\u654f\u611f\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u8c28\u614e\u6743\u8861\u3002"}}
{"id": "2507.16020", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16020", "abs": "https://arxiv.org/abs/2507.16020", "authors": ["Xi Yang", "Jiachen Wang", "Song Han", "Suining He"], "title": "Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network", "comment": "6 pages, UrbComp 2024", "summary": "Efficient use of urban micromobility resources such as bike sharing is\nchallenging due to the unbalanced station-level demand and supply, which causes\nthe maintenance of the bike sharing systems painstaking. Prior efforts have\nbeen made on accurate prediction of bike traffics, i.e., demand/pick-up and\nreturn/drop-off, to achieve system efficiency. However, bike station-level\ntraffic prediction is difficult because of the spatial-temporal complexity of\nbike sharing systems. Moreover, such level of prediction over entire bike\nsharing systems is also challenging due to the large number of bike stations.\nTo fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention\nneural network to predict station-level bike traffic for entire bike sharing\nsystems. The proposed network consists of an encoder and a decoder with an\nattention mechanism representing the spatial correlation between features of\nbike stations in the system and another attention mechanism describing the\ntemporal characteristic of bike station traffic. Through experimental study on\nover 10 millions trips of bike sharing systems (> 700 stations) of New York\nCity, our network showed high accuracy in predicting the bike station traffic\nof all stations in the city.", "AI": {"tldr": "BikeMAN\u795e\u7ecf\u7f51\u7edc\u6709\u6548\u9884\u6d4b\u4e86\u6574\u4e2a\u81ea\u884c\u8f66\u5171\u4eab\u7cfb\u7edf\u7684\u7ad9\u70b9\u7ea7\u522b\u81ea\u884c\u8f66\u6d41\u91cf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u81ea\u884c\u8f66\u5171\u4eab\u7cfb\u7edf\u4e2d\u7ad9\u70b9\u7ea7\u522b\u4f9b\u9700\u4e0d\u5e73\u8861\u5bfc\u81f4\u7684\u7ef4\u62a4\u96be\u9898\uff0c\u4ee5\u53ca\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5bf9\u6574\u4e2a\u7cfb\u7edf\u8fdb\u884c\u51c6\u786e\u9884\u6d4b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5c42\u65f6\u7a7a\u6ce8\u610f\u529b\u795e\u7ecf\u7f51\u7edcBikeMAN\uff0c\u8be5\u7f51\u7edc\u5305\u542b\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff0c\u5e76\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u6765\u8868\u793a\u81ea\u884c\u8f66\u7ad9\u70b9\u7279\u5f81\u4e4b\u95f4\u7684\u7a7a\u95f4\u76f8\u5173\u6027\u548c\u81ea\u884c\u8f66\u7ad9\u70b9\u6d41\u91cf\u7684\u65f6\u95f4\u7279\u5f81\u3002", "result": "\u5728\u7ebd\u7ea6\u5e02\u8d85\u8fc7700\u4e2a\u7ad9\u70b9\uff0c1000\u4e07\u6b21\u884c\u7a0b\u7684\u6570\u636e\u96c6\u4e0a\uff0cBikeMAN\u7f51\u7edc\u5728\u9884\u6d4b\u81ea\u884c\u8f66\u7ad9\u70b9\u6d41\u91cf\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "BikeMAN\uff0c\u4e00\u4e2a\u591a\u5c42\u65f6\u7a7a\u6ce8\u610f\u529b\u795e\u7ecf\u7f51\u7edc\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u6574\u4e2a\u81ea\u884c\u8f66\u5171\u4eab\u7cfb\u7edf\u4e2d\u5404\u4e2a\u7ad9\u70b9\u7ea7\u522b\u7684\u81ea\u884c\u8f66\u6d41\u91cf\uff0c\u5e76\u5728\u7ebd\u7ea6\u5e02\u8d85\u8fc7700\u4e2a\u7ad9\u70b9\uff0c1000\u4e07\u6b21\u884c\u7a0b\u7684\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2507.16028", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16028", "abs": "https://arxiv.org/abs/2507.16028", "authors": ["Tehseen Rug", "Felix B\u00f6hmer", "Tessa Pfattheicher"], "title": "From Logic to Language: A Trust Index for Problem Solving with LLMs", "comment": "17 pages, 2 figures", "summary": "Classical computation, grounded in formal, logical systems, has been the\nengine of technological progress for decades, excelling at problems that can be\ndescribed with unambiguous rules. This paradigm, however, leaves a vast ocean\nof human problems -- those characterized by ambiguity, dynamic environments,\nand subjective context -- largely untouched. The advent of Large Language\nModels (LLMs) represents a fundamental shift, enabling computational systems to\nengage with this previously inaccessible domain using natural language. This\npaper introduces a unified framework to understand and contrast these\nproblem-solving paradigms. We define and delineate the problem spaces\naddressable by formal languages versus natural language. While solutions to the\nformer problem class can be evaluated using binary quality measures, the latter\nrequires a much more nuanced definition of approximate solution space taking\ninto account the vagueness, subjectivity and ambiguity inherent to natural\nlanguage. We therefore introduce a vector-valued trust index Q, which reflects\nsolution quality and distinguishes the binary correctness of formal solutions\nfrom the continuous adequacy spectrum characteristic of natural language\nsolutions. Within this framework, we propose two statistical quality\ndimensions. Normalized bi-semantic entropy measures robustness and conceptual\ndiversity of LLM answers given semantic variation in problem formulations.\nEmotional valence maps subjective valuation of a solution to a quantifiable\nmetric that can be maximized by invoking statistical measures. The concepts\nintroduced in this work will provide a more rigorous understanding of the\ncapabilities, limitations, and inherent nature of problem-solving in the age of\nLLMs.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5bf9\u6bd4\u4e86\u7ecf\u5178\u8ba1\u7b97\u548c\u57fa\u4e8eLLM\u7684\u8ba1\u7b97\u5728\u89e3\u51b3\u95ee\u9898\u4e0a\u7684\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u8bc4\u4f30LLM\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u7ecf\u5178\u8ba1\u7b97\u96be\u4ee5\u5904\u7406\u6a21\u7cca\u3001\u52a8\u6001\u548c\u4e3b\u89c2\u6027\u5f3a\u7684\u95ee\u9898\uff0c\u800cLLM\u80fd\u591f\u5904\u7406\u81ea\u7136\u8bed\u8a00\uff0c\u8fdb\u800c\u89e3\u51b3\u8fd9\u7c7b\u95ee\u9898\u3002", "method": "\u5b9a\u4e49\u4e86\u5f62\u5f0f\u8bed\u8a00\u548c\u81ea\u7136\u8bed\u8a00\u53ef\u89e3\u51b3\u7684\u95ee\u9898\u7a7a\u95f4\uff0c\u5e76\u5f15\u5165\u4e86\u8861\u91cfLLM\u7b54\u6848\u7a33\u5065\u6027\u548c\u6982\u5ff5\u591a\u6837\u6027\u7684\u6307\u6807\uff0c\u4ee5\u53ca\u5c06\u4e3b\u89c2\u8bc4\u4ef7\u91cf\u5316\u7684\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u7406\u89e3\u548c\u5bf9\u6bd4\u4e24\u79cd\u8303\u5f0f\uff0c\u5e76\u5b9a\u4e49\u4e86\u8861\u91cf\u81ea\u7136\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u7684\u5411\u91cf\u503c\u4fe1\u4efb\u6307\u6570 Q \u548c\u76f8\u5e94\u7684\u7edf\u8ba1\u8d28\u91cf\u7ef4\u5ea6\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u7406\u89e3\u548c\u5bf9\u6bd4\u7ecf\u5178\u8ba1\u7b97\u548c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u8ba1\u7b97\u8303\u5f0f\u5728\u89e3\u51b3\u95ee\u9898\u4e0a\u7684\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5411\u91cf\u503c\u4fe1\u4efb\u6307\u6570 Q \u6765\u8861\u91cf\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u89e3\u51b3\u65b9\u6848\u7684\u8d28\u91cf\u3002"}}
{"id": "2507.16067", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.16067", "abs": "https://arxiv.org/abs/2507.16067", "authors": ["Jeroen Spaans", "Jesse Heyninck"], "title": "A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)", "comment": "Full version, including proofs and appendices, of paper accepted at\n  IJCAI 2025", "summary": "Constraint Logic Programming (CLP) is a logic programming formalism used to\nsolve problems requiring the consideration of constraints, like resource\nallocation and automated planning and scheduling. It has previously been\nextended in various directions, for example to support fuzzy constraint\nsatisfaction, uncertainty, or negation, with different notions of semiring\nbeing used as a unifying abstraction for these generalizations. None of these\nextensions have studied clauses with negation allowed in the body. We\ninvestigate an extension of CLP which unifies many of these extensions and\nallows negation in the body. We provide semantics for such programs, using the\nframework of approximation fixpoint theory, and give a detailed overview of the\nimpacts of properties of the semirings on the resulting semantics. As such, we\nprovide a unifying framework that captures existing approaches and allows\nextending them with a more expressive language.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86CLP\u4ee5\u5141\u8bb8\u5728\u4f53\u4e2d\u4f7f\u7528\u5426\u5b9a\uff0c\u5e76\u4f7f\u7528\u8fd1\u4f3c\u4e0d\u52a8\u70b9\u7406\u8bba\u6846\u67b6\u63d0\u4f9b\u4e86\u5176\u8bed\u4e49\u3002", "motivation": "\u73b0\u6709\u7684CLP\u6269\u5c55\u6ca1\u6709\u7814\u7a76\u5141\u8bb8\u5728\u4f53\u4e2d\u4f7f\u7528\u5426\u5b9a\u7684\u5b50\u53e5\uff0c\u672c\u6587\u65e8\u5728\u6269\u5c55CLP\u4ee5\u7edf\u4e00\u8fd9\u4e9b\u6269\u5c55\u5e76\u5141\u8bb8\u5728\u4f53\u4e2d\u4f7f\u7528\u5426\u5b9a\u3002", "method": "\u4f7f\u7528\u8fd1\u4f3c\u4e0d\u52a8\u70b9\u7406\u8bba\u6846\u67b6", "result": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6355\u83b7\u4e86\u73b0\u6709\u65b9\u6cd5\u5e76\u5141\u8bb8\u4f7f\u7528\u66f4\u5177\u8868\u8fbe\u529b\u7684\u8bed\u8a00\u6269\u5c55\u5b83\u4eec\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u5141\u8bb8\u5728\u4f53\u4e2d\u4f7f\u7528\u5426\u5b9a\u7684CLP\u7684\u6269\u5c55\uff0c\u5e76\u4f7f\u7528\u8fd1\u4f3c\u4e0d\u52a8\u70b9\u7406\u8bba\u6846\u67b6\u63d0\u4f9b\u4e86\u6b64\u7c7b\u7a0b\u5e8f\u7684\u8bed\u4e49\uff0c\u8be6\u7ec6\u6982\u8ff0\u4e86\u534a\u73af\u5c5e\u6027\u5bf9\u7ed3\u679c\u8bed\u4e49\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.16110", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16110", "abs": "https://arxiv.org/abs/2507.16110", "authors": ["Shengchao Liu", "Hannan Xu", "Yan Ai", "Huanxin Li", "Yoshua Bengio", "Harry Guo"], "title": "Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization", "comment": null, "summary": "Large language models (LLMs) leverage chain-of-thought (CoT) techniques to\ntackle complex problems, representing a transformative breakthrough in\nartificial intelligence (AI). However, their reasoning capabilities have\nprimarily been demonstrated in solving math and coding problems, leaving their\npotential for domain-specific applications-such as battery discovery-largely\nunexplored. Inspired by the idea that reasoning mirrors a form of guided\nsearch, we introduce ChatBattery, a novel agentic framework that integrates\ndomain knowledge to steer LLMs toward more effective reasoning in materials\ndesign. Using ChatBattery, we successfully identify, synthesize, and\ncharacterize three novel lithium-ion battery cathode materials, which achieve\npractical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over\nthe widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this\ndiscovery, ChatBattery paves a new path by showing a successful LLM-driven and\nreasoning-based platform for battery materials invention. This complete\nAI-driven cycle-from design to synthesis to characterization-demonstrates the\ntransformative potential of AI-driven reasoning in revolutionizing materials\ndiscovery.", "AI": {"tldr": "AI\u9a71\u52a8\u7684ChatBattery\u6846\u67b6\u5b9e\u73b0\u4e86\u4ece\u8bbe\u8ba1\u5230\u5408\u6210\u5230\u8868\u5f81\u7684\u5b8c\u6574\u95ed\u73af\uff0c\u6210\u529f\u53d1\u73b0\u4e86\u4e09\u79cd\u65b0\u578b\u9502\u79bb\u5b50\u7535\u6c60\u6b63\u6781\u6750\u6599\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7535\u6c60\u5bb9\u91cf\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u5e94\u7528\uff08\u5982\u7535\u6c60\u53d1\u73b0\uff09\u4e2d\u7684\u6f5c\u529b\u3002", "method": "ChatBattery\u6846\u67b6\uff0c\u4e00\u79cd\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u6765\u5f15\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u66f4\u6709\u6548\u63a8\u7406\u7684\u4ee3\u7406\u6846\u67b6\u3002", "result": "\u6210\u529f\u8bc6\u522b\u3001\u5408\u6210\u548c\u8868\u5f81\u4e09\u79cd\u65b0\u578b\u9502\u79bb\u5b50\u7535\u6c60\u6b63\u6781\u6750\u6599\uff0c\u5bb9\u91cf\u5206\u522b\u63d0\u9ad828.8%\u300125.2%\u548c18.5%\u3002", "conclusion": "ChatBattery\u6846\u67b6\u6210\u529f\u5730\u8bc6\u522b\u3001\u5408\u6210\u548c\u8868\u5f81\u4e86\u4e09\u79cd\u65b0\u578b\u9502\u79bb\u5b50\u7535\u6c60\u6b63\u6781\u6750\u6599\uff0c\u5176\u5bb9\u91cf\u5206\u522b\u6bd4\u5e38\u7528\u7684NMC811\u6b63\u6781\u6750\u6599\u63d0\u9ad8\u4e8628.8%\u300125.2%\u548c18.5%\uff0c\u5e76\u5c55\u793a\u4e86AI\u9a71\u52a8\u7684\u63a8\u7406\u5728\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u53d8\u9769\u6f5c\u529b\u3002"}}
{"id": "2507.16126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16126", "abs": "https://arxiv.org/abs/2507.16126", "authors": ["Michael R. Bock", "Kara Molisee", "Zachary Ozer", "Sumit Shah"], "title": "TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task", "comment": null, "summary": "Can AI file your taxes? Not yet. Calculating US personal income taxes is a\ntask that requires building an understanding of vast amounts of English text\nand using that knowledge to carefully compute results. We propose TaxCalcBench,\na benchmark for determining models' abilities to calculate personal income tax\nreturns given all of the necessary information. Our experiment shows that\nstate-of-the-art models succeed in calculating less than a third of federal\nincome tax returns even on this simplified sample set. Our analysis concludes\nthat models consistently misuse tax tables, make errors in tax calculation, and\nincorrectly determine eligibility. Our findings point to the need for\nadditional infrastructure to apply LLMs to the personal income tax calculation\ntask.", "AI": {"tldr": "AI\u5c1a\u65e0\u6cd5\u51c6\u786e\u8ba1\u7b97\u7f8e\u56fd\u4e2a\u4eba\u6240\u5f97\u7a0e\u3002", "motivation": "\u63a2\u7d22AI\u8ba1\u7b97\u4e2a\u4eba\u6240\u5f97\u7a0e\u7684\u53ef\u884c\u6027\u3002", "method": "\u6784\u5efaTaxCalcBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6a21\u578b\u8ba1\u7b97\u4e2a\u4eba\u6240\u5f97\u7a0e\u7684\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u7b80\u5316\u7684\u6837\u672c\u96c6\u4e0a\uff0c\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u96be\u4ee5\u80dc\u4efb\u8fd9\u9879\u4efb\u52a1\u3002", "conclusion": "\u73b0\u6709\u6a21\u578b\u5728\u8ba1\u7b97\u4e2a\u4eba\u6240\u5f97\u7a0e\u65b9\u9762\u51c6\u786e\u7387\u4e0d\u8db3\u4e09\u5206\u4e4b\u4e00\uff0c\u9519\u8bef\u4e3b\u8981\u4f53\u73b0\u5728\u8bef\u7528\u7a0e\u8868\u3001\u8ba1\u7b97\u9519\u8bef\u548c\u8d44\u683c\u8ba4\u5b9a\u9519\u8bef\u3002"}}
