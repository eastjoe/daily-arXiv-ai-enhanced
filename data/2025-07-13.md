<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
*Javal Vyas,Mehmet Mercangoz*

Main category: cs.AI

TL;DR: 利用LLM统一化工过程的离散故障恢复和连续控制，提高了自动化系统的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现代化工过程日益复杂，劳动力短缺和故障场景复杂，需要一种将符号推理与自适应控制相结合的新型自动化模式。

Method: 该框架采用有限状态机 (FSM) 作为可解释的操作范围，结合LLM驱动的规划代理、仿真代理和验证-重提示循环，实现了高水平符号规划和低水平连续控制的统一。

Result: 案例研究表明，该框架在不同规模的FSM中取得了100%的有效路径成功率，并且在TCLab平台上的控制性能与经典PID控制相似，同时展现了其处理非线性动态的能力。

Conclusion: 该研究提出了一种利用大型语言模型 (LLM) 统一离散故障恢复规划和连续过程控制的框架，并通过案例研究验证了其在化学工程自动化中的有效性，尤其是在处理非线性动态方面。

Abstract: The increasing complexity of modern chemical processes, coupled with
workforce shortages and intricate fault scenarios, demands novel automation
paradigms that blend symbolic reasoning with adaptive control. In this work, we
introduce a unified agentic framework that leverages large language models
(LLMs) for both discrete fault-recovery planning and continuous process control
within a single architecture. We adopt Finite State Machines (FSMs) as
interpretable operating envelopes: an LLM-driven planning agent proposes
recovery sequences through the FSM, a Simulation Agent executes and checks each
transition, and a Validator-Reprompting loop iteratively refines invalid plans.
In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25
states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path
success within five reprompts-outperforming open-source LLMs in both accuracy
and latency. In Case Study 2, the same framework modulates dual-heater inputs
on a laboratory TCLab platform (and its digital twin) to maintain a target
average temperature under persistent asymmetric disturbances. Compared to
classical PID control, our LLM-based controller attains similar performance,
while ablation of the prompting loop reveals its critical role in handling
nonlinear dynamics. We analyze key failure modes-such as instruction following
lapses and coarse ODE approximations. Our results demonstrate that, with
structured feedback and modular agents, LLMs can unify high-level symbolic
planningand low-level continuous control, paving the way towards resilient,
language-driven automation in chemical engineering.

</details>


### [2] [BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks](https://arxiv.org/abs/2507.07134)
*Mridula Vijendran,Shuang Chen,Jingjing Deng,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: BOOST方法有效缓解了AI绘画分类模型的偏差问题，提高了模型的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI绘画分类模型存在偏差问题，尤其是在处理分布外数据时，这种偏差会影响模型的公平性和准确性。

Method: 提出了一种新的基于OOD的模型偏差自适应采样方法BOOST，该方法通过动态调整温度缩放和采样概率来促进所有类别的更公平表示。

Result: BOOST方法能够有效降低类偏差，并在保证高性能的同时提高公平性，提出了一种新的度量指标SODC来评估类间分离和每个类的偏差降低。

Conclusion: 提出了一种新的偏差自适应采样方法BOOST，用于解决AI模型在艺术分类中的偏差问题，并在KaoKore和PACS数据集上进行了评估，结果表明该方法能够在保证高性能的同时提高公平性。

Abstract: The pervasive issue of bias in AI presents a significant challenge to
painting classification, and is getting more serious as these systems become
increasingly integrated into tasks like art curation and restoration. Biases,
often arising from imbalanced datasets where certain artistic styles dominate,
compromise the fairness and accuracy of model predictions, i.e., classifiers
are less accurate on rarely seen paintings. While prior research has made
strides in improving classification performance, it has largely overlooked the
critical need to address these underlying biases, that is, when dealing with
out-of-distribution (OOD) data. Our insight highlights the necessity of a more
robust approach to bias mitigation in AI models for art classification on
biased training data. We propose a novel OOD-informed model bias adaptive
sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It
addresses these challenges by dynamically adjusting temperature scaling and
sampling probabilities, thereby promoting a more equitable representation of
all classes. We evaluate our proposed approach to the KaoKore and PACS
datasets, focusing on the model's ability to reduce class-wise bias. We further
propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to
assess class-wise separation and per-class bias reduction. Our method
demonstrates the ability to balance high performance with fairness, making it a
robust solution for unbiasing AI models in the art domain.

</details>


### [3] [State-Inference-Based Prompting for Natural Language Trading with Game NPCs](https://arxiv.org/abs/2507.07203)
*Minkyung Kim,Junsik Kim,Hwidong Bae,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: SIBP 通过状态推理提高了LLM在游戏交易中的可靠性，显著降低了规则违反的概率。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在规则驱动的交易系统中存在规则违反的问题，例如项目幻觉和计算错误，这会降低玩家的信任度。

Method: 提出了一种基于状态推理的提示方法（SIBP），将交易分解成六个状态，并使用上下文感知的项目引用和基于占位符的价格计算。

Result: 在100次交易对话的评估中，SIBP取得了97%以上的状态符合率、95%以上的引用准确率和99.7%的计算精度，优于基线方法。

Conclusion: 该论文提出了一种基于状态推理的提示方法（SIBP），用于在大型语言模型中实现可靠的、符合规则的交易系统，并通过实验验证了其有效性，为构建可信的NPC互动奠定了基础。

Abstract: Large Language Models enable dynamic game interactions but struggle with
rule-governed trading systems. Current implementations suffer from rule
violations, such as item hallucinations and calculation errors, that erode
player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable
trading through autonomous dialogue state inference and context-specific rule
adherence. The approach decomposes trading into six states within a unified
prompt framework, implementing context-aware item referencing and
placeholder-based price calculations. Evaluation across 100 trading dialogues
demonstrates >97% state compliance, >95% referencing accuracy, and 99.7%
calculation precision. SIBP maintains computational efficiency while
outperforming baseline approaches, establishing a practical foundation for
trustworthy NPC interactions in commercial games.

</details>


### [4] [Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains](https://arxiv.org/abs/2507.07217)
*Zili Wang,Frank Montabon,Kristin Yvonne Rozier*

Main category: cs.AI

TL;DR: 神经符号方法结合问题树方法，用于检测供应链非法活动，并评估人工与机器分类新闻文章的差异。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习技术需要大量训练数据集，而非法供应链的数据稀疏且不可靠。

Method: 使用神经符号方法，并提出了一种基于问题树的方法查询大型语言模型。

Result: 比较了人工和自动特征提取的有效性，并系统地评估了人类和机器对与供应链强迫劳动相关的新闻文章进行分类的差异。

Conclusion: 本文探讨了使用神经符号方法检测供应链中的非法活动，并比较了人工和自动特征提取的有效性，提出了一种基于问题树的方法来查询大型语言模型以识别和量化新闻文章的相关性，从而系统地评估人类和机器对与供应链强迫劳动相关的新闻文章进行分类的差异。

Abstract: Supply chain networks are complex systems that are challenging to analyze;
this problem is exacerbated when there are illicit activities involved in the
supply chain, such as counterfeit parts, forced labor, or human trafficking.
While machine learning (ML) can find patterns in complex systems like supply
chains, traditional ML techniques require large training data sets. However,
illicit supply chains are characterized by very sparse data, and the data that
is available is often (purposely) corrupted or unreliable in order to hide the
nature of the activities. We need to be able to automatically detect new
patterns that correlate with such illegal activity over complex, even temporal
data, without requiring large training data sets. We explore neurosymbolic
methods for identifying instances of illicit activity in supply chains and
compare the effectiveness of manual and automated feature extraction from news
articles accurately describing illicit activities uncovered by authorities. We
propose a question tree approach for querying a large language model (LLM) to
identify and quantify the relevance of articles. This enables a systematic
evaluation of the differences between human and machine classification of news
articles related to forced labor in supply chains.

</details>


### [5] [Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](https://arxiv.org/abs/2507.07257)
*Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekiou,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet*

Main category: cs.AI

TL;DR: 多智能体系统cmbagent自动化科学研究，表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动化科学研究任务，提高效率。

Method: 采用计划与控制策略协调代理工作流程，每个代理负责不同的任务（例如，检索科学论文和代码库、编写代码、解释结果、评论其他代理的输出）。

Result: 成功应用于博士级别的宇宙学任务（使用超新星数据测量宇宙学参数），并在两个基准数据集上表现优于最先进的LLM。

Conclusion: cmbagent，一个由约30个大型语言模型(LLM)代理组成的多智能体系统，能够自动执行科学研究任务，并在宇宙学参数测量任务中表现优于最先进的LLM。

Abstract: We present a multi-agent system for automation of scientific research tasks,
cmbagent. The system is formed by about 30 Large Language Model (LLM) agents
and implements a Planning & Control strategy to orchestrate the agentic
workflow, with no human-in-the-loop at any point. Each agent specializes in a
different task (performing retrieval on scientific papers and codebases,
writing code, interpreting results, critiquing the output of other agents) and
the system is able to execute code locally. We successfully apply cmbagent to
carry out a PhD level cosmology task (the measurement of cosmological
parameters using supernova data) and evaluate its performance on two benchmark
sets, finding superior performance over state-of-the-art LLMs. The source code
is available on GitHub, demonstration videos are also available, and the system
is deployed on HuggingFace and will be available on the cloud.

</details>


### [6] [Application of LLMs to Multi-Robot Path Planning and Task Allocation](https://arxiv.org/abs/2507.07302)
*Ashish Kumar*

Main category: cs.AI

TL;DR: 利用大型语言模型提高多智能体强化学习探索效率


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中，有效探索是一个难题，本文研究了专家探索的策略

Method: 将大型语言模型用作多智能体强化学习中的专家规划器，以提高探索效率

Result: 利用大型语言模型作为专家规划器可以提高多智能体强化学习中基于规划任务的探索效率

Conclusion: 本文研究了利用大型语言模型作为专家规划器来提高多智能体强化学习中基于规划任务的探索效率

Abstract: Efficient exploration is a well known problem in deep reinforcement learning
and this problem is exacerbated in multi-agent reinforcement learning due the
intrinsic complexities of such algorithms. There are several approaches to
efficiently explore an environment to learn to solve tasks by multi-agent
operating in that environment, of which, the idea of expert exploration is
investigated in this work. More specifically, this work investigates the
application of large-language models as expert planners for efficient
exploration in planning based tasks for multiple agents.

</details>


### [7] [ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning](https://arxiv.org/abs/2507.07306)
*Yichen Lu,Wei Dai,Jiaen Liu,Ching Wing Kwok,Zongheng Wu,Xudong Xiao,Ao Sun,Sheng Fu,Jianyuan Zhan,Yian Wang,Takatomo Saito,Sicheng Lai*

Main category: cs.AI

TL;DR: ViDove是一个多模态翻译代理系统，利用视觉和上下文信息以及多模态记忆系统，显著提高了翻译质量。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM翻译代理通常仅限于文本输入，ViDove旨在解决这个问题，以实现对多模态输入的翻译。

Method: ViDove利用视觉和上下文背景信息来增强翻译过程，集成了多模态记忆系统和长短期记忆模块，并加入了特定领域的知识。

Result: BLEU得分提高28%，SubER提高15%，并发布了新的基准测试DoveBench。

Conclusion: ViDove系统在字幕生成和一般翻译任务中取得了显著更高的翻译质量，BLEU得分提高了28%，SubER提高了15%。

Abstract: LLM-based translation agents have achieved highly human-like translation
results and are capable of handling longer and more complex contexts with
greater efficiency. However, they are typically limited to text-only inputs. In
this paper, we introduce ViDove, a translation agent system designed for
multimodal input. Inspired by the workflow of human translators, ViDove
leverages visual and contextual background information to enhance the
translation process. Additionally, we integrate a multimodal memory system and
long-short term memory modules enriched with domain-specific knowledge,
enabling the agent to perform more accurately and adaptively in real-world
scenarios. As a result, ViDove achieves significantly higher translation
quality in both subtitle generation and general translation tasks, with a 28%
improvement in BLEU scores and a 15% improvement in SubER compared to previous
state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark
for long-form automatic video subtitling and translation, featuring 17 hours of
high-quality, human-annotated data. Our code is available here:
https://github.com/pigeonai-org/ViDove

</details>


### [8] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

Main category: cs.AI

TL;DR: 对大型语言模型进行安全过滤在计算上是困难的，不能仅依靠外部过滤器


<details>
  <summary>Details</summary>
Motivation: 关注大型语言模型(LLM)的潜在滥用，特别是生成有害内容的问题。

Method: 研究了对大型语言模型(LLM)进行安全过滤的计算挑战，包括输入提示过滤和输出过滤。

Result: 证明了在过滤提示和输出方面都存在计算挑战。对抗性提示很容易被构造出来，并且在计算上与良性提示难以区分。在自然设置中，输出过滤在计算上是难以处理的。

Conclusion: 安全无法通过设计LLM内部（架构和权重）外部的过滤器来实现；特别是，对LLM的黑盒访问是不够的。

Abstract: With the increased deployment of large language models (LLMs), one concern is
their potential misuse for generating harmful content. Our work studies the
alignment challenge, with a focus on filters to prevent the generation of
unsafe information. Two natural points of intervention are the filtering of the
input prompt before it reaches the model, and filtering the output after
generation. Our main results demonstrate computational challenges in filtering
both prompts and outputs. First, we show that there exist LLMs for which there
are no efficient prompt filters: adversarial prompts that elicit harmful
behavior can be easily constructed, which are computationally indistinguishable
from benign prompts for any efficient filter. Our second main result identifies
a natural setting in which output filtering is computationally intractable. All
of our separation results are under cryptographic hardness assumptions. In
addition to these core findings, we also formalize and study relaxed mitigation
approaches, demonstrating further computational barriers. We conclude that
safety cannot be achieved by designing filters external to the LLM internals
(architecture and weights); in particular, black-box access to the LLM will not
suffice. Based on our technical results, we argue that an aligned AI system's
intelligence cannot be separated from its judgment.

</details>


### [9] [Supply Chain Optimization via Generative Simulation and Iterative Decision Policies](https://arxiv.org/abs/2507.07355)
*Haoyue Bai,Haoyu Wang,Nanxu Gong,Xinyuan Wang,Wangyang Ying,Haifeng Chen,Yanjie Fu*

Main category: cs.AI

TL;DR: Sim-to-Dec框架通过结合生成式模拟和历史-未来双感知决策模型，有效提高了供应链运输的效率和盈利能力。


<details>
  <summary>Details</summary>
Motivation: 提高供应链运输中的响应速度和经济效率，关注运输模式的战略决策。

Method: Sim-to-Dec框架结合了生成式模拟模块（利用自回归模型模拟状态变化）和历史-未来双感知决策模型（通过端到端优化与模拟器交互迭代改进）。

Result: 在三个真实数据集上的大量实验表明，Sim-to-Dec框架显著提高了准时送达率和利润。

Conclusion: Sim-to-Dec框架显著提高了准时送达率和利润。

Abstract: High responsiveness and economic efficiency are critical objectives in supply
chain transportation, both of which are influenced by strategic decisions on
shipping mode. An integrated framework combining an efficient simulator with an
intelligent decision-making algorithm can provide an observable, low-risk
environment for transportation strategy design. An ideal simulation-decision
framework must (1) generalize effectively across various settings, (2) reflect
fine-grained transportation dynamics, (3) integrate historical experience with
predictive insights, and (4) maintain tight integration between simulation
feedback and policy refinement. We propose Sim-to-Dec framework to satisfy
these requirements. Specifically, Sim-to-Dec consists of a generative
simulation module, which leverages autoregressive modeling to simulate
continuous state changes, reducing dependence on handcrafted domain-specific
rules and enhancing robustness against data fluctuations; and a history-future
dual-aware decision model, refined iteratively through end-to-end optimization
with simulator interactions. Extensive experiments conducted on three
real-world datasets demonstrate that Sim-to-Dec significantly improves timely
delivery rates and profit.

</details>


### [10] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
*Zerui Yang,Yuwei Wan,Yinqiao Li,Yudai Matsuda,Tong Xie,Linqi Song*

Main category: cs.AI

TL;DR: DrugMCTS框架通过结合RAG、多Agent协作和MCTS，显著提升了LLM在药物再利用任务中的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在科学领域（如药物发现）中的应用受到预训练知识限制，微调和检索增强生成方法存在计算开销大或无法充分利用结构化科学数据的问题。

Method: 该研究提出了一种名为DrugMCTS的新框架，该框架整合了检索增强生成（RAG）、多Agent协作和蒙特卡洛树搜索（MCTS），并利用五个专业Agent进行分子和蛋白质信息的检索和分析，实现结构化和迭代推理。

Result: DrugMCTS在DrugBank和KIBA数据集上的实验结果表明，其性能显著优于通用LLM和深度学习基线，具有更高的召回率和鲁棒性，在无需特定领域微调的情况下，超过了Deepseek-R1 20%以上。

Conclusion: DrugMCTS框架在药物 repurposing 任务中取得了比Deepseek-R1高20%以上的优异性能，在DrugBank和KIBA数据集上展现出更高的召回率和鲁棒性，证明了结构化推理、基于Agent的协作和反馈驱动搜索机制对于推进LLM在药物发现中的应用至关重要。

Abstract: Recent advances in large language models have demonstrated considerable
potential in scientific domains such as drug discovery. However, their
effectiveness remains constrained when reasoning extends beyond the knowledge
acquired during pretraining. Conventional approaches, such as fine-tuning or
retrieval-augmented generation, face limitations in either imposing high
computational overhead or failing to fully exploit structured scientific data.
To overcome these challenges, we propose DrugMCTS, a novel framework that
synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree
Search for drug repurposing. The framework employs five specialized agents
tasked with retrieving and analyzing molecular and protein information, thereby
enabling structured and iterative reasoning. Without requiring domain-specific
fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by
over 20\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate
that DrugMCTS achieves substantially higher recall and robustness compared to
both general-purpose LLMs and deep learning baselines. Our results highlight
the importance of structured reasoning, agent-based collaboration, and
feedback-driven search mechanisms in advancing LLM applications for drug
discovery.

</details>


### [11] [StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](https://arxiv.org/abs/2507.07445)
*Weihao Tan,Changjiu Jiang,Yu Duan,Mingcong Lei,Jiageng Li,Yitian Hong,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: StarDojo 是一个新的基准，用于评估 AI 智能体在星露谷物语环境下的生产生活能力，结果显示现有模型性能远未达到预期。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试很少同时评估生产活动和社会互动，StarDojo 旨在弥合这一差距。

Method: StarDojo 基于星露谷物语，评估 AI 智能体在开放式生产生活模拟中的能力，涵盖农业、工艺、探索、战斗和社交互动五大领域，提供 1000 个任务和 100 个代表性子集。

Result: GPT-4.1 等最先进 MLLM 智能体在 StarDojo 上表现不佳，成功率低，凸显了在复杂生产生活环境中构建强大、开放式智能体的挑战。

Conclusion: StarDojo 作为基准测试，暴露了最先进的多模态大型语言模型（MLLM）代理在视觉理解、多模态推理和低级操作方面的局限性，即使是 GPT-4.1 也只有 12.7% 的成功率。

Abstract: Autonomous agents navigating human society must master both production
activities and social interactions, yet existing benchmarks rarely evaluate
these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel
benchmark based on Stardew Valley, designed to assess AI agents in open-ended
production-living simulations. In StarDojo, agents are tasked to perform
essential livelihood activities such as farming and crafting, while
simultaneously engaging in social interactions to establish relationships
within a vibrant community. StarDojo features 1,000 meticulously curated tasks
across five key domains: farming, crafting, exploration, combat, and social
interactions. Additionally, we provide a compact subset of 100 representative
tasks for efficient model evaluation. The benchmark offers a unified,
user-friendly interface that eliminates the need for keyboard and mouse
control, supports all major operating systems, and enables the parallel
execution of multiple environment instances, making it particularly well-suited
for evaluating the most capable foundation agents, powered by multimodal large
language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents
demonstrate substantial limitations, with the best-performing model, GPT-4.1,
achieving only a 12.7% success rate, primarily due to challenges in visual
understanding, multimodal reasoning and low-level manipulation. As a
user-friendly environment and benchmark, StarDojo aims to facilitate further
research towards robust, open-ended agents in complex production-living
environments.

</details>


### [12] [Position: We Need An Algorithmic Understanding of Generative AI](https://arxiv.org/abs/2507.07544)
*Oliver Eberle,Thomas McGee,Hamza Giaffar,Taylor Webb,Ida Momennejad*

Main category: cs.AI

TL;DR: 研究LLM的算法机制，提出AlgEval框架用于系统性研究。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注通过扩展模型规模来提升性能，缺乏对LLM底层算法的理论和实证理解。

Method: 提出AlgEval框架，结合自上而下的假设和自下而上的测试（例如电路级分析注意力模式和隐藏状态），对LLM如何解决特定任务进行系统评估。

Result: 提出AlgEval框架，并以涌现搜索算法为例进行案例研究，展示了该框架的应用。

Conclusion: 该论文提出AlgEval框架，旨在系统性地研究大型语言模型（LLM）学习和使用的算法，通过分析潜在表示、注意力机制和推理时间计算来揭示算法基元及其组合方式。

Abstract: What algorithms do LLMs actually learn and use to solve problems? Studies
addressing this question are sparse, as research priorities are focused on
improving performance through scale, leaving a theoretical and empirical gap in
understanding emergent algorithms. This position paper proposes AlgEval: a
framework for systematic research into the algorithms that LLMs learn and use.
AlgEval aims to uncover algorithmic primitives, reflected in latent
representations, attention, and inference-time compute, and their algorithmic
composition to solve task-specific problems. We highlight potential
methodological paths and a case study toward this goal, focusing on emergent
search algorithms. Our case study illustrates both the formation of top-down
hypotheses about candidate algorithms, and bottom-up tests of these hypotheses
via circuit-level analysis of attention patterns and hidden states. The
rigorous, systematic evaluation of how LLMs actually solve tasks provides an
alternative to resource-intensive scaling, reorienting the field toward a
principled understanding of underlying computations. Such algorithmic
explanations offer a pathway to human-understandable interpretability, enabling
comprehension of the model's internal reasoning performance measures. This can
in turn lead to more sample-efficient methods for training and improving
performance, as well as novel architectures for end-to-end and multi-agent
systems.

</details>


### [13] [On Trustworthy Rule-Based Models and Explanations](https://arxiv.org/abs/2507.07576)
*Mohamed Siala,Jordi Planes,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 规则型机器学习模型存在负面方面（负重叠、冗余），且常用学习工具会产生此类模型。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型的可解释性在高风险领域至关重要，错误的解释会误导人类决策者。规则型模型虽然被广泛应用，但存在负重叠和冗余等问题。

Method: 分析规则型机器学习模型的负面方面，例如负重叠和冗余。

Result: 开发了分析规则型系统中这些负面方面的算法，并得出结论：现有工具学习到的规则集存在这些问题。

Conclusion: 现有学习规则型机器学习模型的工具会产生具有一个或多个负面方面的规则集。

Abstract: A task of interest in machine learning (ML) is that of ascribing explanations
to the predictions made by ML models. Furthermore, in domains deemed high risk,
the rigor of explanations is paramount. Indeed, incorrect explanations can and
will mislead human decision makers. As a result, and even if interpretability
is acknowledged as an elusive concept, so-called interpretable models are
employed ubiquitously in high-risk uses of ML and data mining (DM). This is the
case for rule-based ML models, which encompass decision trees, diagrams, sets
and lists. This paper relates explanations with well-known undesired facets of
rule-based ML models, which include negative overlap and several forms of
redundancy. The paper develops algorithms for the analysis of these undesired
facets of rule-based systems, and concludes that well-known and widely used
tools for learning rule-based ML models will induce rule sets that exhibit one
or more negative facets.

</details>


### [14] [Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs](https://arxiv.org/abs/2507.07595)
*Zhixiang Su,Di Wang,Chunyan Miao*

Main category: cs.AI

TL;DR: 提出一种新的上下文池化方法，提升了基于图神经网络的知识图谱链接预测模型的性能，并在多个数据集上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图神经网络的知识图谱链接预测模型，其简单的聚合方式并未显著影响模型性能，因此本文旨在提出一种新的方法来提高模型的有效性。

Method: 提出了一种名为上下文池化的图池化方法，该方法能够生成特定于查询的图，并通过邻域精度和邻域召回率评估邻居的逻辑相关性，从而识别出与链接预测相关的邻居。

Result: 在三个公共数据集上，应用于两个最先进的模型，并在48个设置中的42个中取得了最先进的性能。

Conclusion: 本文提出了一种新颖的上下文池化方法，用于增强基于图神经网络的知识图谱链接预测模型的有效性，并在48个设置中的42个中取得了最先进的性能。

Abstract: Recent investigations on the effectiveness of Graph Neural Network
(GNN)-based models for link prediction in Knowledge Graphs (KGs) show that
vanilla aggregation does not significantly impact the model performance. In
this paper, we introduce a novel method, named Context Pooling, to enhance
GNN-based models' efficacy for link predictions in KGs. To our best of
knowledge, Context Pooling is the first methodology that applies graph pooling
in KGs. Additionally, Context Pooling is first-of-its-kind to enable the
generation of query-specific graphs for inductive settings, where testing
entities are unseen during training. Specifically, we devise two metrics,
namely neighborhood precision and neighborhood recall, to assess the neighbors'
logical relevance regarding the given queries, thereby enabling the subsequent
comprehensive identification of only the logically relevant neighbors for link
prediction. Our method is generic and assessed by being applied to two
state-of-the-art (SOTA) models on three public transductive and inductive
datasets, achieving SOTA performance in 42 out of 48 settings.

</details>


### [15] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

Main category: cs.AI

TL;DR: 微调的Llama 3B模型有效提取急诊病历中的疫苗信息，用于疫苗安全监测。


<details>
  <summary>Details</summary>
Motivation: 评估微调的Llama 3.2模型从急诊分诊记录中提取疫苗相关信息的能力，以支持近乎实时的疫苗安全监测。

Method: 微调Llama 3.2B参数模型，并与提示工程模型和基于规则的方法进行比较。使用了模型量化以提高在资源受限环境下的效率。

Result: 微调的Llama 30亿参数模型在提取疫苗名称的准确性方面优于其他模型。模型量化技术实现了在资源受限环境下的高效部署。

Conclusion: 大型语言模型(LLM)在自动提取急诊室病历中的疫苗信息方面具有潜力，可有效支持疫苗安全监测和早期发现免疫后不良事件。

Abstract: This study evaluates fine-tuned Llama 3.2 models for extracting
vaccine-related information from emergency department triage notes to support
near real-time vaccine safety surveillance. Prompt engineering was used to
initially create a labeled dataset, which was then confirmed by human
annotators. The performance of prompt-engineered models, fine-tuned models, and
a rule-based approach was compared. The fine-tuned Llama 3 billion parameter
model outperformed other models in its accuracy of extracting vaccine names.
Model quantization enabled efficient deployment in resource-constrained
environments. Findings demonstrate the potential of large language models in
automating data extraction from emergency department notes, supporting
efficient vaccine safety surveillance and early detection of emerging adverse
events following immunization issues.

</details>


### [16] [Towards conservative inference in credal networks using belief functions: the case of credal chains](https://arxiv.org/abs/2507.07619)
*Marco Sangalli,Thomas Krak,Cassio de Campos*

Main category: cs.AI

TL;DR: 本文提出了一种新的、更高效的置信度推理框架，用于链式credal网络，并对其进行了评估。


<details>
  <summary>Details</summary>
Motivation: 探索在credal网络中进行置信度推理的方法。

Method: 基于Dempster-Shafer理论，对credal网络中的置信度推理进行了研究，提出了一种新的置信度传播框架。

Result: 提出了一种新的在链式credal网络中进行置信度推理的框架，并通过数值结果比较了基于置信度的推理和经典的敏感性分析。

Conclusion: 本文提出了一种新的框架，用于在特定类型的credal网络（链式网络）中进行置信度推理，该框架有效地结合了计算速度和鲁棒的不确定性表示。

Abstract: This paper explores belief inference in credal networks using Dempster-Shafer
theory. By building on previous work, we propose a novel framework for
propagating uncertainty through a subclass of credal networks, namely chains.
The proposed approach efficiently yields conservative intervals through belief
and plausibility functions, combining computational speed with robust
uncertainty representation. Key contributions include formalizing belief-based
inference methods and comparing belief-based inference against classical
sensitivity analysis. Numerical results highlight the advantages and
limitations of applying belief inference within this framework, providing
insights into its practical utility for chains and for credal networks in
general.

</details>
