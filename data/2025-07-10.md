<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 8]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Digital Wargames to Enhance Military Medical Evacuation Decision-Making](https://arxiv.org/abs/2507.06373)
*Jeremy Fischer,Ram Krishnamoorthy,Vishal Kumar,Mahdi Al-Husseini*

Main category: cs.AI

TL;DR: A new Unity-based simulation, MEWI, effectively trains medical evacuation planning and decision-making, showing substantial improvement in student learning and teamwork.


<details>
  <summary>Details</summary>
Motivation: Lack of a medium to simulate medical evacuation networks in a classroom setting for offline planning and online decision-making evaluation.

Method: Developed a 3D multiplayer simulation (MEWI) in Unity to simulate battlefield medical evacuation scenarios.  Utilized two scenarios (Pacific amphibious assault and Eurasian conflict) and analyzed data from two iterations of the Pacific scenario, incorporating Likert survey data and observer notes.

Result: MEWI participation substantially improves medical evacuation lesson uptake and cooperative decision-making.  The simulation offers valuable insights for improving medical evacuation education and operations.

Conclusion: MEWI, a 3D multiplayer simulation in Unity, significantly improves medical evacuation lesson uptake and cooperative decision-making in classroom settings.

Abstract: Medical evacuation is one of the United States Army's most storied and
critical mission sets, responsible for efficiently and expediently evacuating
the battlefield ill and injured. Medical evacuation planning involves designing
a robust network of medical platforms and facilities capable of moving and
treating large numbers of casualties. Until now, there has not been a medium to
simulate these networks in a classroom setting and evaluate both offline
planning and online decision-making performance. This work describes the
Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer
simulation developed in Unity that replicates battlefield constraints and
uncertainties. MEWI accurately models patient interactions at casualty
collection points, ambulance exchange points, medical treatment facilities, and
evacuation platforms. Two operational scenarios are introduced: an amphibious
island assault in the Pacific and a Eurasian conflict across a sprawling road
and river network. These scenarios pit students against the clock to save as
many casualties as possible while adhering to doctrinal lessons learned during
didactic training. We visualize performance data collected from two iterations
of the MEWI Pacific scenario executed in the United States Army's Medical
Evacuation Doctrine Course. We consider post-wargame Likert survey data from
student participants and external observer notes to identify key planning
decision points, document medical evacuation lessons learned, and quantify
general utility. Results indicate that MEWI participation substantially
improves uptake of medical evacuation lessons learned and co-operative
decision-making. MEWI is a substantial step forward in the field of
high-fidelity training tools for medical education, and our study findings
offer critical insights into improving medical evacuation education and
operations across the joint force.

</details>


### [2] [Representing Prompting Patterns with PDL: Compliance Agent Case Study](https://arxiv.org/abs/2507.06396)
*Mandana Vaziri,Louis Mandel,Yuji Watanabe,Hirokuni Kitahara,Martin Hirzel,Anca Sailer*

Main category: cs.AI

TL;DR: PDL 是一种新的提示表示语言，通过抽象化提示组合，提高了大型语言模型提示的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的框架要么隐藏了复杂性，要么提供了僵化的预设模式，难以定制，难以进行复杂的自主编程。

Method: 提出了一种新的Prompt声明语言（PDL），用于表示提示，并结合规则代码和外部工具，支持手动和自动提示调整。

Result: 通过合规代理的案例研究，证明了PDL的实用性，与使用预设代理和提示模式相比，性能提升高达4倍。

Conclusion: 提出了一种新的Prompt声明语言（PDL），用于表示和优化大型语言模型的提示，通过抽象化提示组合的底层实现，提高了程序员的生产力，并在合规代理案例研究中取得了显著的性能提升。

Abstract: Prompt engineering for LLMs remains complex, with existing frameworks either
hiding complexity behind restrictive APIs or providing inflexible canned
patterns that resist customization -- making sophisticated agentic programming
challenging. We present the Prompt Declaration Language (PDL), a novel approach
to prompt representation that tackles this fundamental complexity by bringing
prompts to the forefront, enabling manual and automatic prompt tuning while
capturing the composition of LLM calls together with rule-based code and
external tools. By abstracting away the plumbing for such compositions, PDL
aims at improving programmer productivity while providing a declarative
representation that is amenable to optimization. This paper demonstrates PDL's
utility through a real-world case study of a compliance agent. Tuning the
prompting pattern of this agent yielded up to 4x performance improvement
compared to using a canned agent and prompt pattern.

</details>


### [3] [Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI](https://arxiv.org/abs/2507.06398)
*David Orban*

Main category: cs.AI

TL;DR: 研究 AI 超指数增长的“震动技术假说”，开发理论框架和验证方法，为未来研究和政策提供见解。


<details>
  <summary>Details</summary>
Motivation: 研究 AI 能力的超指数增长（震动技术假说）及其潜在影响

Method: 开发理论框架和蒙特卡洛模拟验证检测方法

Result: 创建了用于未来实证研究的可靠工具，为理解潜在的 AI 轨迹及其对 AGI 出现的影响提供了数学基础。

Conclusion: 该论文研究了 AI 能力的超指数增长（加速增长或正的三阶导数）的“震动技术假说”，开发了一个理论框架并通过蒙特卡洛模拟验证了检测方法，同时承认经验验证需要合适的数据。分析集中在为未来的实证研究创建可靠的工具，并探讨了该假设被证明有效的潜在影响。

Abstract: This paper investigates the Jolting Technologies Hypothesis, which posits
superexponential growth (increasing acceleration, or a positive third
derivative) in the development of AI capabilities. We develop a theoretical
framework and validate detection methodologies through Monte Carlo simulations,
while acknowledging that empirical validation awaits suitable longitudinal
data. Our analysis focuses on creating robust tools for future empirical
studies and exploring the potential implications should the hypothesis prove
valid. The study examines how factors such as shrinking idea-to-action
intervals and compounding iterative AI improvements drive this jolting pattern.
By formalizing jolt dynamics and validating detection methods through
simulation, this work provides the mathematical foundation necessary for
understanding potential AI trajectories and their consequences for AGI
emergence, offering insights for research and policy.

</details>


### [4] [Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)](https://arxiv.org/abs/2507.06798)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: q-辩证系统强于p-辩证系统，强于(d-)辩证系统。


<details>
  <summary>Details</summary>
Motivation: 对辩证系统进行建模，以捕捉研究人员或研究团体在追求真理的过程中如何改进信念。

Method: 证明

Result: 证明了不同类型辩证系统能力的差异，突出了反例和矛盾在自动信念修正中的互补作用。

Conclusion: 证明了q-辩证系统严格强于p-辩证系统，p-辩证系统严格强于(d-)辩证系统，解决了文献中的一个开放性问题。

Abstract: Dialectical systems are a mathematical formalism for modeling an agent
updating a knowledge base seeking consistency. Introduced in the 1970s by
Roberto Magari, they were originally conceived to capture how a working
mathematician or a research community refines beliefs in the pursuit of truth.
Dialectical systems also serve as natural models for the belief change of an
automated agent, offering a unifying, computable framework for dynamic belief
management.
  The literature distinguishes three main models of dialectical systems:
(d-)dialectical systems based on revising beliefs when they are seen to be
inconsistent, p-dialectical systems based on revising beliefs based on finding
a counterexample, and q-dialectical systems which can do both. We answer an
open problem in the literature by proving that q-dialectical systems are
strictly more powerful than p-dialectical systems, which are themselves known
to be strictly stronger than (d-)dialectical systems. This result highlights
the complementary roles of counterexample and contradiction in automated belief
revision, and thus also in the reasoning processes of mathematicians and
research communities.

</details>


### [5] [SCC-recursiveness in infinite argumentation (extended version)](https://arxiv.org/abs/2507.06852)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 扩展SCC递归性到无限论证框架，发现方向性在无限环境中通常失败，但在有限环境中部分有效。


<details>
  <summary>Details</summary>
Motivation: 现有的SCC递归语义在无限AF中可靠性不高，因此需要扩展到无限环境。

Method: 提出两种扩展SCC递归性的方法，并使用Baroni和Giacomin的标准进行评估。

Result: 两种方法在无限环境下方向性通常失败，但在有限框架下部分满足方向性。

Conclusion: 提出两种将SCC递归性扩展到无限环境的方法，并使用Baroni和Giacomin的既定标准对其进行系统评估，结果表明方向性通常会失败，但在有限框架中，部分语义满足方向性。

Abstract: Argumentation frameworks (AFs) are a foundational tool in artificial
intelligence for modeling structured reasoning and conflict. SCC-recursiveness
is a well-known design principle in which the evaluation of arguments is
decomposed according to the strongly connected components (SCCs) of the attack
graph, proceeding recursively from "higher" to "lower" components. While
SCC-recursive semantics such as \cft and \stgt have proven effective for finite
AFs, Baumann and Spanring showed the failure of SCC-recursive semantics to
generalize reliably to infinite AFs due to issues with well-foundedness.
  We propose two approaches to extending SCC-recursiveness to the infinite
setting. We systematically evaluate these semantics using Baroni and Giacomin's
established criteria, showing in particular that directionality fails in
general. We then examine these semantics' behavior in finitary frameworks,
where we find some of our semantics satisfy directionality. These results
advance the theory of infinite argumentation and lay the groundwork for
reasoning systems capable of handling unbounded or evolving domains.

</details>


### [6] [Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report](https://arxiv.org/abs/2507.06968)
*Li Du,Hanyu Zhao,Yiming Ju,Tengfei Pan*

Main category: cs.AI

TL;DR: 提出一种构建高质量指令数据集的框架，构建了InfinityInstruct-Subject数据集，提升了模型的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有的指令数据集虽然规模庞大，但在处理复杂指令和罕见领域任务时仍存在不足，主要原因是指令集的覆盖范围和深度有限。

Method: 提出了一种系统化的指令数据构建框架，包含分层标注系统、信息种子选择算法、进化数据合成过程和模型缺陷诊断与目标数据生成。

Result: 构建了包含约150万条指令的InfinityInstruct-Subject数据集，实验表明该数据集能有效提升多个基础模型在多个基准任务上的指令遵循能力，并具有更广的覆盖范围和更深的深度。

Conclusion: 这项工作提出了一种系统化的指令数据构建框架，用于持续改进指令数据的覆盖范围和深度，并构建了一个名为InfinityInstruct-Subject的高质量数据集，实验结果表明该数据集能有效提升模型的指令遵循能力。

Abstract: Instruction tuning has become a foundation for unlocking the capabilities of
large-scale pretrained models and improving their performance on complex tasks.
Thus, the construction of high-quality instruction datasets is crucial for
enhancing model performance and generalizability. Although current instruction
datasets have reached tens of millions of samples, models finetuned on them may
still struggle with complex instruction following and tasks in rare domains.
This is primarily due to limited expansion in both ``coverage'' (coverage of
task types and knowledge areas) and ``depth'' (instruction complexity) of the
instruction set. To address this issue, we propose a systematic instruction
data construction framework, which integrates a hierarchical labeling system,
an informative seed selection algorithm, an evolutionary data synthesis
process, and a model deficiency diagnosis with targeted data generation. These
components form an iterative closed-loop to continuously enhance the coverage
and depth of instruction data. Based on this framework, we construct
InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million
instructions. Experiments on multiple foundation models and benchmark tasks
demonstrate its effectiveness in improving instruction-following capabilities.
Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage
and depth compared to comparable synthesized instruction datasets. Our work
lays a theoretical and practical foundation for the efficient, continuous
evolution of instruction datasets, moving from data quantity expansion to
qualitative improvement.

</details>


### [7] [The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation](https://arxiv.org/abs/2507.06993)
*Jieren Deng,Aleksandar Cvetkovic,Pak Kiu Chung,Dragomir Yankov,Chiqun Zhang*

Main category: cs.AI

TL;DR: 提出一种基于三个协作代理的智能旅行规划系统，以应对现实世界中旅行规划的复杂性和动态性。


<details>
  <summary>Details</summary>
Motivation: 现有旅行规划系统静态且零散，难以应对现实环境变化和行程中断。

Method: 提出三个协作代理：旅行规划代理、目的地辅助代理和本地发现代理，分别负责智能行程规划、精准“最后一公里”导航和动态行程调整。

Result: 实验证明，该系统在查询解释、导航精度和中断恢复能力方面有显著提升。

Conclusion: 该系统在查询解释、导航精度和中断恢复能力方面均有显著提升，显示出其在城市探索和紧急响应等应用中的潜力。

Abstract: Traditional travel-planning systems are often static and fragmented, leaving
them ill-equipped to handle real-world complexities such as evolving
environmental conditions and unexpected itinerary disruptions. In this paper,
we identify three gaps between existing service providers causing frustrating
user experience: intelligent trip planning, precision "last-100-meter"
navigation, and dynamic itinerary adaptation. We propose three cooperative
agents: a Travel Planning Agent that employs grid-based spatial grounding and
map analysis to help resolve complex multi-modal user queries; a Destination
Assistant Agent that provides fine-grained guidance for the final navigation
leg of each journey; and a Local Discovery Agent that leverages image
embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to
trip plan disruptions. With evaluations and experiments, our system
demonstrates substantial improvements in query interpretation, navigation
accuracy, and disruption resilience, underscoring its promise for applications
from urban exploration to emergency response.

</details>


### [8] [First Return, Entropy-Eliciting Explore](https://arxiv.org/abs/2507.07017)
*Tianyu Zheng,Tianshun Xing,Qingshui Gu,Taoran Liang,Xingwei Qu,Xin Zhou,Yizhi Li,Zhoufutu Wen,Chenghua Lin,Wenhao Huang,Qian Liu,Ge Zhang,Zejun Ma*

Main category: cs.AI

TL;DR: FR3E是一种新的探索框架，通过有针对性的引导，提高了LLM在数学推理任务上的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: RLVR提高了LLM的推理能力，但存在探索不稳定的问题。

Method: 提出了一种结构化的探索框架FR3E，用于识别推理轨迹中的高不确定性决策点，并执行有针对性的展开以构建语义相关的中间反馈。

Result: 在数学推理基准测试(AIME24)上，FR3E促进了更稳定的训练，产生更长、更连贯的响应，并提高了完全正确轨迹的比例。

Conclusion: FR3E框架通过更强大和结构化的探索，提高了LLM的推理能力。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning
abilities of Large Language Models (LLMs) but it struggles with unstable
exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a
structured exploration framework that identifies high-uncertainty decision
points in reasoning trajectories and performs targeted rollouts to construct
semantically grounded intermediate feedback. Our method provides targeted
guidance without relying on dense supervision. Empirical results on
mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable
training, produces longer and more coherent responses, and increases the
proportion of fully correct trajectories. These results highlight the
framework's effectiveness in improving LLM reasoning through more robust and
structured exploration.

</details>
