{"id": "2509.07011", "categories": ["cs.AI", "03E72, 94D05,"], "pdf": "https://arxiv.org/pdf/2509.07011", "abs": "https://arxiv.org/abs/2509.07011", "authors": ["Kirisci Murat"], "title": "Renewable Energy Sources Selection Analysis with the Maximizing Deviation Method", "comment": "25 pages, 5 figures, 6 Tables", "summary": "Multi-criteria decision-making methods provide decision-makers with\nappropriate tools to make better decisions in uncertain, complex, and\nconflicting situations. Fuzzy set theory primarily deals with the uncertainty\ninherent in human thoughts and perceptions and attempts to quantify this\nuncertainty. Fuzzy logic and fuzzy set theory are utilized with multi-criteria\ndecision-making methods because they effectively handle uncertainty and\nfuzziness in decision-makers' judgments, allowing for verbal judgments of the\nproblem. This study utilizes the Fermatean fuzzy environment, a generalization\nof fuzzy sets. An optimization model based on the deviation maximization method\nis proposed to determine partially known feature weights. This method is\ncombined with interval-valued Fermatean fuzzy sets. The proposed method was\napplied to the problem of selecting renewable energy sources. The reason for\nchoosing renewable energy sources is that meeting energy needs from renewable\nsources, balancing carbon emissions, and mitigating the effects of global\nclimate change are among the most critical issues of the recent period. Even\nthough selecting renewable energy sources is a technical issue, the managerial\nand political implications of this issue are also important, and are discussed\nin this study.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u504f\u5dee\u6700\u5927\u5316\u65b9\u6cd5\u7684\u4f18\u5316\u6a21\u578b\uff0c\u7528\u4e8e\u786e\u5b9a\u90e8\u5206\u5df2\u77e5\u7279\u5f81\u6743\u91cd\uff0c\u5e76\u5c06\u5176\u4e0e\u533a\u95f4\u503cFermatean\u6a21\u7cca\u96c6\u76f8\u7ed3\u5408\uff0c\u5e94\u7528\u4e8e\u53ef\u518d\u751f\u80fd\u6e90\u7684\u9009\u62e9\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5728\u4e0d\u786e\u5b9a\u3001\u590d\u6742\u548c\u51b2\u7a81\u73af\u5883\u4e0b\u9009\u62e9\u53ef\u518d\u751f\u80fd\u6e90\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u504f\u5dee\u6700\u5927\u5316\u65b9\u6cd5\u7684\u4f18\u5316\u6a21\u578b\uff0c\u7ed3\u5408\u533a\u95f4\u503cFermatean\u6a21\u7cca\u96c6\u5904\u7406\u6a21\u7cca\u51b3\u7b56\u3002", "result": "\u5c06\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5e94\u7528\u4e8e\u53ef\u518d\u751f\u80fd\u6e90\u7684\u9009\u62e9\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u5904\u7406\u4e86\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u6a21\u7cca\u6027\uff0c\u4e3a\u53ef\u518d\u751f\u80fd\u6e90\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2509.07017", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.07017", "abs": "https://arxiv.org/abs/2509.07017", "authors": ["Andrew Kiruluta", "Priscilla Burity"], "title": "From Eigenmodes to Proofs: Integrating Graph Spectral Operators with Symbolic Interpretable Reasoning", "comment": null, "summary": "We introduce Spectral NSR, a fully spectral neuro-symbolic reasoning\nframework that embeds logical rules as spectral templates and performs\ninference directly in the graph spectral domain. By leveraging graph signal\nprocessing (GSP) and frequency-selective filters grounded in the Laplacian\neigenstructure of knowledge graphs, the architecture unifies the\ninterpretability of symbolic reasoning with the scalability and adaptability of\nspectral learning. Beyond the core formulation, we incorporate a comprehensive\nset of extensions, including dynamic graph and basis learning, rational and\ndiffusion filters for sharper spectral selectivity, mixture-of-spectral-experts\nfor modular specialization, proof-guided training with spectral curricula, and\nuncertainty quantification for calibrated confidence. Additional enhancements\nsuch as large language model coupling, co-spectral transfer alignment,\nadversarial robustness, efficient GPU kernels, generalized Laplacians, and\ncausal interventions further expand the versatility of the framework.\n  Empirical evaluation on state-of-the-art reasoning benchmarks such as\nProofWriter and CLUTRR demonstrates that Spectral NSR achieves superior\naccuracy, faster inference, improved robustness to adversarial perturbations,\nand higher interpretability compared to leading baselines including\ntransformers, message-passing neural networks, and neuro-symbolic logic\nprogramming systems. Spectral attribution and proof-band agreement analyses\nconfirm that model decisions align closely with symbolic proof structures,\nwhile transfer experiments validate effective domain adaptation through\nco-spectral alignment. These results establish Spectral NSR as a scalable and\nprincipled foundation for the next generation of reasoning systems, offering\ntransparency, robustness, and generalization beyond conventional approaches.", "AI": {"tldr": "Spectral NSR\u6846\u67b6\u7ed3\u5408\u56fe\u8c31\u9891\u8c31\u5206\u6790\u8fdb\u884c\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\uff0c\u517c\u5177\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faSpectral NSR\u6846\u67b6\uff0c\u5229\u7528\u56fe\u4fe1\u53f7\u5904\u7406\u548c\u62c9\u666e\u62c9\u65af\u7279\u5f81\u7ed3\u6784\uff0c\u5c06\u903b\u8f91\u89c4\u5219\u5d4c\u5165\u4e3a\u9891\u8c31\u6a21\u677f\uff0c\u5728\u56fe\u8c31\u9891\u8c31\u57df\u76f4\u63a5\u8fdb\u884c\u63a8\u7406\u3002", "result": "\u5728ProofWriter\u548cCLUTRR\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSpectral NSR\u5728\u51c6\u786e\u6027\u3001\u63a8\u7406\u901f\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Spectral NSR\u4e3a\u4e0b\u4e00\u4ee3\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u9760\u4e14\u5177\u6709\u539f\u5219\u6027\u7684\u57fa\u7840\u3002"}}
{"id": "2509.07054", "categories": ["cs.AI", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.07054", "abs": "https://arxiv.org/abs/2509.07054", "authors": ["Edgar Dobriban"], "title": "Statistical Methods in Generative AI", "comment": "Invited review paper for Annual Review of Statistics and Its\n  Application. Feedback welcome", "summary": "Generative Artificial Intelligence is emerging as an important technology,\npromising to be transformative in many areas. At the same time, generative AI\ntechniques are based on sampling from probabilistic models, and by default,\nthey come with no guarantees about correctness, safety, fairness, or other\nproperties. Statistical methods offer a promising potential approach to improve\nthe reliability of generative AI techniques. In addition, statistical methods\nare also promising for improving the quality and efficiency of AI evaluation,\nas well as for designing interventions and experiments in AI.\n  In this paper, we review some of the existing work on these topics,\nexplaining both the general statistical techniques used, as well as their\napplications to generative AI. We also discuss limitations and potential future\ndirections.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u7edf\u8ba1\u65b9\u6cd5\u5728\u63d0\u9ad8\u751f\u6210\u5f0fAI\u53ef\u9760\u6027\u3001\u8d28\u91cf\u548c\u6548\u7387\u65b9\u9762\u7684\u5e94\u7528\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5c40\u9650\u6027\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7f3a\u4e4f\u6b63\u786e\u6027\u3001\u5b89\u5168\u6027\u548c\u516c\u5e73\u6027\u7b49\u4fdd\u8bc1\uff0c\u7edf\u8ba1\u65b9\u6cd5\u53ef\u7528\u4e8e\u63d0\u9ad8\u5176\u53ef\u9760\u6027\u53ca\u8bc4\u4f30\u8d28\u91cf\u3002", "method": "\u7efc\u8ff0\u73b0\u6709\u7814\u7a76\u5de5\u4f5c\uff0c\u89e3\u91ca\u4f7f\u7528\u7684\u7edf\u8ba1\u6280\u672f\u53ca\u5176\u5728\u751f\u6210\u5f0fAI\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u7efc\u8ff0\u4e86\u7edf\u8ba1\u65b9\u6cd5\u5728\u751f\u6210\u5f0fAI\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u6307\u51fa\u4e86\u5176\u5c40\u9650\u6027\u3002", "conclusion": "\u7edf\u8ba1\u65b9\u6cd5\u5728\u63d0\u9ad8\u751f\u6210\u5f0fAI\u7684\u53ef\u9760\u6027\u3001\u8d28\u91cf\u548c\u6548\u7387\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u4e00\u4e9b\u5c40\u9650\u6027\uff0c\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2509.07098", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.07098", "abs": "https://arxiv.org/abs/2509.07098", "authors": ["Yinheng Li", "Hailey Hultquist", "Justin Wagle", "Kazuhito Koishida"], "title": "Instruction Agent: Enhancing Agent with Expert Demonstration", "comment": null, "summary": "Graphical user interface (GUI) agents have advanced rapidly but still\nstruggle with complex tasks involving novel UI elements, long-horizon actions,\nand personalized trajectories. In this work, we introduce Instruction Agent, a\nGUI agent that leverages expert demonstrations to solve such tasks, enabling\ncompletion of otherwise difficult workflows. Given a single demonstration, the\nagent extracts step-by-step instructions and executes them by strictly\nfollowing the trajectory intended by the user, which avoids making mistakes\nduring execution. The agent leverages the verifier and backtracker modules\nfurther to improve robustness. Both modules are critical to understand the\ncurrent outcome from each action and handle unexpected interruptions(such as\npop-up windows) during execution. Our experiments show that Instruction Agent\nachieves a 60% success rate on a set of tasks in OSWorld that all top-ranked\nagents failed to complete. The Instruction Agent offers a practical and\nextensible framework, bridging the gap between current GUI agents and reliable\nreal-world GUI task automation.", "AI": {"tldr": "Instruction Agent\u5229\u7528\u4e13\u5bb6\u6f14\u793a\u89e3\u51b3\u590d\u6742GUI\u4efb\u52a1\uff0c\u6210\u529f\u7387\u8fbe60%\u3002", "motivation": "\u73b0\u6709GUI\u4ee3\u7406\u96be\u4ee5\u5904\u7406\u6d89\u53ca\u65b0UI\u5143\u7d20\u3001\u957f\u65f6\u5e8f\u52a8\u4f5c\u548c\u4e2a\u6027\u5316\u8f68\u8ff9\u7684\u590d\u6742\u4efb\u52a1\u3002", "method": "\u8be5\u4ee3\u7406\u4ece\u5355\u4e00\u6f14\u793a\u4e2d\u63d0\u53d6\u6b65\u9aa4\u6307\u4ee4\uff0c\u4e25\u683c\u9075\u5faa\u7528\u6237\u8f68\u8ff9\u6267\u884c\uff0c\u5e76\u5305\u542b\u9a8c\u8bc1\u5668\u548c\u56de\u6eaf\u6a21\u5757\u5904\u7406\u610f\u5916\u4e2d\u65ad\u3002", "result": "\u5728OSWorld\u6570\u636e\u96c6\u4e0a\uff0cInstruction Agent\u6210\u529f\u5b8c\u6210\u4e86\u4e00\u7cfb\u5217\u9876\u7ea7\u4ee3\u7406\u90fd\u5931\u8d25\u7684\u4efb\u52a1\uff08\u6210\u529f\u738760%\uff09\u3002", "conclusion": "Instruction Agent\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u5f25\u5408\u4e86\u73b0\u6709GUI\u4ee3\u7406\u4e0e\u53ef\u9760\u7684\u73b0\u5b9e\u4e16\u754cGUI\u4efb\u52a1\u81ea\u52a8\u5316\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2509.07122", "categories": ["cs.AI", "cs.CL", "cs.SC"], "pdf": "https://arxiv.org/pdf/2509.07122", "abs": "https://arxiv.org/abs/2509.07122", "authors": ["Sania Sinha", "Tanawan Premsri", "Danial Kamali", "Parisa Kordjamshidi"], "title": "Neuro-Symbolic Frameworks: Conceptual Characterization and Empirical Comparative Analysis", "comment": null, "summary": "Neurosymbolic (NeSy) frameworks combine neural representations and learning\nwith symbolic representations and reasoning. Combining the reasoning\ncapacities, explainability, and interpretability of symbolic processing with\nthe flexibility and power of neural computing allows us to solve complex\nproblems with more reliability while being data-efficient. However, this\nrecently growing topic poses a challenge to developers with its learning curve,\nlack of user-friendly tools, libraries, and unifying frameworks. In this paper,\nwe characterize the technical facets of existing NeSy frameworks, such as the\nsymbolic representation language, integration with neural models, and the\nunderlying algorithms. A majority of the NeSy research focuses on algorithms\ninstead of providing generic frameworks for declarative problem specification\nto leverage problem solving. To highlight the key aspects of Neurosymbolic\nmodeling, we showcase three generic NeSy frameworks - \\textit{DeepProbLog},\n\\textit{Scallop}, and \\textit{DomiKnowS}. We identify the challenges within\neach facet that lay the foundation for identifying the expressivity of each\nframework in solving a variety of problems. Building on this foundation, we aim\nto spark transformative action and encourage the community to rethink this\nproblem in novel ways.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u795e\u7ecf\u7b26\u53f7 (NeSy) \u6846\u67b6\u7684\u73b0\u72b6\uff0c\u6307\u51fa\u5176\u7f3a\u4e4f\u6613\u7528\u5de5\u5177\u548c\u7edf\u4e00\u6846\u67b6\uff0c\u5e76\u4ecb\u7ecd\u4e86\u4e09\u4e2a\u4ee3\u8868\u6027\u6846\u67b6\uff1aDeepProbLog\uff0cScallop \u548c DomiKnowS\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u7f3a\u4e4f\u6613\u7528\u6027\uff0c\u963b\u788d\u4e86\u5176\u53d1\u5c55\u3002", "method": "\u5bf9\u73b0\u6709\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u7684\u6280\u672f\u7279\u6027\u8fdb\u884c\u7279\u5f81\u5206\u6790\uff0c\u5e76\u4ecb\u7ecd\u4e09\u4e2a\u4ee3\u8868\u6027\u6846\u67b6\u3002", "result": "\u8bc6\u522b\u4e86\u6bcf\u4e2a\u6846\u67b6\u5728\u8868\u8fbe\u529b\u548c\u89e3\u51b3\u4e0d\u540c\u95ee\u9898\u65b9\u9762\u7684\u6311\u6218\u3002", "conclusion": "\u547c\u5401\u793e\u533a\u91cd\u65b0\u601d\u8003\u795e\u7ecf\u7b26\u53f7\u5efa\u6a21\u95ee\u9898\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2509.07146", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07146", "abs": "https://arxiv.org/abs/2509.07146", "authors": ["Farnoush Baghestani", "Jihye Moon", "Youngsun Kong", "Ki Chon"], "title": "Autoencoder-Based Denoising of Muscle Artifacts in ECG to Preserve Skin Nerve Activity (SKNA) for Cognitive Stress Detection", "comment": "11 pages, 7 figures, 6 tables", "summary": "The sympathetic nervous system (SNS) plays a central role in regulating the\nbody's responses to stress and maintaining physiological stability. Its\ndysregulation is associated with a wide range of conditions, from\ncardiovascular disease to anxiety disorders. Skin nerve activity (SKNA)\nextracted from high-frequency electrocardiogram (ECG) recordings provides a\nnoninvasive window into SNS dynamics, but its measurement is highly susceptible\nto electromyographic (EMG) contamination. Traditional preprocessing based on\nbandpass filtering within a fixed range (e.g., 500--1000 Hz) is susceptible to\noverlapping EMG and SKNA spectral components, especially during sustained\nmuscle activity. We present a denoising approach using a lightweight\none-dimensional convolutional autoencoder with a long short-term memory (LSTM)\nbottleneck to reconstruct clean SKNA from EMG-contaminated recordings. Using\nclean ECG-derived SKNA data from cognitive stress experiments and EMG noise\nfrom chaotic muscle stimulation recordings, we simulated contamination at\nrealistic noise levels (--4 dB, --8 dB signal-to-noise ratio) and trained the\nmodel in the leave-one-subject-out cross-validation framework. The method\nimproved signal-to-noise ratio by up to 9.65 dB, increased cross correlation\nwith clean SKNA from 0.40 to 0.72, and restored burst-based SKNA features to\nnear-clean discriminability (AUROC $\\geq$ 0.96). Classification of baseline\nversus sympathetic stimulation (cognitive stress) conditions reached accuracies\nof 91--98\\% across severe noise levels, comparable to clean data. These results\ndemonstrate that deep learning--based reconstruction can preserve\nphysiologically relevant sympathetic bursts during substantial EMG\ninterference, enabling more robust SKNA monitoring in naturalistic,\nmovement-rich environments.", "AI": {"tldr": "\u5229\u7528\u8f7b\u91cf\u7ea7\u4e00\u7ef4\u5377\u79ef\u81ea\u52a8\u7f16\u7801\u5668\u548cLSTM\u74f6\u9888\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u53bb\u566a\u65b9\u6cd5\uff0c\u6709\u6548\u53bb\u9664\u808c\u7535\u56fe\u4f2a\u8ff9\uff0c\u63d0\u9ad8\u76ae\u80a4\u795e\u7ecf\u6d3b\u52a8\uff08SKNA\uff09\u4fe1\u53f7\u8d28\u91cf\uff0c\u63d0\u5347\u4ea4\u611f\u795e\u7ecf\u6d3b\u52a8\u76d1\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u53bb\u9664\u808c\u7535\u56fe\u4f2a\u8ff9\u5bf9SKNA\u4fe1\u53f7\u7684\u5f71\u54cd\uff0c\u9650\u5236\u4e86\u5176\u5728\u81ea\u7136\u73af\u5883\u4e0b\u7684\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u4e00\u7ef4\u5377\u79ef\u81ea\u52a8\u7f16\u7801\u5668\u548cLSTM\u74f6\u9888\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5bf9ECG\u6570\u636e\u8fdb\u884c\u53bb\u566a\u5904\u7406\uff0c\u5e76\u91c7\u7528\u7559\u4e00\u6cd5\u4ea4\u53c9\u9a8c\u8bc1\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4fe1\u566a\u6bd4\uff0c\u589e\u52a0\u4e86\u4e0e\u5e72\u51c0SKNA\u7684\u4e92\u76f8\u5173\u6027\uff0c\u6062\u590d\u4e86\u57fa\u4e8e\u7206\u53d1\u7684SKNA\u7279\u5f81\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u4ea4\u611f\u795e\u7ecf\u523a\u6fc0\u5206\u7c7b\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u53bb\u9664\u808c\u7535\u56fe\u4f2a\u8ff9\uff0c\u63d0\u9ad8SKNA\u76d1\u6d4b\u7684\u9c81\u68d2\u6027\uff0c\u4f7f\u5176\u5728\u66f4\u81ea\u7136\u7684\u8fd0\u52a8\u73af\u5883\u4e2d\u5e94\u7528\u3002"}}
{"id": "2509.07159", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07159", "abs": "https://arxiv.org/abs/2509.07159", "authors": ["Heng Hao", "Wenjun Hu", "Oxana Verkholyak", "Davoud Ataee Tarzanagh", "Baruch Gutow", "Sima Didari", "Masoud Faraki", "Hankyu Moon", "Seungjai Min"], "title": "PaVeRL-SQL: Text-to-SQL via Partial-Match Rewards and Verbal Reinforcement Learning", "comment": "10 pages", "summary": "Text-to-SQL models allow users to interact with a database more easily by\ngenerating executable SQL statements from natural-language questions. Despite\nrecent successes on simpler databases and questions, current Text-to-SQL\nmethods still suffer from low execution accuracy on industry-scale databases\nand complex questions involving domain-specific business logic. We present\n\\emph{PaVeRL-SQL}, a framework that combines \\emph{Partial-Match Rewards} and\n\\emph{Verbal Reinforcement Learning} to drive self-improvement in reasoning\nlanguage models (RLMs) for Text-to-SQL. To handle practical use cases, we adopt\ntwo pipelines: (1) a newly designed in-context learning framework with group\nself-evaluation (verbal-RL), using capable open- and closed-source large\nlanguage models (LLMs) as backbones; and (2) a chain-of-thought (CoT) RL\npipeline with a small backbone model (OmniSQL-7B) trained with a specially\ndesigned reward function and two-stage RL. These pipelines achieve\nstate-of-the-art (SOTA) results on popular Text-to-SQL benchmarks -- Spider,\nSpider 2.0, and BIRD. For the industrial-level Spider2.0-SQLite benchmark, the\nverbal-RL pipeline achieves an execution accuracy 7.4\\% higher than SOTA, and\nthe CoT pipeline is 1.4\\% higher. RL training with mixed SQL dialects yields\nstrong, threefold gains, particularly for dialects with limited training data.\nOverall, \\emph{PaVeRL-SQL} delivers reliable, SOTA Text-to-SQL under realistic\nindustrial constraints. The code is available at\nhttps://github.com/PaVeRL-SQL/PaVeRL-SQL.", "AI": {"tldr": "PaVeRL-SQL\u6846\u67b6\u7ed3\u5408\u5c40\u90e8\u5339\u914d\u5956\u52b1\u548c\u8bed\u8a00\u589e\u5f3a\u5b66\u4e60\uff0c\u63d0\u5347\u4e86Text-to-SQL\u6a21\u578b\u5728\u5904\u7406\u5de5\u4e1a\u7ea7\u6570\u636e\u5e93\u548c\u590d\u6742\u95ee\u9898\u7684\u51c6\u786e\u6027\uff0c\u5728Spider, Spider 2.0\u548cBIRD\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709Text-to-SQL\u65b9\u6cd5\u5728\u5904\u7406\u5de5\u4e1a\u89c4\u6a21\u6570\u636e\u5e93\u548c\u6d89\u53ca\u9886\u57df\u7279\u5b9a\u4e1a\u52a1\u903b\u8f91\u7684\u590d\u6742\u95ee\u9898\u65f6\uff0c\u6267\u884c\u51c6\u786e\u7387\u4f4e\u3002", "method": "\u63d0\u51faPaVeRL-SQL\u6846\u67b6\uff0c\u7ed3\u5408\u5c40\u90e8\u5339\u914d\u5956\u52b1\u548c\u8bed\u8a00\u589e\u5f3a\u5b66\u4e60\uff0c\u5305\u542b\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\u548c\u57fa\u4e8e\u94fe\u5f0f\u601d\u7ef4\u7684\u5f3a\u5316\u5b66\u4e60\u6d41\u7a0b\u4e24\u79cdpipeline\u3002", "result": "\u5728Spider, Spider 2.0\u548cBIRD\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5728Spider2.0-SQLite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6267\u884c\u51c6\u786e\u7387\u6bd4\u73b0\u6709\u6280\u672f\u9ad8\u51fa7.4% (verbal-RL pipeline) \u548c1.4% (CoT pipeline)\u3002\u6df7\u5408SQL\u65b9\u8a00\u8bad\u7ec3\u6548\u679c\u663e\u8457\u3002", "conclusion": "PaVeRL-SQL\u5728\u5b9e\u9645\u5de5\u4e1a\u7ea6\u675f\u4e0b\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u5148\u8fdb\u7684Text-to-SQL\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07170", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.07170", "abs": "https://arxiv.org/abs/2509.07170", "authors": ["Quinten Steenhuis"], "title": "That's So FETCH: Fashioning Ensemble Techniques for LLM Classification in Civil Legal Intake and Referral", "comment": "Submission to JURIX 2025", "summary": "Each year millions of people seek help for their legal problems by calling a\nlegal aid program hotline, walking into a legal aid office, or using a lawyer\nreferral service. The first step to match them to the right help is to identify\nthe legal problem the applicant is experiencing. Misdirection has consequences.\nApplicants may miss a deadline, experience physical abuse, lose housing or lose\ncustody of children while waiting to connect to the right legal help. We\nintroduce and evaluate the FETCH classifier for legal issue classification and\ndescribe two methods for improving accuracy: a hybrid LLM/ML ensemble\nclassification method, and the automatic generation of follow-up questions to\nenrich the initial problem narrative. We employ a novel data set of 419\nreal-world queries to a nonprofit lawyer referral service. Ultimately, we show\nclassification accuracy (hits@2) of 97.37\\% using a mix of inexpensive models,\nexceeding the performance of the current state-of-the-art GPT-5 model. Our\napproach shows promise in significantly reducing the cost of guiding users of\nthe legal system to the right resource for their problem while achieving high\naccuracy.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aFETCH\u7684\u6cd5\u5f8b\u95ee\u9898\u5206\u7c7b\u5668\uff0c\u8be5\u5206\u7c7b\u5668\u7ed3\u5408\u4e86LLM\u548cML\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe97.37%\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6cd5\u5f8b\u63f4\u52a9\u670d\u52a1\u7684\u6548\u7387\u3002", "motivation": "\u6bcf\u5e74\u6709\u6570\u767e\u4e07\u4eba\u5bfb\u6c42\u6cd5\u5f8b\u63f4\u52a9\uff0c\u51c6\u786e\u8bc6\u522b\u5176\u6cd5\u5f8b\u95ee\u9898\u81f3\u5173\u91cd\u8981\uff0c\u9519\u8bef\u5339\u914d\u4f1a\u5bfc\u81f4\u4e25\u91cd\u540e\u679c\u3002", "method": "\u4f7f\u7528419\u4e2a\u771f\u5b9e\u4e16\u754c\u67e5\u8be2\u6570\u636e\u96c6\uff0c\u7ed3\u5408LLM/ML\u96c6\u6210\u5206\u7c7b\u65b9\u6cd5\u548c\u81ea\u52a8\u751f\u6210\u540e\u7eed\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5bf9\u6cd5\u5f8b\u95ee\u9898\u8fdb\u884c\u5206\u7c7b\u3002", "result": "FETCH\u5206\u7c7b\u5668\u7684\u51c6\u786e\u7387\u8fbe\u523097.37%\uff08hits@2\uff09\uff0c\u8d85\u8fc7\u4e86GPT-5\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4e\u6cd5\u5f8b\u63f4\u52a9\u670d\u52a1\u7684\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u8bc1\u9ad8\u51c6\u786e\u7387\uff0c\u5177\u6709\u663e\u8457\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.07208", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07208", "abs": "https://arxiv.org/abs/2509.07208", "authors": ["Abdulhakim Alsaiari", "Mohammad Ilyas"], "title": "A Hybrid CNN-LSTM Deep Learning Model for Intrusion Detection in Smart Grid", "comment": null, "summary": "The evolution of the traditional power grid into the \"smart grid\" has\nresulted in a fundamental shift in energy management, which allows the\nintegration of renewable energy sources with modern communication technology.\nHowever, this interconnection has increased smart grids' vulnerability to\nattackers, which might result in privacy breaches, operational interruptions,\nand massive outages. The SCADA-based smart grid protocols are critical for\nreal-time data collection and control, but they are vulnerable to attacks like\nunauthorized access and denial of service (DoS). This research proposes a\nhybrid deep learning-based Intrusion Detection System (IDS) intended to improve\nthe cybersecurity of smart grids. The suggested model takes advantage of\nConvolutional Neural Networks' (CNN) feature extraction capabilities as well as\nLong Short-Term Memory (LSTM) networks' temporal pattern recognition skills.\nDNP3 and IEC104 intrusion detection datasets are employed to train and test our\nCNN-LSTM model to recognize and classify the potential cyber threats. Compared\nto other deep learning approaches, the results demonstrate considerable\nimprovements in accuracy, precision, recall, and F1-score, with a detection\naccuracy of 99.70%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCNN-LSTM\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u667a\u80fd\u7535\u7f51\u7684\u7f51\u7edc\u5b89\u5168\u6027\u80fd\uff0c\u5e76\u5728DNP3\u548cIEC104\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e8699.70%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u667a\u80fd\u7535\u7f51\u4e2dSCADA\u534f\u8bae\u7684\u6f0f\u6d1e\u4f7f\u5176\u5bb9\u6613\u53d7\u5230\u653b\u51fb\uff0c\u53ef\u80fd\u5bfc\u81f4\u9690\u79c1\u6cc4\u9732\u548c\u505c\u7535\u3002", "method": "\u4f7f\u7528CNN-LSTM\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5165\u4fb5\u68c0\u6d4b\u3002", "result": "\u5728DNP3\u548cIEC104\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e8699.70%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6df7\u5408\u6a21\u578b\u6709\u6548\u63d0\u9ad8\u4e86\u667a\u80fd\u7535\u7f51\u7684\u7f51\u7edc\u5b89\u5168\u6c34\u5e73\u3002"}}
{"id": "2509.07209", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07209", "abs": "https://arxiv.org/abs/2509.07209", "authors": ["Nicholas Sung", "Steven Spreizer", "Mohamed Elrefaie", "Kaira Samuel", "Matthew C. Jones", "Faez Ahmed"], "title": "BlendedNet: A Blended Wing Body Aircraft Dataset and Surrogate Model for Aerodynamic Predictions", "comment": "Accepted at ASME IDETC/CIE 2025 (DETC2025-168977). Dataset\n  availability: BlendedNet dataset is openly available at Harvard Dataverse\n  (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VJT9EP)", "summary": "BlendedNet is a publicly available aerodynamic dataset of 999 blended wing\nbody (BWB) geometries. Each geometry is simulated across about nine flight\nconditions, yielding 8830 converged RANS cases with the Spalart-Allmaras model\nand 9 to 14 million cells per case. The dataset is generated by sampling\ngeometric design parameters and flight conditions, and includes detailed\npointwise surface quantities needed to study lift and drag. We also introduce\nan end-to-end surrogate framework for pointwise aerodynamic prediction. The\npipeline first uses a permutation-invariant PointNet regressor to predict\ngeometric parameters from sampled surface point clouds, then conditions a\nFeature-wise Linear Modulation (FiLM) network on the predicted parameters and\nflight conditions to predict pointwise coefficients Cp, Cfx, and Cfz.\nExperiments show low errors in surface predictions across diverse BWBs.\nBlendedNet addresses data scarcity for unconventional configurations and\nenables research on data-driven surrogate modeling for aerodynamic design.", "AI": {"tldr": "BlendedNet\u6570\u636e\u96c6\u5305\u542b\u8fd1\u4e5d\u5343\u4e2a\u878d\u5408\u7ffc\u8eab\u7ec4\u5408\u4f53(BWB)\u7684RANS\u7b97\u4f8b\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u57fa\u4e8e\u70b9\u4e91\u7684\u8868\u9762\u6c14\u52a8\u7279\u6027\u9884\u6d4b\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u975e\u4f20\u7edf\u6784\u578b\u6c14\u52a8\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u4fc3\u8fdb\u6570\u636e\u9a71\u52a8\u7684\u6c14\u52a8\u8bbe\u8ba1\u7814\u7a76\u3002", "method": "\u6784\u5efaBlendedNet\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8ePointNet\u548cFiLM\u7f51\u7edc\u6784\u5efa\u6c14\u52a8\u9884\u6d4b\u6846\u67b6\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9\u4e0d\u540cBWB\u6784\u578b\u7684\u8868\u9762\u6c14\u52a8\u7279\u6027(Cp, Cfx, Cfz)\u7684\u4f4e\u8bef\u5dee\u9884\u6d4b\u3002", "conclusion": "BlendedNet\u6570\u636e\u96c6\u548c\u9884\u6d4b\u6846\u67b6\u53ef\u7528\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u6c14\u52a8\u8bbe\u8ba1\u7814\u7a76\u3002"}}
{"id": "2509.07220", "categories": ["cs.AI", "I.2.10; I.2.1; I.4.8"], "pdf": "https://arxiv.org/pdf/2509.07220", "abs": "https://arxiv.org/abs/2509.07220", "authors": ["Siddhant Karki", "Ethan Han", "Nadim Mahmud", "Suman Bhunia", "John Femiani", "Vaskar Raychoudhury"], "title": "OmniAcc: Personalized Accessibility Assistant Using Generative AI", "comment": "11 Pages, 9 Figures, Published in the 1st Workshop on AI for Urban\n  Planning, AAAI 2025 Workshop", "summary": "Individuals with ambulatory disabilities often encounter significant barriers\nwhen navigating urban environments due to the lack of accessible information\nand tools. This paper presents OmniAcc, an AI-powered interactive navigation\nsystem that utilizes GPT-4, satellite imagery, and OpenStreetMap data to\nidentify, classify, and map wheelchair-accessible features such as ramps and\ncrosswalks in the built environment. OmniAcc offers personalized route\nplanning, real-time hands-free navigation, and instant query responses\nregarding physical accessibility. By using zero-shot learning and customized\nprompts, the system ensures precise detection of accessibility features, while\nsupporting validation through structured workflows. This paper introduces\nOmniAcc and explores its potential to assist urban planners and mobility-aid\nusers, demonstrated through a case study on crosswalk detection. With a\ncrosswalk detection accuracy of 97.5%, OmniAcc highlights the transformative\npotential of AI in improving navigation and fostering more inclusive urban\nspaces.", "AI": {"tldr": "OmniAcc\u7cfb\u7edf\u5229\u7528AI\u3001\u536b\u661f\u56fe\u50cf\u548cOpenStreetMap\u6570\u636e\uff0c\u4e3a\u8f6e\u6905\u4f7f\u7528\u8005\u63d0\u4f9b\u4e2a\u6027\u5316\u3001\u5b9e\u65f6\u7684\u65e0\u969c\u788d\u5bfc\u822a\u670d\u52a1\uff0c\u5e76\u5728\u4ea4\u53c9\u8def\u53e3\u68c0\u6d4b\u4e2d\u8fbe\u523097.5%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u8f6e\u6905\u4f7f\u7528\u8005\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u5bfc\u822a\u7684\u969c\u788d\uff0c\u7f3a\u4e4f\u65e0\u969c\u788d\u4fe1\u606f\u548c\u5de5\u5177\u3002", "method": "\u5229\u7528GPT-4\u3001\u536b\u661f\u56fe\u50cf\u548cOpenStreetMap\u6570\u636e\uff0c\u901a\u8fc7\u96f6\u6837\u672c\u5b66\u4e60\u548c\u5b9a\u5236\u63d0\u793a\uff0c\u8bc6\u522b\u3001\u5206\u7c7b\u548c\u7ed8\u5236\u65e0\u969c\u788d\u8bbe\u65bd\uff08\u5982\u5761\u9053\u548c\u4ea4\u53c9\u8def\u53e3\uff09\u5730\u56fe\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u8def\u7ebf\u89c4\u5212\u548c\u5b9e\u65f6\u514d\u63d0\u5bfc\u822a\u3002", "result": "\u4ea4\u53c9\u8def\u53e3\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe97.5%\u3002", "conclusion": "OmniAcc\u7cfb\u7edf\u6709\u6f5c\u529b\u5e2e\u52a9\u57ce\u5e02\u89c4\u5212\u8005\u548c\u884c\u52a8\u4e0d\u4fbf\u4eba\u58eb\uff0c\u4fc3\u8fdb\u66f4\u5305\u5bb9\u7684\u57ce\u5e02\u7a7a\u95f4\u3002"}}
{"id": "2509.07260", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.07260", "abs": "https://arxiv.org/abs/2509.07260", "authors": ["Xin Wang", "Ting Dang", "Xinyu Zhang", "Vassilis Kostakos", "Michael J. Witbrock", "Hong Jia"], "title": "HealthSLM-Bench: Benchmarking Small Language Models for Mobile and Wearable Healthcare Monitoring", "comment": "9 pages, 6 tables, 6 figures", "summary": "Mobile and wearable healthcare monitoring play a vital role in facilitating\ntimely interventions, managing chronic health conditions, and ultimately\nimproving individuals' quality of life. Previous studies on large language\nmodels (LLMs) have highlighted their impressive generalization abilities and\neffectiveness in healthcare prediction tasks. However, most LLM-based\nhealthcare solutions are cloud-based, which raises significant privacy concerns\nand results in increased memory usage and latency. To address these challenges,\nthere is growing interest in compact models, Small Language Models (SLMs),\nwhich are lightweight and designed to run locally and efficiently on mobile and\nwearable devices. Nevertheless, how well these models perform in healthcare\nprediction remains largely unexplored. We systematically evaluated SLMs on\nhealth prediction tasks using zero-shot, few-shot, and instruction fine-tuning\napproaches, and deployed the best performing fine-tuned SLMs on mobile devices\nto evaluate their real-world efficiency and predictive performance in practical\nhealthcare scenarios. Our results show that SLMs can achieve performance\ncomparable to LLMs while offering substantial gains in efficiency and privacy.\nHowever, challenges remain, particularly in handling class imbalance and\nfew-shot scenarios. These findings highlight SLMs, though imperfect in their\ncurrent form, as a promising solution for next-generation, privacy-preserving\nhealthcare monitoring.", "AI": {"tldr": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(SLM)\u5728\u79fb\u52a8\u533b\u7597\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u517c\u987e\u6548\u7387\u548c\u9690\u79c1\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u4ee5\u5e94\u5bf9\u6570\u636e\u4e0d\u5e73\u8861\u548c\u5c11\u6837\u672c\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u533b\u7597\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u9690\u79c1\u548c\u6548\u7387\u95ee\u9898\uff0c\u56e0\u6b64\u7814\u7a76SLM\u5728\u79fb\u52a8\u533b\u7597\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e86SLM\u5728\u5065\u5eb7\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u4e86\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u6307\u4ee4\u5fae\u8c03\u65b9\u6cd5\uff0c\u5e76\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u90e8\u7f72\u4e86\u6027\u80fd\u6700\u4f73\u7684\u5fae\u8c03SLM\u3002", "result": "SLM\u5728\u6027\u80fd\u4e0a\u53ef\u4e0eLLM\u5ab2\u7f8e\uff0c\u540c\u65f6\u5728\u6548\u7387\u548c\u9690\u79c1\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u5728\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u548c\u5c11\u6837\u672c\u573a\u666f\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002", "conclusion": "SLM\u662f\u4e0b\u4e00\u4ee3\u9690\u79c1\u4fdd\u62a4\u533b\u7597\u76d1\u63a7\u7684\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07339", "abs": "https://arxiv.org/abs/2509.07339", "authors": ["Vardhan Palod", "Karthik Valmeekam", "Kaya Stechly", "Subbarao Kambhampati"], "title": "Performative Thinking? The Brittle Correlation Between CoT Length and Problem Complexity", "comment": null, "summary": "Intermediate token generation (ITG), where a model produces output before the\nsolution, has been proposed as a method to improve the performance of language\nmodels on reasoning tasks. While these reasoning traces or Chain of Thoughts\n(CoTs) are correlated with performance gains, the mechanisms underlying them\nremain unclear. A prevailing assumption in the community has been to\nanthropomorphize these tokens as \"thinking\", treating longer traces as evidence\nof higher problem-adaptive computation. In this work, we critically examine\nwhether intermediate token sequence length reflects or correlates with problem\ndifficulty. To do so, we train transformer models from scratch on derivational\ntraces of the A* search algorithm, where the number of operations required to\nsolve a maze problem provides a precise and verifiable measure of problem\ncomplexity. We first evaluate the models on trivial free-space problems,\nfinding that even for the simplest tasks, they often produce excessively long\nreasoning traces and sometimes fail to generate a solution. We then\nsystematically evaluate the model on out-of-distribution problems and find that\nthe intermediate token length and ground truth A* trace length only loosely\ncorrelate. We notice that the few cases where correlation appears are those\nwhere the problems are closer to the training distribution, suggesting that the\neffect arises from approximate recall rather than genuine problem-adaptive\ncomputation. This suggests that the inherent computational complexity of the\nproblem instance is not a significant factor, but rather its distributional\ndistance from the training data. These results challenge the assumption that\nintermediate trace generation is adaptive to problem difficulty and caution\nagainst interpreting longer sequences in systems like R1 as automatically\nindicative of \"thinking effort\".", "AI": {"tldr": "\u6a21\u578b\u751f\u6210\u7684\u4e2d\u95f4\u4ee4\u724c\u5e8f\u5217\u957f\u5ea6\u4e0e\u95ee\u9898\u96be\u5ea6\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u5e76\u4e0d\u5f3a\uff0c\u957f\u5e8f\u5217\u5e76\u4e0d\u4e00\u5b9a\u4ee3\u8868\u66f4\u590d\u6742\u7684\u601d\u8003\u8fc7\u7a0b\u3002", "motivation": "\u68c0\u9a8c\u4e2d\u95f4\u4ee4\u724c\u751f\u6210\u957f\u5ea6\u662f\u5426\u53cd\u6620\u6216\u4e0e\u95ee\u9898\u96be\u5ea6\u76f8\u5173\u3002", "method": "\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3transformer\u6a21\u578b\uff0c\u4f7f\u7528A*\u641c\u7d22\u7b97\u6cd5\u7684\u63a8\u5bfc\u8f68\u8ff9\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\uff0c\u5bf9\u4e0d\u540c\u96be\u5ea6\u7684\u8ff7\u5bab\u95ee\u9898\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5373\u4f7f\u662f\u6700\u7b80\u5355\u7684\u4efb\u52a1\uff0c\u6a21\u578b\u4e5f\u4f1a\u4ea7\u751f\u8fc7\u957f\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u6709\u65f6\u751a\u81f3\u65e0\u6cd5\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff1b\u4e2d\u95f4\u4ee4\u724c\u957f\u5ea6\u548c\u771f\u5b9eA*\u8f68\u8ff9\u957f\u5ea6\u7684\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u53ea\u6709\u5728\u95ee\u9898\u63a5\u8fd1\u8bad\u7ec3\u5206\u5e03\u65f6\u624d\u51fa\u73b0\u76f8\u5173\u6027\u3002", "conclusion": "\u95ee\u9898\u5b9e\u4f8b\u7684\u56fa\u6709\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u975e\u91cd\u8981\u56e0\u7d20\uff0c\u5176\u4e0e\u8bad\u7ec3\u6570\u636e\u7684\u5206\u5e03\u8ddd\u79bb\u624d\u662f\u5173\u952e\uff1b\u957f\u5e8f\u5217\u4e0d\u80fd\u81ea\u52a8\u89c6\u4e3a\u201c\u601d\u8003\u52aa\u529b\u201d\u7684\u6307\u6807\u3002"}}
{"id": "2509.07367", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.07367", "abs": "https://arxiv.org/abs/2509.07367", "authors": ["Cunxi Yu", "Rongjian Liang", "Chia-Tung Ho", "Haoxing Ren"], "title": "Autonomous Code Evolution Meets NP-Completeness", "comment": "31 pages, 11 figures", "summary": "Large language models (LLMs) have recently shown strong coding abilities,\nenabling not only static code generation but also iterative code self-evolving\nthrough agentic frameworks. Recently, AlphaEvolve \\cite{novikov2025alphaevolve}\ndemonstrated that LLM-based coding agents can autonomously improve algorithms\nand surpass human experts, with scopes limited to isolated kernels spanning\nhundreds of lines of code. Inspired by AlphaEvolve, we present SATLUTION, the\nfirst framework to extend LLM-based code evolution to the full repository\nscale, encompassing hundreds of files and tens of thousands of lines of C/C++\ncode. Targeting Boolean Satisfiability (SAT), the canonical NP-complete problem\nand a cornerstone of both theory and applications. SATLUTION orchestrates LLM\nagents to directly evolve solver repositories under strict correctness\nguarantees and distributed runtime feedback, while simultaneously self-evolving\nits own evolution policies and rules. Starting from SAT Competition 2024\ncodebases and benchmark, SATLUTION evolved solvers that decisively outperformed\nthe human-designed winners of the SAT Competition 2025, and also surpassed both\n2024 and 2025 champions on the 2024 benchmarks.", "AI": {"tldr": "LLM\u9a71\u52a8\u4ee3\u7801\u8fdb\u5316\u6846\u67b6SATLUTION\u5728SAT\u6c42\u89e3\u5668\u4e0a\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6", "motivation": "\u73b0\u6709LLM\u4ee3\u7801\u8fdb\u5316\u65b9\u6cd5\u5c40\u9650\u4e8e\u5c0f\u89c4\u6a21\u4ee3\u7801\uff0cSATLUTION\u6269\u5c55\u5230\u6574\u4e2a\u4ee3\u7801\u5e93", "method": "\u5229\u7528LLM agent\u8fdb\u5316SAT\u6c42\u89e3\u5668\u4ee3\u7801\u5e93\uff0c\u5305\u542b\u6570\u767e\u4e2a\u6587\u4ef6\u548c\u6570\u4e07\u884c\u4ee3\u7801\uff0c\u5e76\u81ea\u8fdb\u5316\u7b56\u7565\u548c\u89c4\u5219\uff0c\u4fdd\u8bc1\u6b63\u786e\u6027", "result": "\u5728SAT\u7ade\u8d5b2024\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8d85\u8d8a\u4e862025\u5e74\u4eba\u5de5\u8bbe\u8ba1\u7684\u51a0\u519b", "conclusion": "SATLUTION\u8bc1\u660e\u4e86LLM\u5728\u5927\u578b\u4ee3\u7801\u5e93\u8fdb\u5316\u4e2d\u7684\u6f5c\u529b"}}
{"id": "2509.07414", "categories": ["cs.AI", "cs.CL", "cs.GT"], "pdf": "https://arxiv.org/pdf/2509.07414", "abs": "https://arxiv.org/abs/2509.07414", "authors": ["Jakub Grudzien Kuba", "Mengting Gu", "Qi Ma", "Yuandong Tian", "Vijai Mohan"], "title": "Language Self-Play For Data-Free Training", "comment": null, "summary": "Large language models (LLMs) have advanced rapidly in recent years, driven by\nscale, abundant high-quality training data, and reinforcement learning. Yet\nthis progress faces a fundamental bottleneck: the need for ever more data from\nwhich models can continue to learn. In this work, we propose a reinforcement\nlearning approach that removes this dependency by enabling models to improve\nwithout additional data. Our method leverages a game-theoretic framework of\nself-play, where a model's capabilities are cast as performance in a\ncompetitive game and stronger policies emerge by having the model play against\nitself - a process we call Language Self-Play (LSP). Experiments with\nLlama-3.2-3B-Instruct on instruction-following benchmarks show that pretrained\nmodels can not only enhance their performance on challenging tasks through\nself-play alone, but can also do so more effectively than data-driven\nbaselines.", "AI": {"tldr": "\u901a\u8fc7\u8bed\u8a00\u81ea\u6211\u535a\u5f08(LSP)\u65b9\u6cd5\uff0c\u65e0\u9700\u989d\u5916\u6570\u636e\u5373\u53ef\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u6027\u80fd\uff0c\u5728\u6307\u4ee4\u9075\u5faa\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6548\u679c\u4f18\u4e8e\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3LLM\u8bad\u7ec3\u4f9d\u8d56\u6d77\u91cf\u6570\u636e\u7684\u74f6\u9888\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u535a\u5f08\u8bba\u6846\u67b6\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6a21\u578b\u901a\u8fc7\u81ea\u6211\u535a\u5f08\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u4ec5\u901a\u8fc7\u81ea\u6211\u535a\u5f08\u5373\u53ef\u63d0\u5347\u5176\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4e14\u6548\u679c\u4f18\u4e8e\u6570\u636e\u9a71\u52a8\u57fa\u7ebf\u3002", "conclusion": "\u8bed\u8a00\u81ea\u6211\u535a\u5f08(LSP)\u4e3aLLM\u7684\u6301\u7eed\u6539\u8fdb\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u989d\u5916\u6570\u636e\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2509.07473", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07473", "abs": "https://arxiv.org/abs/2509.07473", "authors": ["Qin Chen", "Yuanyi Ren", "Xiaojun Ma", "Mugeng Liu", "Han Shi", "Dongmei Zhang"], "title": "SheetDesigner: MLLM-Powered Spreadsheet Layout Generation with Rule-Based and Vision-Based Reflection", "comment": "Accepted to EMNLP 2025 Main Conference", "summary": "Spreadsheets are critical to data-centric tasks, with rich, structured\nlayouts that enable efficient information transmission. Given the time and\nexpertise required for manual spreadsheet layout design, there is an urgent\nneed for automated solutions. However, existing automated layout models are\nill-suited to spreadsheets, as they often (1) treat components as axis-aligned\nrectangles with continuous coordinates, overlooking the inherently discrete,\ngrid-based structure of spreadsheets; and (2) neglect interrelated semantics,\nsuch as data dependencies and contextual links, unique to spreadsheets. In this\npaper, we first formalize the spreadsheet layout generation task, supported by\na seven-criterion evaluation protocol and a dataset of 3,326 spreadsheets. We\nthen introduce SheetDesigner, a zero-shot and training-free framework using\nMultimodal Large Language Models (MLLMs) that combines rule and vision\nreflection for component placement and content population. SheetDesigner\noutperforms five baselines by at least 22.6\\%. We further find that through\nvision modality, MLLMs handle overlap and balance well but struggle with\nalignment, necessitates hybrid rule and visual reflection strategies. Our codes\nand data is available at Github.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u7535\u5b50\u8868\u683c\u5e03\u5c40\u751f\u6210\u6846\u67b6SheetDesigner\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u89c4\u5219\u548c\u89c6\u89c9\u53cd\u5c04\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u5e03\u5c40\u6a21\u578b\u4e0d\u9002\u7528\u4e8e\u7535\u5b50\u8868\u683c\uff0c\u5ffd\u7565\u4e86\u5176\u79bb\u6563\u7684\u7f51\u683c\u7ed3\u6784\u548c\u8bed\u4e49\u5173\u8054\u3002", "method": "\u63d0\u51faSheetDesigner\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b(MLLMs)\u7ed3\u5408\u89c4\u5219\u548c\u89c6\u89c9\u53cd\u5c04\u8fdb\u884c\u7ec4\u4ef6\u653e\u7f6e\u548c\u5185\u5bb9\u586b\u5145\u3002", "result": "SheetDesigner\u4f18\u4e8e\u4e94\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u81f3\u5c1122.6%\u3002\u89c6\u89c9\u6a21\u6001\u5904\u7406\u91cd\u53e0\u548c\u5e73\u8861\u8f83\u597d\uff0c\u4f46\u5728\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u6df7\u5408\u89c4\u5219\u548c\u89c6\u89c9\u53cd\u5c04\u7b56\u7565\u3002", "conclusion": "SheetDesigner\u4e3a\u81ea\u52a8\u5316\u7535\u5b50\u8868\u683c\u5e03\u5c40\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.07577", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07577", "abs": "https://arxiv.org/abs/2509.07577", "authors": ["Riccardo DElia", "Alberto Termine", "Francesco Flammini"], "title": "Towards explainable decision support using hybrid neural models for logistic terminal automation", "comment": null, "summary": "The integration of Deep Learning (DL) in System Dynamics (SD) modeling for\ntransportation logistics offers significant advantages in scalability and\npredictive accuracy. However, these gains are often offset by the loss of\nexplainability and causal reliability $-$ key requirements in critical\ndecision-making systems. This paper presents a novel framework for\ninterpretable-by-design neural system dynamics modeling that synergizes DL with\ntechniques from Concept-Based Interpretability, Mechanistic Interpretability,\nand Causal Machine Learning. The proposed hybrid approach enables the\nconstruction of neural network models that operate on semantically meaningful\nand actionable variables, while retaining the causal grounding and transparency\ntypical of traditional SD models. The framework is conceived to be applied to\nreal-world case-studies from the EU-funded project AutoMoTIF, focusing on\ndata-driven decision support, automation, and optimization of multimodal\nlogistic terminals. We aim at showing how neuro-symbolic methods can bridge the\ngap between black-box predictive models and the need for critical decision\nsupport in complex dynamical environments within cyber-physical systems enabled\nby the industrial Internet-of-Things.", "AI": {"tldr": "\"\u5c06\u6df1\u5ea6\u5b66\u4e60\u4e0e\u7cfb\u7edf\u52a8\u529b\u5b66\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u63d0\u9ad8\u4ea4\u901a\u7269\u6d41\u9884\u6d4b\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u8bc1\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u56e0\u679c\u53ef\u9760\u6027\u3002\"", "motivation": "\"\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u4ea4\u901a\u7269\u6d41\u9884\u6d4b\u4e2d\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u56e0\u679c\u53ef\u9760\u6027\uff0c\u9650\u5236\u4e86\u5176\u5728\u5173\u952e\u51b3\u7b56\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002\"", "method": "\"\u63d0\u51fa\u4e00\u79cd\u53ef\u89e3\u91ca\u795e\u7ecf\u7cfb\u7edf\u52a8\u529b\u5b66\u5efa\u6a21\u6846\u67b6\uff0c\u878d\u5408\u6df1\u5ea6\u5b66\u4e60\u3001\u57fa\u4e8e\u6982\u5ff5\u7684\u53ef\u89e3\u91ca\u6027\u3001\u673a\u68b0\u8bba\u53ef\u89e3\u91ca\u6027\u548c\u56e0\u679c\u673a\u5668\u5b66\u4e60\u7b49\u6280\u672f\u3002\"", "result": "\"\u6784\u5efa\u80fd\u591f\u64cd\u4f5c\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u53ef\u6267\u884c\u53d8\u91cf\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u4f20\u7edf\u7cfb\u7edf\u52a8\u529b\u5b66\u6a21\u578b\u7684\u56e0\u679c\u57fa\u7840\u548c\u900f\u660e\u5ea6\u3002\"", "conclusion": "\"\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u53ef\u4ee5\u5f25\u5408\u9ed1\u76d2\u9884\u6d4b\u6a21\u578b\u4e0e\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u5173\u952e\u51b3\u7b56\u652f\u6301\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\""}}
