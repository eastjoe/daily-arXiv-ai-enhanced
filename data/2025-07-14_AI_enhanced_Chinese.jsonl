{"id": "2507.08001", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.08001", "abs": "https://arxiv.org/abs/2507.08001", "authors": ["Shengyi Xie"], "title": "Human Creativity and AI", "comment": null, "summary": "With the advancement of science and technology, the philosophy of creativity\nhas undergone significant reinterpretation. This paper investigates\ncontemporary research in the fields of psychology, cognitive neuroscience, and\nthe philosophy of creativity, particularly in the context of the development of\nartificial intelligence (AI) techniques. It aims to address the central\nquestion: Can AI exhibit creativity? The paper reviews the historical\nperspectives on the philosophy of creativity and explores the influence of\npsychological advancements on the study of creativity. Furthermore, it analyzes\nvarious definitions of creativity and examines the responses of naturalism and\ncognitive neuroscience to the concept of creativity.", "AI": {"tldr": "\u672c\u6587\u63a2\u8a0e\u4eba\u5de5\u667a\u6167\u662f\u5426\u5177\u6709\u5275\u9020\u529b\uff0c\u4e26\u56de\u9867\u4e86\u5275\u9020\u529b\u54f2\u5b78\u548c\u76f8\u95dc\u79d1\u5b78\u7814\u7a76\u7684\u9032\u5c55\u3002", "motivation": "\u63a2\u8a0e\u4eba\u5de5\u667a\u6167\u8207\u5275\u9020\u529b\u7684\u95dc\u4fc2\uff0c\u4e26\u91cd\u65b0\u8a6e\u91cb\u5275\u9020\u529b\u7684\u54f2\u5b78\u3002", "method": "\u56de\u9867\u6587\u737b\u3001\u5206\u6790", "result": "\u63a2\u8a0e\u4e86\u5275\u9020\u529b\u7684\u5b9a\u7fa9\uff0c\u4ee5\u53ca\u81ea\u7136\u4e3b\u7fa9\u548c\u8a8d\u77e5\u795e\u7d93\u79d1\u5b78\u5c0d\u5275\u9020\u529b\u7684\u56de\u61c9\u3002", "conclusion": "\u672c\u6587\u63a2\u8a0e\u4e86\u4eba\u5de5\u667a\u6167\u662f\u5426\u80fd\u5c55\u73fe\u5275\u9020\u529b\uff0c\u56de\u9867\u4e86\u5275\u9020\u529b\u54f2\u5b78\u7684\u6b77\u53f2\u89c0\u9ede\uff0c\u4e26\u63a2\u8a0e\u4e86\u5fc3\u7406\u5b78\u548c\u8a8d\u77e5\u795e\u7d93\u79d1\u5b78\u7684\u9032\u5c55\u5c0d\u5275\u9020\u529b\u7814\u7a76\u7684\u5f71\u97ff\u3002"}}
{"id": "2507.08046", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08046", "abs": "https://arxiv.org/abs/2507.08046", "authors": ["Sishi Xiong", "Dakai Wang", "Yu Zhao", "Jie Zhang", "Changzai Pan", "Haowei He", "Xiangyu Li", "Wenhan Chang", "Zhongjiang He", "Shuangyong Song", "Yongxiang Li"], "title": "TableReasoner: Advancing Table Reasoning Framework with Large Language Models", "comment": null, "summary": "The paper presents our system developed for table question answering (TQA).\nTQA tasks face challenges due to the characteristics of real-world tabular\ndata, such as large size, incomplete column semantics, and entity ambiguity. To\naddress these issues, we propose a large language model (LLM)-powered and\nprogramming-based table reasoning framework, named TableReasoner. It models a\ntable using the schema that combines structural and semantic representations,\nenabling holistic understanding and efficient processing of large tables. We\ndesign a multi-step schema linking plan to derive a focused table schema that\nretains only query-relevant information, eliminating ambiguity and alleviating\nhallucinations. This focused table schema provides precise and sufficient table\ndetails for query refinement and programming. Furthermore, we integrate the\nreasoning workflow into an iterative thinking architecture, allowing\nincremental cycles of thinking, reasoning and reflection. Our system achieves\nfirst place in both subtasks of SemEval-2025 Task 8.", "AI": {"tldr": "\u57fa\u4e8eLLM\u548c\u7f16\u7a0b\u7684TableReasoner\u7cfb\u7edf\u5728TQA\u4efb\u52a1\u4e2d\u53d6\u5f97SOTA\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u771f\u5b9e\u4e16\u754c\u8868\u683c\u6570\u636e\u5e26\u6765\u7684\u6311\u6218\uff0c\u4f8b\u5982\u5927\u5c3a\u5bf8\u3001\u4e0d\u5b8c\u6574\u7684\u5217\u8bed\u4e49\u548c\u5b9e\u4f53\u6b67\u4e49\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u7f16\u7a0b\u7684\u8868\u683c\u63a8\u7406\u6846\u67b6TableReasoner\uff0c\u8be5\u6846\u67b6\u4f7f\u7528\u7ed3\u5408\u7ed3\u6784\u548c\u8bed\u4e49\u8868\u793a\u7684\u6a21\u5f0f\u5bf9\u8868\u683c\u5efa\u6a21\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u591a\u6b65\u9aa4\u6a21\u5f0f\u94fe\u63a5\u8ba1\u5212\u6765\u5bfc\u51fa\u4ec5\u5305\u542b\u67e5\u8be2\u76f8\u5173\u4fe1\u606f\u7684\u805a\u7126\u8868\u683c\u6a21\u5f0f\u3002", "result": "\u5728SemEval-2025 Task 8\u7684\u4e24\u4e2a\u5b50\u4efb\u52a1\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d\u3002", "conclusion": "TableReasoner\u7cfb\u7edf\u5728SemEval-2025 Task 8\u7684\u4e24\u4e2a\u5b50\u4efb\u52a1\u4e2d\u5747\u83b7\u5f97\u7b2c\u4e00\u540d\u3002"}}
{"id": "2507.08207", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08207", "abs": "https://arxiv.org/abs/2507.08207", "authors": ["Zhengye Han", "Quanyan Zhu"], "title": "A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in critical\napplications, the challenge of jailbreaking, where adversaries manipulate the\nmodels to bypass safety mechanisms, has become a significant concern. This\npaper presents a dynamic Stackelberg game framework to model the interactions\nbetween attackers and defenders in the context of LLM jailbreaking. The\nframework treats the prompt-response dynamics as a sequential extensive-form\ngame, where the defender, as the leader, commits to a strategy while\nanticipating the attacker's optimal responses. We propose a novel agentic AI\nsolution, the \"Purple Agent,\" which integrates adversarial exploration and\ndefensive strategies using Rapidly-exploring Random Trees (RRT). The Purple\nAgent actively simulates potential attack trajectories and intervenes\nproactively to prevent harmful outputs. This approach offers a principled\nmethod for analyzing adversarial dynamics and provides a foundation for\nmitigating the risk of jailbreaking.", "AI": {"tldr": "\u5229\u7528\u535a\u5f08\u8bba\u548cRRT\u7b97\u6cd5\u63d0\u51faPurple Agent\uff0c\u6709\u6548\u9632\u5fa1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u8d8a\u72f1\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "\u52a8\u6001Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u5feb\u901f\u63a2\u7d22\u968f\u673a\u6811\uff08RRT\uff09", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ee3\u7406AI\u89e3\u51b3\u65b9\u6848Purple Agent\uff0c\u7528\u4e8e\u4e3b\u52a8\u9632\u5fa1LLM\u8d8a\u72f1\u653b\u51fb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001Stackelberg\u535a\u5f08\u6846\u67b6\u6765\u6a21\u62df\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u573a\u666f\u4e0b\u7684\u4ea4\u4e92\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ee3\u7406AI\u89e3\u51b3\u65b9\u6848\u2014\u2014Purple Agent\uff0c\u8be5\u65b9\u6848\u4f7f\u7528\u5feb\u901f\u63a2\u7d22\u968f\u673a\u6811\uff08RRT\uff09\u96c6\u6210\u5bf9\u6297\u6027\u63a2\u7d22\u548c\u9632\u5fa1\u7b56\u7565\uff0c\u4e3b\u52a8\u6a21\u62df\u6f5c\u5728\u653b\u51fb\u8f68\u8ff9\u5e76\u79ef\u6781\u5e72\u9884\u4ee5\u9632\u6b62\u6709\u5bb3\u8f93\u51fa\u3002"}}
{"id": "2507.08208", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.08208", "abs": "https://arxiv.org/abs/2507.08208", "authors": ["Quanyan Zhu"], "title": "Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions", "comment": null, "summary": "We introduce the LLM-Nash framework, a game-theoretic model where agents\nselect reasoning prompts to guide decision-making via Large Language Models\n(LLMs). Unlike classical games that assume utility-maximizing agents with full\nrationality, this framework captures bounded rationality by modeling the\nreasoning process explicitly. Equilibrium is defined over the prompt space,\nwith actions emerging as the behavioral output of LLM inference. This approach\nenables the study of cognitive constraints, mindset expressiveness, and\nepistemic learning. Through illustrative examples, we show how reasoning\nequilibria can diverge from classical Nash outcomes, offering a new foundation\nfor strategic interaction in LLM-enabled systems.", "AI": {"tldr": "\u63d0\u51faLLM-Nash\u6846\u67b6\uff0c\u5efa\u6a21LLM\u9a71\u52a8\u7684\u7b56\u7565\u4e92\u52a8\uff0c\u8003\u8651\u6709\u9650\u7406\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u4e0e\u7ecf\u5178\u535a\u5f08\u8bba\u4e0d\u540c\u7684\u5747\u8861\u7ed3\u679c\u3002", "motivation": "\u63a2\u7d22LLM\u9a71\u52a8\u51b3\u7b56\u7cfb\u7edf\u4e2d\u7684\u7b56\u7565\u4e92\u52a8\uff0c\u8003\u8651\u8ba4\u77e5\u7ea6\u675f\u3001\u601d\u7ef4\u8868\u8fbe\u548c\u8ba4\u77e5\u5b66\u4e60\u3002", "method": "\u535a\u5f08\u8bba\u6a21\u578b\uff0c\u5728\u63d0\u793a\u7a7a\u95f4\u4e0a\u5b9a\u4e49\u5747\u8861\uff0cLLM\u63a8\u7406\u4f5c\u4e3a\u884c\u4e3a\u8f93\u51fa\u3002", "result": "\u5c55\u793a\u4e86\u63a8\u7406\u5747\u8861\u4e0e\u7ecf\u5178\u7eb3\u4ec0\u5747\u8861\u7684\u5dee\u5f02\uff0c\u4e3aLLM\u9a71\u52a8\u7cfb\u7edf\u4e2d\u7684\u7b56\u7565\u4e92\u52a8\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u7840\u3002", "conclusion": "LLM-Nash\u6846\u67b6\u4e3aLLM\u9a71\u52a8\u7684\u51b3\u7b56\u7cfb\u7edf\u4e2d\u7b56\u7565\u4e92\u52a8\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u7840\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u63a8\u7406\u8fc7\u7a0b\u6765\u6355\u6349\u6709\u9650\u7406\u6027\uff0c\u5e76\u5c55\u73b0\u51fa\u4e0e\u7ecf\u5178\u7eb3\u4ec0\u5747\u8861\u4e0d\u540c\u7684\u63a8\u7406\u5747\u8861\u3002"}}
{"id": "2507.08210", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08210", "abs": "https://arxiv.org/abs/2507.08210", "authors": ["Fryderyk Mantiuk", "Hanqi Zhou", "Charley M. Wu"], "title": "From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration", "comment": null, "summary": "What drives an agent to explore the world while also maintaining control over\nthe environment? From a child at play to scientists in the lab, intelligent\nagents must balance curiosity (the drive to seek knowledge) with competence\n(the drive to master and control the environment). Bridging cognitive theories\nof intrinsic motivation with reinforcement learning, we ask how evolving\ninternal representations mediate the trade-off between curiosity (novelty or\ninformation gain) and competence (empowerment). We compare two model-based\nagents using handcrafted state abstractions (Tabular) or learning an internal\nworld model (Dreamer). The Tabular agent shows curiosity and competence guide\nexploration in distinct patterns, while prioritizing both improves exploration.\nThe Dreamer agent reveals a two-way interaction between exploration and\nrepresentation learning, mirroring the developmental co-evolution of curiosity\nand competence. Our findings formalize adaptive exploration as a balance\nbetween pursuing the unknown and the controllable, offering insights for\ncognitive theories and efficient reinforcement learning.", "AI": {"tldr": "\u597d\u5947\u5fc3\u4e0e\u80fd\u529b\u5171\u540c\u9a71\u52a8\u9ad8\u6548\u63a2\u7d22\uff0c\u4e24\u8005\u5e73\u8861\u662f\u5173\u952e\u3002", "motivation": "\u63a2\u7a76\u9a71\u4f7f\u667a\u80fd\u4f53\u63a2\u7d22\u4e16\u754c\u540c\u65f6\u4fdd\u6301\u73af\u5883\u63a7\u5236\u529b\u7684\u56e0\u7d20\uff0c\u5373\u597d\u5947\u5fc3\uff08\u5bfb\u6c42\u77e5\u8bc6\u7684\u9a71\u52a8\u529b\uff09\u548c\u80fd\u529b\uff08\u638c\u63e1\u548c\u63a7\u5236\u73af\u5883\u7684\u9a71\u52a8\u529b\uff09\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "method": "\u6bd4\u8f83\u4e86\u4f7f\u7528\u624b\u5de5\u72b6\u6001\u62bd\u8c61\uff08Tabular\uff09\u6216\u5b66\u4e60\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff08Dreamer\uff09\u7684\u4e24\u4e2a\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\u3002", "result": "Tabular\u667a\u80fd\u4f53\u663e\u793a\u597d\u5947\u5fc3\u548c\u80fd\u529b\u6307\u5bfc\u63a2\u7d22\u7684\u4e0d\u540c\u6a21\u5f0f\uff0c\u540c\u65f6\u4f18\u5148\u8003\u8651\u4e24\u8005\u80fd\u6539\u8fdb\u63a2\u7d22\uff1bDreamer\u667a\u80fd\u4f53\u63ed\u793a\u4e86\u63a2\u7d22\u548c\u8868\u5f81\u5b66\u4e60\u4e4b\u95f4\u7684\u53cc\u5411\u4ea4\u4e92\u4f5c\u7528\uff0c\u53cd\u6620\u4e86\u597d\u5947\u5fc3\u548c\u80fd\u529b\u7684\u53d1\u5c55\u6027\u5171\u540c\u8fdb\u5316\u3002", "conclusion": "\u597d\u5947\u5fc3\u548c\u80fd\u529b\u5728\u63a2\u7d22\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u4e24\u8005\u5e73\u8861\u624d\u80fd\u5b9e\u73b0\u9ad8\u6548\u63a2\u7d22\u3002\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5b9e\u9a8c\u8868\u660e\uff0c\u597d\u5947\u5fc3\u548c\u80fd\u529b\u5206\u522b\u5f15\u5bfc\u63a2\u7d22\uff0c\u4f46\u540c\u65f6\u4f18\u5148\u8003\u8651\u4e24\u8005\u80fd\u6539\u8fdb\u63a2\u7d22\u6548\u679c\u3002"}}
{"id": "2507.08216", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08216", "abs": "https://arxiv.org/abs/2507.08216", "authors": ["Rodrigo Castellano Ontiveros", "Francesco Giannini", "Marco Gori", "Giuseppe Marra", "Michelangelo Diligenti"], "title": "Grounding Methods for Neural-Symbolic AI", "comment": null, "summary": "A large class of Neural-Symbolic (NeSy) methods employs a machine learner to\nprocess the input entities, while relying on a reasoner based on First-Order\nLogic to represent and process more complex relationships among the entities. A\nfundamental role for these methods is played by the process of logic grounding,\nwhich determines the relevant substitutions for the logic rules using a\n(sub)set of entities. Some NeSy methods use an exhaustive derivation of all\npossible substitutions, preserving the full expressive power of the logic\nknowledge. This leads to a combinatorial explosion in the number of ground\nformulas to consider and, therefore, strongly limits their scalability. Other\nmethods rely on heuristic-based selective derivations, which are generally more\ncomputationally efficient, but lack a justification and provide no guarantees\nof preserving the information provided to and returned by the reasoner. Taking\ninspiration from multi-hop symbolic reasoning, this paper proposes a\nparametrized family of grounding methods generalizing classic Backward\nChaining. Different selections within this family allow us to obtain commonly\nemployed grounding methods as special cases, and to control the trade-off\nbetween expressiveness and scalability of the reasoner. The experimental\nresults show that the selection of the grounding criterion is often as\nimportant as the NeSy method itself.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53c2\u6570\u5316\u903b\u8f91\u63a5\u5730\u65b9\u6cd5\u65cf\uff0c\u5e73\u8861\u8868\u8fbe\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u63a5\u5730\u51c6\u5219\u9009\u62e9\u5f88\u91cd\u8981", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5728\u903b\u8f91\u63a5\u5730\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7ec4\u5408\u7206\u70b8\u6216\u7f3a\u4e4f\u4fe1\u606f\u4fdd\u8bc1\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u5316\u7684\u903b\u8f91\u63a5\u5730\u65b9\u6cd5\u65cf\uff0c\u8be5\u65b9\u6cd5\u6982\u62ec\u4e86\u7ecf\u5178\u7684\u9006\u5411\u94fe\u63a5\u65b9\u6cd5\uff0c\u5e76\u5728\u8868\u8fbe\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63a5\u5730\u51c6\u5219\u7684\u9009\u62e9\u4e0eNeSy\u65b9\u6cd5\u672c\u8eab\u540c\u7b49\u91cd\u8981\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u5316\u7684\u903b\u8f91\u63a5\u5730\u65b9\u6cd5\u65cf\uff0c\u8be5\u65b9\u6cd5\u65cf\u6982\u62ec\u4e86\u7ecf\u5178\u7684\u9006\u5411\u94fe\u63a5\u65b9\u6cd5\uff0c\u5e76\u5728\u8868\u8fbe\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63a5\u5730\u51c6\u5219\u7684\u9009\u62e9\u4e0eNeSy\u65b9\u6cd5\u672c\u8eab\u540c\u7b49\u91cd\u8981\u3002"}}
{"id": "2507.08217", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08217", "abs": "https://arxiv.org/abs/2507.08217", "authors": ["Atit Pokharel", "Ratun Rahman", "Thomas Morris", "Dinh C. Nguyen"], "title": "Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach", "comment": "This paper was presented at BEAM with CVPR 2025", "summary": "Quantum federated learning (QFL) has been recently introduced to enable a\ndistributed privacy-preserving quantum machine learning (QML) model training\nacross quantum processors (clients). Despite recent research efforts, existing\nQFL frameworks predominantly focus on unimodal systems, limiting their\napplicability to real-world tasks that often naturally involve multiple\nmodalities. To fill this significant gap, we present for the first time a novel\nmultimodal approach specifically tailored for the QFL setting with the\nintermediate fusion using quantum entanglement. Furthermore, to address a major\nbottleneck in multimodal QFL, where the absence of certain modalities during\ntraining can degrade model performance, we introduce a Missing Modality\nAgnostic (MMA) mechanism that isolates untrained quantum circuits, ensuring\nstable training without corrupted states. Simulation results demonstrate that\nthe proposed multimodal QFL method with MMA yields an improvement in accuracy\nof 6.84% in independent and identically distributed (IID) and 7.25% in non-IID\ndata distributions compared to the state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u6a21\u6001\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7MMA\u673a\u5236\u89e3\u51b3\u4e86\u7f3a\u5931\u6a21\u6001\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u7684QFL\u6846\u67b6\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u6a21\u6001\u7cfb\u7edf\u4e0a\uff0c\u9650\u5236\u4e86\u5176\u5728\u6d89\u53ca\u591a\u79cd\u6a21\u6001\u7684\u73b0\u5b9e\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u91cf\u5b50\u7ea0\u7f20\u7684\u4e2d\u95f4\u878d\u5408\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86MMA\u673a\u5236\u6765\u5904\u7406\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7f3a\u5931\u6a21\u6001\u7684\u95ee\u9898\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728IID\u548cnon-IID\u6570\u636e\u5206\u5e03\u4e0b\uff0c\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0c\u51c6\u786e\u7387\u5206\u522b\u63d0\u9ad8\u4e866.84%\u548c7.25%\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001\u91cf\u5b50\u8054\u90a6\u5b66\u4e60(QFL)\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u7f3a\u5931\u6a21\u6001\u4e0d\u53ef\u77e5(MMA)\u673a\u5236\uff0c\u4ee5\u63d0\u9ad8\u5728\u72ec\u7acb\u540c\u5206\u5e03(IID)\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03(non-IID)\u6570\u636e\u5206\u5e03\u4e0b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2507.08249", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.08249", "abs": "https://arxiv.org/abs/2507.08249", "authors": ["Bill Marino", "Ari Juels"], "title": "Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm", "comment": null, "summary": "There is growing interest in giving AI agents access to cryptocurrencies as\nwell as to the smart contracts that transact them. But doing so, this position\npaper argues, could lead to formidable new vectors of AI harm. To support this\nargument, we first examine the unique properties of cryptocurrencies and smart\ncontracts that could lead to these new vectors of harm. Next, we describe each\nof these new vectors of harm in detail. Finally, we conclude with a call for\nmore technical research aimed at preventing and mitigating these harms and,\nthereby making it safer to endow AI agents with cryptocurrencies and smart\ncontracts.", "AI": {"tldr": "\u8d4b\u4e88AI\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u8bbf\u95ee\u6743\u9650\u53ef\u80fd\u5e26\u6765\u91cd\u5927\u98ce\u9669\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u786e\u4fdd\u5b89\u5168\u3002", "motivation": "\u5bf9\u8d4b\u4e88AI\u667a\u80fd\u4f53\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u8bbf\u95ee\u6743\u9650\u65e5\u76ca\u589e\u957f\u7684\u5174\u8da3\uff0c\u4ee5\u53ca\u7531\u6b64\u53ef\u80fd\u4ea7\u751f\u7684AI\u98ce\u9669\u3002", "method": "\u9996\u5148\u5206\u6790\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u7684\u7279\u6027\uff0c\u7136\u540e\u8be6\u7ec6\u63cf\u8ff0\u8fd9\u4e9b\u65b0\u98ce\u9669\u5411\u91cf\uff0c\u6700\u540e\u547c\u5401\u8fdb\u884c\u66f4\u591a\u6280\u672f\u7814\u7a76\u3002", "result": "\u8bc6\u522b\u51fa\u8d4b\u4e88AI\u667a\u80fd\u4f53\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u8bbf\u95ee\u6743\u9650\u53ef\u80fd\u5bfc\u81f4\u7684\u65b0\u7684AI\u98ce\u9669\u5411\u91cf\u3002", "conclusion": "\u8d4b\u4e88AI\u667a\u80fd\u4f53\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u8bbf\u95ee\u6743\u9650\u53ef\u80fd\u5bfc\u81f4\u65b0\u7684AI\u98ce\u9669\uff0c\u9700\u8981\u66f4\u591a\u6280\u672f\u7814\u7a76\u6765\u9884\u9632\u548c\u51cf\u8f7b\u8fd9\u4e9b\u98ce\u9669\u3002"}}
{"id": "2507.08264", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08264", "abs": "https://arxiv.org/abs/2507.08264", "authors": ["Abhinav Sood", "Kazjon Grace", "Stephen Wan", "Cecile Paris"], "title": "Abductive Computational Systems: Creative Abduction and Future Directions", "comment": "Published in the 16th International Conference on Computational\n  Creativity, ICCC25. Accepted Paper in\n  https://computationalcreativity.net/iccc25/wp-content/uploads/papers/iccc25-sood2025abductive.pdf", "summary": "Abductive reasoning, reasoning for inferring explanations for observations,\nis often mentioned in scientific, design-related and artistic contexts, but its\nunderstanding varies across these domains. This paper reviews how abductive\nreasoning is discussed in epistemology, science and design, and then analyses\nhow various computational systems use abductive reasoning. Our analysis shows\nthat neither theoretical accounts nor computational implementations of\nabductive reasoning adequately address generating creative hypotheses.\nTheoretical frameworks do not provide a straightforward model for generating\ncreative abductive hypotheses, computational systems largely implement\nsyllogistic forms of abductive reasoning. We break down abductive computational\nsystems into components and conclude by identifying specific directions for\nfuture research that could advance the state of creative abductive reasoning in\ncomputational systems.", "AI": {"tldr": "\u73b0\u6709\u5bf9\u6eaf\u56e0\u63a8\u7406\u7684\u7406\u8bba\u548c\u8ba1\u7b97\u5b9e\u73b0\u90fd\u4e0d\u80fd\u5145\u5206\u5904\u7406\u521b\u9020\u6027\u5047\u8bbe\u751f\u6210\u3002", "motivation": "\u6eaf\u56e0\u63a8\u7406\u5728\u79d1\u5b66\u3001\u8bbe\u8ba1\u548c\u827a\u672f\u9886\u57df\u90fd\u6709\u63d0\u53ca\uff0c\u4f46\u5176\u7406\u89e3\u5404\u4e0d\u76f8\u540c\u3002", "method": "\u56de\u987e\u6027\u5206\u6790\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u9886\u57df\u5bf9\u6eaf\u56e0\u63a8\u7406\u7684\u7406\u89e3\uff0c\u5e76\u5206\u6790\u4e86\u5404\u79cd\u8ba1\u7b97\u7cfb\u7edf\u5982\u4f55\u4f7f\u7528\u6eaf\u56e0\u63a8\u7406\u3002", "result": "\u7406\u8bba\u6846\u67b6\u6ca1\u6709\u63d0\u4f9b\u751f\u6210\u521b\u9020\u6027\u6eaf\u56e0\u5047\u8bbe\u7684\u76f4\u63a5\u6a21\u578b\uff0c\u8ba1\u7b97\u7cfb\u7edf\u5927\u591a\u5b9e\u73b0\u4e86\u6eaf\u56e0\u63a8\u7406\u7684syllogistic\u5f62\u5f0f\u3002", "conclusion": "\u73b0\u6709\u7406\u8bba\u6846\u67b6\u548c\u8ba1\u7b97\u7cfb\u7edf\u90fd\u4e0d\u80fd\u5145\u5206\u89e3\u51b3\u521b\u9020\u6027\u5047\u8bbe\u751f\u6210\u7684\u95ee\u9898\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u624d\u80fd\u6539\u8fdb\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u521b\u9020\u6027\u6eaf\u56e0\u63a8\u7406\u7684\u73b0\u72b6\u3002"}}
{"id": "2507.08270", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.08270", "abs": "https://arxiv.org/abs/2507.08270", "authors": ["Zeyang Sha", "Hanling Tian", "Zhuoer Xu", "Shiwen Cui", "Changhua Meng", "Weiqiang Wang"], "title": "Agent Safety Alignment via Reinforcement Learning", "comment": null, "summary": "The emergence of autonomous Large Language Model (LLM) agents capable of tool\nusage has introduced new safety risks that go beyond traditional conversational\nmisuse. These agents, empowered to execute external functions, are vulnerable\nto both user-initiated threats (e.g., adversarial prompts) and tool-initiated\nthreats (e.g., malicious outputs from compromised tools). In this paper, we\npropose the first unified safety-alignment framework for tool-using agents,\nenabling models to handle both channels of threat via structured reasoning and\nsandboxed reinforcement learning. We introduce a tri-modal taxonomy, including\nbenign, malicious, and sensitive for both user prompts and tool responses, and\ndefine a policy-driven decision model. Our framework employs a custom-designed\nsandbox environment that simulates real-world tool execution and allows\nfine-grained reward shaping. Through extensive evaluations on public and\nself-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we\ndemonstrate that our safety-aligned agents significantly improve resistance to\nsecurity threats while preserving strong utility on benign tasks. Our results\nshow that safety and effectiveness can be jointly optimized, laying the\ngroundwork for trustworthy deployment of autonomous LLM agents.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u589e\u5f3a\u5de5\u5177\u578bLLM\u4ee3\u7406\u7684\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u6709\u6548", "motivation": "\u968f\u7740\u81ea\u4e3b LLM \u4ee3\u7406\u80fd\u591f\u4f7f\u7528\u5de5\u5177\uff0c\u51fa\u73b0\u4e86\u8d85\u51fa\u4f20\u7edf\u5bf9\u8bdd\u6ee5\u7528\u7684\u65b0\u5b89\u5168\u98ce\u9669\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u65b0\u98ce\u9669\u3002", "method": "\u8be5\u6846\u67b6\u91c7\u7528\u4e09\u6a21\u6001\u5206\u7c7b\u6cd5\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u63a8\u7406\u548c\u6c99\u76d2\u5f3a\u5316\u5b66\u4e60\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u81ea\u5b9a\u4e49\u6c99\u76d2\u73af\u5883\u6765\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u7684\u5de5\u5177\u6267\u884c\uff0c\u5e76\u8fdb\u884c\u5956\u52b1\u5851\u9020\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5b89\u5168\u5bf9\u9f50\u7684\u4ee3\u7406\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u5b89\u5168\u5a01\u80c1\u7684\u62b5\u6297\u529b\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u826f\u6027\u4efb\u52a1\u4e0a\u7684\u5f3a\u5927\u6548\u7528\uff0c\u8bc1\u660e\u4e86\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\u53ef\u4ee5\u5171\u540c\u4f18\u5316\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5de5\u5177\u4f7f\u7528\u578b\u81ea\u4e3b\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4ee3\u7406\u7684\u7edf\u4e00\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\uff0c\u4ee5\u5e94\u5bf9\u7528\u6237\u548c\u5de5\u5177\u5f15\u53d1\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u4fdd\u6301\u6548\u7528\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.08306", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.08306", "abs": "https://arxiv.org/abs/2507.08306", "authors": ["Inclusion AI", ":", "Fudong Wang", "Jiajia Liu", "Jingdong Chen", "Jun Zhou", "Kaixiang Ji", "Lixiang Ru", "Qingpei Guo", "Ruobing Zheng", "Tianqi Li", "Yi Yuan", "Yifan Mao", "Yuting Xiao", "Ziping Ma"], "title": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning", "comment": "31pages, 14 figures", "summary": "Recent advancements in Multimodal Large Language Models (MLLMs), particularly\nthrough Reinforcement Learning with Verifiable Rewards (RLVR), have\nsignificantly enhanced their reasoning abilities. However, a critical gap\npersists: these models struggle with dynamic spatial interactions, a capability\nessential for real-world applications. To bridge this gap, we introduce\nM2-Reasoning-7B, a model designed to excel in both general and spatial\nreasoning. Our approach integrates two key innovations: (1) a novel data\npipeline that generates 294.2K high-quality data samples (168K for cold-start\nfine-tuning and 126.2K for RLVR), which feature logically coherent reasoning\ntrajectories and have undergone comprehensive assessment; and (2) a dynamic\nmulti-task training strategy with step-wise optimization to mitigate conflicts\nbetween data, and task-specific rewards for delivering tailored incentive\nsignals. This combination of curated data and advanced training allows\nM2-Reasoning-7B to set a new state-of-the-art (SOTA) across 8 benchmarks,\nshowcasing superior performance in both general and spatial reasoning domains.", "AI": {"tldr": "M2-Reasoning-7B\u6a21\u578b\u901a\u8fc7\u6539\u8fdb\u6570\u636e\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e00\u822c\u548c\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u5f25\u5408\u73b0\u6709MLLMs\u6a21\u578b\u5728\u52a8\u6001\u7a7a\u95f4\u4ea4\u4e92\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u63d0\u5347\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u8be5\u6a21\u578b\u6574\u5408\u4e86\u65b0\u9896\u7684\u6570\u636e\u7ba1\u9053\u548c\u52a8\u6001\u591a\u4efb\u52a1\u8bad\u7ec3\u7b56\u7565\uff0c\u5305\u542b\u9ad8\u8d28\u91cf\u6570\u636e\u6837\u672c\u7684\u751f\u6210\u4ee5\u53ca\u9010\u6b65\u4f18\u5316\u7684\u7b56\u7565\u3002", "result": "\u57288\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "M2-Reasoning-7B\u6a21\u578b\u57288\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5728\u4e00\u822c\u63a8\u7406\u548c\u7a7a\u95f4\u63a8\u7406\u9886\u57df\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.08392", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.08392", "abs": "https://arxiv.org/abs/2507.08392", "authors": ["Asma Yamani", "Malak Baslyman", "Moataz Ahmed"], "title": "Multi-Agent LLMs as Ethics Advocates in AI-Based Systems", "comment": null, "summary": "Incorporating ethics into the requirement elicitation process is essential\nfor creating ethically aligned systems. Although eliciting manual ethics\nrequirements is effective, it requires diverse input from multiple\nstakeholders, which can be challenging due to time and resource constraints.\nMoreover, it is often given a low priority in the requirements elicitation\nprocess. This study proposes a framework for generating ethics requirements\ndrafts by introducing an ethics advocate agent in a multi-agent LLM setting.\nThis agent critiques and provides input on ethical issues based on the system\ndescription. The proposed framework is evaluated through two case studies from\ndifferent contexts, demonstrating that it captures the majority of ethics\nrequirements identified by researchers during 30-minute interviews and\nintroduces several additional relevant requirements. However, it also\nhighlights reliability issues in generating ethics requirements, emphasizing\nthe need for human feedback in this sensitive domain. We believe this work can\nfacilitate the broader adoption of ethics in the requirements engineering\nprocess, ultimately leading to more ethically aligned products.", "AI": {"tldr": "\u5229\u7528\u591a\u667a\u80fd\u4f53LLM\u548c\u4f26\u7406\u5021\u5bfc\u8005\u667a\u80fd\u4f53\u81ea\u52a8\u751f\u6210\u4f26\u7406\u9700\u6c42\uff0c\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u9700\u4eba\u5de5\u6821\u9a8c", "motivation": "\u4f20\u7edf\u7684\u4f26\u7406\u9700\u6c42\u83b7\u53d6\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\uff0c\u96be\u4ee5\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u5f97\u5230\u91cd\u89c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u7684\u4f26\u7406\u9700\u6c42\u751f\u6210\u65b9\u6cd5\uff0c\u5f15\u5165\u4f26\u7406\u5021\u5bfc\u8005\u667a\u80fd\u4f53\u8fdb\u884c\u4f26\u7406\u5ba1\u67e5\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u751f\u6210\u4f26\u7406\u9700\u6c42\u8349\u6848\uff0c\u4f46\u53ef\u9760\u6027\u6709\u5f85\u63d0\u9ad8\uff0c\u9700\u8981\u7ed3\u5408\u4eba\u5de5\u53cd\u9988\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u751f\u6210\u4f26\u7406\u9700\u6c42\u8349\u6848\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u4f26\u7406\u5021\u5bfc\u8005\u667a\u80fd\u4f53\u6765\u8bc4\u4ef7\u548c\u63d0\u4f9b\u4f26\u7406\u95ee\u9898\u7684\u53cd\u9988\u3002\u6848\u4f8b\u7814\u7a76\u8868\u660e\u8be5\u6846\u67b6\u80fd\u591f\u6355\u6349\u5230\u5927\u90e8\u5206\u4f26\u7406\u9700\u6c42\uff0c\u4f46\u4e5f\u5b58\u5728\u53ef\u9760\u6027\u95ee\u9898\uff0c\u9700\u8981\u4eba\u5de5\u53cd\u9988\u3002"}}
{"id": "2507.08454", "categories": ["cs.AI", "cs.LG", "cs.LO", "68T27, 03B05", "I.2.3; F.4.1"], "pdf": "https://arxiv.org/pdf/2507.08454", "abs": "https://arxiv.org/abs/2507.08454", "authors": ["Tobias Geibinger", "Reijo Jaakkola", "Antti Kuusisto", "Xinghan Liu", "Miikka Vilander"], "title": "Why this and not that? A Logic-based Framework for Contrastive Explanations", "comment": "20 pages, accepted to JELIA 2025", "summary": "We define several canonical problems related to contrastive explanations,\neach answering a question of the form ''Why P but not Q?''. The problems\ncompute causes for both P and Q, explicitly comparing their differences. We\ninvestigate the basic properties of our definitions in the setting of\npropositional logic. We show, inter alia, that our framework captures a\ncardinality-minimal version of existing contrastive explanations in the\nliterature. Furthermore, we provide an extensive analysis of the computational\ncomplexities of the problems. We also implement the problems for CNF-formulas\nusing answer set programming and present several examples demonstrating how\nthey work in practice.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u5bf9\u6bd4\u89e3\u91ca\u95ee\u9898\uff0c\u5206\u6790\u4e86\u5176\u6027\u8d28\u548c\u590d\u6742\u5ea6\uff0c\u5e76\u7528Answer Set Programming\u5b9e\u73b0\u4e86\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u56de\u7b54\u201c\u4e3a\u4ec0\u4e48\u662fP\u800c\u4e0d\u662fQ\uff1f\u201d\u5f62\u5f0f\u7684\u95ee\u9898\uff0c\u8ba1\u7b97P\u548cQ\u7684\u539f\u56e0\uff0c\u660e\u786e\u6bd4\u8f83\u5b83\u4eec\u7684\u5dee\u5f02\uff0c\u6355\u83b7\u6587\u732e\u4e2d\u73b0\u6709\u5bf9\u6bd4\u89e3\u91ca\u7684\u57fa\u6570\u6700\u5c0f\u7248\u672c\u3002", "method": "\u5728\u547d\u9898\u903b\u8f91\u7684\u8bbe\u7f6e\u4e0b\uff0c\u7814\u7a76\u4e86\u5bf9\u6bd4\u89e3\u91ca\u95ee\u9898\u7684\u57fa\u672c\u5c5e\u6027\uff0c\u5e76\u4f7f\u7528Answer Set Programming\u5b9e\u73b0\u4e86CNF\u516c\u5f0f\u7684\u95ee\u9898\u3002", "result": "\u5b9a\u4e49\u4e86\u51e0\u4e2a\u4e0e\u5bf9\u6bd4\u89e3\u91ca\u76f8\u5173\u7684\u89c4\u8303\u95ee\u9898\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u5e76\u4f7f\u7528Answer Set Programming\u5b9e\u73b0\u4e86CNF\u516c\u5f0f\u7684\u95ee\u9898\u3002", "conclusion": "\u5b9a\u4e49\u4e86\u51e0\u4e2a\u4e0e\u5bf9\u6bd4\u89e3\u91ca\u76f8\u5173\u7684\u89c4\u8303\u95ee\u9898\uff0c\u6bcf\u4e2a\u95ee\u9898\u90fd\u56de\u7b54\u201c\u4e3a\u4ec0\u4e48\u662fP\u800c\u4e0d\u662fQ\uff1f\u201d\u5f62\u5f0f\u7684\u95ee\u9898\uff0c\u8ba1\u7b97P\u548cQ\u7684\u539f\u56e0\uff0c\u660e\u786e\u6bd4\u8f83\u5b83\u4eec\u7684\u5dee\u5f02\u3002\u7814\u7a76\u4e86\u547d\u9898\u903b\u8f91\u4e2d\u5b9a\u4e49\u7684\u57fa\u672c\u5c5e\u6027\uff0c\u8868\u660e\u8be5\u6846\u67b6\u6355\u83b7\u4e86\u6587\u732e\u4e2d\u73b0\u6709\u5bf9\u6bd4\u89e3\u91ca\u7684\u57fa\u6570\u6700\u5c0f\u7248\u672c\u3002\u6b64\u5916\uff0c\u5bf9\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5206\u6790\uff0c\u5e76\u4f7f\u7528Answer Set Programming\u5b9e\u73b0\u4e86CNF\u516c\u5f0f\u7684\u95ee\u9898\uff0c\u5e76\u7ed9\u51fa\u4e86\u4e00\u4e9b\u4f8b\u5b50\u6765\u8bf4\u660e\u5b83\u4eec\u5728\u5b9e\u8df5\u4e2d\u7684\u5de5\u4f5c\u65b9\u5f0f\u3002"}}
{"id": "2507.08501", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08501", "abs": "https://arxiv.org/abs/2507.08501", "authors": ["Keying Yang", "Hao Wang", "Kai Yang"], "title": "From Language to Logic: A Bi-Level Framework for Structured Reasoning", "comment": null, "summary": "Structured reasoning over natural language inputs remains a core challenge in\nartificial intelligence, as it requires bridging the gap between unstructured\nlinguistic expressions and formal logical representations. In this paper, we\npropose a novel \\textbf{bi-level framework} that maps language to logic through\na two-stage process: high-level task abstraction and low-level logic\ngeneration. At the upper level, a large language model (LLM) parses natural\nlanguage queries into intermediate structured representations specifying the\nproblem type, objectives, decision variables, and symbolic constraints. At the\nlower level, the LLM uses these representations to generate symbolic workflows\nor executable reasoning programs for accurate and interpretable decision\nmaking. The framework supports modular reasoning, enforces explicit\nconstraints, and generalizes across domains such as mathematical problem\nsolving, question answering, and logical inference. We further optimize the\nframework with an end-to-end {bi-level} optimization approach that jointly\nrefines both the high-level abstraction and low-level logic generation stages.\nExperiments on multiple realistic reasoning benchmarks demonstrate that our\napproach significantly outperforms existing baselines in accuracy, with\naccuracy gains reaching as high as 40\\%. Moreover, the bi-level design enhances\ntransparency and error traceability, offering a promising step toward\ntrustworthy and systematic reasoning with LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53cc\u5c42\u6846\u67b6\uff0c\u5229\u7528LLM\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u63a8\u7406\u7a0b\u5e8f\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u63d0\u9ad8\u9ad8\u8fbe40%\u3002", "motivation": "\u89e3\u51b3\u5c06\u975e\u7ed3\u6784\u5316\u8bed\u8a00\u8868\u8fbe\u4e0e\u5f62\u5f0f\u903b\u8f91\u8868\u793a\u4e4b\u95f4\u67b6\u8d77\u6865\u6881\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u5bf9\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u7684\u7ed3\u6784\u5316\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53cc\u5c42\u6846\u67b6\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u6620\u5c04\u5230\u903b\u8f91\uff0c\u5206\u4e3a\u9ad8\u5c42\u4efb\u52a1\u62bd\u8c61\u548c\u4f4e\u5c42\u903b\u8f91\u751f\u6210\u4e24\u4e2a\u9636\u6bb5\u3002\u9ad8\u5c42\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u89e3\u6790\u4e3a\u4e2d\u95f4\u7ed3\u6784\u5316\u8868\u793a\uff0c\u4f4e\u5c42\u4f7f\u7528\u8fd9\u4e9b\u8868\u793a\u751f\u6210\u7b26\u53f7\u5de5\u4f5c\u6d41\u6216\u53ef\u6267\u884c\u63a8\u7406\u7a0b\u5e8f\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u7684\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u9ad8\u8fbe40%\u3002\u53cc\u5c42\u8bbe\u8ba1\u589e\u5f3a\u4e86\u900f\u660e\u5ea6\u548c\u9519\u8bef\u8ffd\u6eaf\u6027\u3002", "conclusion": "\u8be5\u53cc\u5c42\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u9ad8\u8fbe40%\uff0c\u5e76\u589e\u5f3a\u4e86\u900f\u660e\u5ea6\u548c\u9519\u8bef\u8ffd\u6eaf\u6027\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u8d56\u548c\u7cfb\u7edf\u7684\u57fa\u4e8eLLM\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2507.08529", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.08529", "abs": "https://arxiv.org/abs/2507.08529", "authors": ["Mingda Zhang", "Na Zhao", "Jianglong Qin", "Guoyu Ye", "Ruixiang Tang"], "title": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis", "comment": "10 pages,3 figures", "summary": "Despite advances from medical large language models in healthcare,\nrare-disease diagnosis remains hampered by insufficient\nknowledge-representation depth, limited concept understanding, and constrained\nclinical reasoning. We propose a framework that couples multi-granularity\nsparse activation of medical concepts with a hierarchical knowledge graph. Four\ncomplementary matching algorithms, diversity control, and a five-level fallback\nstrategy enable precise concept activation, while a three-layer knowledge graph\n(taxonomy, clinical features, instances) provides structured, up-to-date\ncontext. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09,\nROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89\napproaching the 0.90 clinical threshold. Expert evaluation confirms\nimprovements in information quality, reasoning, and professional expression,\nsuggesting our approach shortens the \"diagnostic odyssey\" for rare-disease\npatients.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u7c92\u5ea6\u7a00\u758f\u6fc0\u6d3b\u7684\u533b\u5b66\u6982\u5ff5\u548c\u5206\u5c42\u77e5\u8bc6\u56fe\u8c31\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7f55\u89c1\u75c5\u8bca\u65ad\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u533b\u7597\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7f55\u89c1\u75c5\u8bca\u65ad\u65b9\u9762\u5b58\u5728\u77e5\u8bc6\u8868\u8fbe\u6df1\u5ea6\u4e0d\u8db3\u3001\u6982\u5ff5\u7406\u89e3\u6709\u9650\u548c\u4e34\u5e8a\u63a8\u7406\u53d7\u9650\u7b49\u95ee\u9898\u3002", "method": "\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u591a\u7c92\u5ea6\u7a00\u758f\u6fc0\u6d3b\u7684\u533b\u5b66\u6982\u5ff5\u548c\u5206\u5c42\u77e5\u8bc6\u56fe\u8c31\uff0c\u4f7f\u7528\u4e86\u56db\u79cd\u4e92\u8865\u5339\u914d\u7b97\u6cd5\u3001\u591a\u6837\u6027\u63a7\u5236\u548c\u4e94\u7ea7\u56de\u9000\u7b56\u7565\uff0c\u4ee5\u53ca\u4e09\u5c42\u77e5\u8bc6\u56fe\u8c31\uff08\u5206\u7c7b\u6cd5\u3001\u4e34\u5e8a\u7279\u5f81\u3001\u5b9e\u4f8b\uff09\u3002", "result": "\u5728BioASQ\u7f55\u89c1\u75c5\u95ee\u7b54\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728BLEU\u3001ROUGE\u548c\u51c6\u786e\u7387\u4e0a\u5206\u522b\u63d0\u9ad8\u4e860.09\u30010.05\u548c0.12\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u8fbe\u52300.89\uff0c\u63a5\u8fd10.90\u7684\u4e34\u5e8a\u9608\u503c\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u7f55\u89c1\u75c5\u8bca\u65ad\u7684\u51c6\u786e\u6027\uff0c\u7f29\u77ed\u4e86\u8bca\u65ad\u65f6\u95f4\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728BLEU\u3001ROUGE\u548c\u51c6\u786e\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u9ad8\uff0c\u63a5\u8fd1\u4e34\u5e8a\u9608\u503c\u3002\u4e13\u5bb6\u8bc4\u4f30\u4e5f\u8bc1\u5b9e\u4e86\u8be5\u65b9\u6cd5\u5728\u4fe1\u606f\u8d28\u91cf\u3001\u63a8\u7406\u548c\u4e13\u4e1a\u8868\u8fbe\u65b9\u9762\u7684\u6539\u8fdb\u3002"}}
