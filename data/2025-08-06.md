<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 18]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Efficient Agents: Building Effective Agents While Reducing Cost](https://arxiv.org/abs/2508.02694)
*Ningning Wang,Xavier Hu,Pai Liu,He Zhu,Yue Hou,Heyuan Huang,Shengyu Zhang,Jian Yang,Jiaheng Liu,Ge Zhang,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: 研究发现，高效的智能体框架设计可以显著降低成本，同时保持较高的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型驱动的智能体的显著能力使得复杂的系统能够处理复杂的多步骤任务，但其不断上升的成本威胁着可扩展性和可及性。

Method: 对GAIA基准进行了实证分析，评估了LLM主干选择、智能体框架设计和测试时缩放策略的影响，使用cost-of-pass指标量化了效率-性能权衡。

Result: Efficient Agents框架在保持高性能的同时，显著降低了运营成本。

Conclusion: 这项工作对现代智能体系统中的效率-有效性权衡进行了首次系统性研究，提出了一种名为Efficient Agents的新型智能体框架，在保持96.7%的OWL框架性能的同时，将运营成本降低了28.4%。

Abstract: The remarkable capabilities of Large Language Model (LLM)-driven agents have
enabled sophisticated systems to tackle complex, multi-step tasks, but their
escalating costs threaten scalability and accessibility. This work presents the
first systematic study of the efficiency-effectiveness trade-off in modern
agent systems, addressing the critical need for cost-effective designs without
sacrificing performance. We investigate three key questions: (1) How much
complexity do agentic tasks inherently require? (2) When do additional modules
yield diminishing returns? (3) How much efficiency can be gained through the
design of efficient agent frameworks? Through an empirical analysis on the GAIA
benchmark, we evaluate the impact of LLM backbone selection, agent framework
designs, and test-time scaling strategies. Using the cost-of-pass metric, we
quantify the efficiency-performance trade-off across these dimensions. Our
findings inform the development of Efficient Agents , a novel agent framework
that has an optimal complexity to task requirements. Efficient Agents retains
96.7% of the performance of OWL, one leading open-source agent framework, while
reducing operational costs from $0.398 to $0.228, resulting in a 28.4%
improvement in cost-of-pass. Our work provides actionable insights for
designing efficient, high-performing agent systems, advancing the accessibility
and sustainability of AI-driven solutions.

</details>


### [2] [Planning with Dynamically Changing Domains](https://arxiv.org/abs/2508.02697)
*Mikhail Soutchanski,Yongmei Liu*

Main category: cs.AI

TL;DR: 提出一种新的规划方法，无需领域闭包假设，并在有限对象集的限制下，解决了顺序广义规划和一致性规划的交集问题。


<details>
  <summary>Details</summary>
Motivation: 经典规划和一致性规划假设存在预先给定的有限多个命名对象，但实际规划问题中对象的集合会动态变化。

Method: 该方法基于一阶逻辑，假设初始理论是一组有限的一致性流畅文字，并在规划时对动作进行接地处理。

Result: 提出了一种无需DCA即可解决有界规划问题的完整且正确的方法，并实现了概念验证。

Conclusion: 本文提出了一种在没有领域闭包假设(DCA)的情况下解决有界规划问题的方法，该方法适用于顺序广义规划和一致性规划的交集，并证明了其正确性和完整性。

Abstract: In classical planning and conformant planning, it is assumed that there are
finitely many named objects given in advance, and only they can participate in
actions and in fluents. This is the Domain Closure Assumption (DCA). However,
there are practical planning problems where the set of objects changes
dynamically as actions are performed; e.g., new objects can be created, old
objects can be destroyed. We formulate the planning problem in first-order
logic, assume an initial theory is a finite consistent set of fluent literals,
discuss when this guarantees that in every situation there are only finitely
many possible actions, impose a finite integer bound on the length of the plan,
and propose to organize search over sequences of actions that are grounded at
planning time. We show the soundness and completeness of our approach. It can
be used to solve the bounded planning problems without DCA that belong to the
intersection of sequential generalized planning (without sensing actions) and
conformant planning, restricted to the case without the disjunction over fluent
literals. We discuss a proof-of-the-concept implementation of our planner.

</details>


### [3] [Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model](https://arxiv.org/abs/2508.02734)
*Weiyu Luo,Chenfeng Xiong*

Main category: cs.AI

TL;DR: VSNIT有效恢复不完整LBS活动序列，提升数据利用率。


<details>
  <summary>Details</summary>
Motivation: 现有基于位置的服务（LBS）数据稀疏，导致活动序列不完整，难以准确推断出行和活动。

Method: 提出了一种新的解决方案：Variable Selection Network-fused Insertion Transformer (VSNIT)，该方法结合了插入Transformer的灵活序列构建和变量选择网络的动态协变量处理能力。

Result: VSNIT能够插入更多样、更真实的活动模式，更有效地恢复中断的活动转换，并在所有指标上均显著优于基线模型。

Conclusion: Variable Selection Network-fused Insertion Transformer (VSNIT) 能够更准确、更全面地恢复不完整活动序列，显著优于基线模型，为基于位置的服务数据分析提供了新的方法。

Abstract: Location-Based Service (LBS) data provides critical insights into human
mobility, yet its sparsity often yields incomplete trip and activity sequences,
making accurate inferences about trips and activities difficult. We raise a
research problem: Can we use activity sequences derived from high-quality LBS
data to recover incomplete activity sequences at the individual level? This
study proposes a new solution, the Variable Selection Network-fused Insertion
Transformer (VSNIT), integrating the Insertion Transformer's flexible sequence
construction with the Variable Selection Network's dynamic covariate handling
capability, to recover missing segments in incomplete activity sequences while
preserving existing data. The findings show that VSNIT inserts more diverse,
realistic activity patterns, more closely matching real-world variability, and
restores disrupted activity transitions more effectively aligning with the
target. It also performs significantly better than the baseline model across
all metrics. These results highlight VSNIT's superior accuracy and diversity in
activity sequence recovery tasks, demonstrating its potential to enhance LBS
data utility for mobility analysis. This approach offers a promising framework
for future location-based research and applications.

</details>


### [4] [Large Language Model-based Data Science Agent: A Survey](https://arxiv.org/abs/2508.02744)
*Peiran Wang,Yaoning Yu,Ke Chen,Xianyang Zhan,Haohan Wang*

Main category: cs.AI

TL;DR: Survey paper reviewing LLM-based agents for data science, offering a framework bridging agent design and data science workflows.


<details>
  <summary>Details</summary>
Motivation: Rapid advancement of LLMs and the emergence of LLM-based agents in diverse domains, particularly data science.

Method: Review and analysis of recent studies on LLM-based agents in data science.

Result: Provides a comprehensive review and a dual-perspective framework for understanding and designing LLM-based agents for data science tasks.

Conclusion: This survey comprehensively analyzes LLM-based agents for data science tasks, offering a dual-perspective framework connecting general agent design with data science workflows.

Abstract: The rapid advancement of Large Language Models (LLMs) has driven novel
applications across diverse domains, with LLM-based agents emerging as a
crucial area of exploration. This survey presents a comprehensive analysis of
LLM-based agents designed for data science tasks, summarizing insights from
recent studies. From the agent perspective, we discuss the key design
principles, covering agent roles, execution, knowledge, and reflection methods.
From the data science perspective, we identify key processes for LLM-based
agents, including data preprocessing, model development, evaluation,
visualization, etc. Our work offers two key contributions: (1) a comprehensive
review of recent developments in applying LLMbased agents to data science
tasks; (2) a dual-perspective framework that connects general agent design
principles with the practical workflows in data science.

</details>


### [5] [Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science](https://arxiv.org/abs/2508.02789)
*Newman Cheng,Gordon Broadbent,William Chappell*

Main category: cs.AI

TL;DR: CLIO enhances LLMs' reasoning capabilities, boosting accuracy and providing scientists with unprecedented control and transparency in scientific discovery.


<details>
  <summary>Details</summary>
Motivation: Existing AI frameworks lack steerability, hindering their utility in scientific discovery.  CLIO addresses this by providing scientists with deep control and insight into the reasoning process.

Method: Introduces CLIO (cognitive loop via in-situ optimization), allowing LLMs to self-formulate problem-solving approaches, adapt based on self-confidence, and provide final beliefs with transparency.

Result: GPT-4.1 with CLIO achieves 22.37% accuracy on HLE, a 13.82% net increase over the base model, exceeding OpenAI's o3 performance. Oscillations in internal uncertainty measures correlate with accuracy.

Conclusion: CLIO, a novel approach enabling deep and precise control over the reasoning process in LLMs, significantly improves accuracy in text-based biology and medicine questions, surpassing existing models.

Abstract: The capacity for artificial intelligence (AI) to formulate, evolve, and test
altered thought patterns under dynamic conditions indicates advanced cognition
that is crucial for scientific discovery. The existing AI development landscape
falls into two categories: 1) frameworks over non-reasoning models that
natively incorporate opinions on how humans think, and 2) reasoning models that
abstract precise control of the reasoning intuition away from end users. While
powerful, for scientists to maximize utility of AI in scientific discovery,
they not only require accuracy and transparency in reasoning, but also
steerability. Hence, we introduce an alternative approach that enables deep and
precise control over the reasoning process called: a cognitive loop via in-situ
optimization (CLIO). CLIO enables large language models (LLMs) to
self-formulate ways of approaching a problem, adapt behavior when
self-confidence is low, and ultimately provide scientists with a final belief
or answer. Through CLIO's open design, scientists can observe uncertainty
levels, understand how final belief states are formulated using graph
structures, and interject corrections. Without any further post-training,
OpenAI's GPT-4.1 with CLIO yields an accuracy of 22.37\% in text-based biology
and medicine questions on Humanity's Last Exam (HLE). This yields a 13.82\% net
or 161.64\% relative increase when compared to the base GPT-4.1 model and
surpasses OpenAI's o3 performance in high and low reasoning effort modes. We
further discovered that oscillations within internal uncertainty measures are
key in determining the accuracy of CLIO's results, revealing how its open
design and internal mechanisms can provide insight and control into scientific
decision-making processes.

</details>


### [6] [A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering](https://arxiv.org/abs/2508.02841)
*Ziruo Yi,Jinyu Liu,Ting Xiao,Mark V. Albert*

Main category: cs.AI

TL;DR: 多智能体系统提升了医学影像问答的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于MLLM和RAG的RVQA方法存在事实准确性、幻觉和跨模态错位等问题。

Method: 提出了一种多智能体系统(MAS)，包含上下文理解、多模态推理和答案验证三个专用智能体。

Result: 实验证明该系统优于强基线，具有可靠性和可解释性。

Conclusion: 多智能体系统在RVQA任务中优于现有的大型语言模型基线，提高了准确性和可解释性，展现了多智能体方法在复杂临床AI应用中的潜力。

Abstract: Radiology visual question answering (RVQA) provides precise answers to
questions about chest X-ray images, alleviating radiologists' workload. While
recent methods based on multimodal large language models (MLLMs) and
retrieval-augmented generation (RAG) have shown promising progress in RVQA,
they still face challenges in factual accuracy, hallucinations, and cross-modal
misalignment. We introduce a multi-agent system (MAS) designed to support
complex reasoning in RVQA, with specialized agents for context understanding,
multimodal reasoning, and answer validation. We evaluate our system on a
challenging RVQA set curated via model disagreement filtering, comprising
consistently hard cases across multiple MLLMs. Extensive experiments
demonstrate the superiority and effectiveness of our system over strong MLLM
baselines, with a case study illustrating its reliability and interpretability.
This work highlights the potential of multi-agent approaches to support
explainable and trustworthy clinical AI applications that require complex
reasoning.

</details>


### [7] [Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game](https://arxiv.org/abs/2508.02900)
*Michael Katz,Harsha Kokel,Sarath Sreedharan*

Main category: cs.AI

TL;DR: 提出一个基于“Countdown”游戏的更具挑战性的规划基准来评估大型语言模型的规划能力。


<details>
  <summary>Details</summary>
Motivation: 现有的规划基准不足以衡量当前基础模型和智能体的规划能力。

Method: 提出了一种基于“Countdown”游戏的规划基准，并对现有LLM辅助规划方法进行了评估。

Result: 提出了一种新的，更具挑战性的规划基准，并通过实验验证了其有效性。

Conclusion: 本文提出了一种基于“Countdown”游戏的新型规划能力评估基准，该基准克服了现有基准的不足，例如任务定义模糊或针对特定算法弱点设计。实验结果表明，该基准对现有的基于LLM的规划方法具有很强的挑战性。

Abstract: There is a broad consensus that the inability to form long-term plans is one
of the key limitations of current foundational models and agents. However, the
existing planning benchmarks remain woefully inadequate to truly measure their
planning capabilities. Most existing benchmarks either focus on loosely defined
tasks like travel planning or end up leveraging existing domains and problems
from international planning competitions. While the former tasks are hard to
formalize and verify, the latter were specifically designed to test and
challenge the weaknesses of existing automated planners. To address these
shortcomings, we propose a procedure for creating a planning benchmark centered
around the game called Countdown, where a player is expected to form a target
number from a list of input numbers through arithmetic operations. We discuss
how this problem meets many of the desiderata associated with an ideal
benchmark for planning capabilities evaluation. Specifically, the domain allows
for an intuitive, natural language description for each problem instance, it is
computationally challenging (NP-complete), and the instance space is rich
enough that we do not have to worry about memorization. We perform an extensive
theoretical analysis, establishing the computational complexity result and
demonstrate the advantage of our instance generation procedure over public
benchmarks. We evaluate a variety of existing LLM-assisted planning methods on
instances generated using our procedure. Our results show that, unlike other
domains like 24 Game (a special case of Countdown), our proposed dynamic
benchmark remains extremely challenging for existing LLM-based approaches.

</details>


### [8] [Enhancing Japanese Large Language Models with Reasoning Vectors](https://arxiv.org/abs/2508.02913)
*Carolina Minami Oguchi,Leo Wei,Koyo Kobayashi,Hsin-Tai Wu,Dipak Ghosal*

Main category: cs.AI

TL;DR: 利用推理向量提升日语LLM推理能力


<details>
  <summary>Details</summary>
Motivation: 现有方法难以提升日语LLM的推理能力，因为资源有限。

Method: 从推理LLM中提取推理向量，并将其应用到日语LLM。

Result: 该方法简单有效地提高了日语LLM的性能。

Conclusion: 本文提出了一种简单有效的方法，通过将推理向量从推理LLM应用到日语LLM，从而提高日语LLM的性能，为其他语言的改进提供了启发。

Abstract: Post-training methods have improved the performance and enhanced the
reasoning capability for mainstream large language models (LLMs), but the same
is challenging for Japanese LLMs to achieve due to the amount of resources
required. Inspired by task vectors that extract the change of weights before
and after training, specifically for a certain task, we obtain reasoning
vectors from reasoning LLMs and apply them to Japanese LLMs to boost their
performance. While the resources available present a challenge to improve
Japanese LLMs, we present a simple and effective way to obtain high improvement
and hope to inspire for other languages.

</details>


### [9] [PentestJudge: Judging Agent Behavior Against Operational Requirements](https://arxiv.org/abs/2508.02921)
*Shane Caldwell,Max Harley,Michael Kouremetis,Vincent Abruzzo,Will Pearce*

Main category: cs.AI

TL;DR: 使用LLM评估渗透测试代理，F1得分0.83，工具使用能力强的模型表现更好，验证比生成更容易。


<details>
  <summary>Details</summary>
Motivation: 评估AI安全代理的过程质量，以便在敏感的生产环境中安全可靠地使用。

Method: 使用大型语言模型(LLM)作为评判者，结合工具访问代理状态和工具调用历史，基于树状结构的评估标准对渗透测试任务进行分解，最终评估简单的是/否标准。

Result: 最佳模型达到0.83的F1分数，工具使用能力强的模型表现更佳，但不同模型在不同类型的评估标准上表现差异较大。较弱的模型可以评估较强模型的渗透测试轨迹。

Conclusion: PentestJudge系统可以有效评估渗透测试代理的操作，其F1分数达到0.83，并且工具使用能力强的模型更接近人类专家的判断。

Abstract: We introduce PentestJudge, a system for evaluating the operations of
penetration testing agents. PentestJudge is a large language model
(LLM)-as-judge with access to tools that allow it to consume arbitrary
trajectories of agent states and tool call history to determine whether a
security agent's actions meet certain operating criteria that would be
impractical to evaluate programmatically. We develop rubrics that use a tree
structure to hierarchically collapse the penetration testing task for a
particular environment into smaller, simpler, and more manageable sub-tasks and
criteria until each leaf node represents simple yes-or-no criteria for
PentestJudge to evaluate. Task nodes are broken down into different categories
related to operational objectives, operational security, and tradecraft.
LLM-as-judge scores are compared to human domain experts as a ground-truth
reference, allowing us to compare their relative performance with standard
binary classification metrics, such as F1 scores. We evaluate several frontier
and open-source models acting as judge agents, with the best model reaching an
F1 score of 0.83. We find models that are better at tool-use perform more
closely to human experts. By stratifying the F1 scores by requirement type, we
find even models with similar overall scores struggle with different types of
questions, suggesting certain models may be better judges of particular
operating criteria. We find that weaker and cheaper models can judge the
trajectories of pentests performed by stronger and more expensive models,
suggesting verification may be easier than generation for the penetration
testing task. We share this methodology to facilitate future research in
understanding the ability of judges to holistically and scalably evaluate the
process quality of AI-based information security agents so that they may be
confidently used in sensitive production environments.

</details>


### [10] [AQUAH: Automatic Quantification and Unified Agent in Hydrology](https://arxiv.org/abs/2508.02936)
*Songkun Yan,Zhi Li,Siyu Zhu,Yixin Wen,Mofan Zhang,Mengye Chen,Jie Cao,Yang Hong*

Main category: cs.AI

TL;DR: LLM-powered agent automates hydrologic modeling from natural language, showing promise but needing further validation.


<details>
  <summary>Details</summary>
Motivation: To streamline complex environmental modeling and improve accessibility of Earth observation data.

Method: Uses vision-enabled LLMs to interpret data, configure models, run simulations, and generate reports.

Result: Successfully performs cold-start simulations and generates analyst-ready documentation without manual intervention. Results deemed clear, transparent, and physically plausible by hydrologists.

Conclusion: AQUAH, a novel language-based agent, automates hydrologic modeling from natural language prompts, producing self-contained reports.  Initial tests show promising results, though further validation is needed.

Abstract: We introduce AQUAH, the first end-to-end language-based agent designed
specifically for hydrologic modeling. Starting from a simple natural-language
prompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to
2022'), AQUAH autonomously retrieves the required terrain, forcing, and gauge
data; configures a hydrologic model; runs the simulation; and generates a
self-contained PDF report. The workflow is driven by vision-enabled large
language models, which interpret maps and rasters on the fly and steer key
decisions such as outlet selection, parameter initialization, and uncertainty
commentary. Initial experiments across a range of U.S. basins show that AQUAH
can complete cold-start simulations and produce analyst-ready documentation
without manual intervention. The results are judged by hydrologists as clear,
transparent, and physically plausible. While further calibration and validation
are still needed for operational deployment, these early outcomes highlight the
promise of LLM-centered, vision-grounded agents to streamline complex
environmental modeling and lower the barrier between Earth observation data,
physics-based tools, and decision makers.

</details>


### [11] [MedBLINK: Probing Basic Perception in Multimodal Language Models for Medicine](https://arxiv.org/abs/2508.02951)
*Mahtab Bigverdi,Wisdom Ikezogwo,Kevin Zhang,Hyewon Jeong,Mingyu Lu,Sungjae Cho,Linda Shapiro,Ranjay Krishna*

Main category: cs.AI

TL;DR: Medblink基准测试显示，当前的多模态语言模型在医学影像感知任务上的表现远低于人类水平，需要进一步改进其视觉理解能力才能在临床应用中发挥作用。


<details>
  <summary>Details</summary>
Motivation: 探究当前多模态语言模型在医学影像感知方面的能力，以促进其在临床实践中的应用。

Method: 构建Medblink基准测试，包含8个临床相关的任务，涵盖多种影像模式和解剖区域，共有1429个多项选择题，基于1605张图像。对19个最先进的MLM模型(包括通用模型和特定领域模型)进行了评估。

Result: 结果表明，目前的MLM模型经常在常规的感知检查中失败，这表明需要加强其视觉基础以支持临床采用。

Conclusion: 当前的多模态语言模型(MLM)在临床决策支持和诊断推理方面显示出前景，但其在一些简单的感知任务上(例如确定图像方向或识别CT扫描是否增强对比度)的错误率较高，阻碍了其临床应用。Medblink基准测试评估了19个最先进的MLM模型在这方面的能力，结果显示，即使是表现最好的模型准确率也只有65%，远低于人类96.4%的准确率。

Abstract: Multimodal language models (MLMs) show promise for clinical decision support
and diagnostic reasoning, raising the prospect of end-to-end automated medical
image interpretation. However, clinicians are highly selective in adopting AI
tools; a model that makes errors on seemingly simple perception tasks such as
determining image orientation or identifying whether a CT scan is
contrast-enhance are unlikely to be adopted for clinical tasks. We introduce
Medblink, a benchmark designed to probe these models for such perceptual
abilities. Medblink spans eight clinically meaningful tasks across multiple
imaging modalities and anatomical regions, totaling 1,429 multiple-choice
questions over 1,605 images. We evaluate 19 state-of-the-art MLMs, including
general purpose (GPT4o, Claude 3.5 Sonnet) and domain specific (Med Flamingo,
LLaVA Med, RadFM) models. While human annotators achieve 96.4% accuracy, the
best-performing model reaches only 65%. These results show that current MLMs
frequently fail at routine perceptual checks, suggesting the need to strengthen
their visual grounding to support clinical adoption. Data is available on our
project page.

</details>


### [12] [Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow](https://arxiv.org/abs/2508.02959)
*Chia-Tung Ho,Jing Gong,Xufeng Yao,Yunsheng Bai,Abhishek B Akkur,Haoxing Ren*

Main category: cs.AI

TL;DR: Polymath 是一种无需标记数据即可自我优化的智能体，在多个基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于标记数据集来训练和优化工作流程，这使得它们在解决现实世界中缺乏标记数据的动态问题时效率低下且缺乏灵活性。

Method: Polymath 集成了多网格启发的图优化和自我反思引导的进化算法，无需标记数据即可优化工作流程。

Result: 在编码、数学和多轮 QA 任务的六个基准数据集上，Polymath 的平均性能比最先进的基线提高了 8.1%。

Conclusion: Polymath，一个具有动态层次工作流程的自我优化代理，通过结合任务流程图的灵活性和代码表示工作流程的表现力，解决了广泛的现实世界动态问题。它在六个基准数据集上的平均性能提高了 8.1%。

Abstract: Large language models (LLMs) excel at solving complex tasks by executing
agentic workflows composed of detailed instructions and structured operations.
Yet, building general-purpose agents by manually embedding foundation models
into agentic systems such as Chain-of-Thought, Self-Reflection, and ReACT
through text interfaces limits scalability and efficiency. Recently, many
researchers have sought to automate the generation and optimization of these
workflows through code-based representations. However, existing methods often
rely on labeled datasets to train and optimize workflows, making them
ineffective and inflexible for solving real-world, dynamic problems where
labeled data is unavailable. To address this challenge, we introduce Polymath,
a self-optimizing agent with dynamic hierarchical workflow that leverages the
flexibility of task flow graphs and the expressiveness of code-represented
workflows to solve a wide range of real-world, dynamic problems. The proposed
optimization methodology integrates multi-grid-inspired graph optimization with
a self-reflection-guided evolutionary algorithm to refine workflows without
labeled data. Experimental results on six benchmark datasets across coding,
math, and multi-turn QA tasks show that Polymath achieves 8.1% average
improvement over state-of-the-art baselines.

</details>


### [13] [Defend LLMs Through Self-Consciousness](https://arxiv.org/abs/2508.02961)
*Boshi Huang,Fabio Nonato de Paula*

Main category: cs.AI

TL;DR: 一种轻量级、经济高效的自我意识防御机制，显著提升大型语言模型的安全性。


<details>
  <summary>Details</summary>
Motivation: 为了对抗提示注入攻击，提升LLM的安全性与伦理道德。

Method: 该方法通过结合元认知和仲裁模块，使LLM能够自主评估和规范自身的输出。

Result: 实验结果表明，该方法显著提高了各种模型和数据集的防御成功率，某些模型在增强模式下实现了完美或接近完美的防御，并在防御成功率提升和计算开销之间取得了平衡。

Conclusion: 本文介绍了一种新颖的自我意识防御机制，用于增强大型语言模型 (LLM) 对提示注入攻击的防御能力，该机制利用LLM自身的推理能力进行自我保护，并在实验中取得了显著成果。

Abstract: This paper introduces a novel self-consciousness defense mechanism for Large
Language Models (LLMs) to combat prompt injection attacks. Unlike traditional
approaches that rely on external classifiers, our method leverages the LLM's
inherent reasoning capabilities to perform self-protection. We propose a
framework that incorporates Meta-Cognitive and Arbitration Modules, enabling
LLMs to evaluate and regulate their own outputs autonomously. Our approach is
evaluated on seven state-of-the-art LLMs using two datasets: AdvBench and
Prompt-Injection-Mixed-Techniques-2024. Experiment results demonstrate
significant improvements in defense success rates across models and datasets,
with some achieving perfect and near-perfect defense in Enhanced Mode. We also
analyze the trade-off between defense success rate improvement and
computational overhead. This self-consciousness method offers a lightweight,
cost-effective solution for enhancing LLM ethics, particularly beneficial for
GenAI use cases across various platforms.

</details>


### [14] [Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling](https://arxiv.org/abs/2508.02979)
*Peng Ding,Rick Stevens*

Main category: cs.AI

TL;DR: 提出一种统一方法，简化大型语言模型的工具集成，减少代码，提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的工具增强型大型语言模型生态系统比较分散，开发人员需要处理多种协议、手动模式定义和复杂的执行工作流。

Method: 提出了一种统一的工具集成方法，该方法能够抽象协议差异，优化执行性能，并支持自动化模式生成、双模并发执行和无缝多源工具管理。

Result: 实验结果表明，该方法能够减少60-80%的代码，将性能提高3.1倍，并完全兼容现有的函数调用标准。

Conclusion: 这项工作为工具集成架构提供了理论见解和实际解决方案，有助于简化大型语言模型的应用开发。

Abstract: The proliferation of tool-augmented Large Language Models (LLMs) has created
a fragmented ecosystem where developers must navigate multiple protocols,
manual schema definitions, and complex execution workflows. We address this
challenge by proposing a unified approach to tool integration that abstracts
protocol differences while optimizing execution performance. Our solution
demonstrates how protocol-agnostic design principles can significantly reduce
development overhead through automated schema generation, dual-mode concurrent
execution, and seamless multi-source tool management. Experimental results show
60-80% code reduction across integration scenarios, performance improvements up
to 3.1x through optimized concurrency, and full compatibility with existing
function calling standards. This work contributes both theoretical insights
into tool integration architecture and practical solutions for real-world LLM
application development.

</details>


### [15] [When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs](https://arxiv.org/abs/2508.02994)
*Fangyi Yu*

Main category: cs.AI

TL;DR: AI agent可用于评估LLM输出，但需进一步解决偏差和鲁棒性等问题，以实现可信赖和可扩展的评估。


<details>
  <summary>Details</summary>
Motivation: 随着LLM能力的提升，对输出结果的评估成为瓶颈，agent-as-a-judge方法利用AI agent评估其他模型的质量和安全性，提供可扩展和细致的替代方案。

Method: 回顾分析了agent-as-a-judge方法的演变，从单模型到多Agent辩论框架，并比较了不同方法的优缺点。

Result: 该方法在医学、法律、金融和教育等领域有实际应用，但仍面临偏差、鲁棒性和元评估等挑战。

Conclusion: Agent-as-a-judge方法可以辅助人工评估，但不能完全取代人工；该方法在可靠性、成本和与人类一致性方面各有优劣，未来研究方向包括偏差、鲁棒性和元评估等问题。

Abstract: As large language models (LLMs) grow in capability and autonomy, evaluating
their outputs-especially in open-ended and complex tasks-has become a critical
bottleneck. A new paradigm is emerging: using AI agents as the evaluators
themselves. This "agent-as-a-judge" approach leverages the reasoning and
perspective-taking abilities of LLMs to assess the quality and safety of other
models, promising calable and nuanced alternatives to human evaluation. In this
review, we define the agent-as-a-judge concept, trace its evolution from
single-model judges to dynamic multi-agent debate frameworks, and critically
examine their strengths and shortcomings. We compare these approaches across
reliability, cost, and human alignment, and survey real-world deployments in
domains such as medicine, law, finance, and education. Finally, we highlight
pressing challenges-including bias, robustness, and meta evaluation-and outline
future research directions. By bringing together these strands, our review
demonstrates how agent-based judging can complement (but not replace) human
oversight, marking a step toward trustworthy, scalable evaluation for
next-generation LLMs.

</details>


### [16] [AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots](https://arxiv.org/abs/2508.02999)
*Xinjie Zhao,Moritz Blum,Fan Gao,Yingjian Chen,Boming Yang,Luis Marquez-Carpintero,Mónica Pina-Navarro,Yanran Fu,So Morikawa,Yusuke Iwasawa,Yutaka Matsuo,Chanjun Park,Irene Li*

Main category: cs.AI

TL;DR: AGENTiGraph是一个用户友好的知识图谱管理系统，使用自然语言交互，在基准测试中表现出色，具有良好的应用前景。


<details>
  <summary>Details</summary>
Motivation: 为了使非技术用户能够直观地构建和完善知识库，AGENTiGraph提供了完整的可视化解决方案，允许多轮对话和动态更新，无需专门的查询语言。

Method: AGENTiGraph是一个用户友好的、代理驱动的系统，允许用户通过自然语言操作知识图来交互和管理特定领域的数据。它包括意图分类、任务规划和自动知识整合等功能。

Result: 在教育场景下的3500个查询基准测试中，AGENTiGraph的分类准确率达到95.12%，执行成功率达到90.45%，优于强零样本基线。

Conclusion: AGENTiGraph系统在教育场景下的3500个查询基准测试中，分类准确率达到95.12%，执行成功率达到90.45%，优于强零样本基线，显示出其在法律和医疗等领域处理合规性关键或多步骤查询的潜力。

Abstract: AGENTiGraph is a user-friendly, agent-driven system that enables intuitive
interaction and management of domain-specific data through the manipulation of
knowledge graphs in natural language. It gives non-technical users a complete,
visual solution to incrementally build and refine their knowledge bases,
allowing multi-round dialogues and dynamic updates without specialized query
languages. The flexible design of AGENTiGraph, including intent classification,
task planning, and automatic knowledge integration, ensures seamless reasoning
between diverse tasks. Evaluated on a 3,500-query benchmark within an
educational scenario, the system outperforms strong zero-shot baselines
(achieving 95.12% classification accuracy, 90.45% execution success),
indicating potential scalability to compliance-critical or multi-step queries
in legal and medical domains, e.g., incorporating new statutes or research on
the fly. Our open-source demo offers a powerful new paradigm for multi-turn
enterprise knowledge management that bridges LLMs and structured graphs.

</details>


### [17] [Beyond Policy Optimization: A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning](https://arxiv.org/abs/2508.03018)
*Yutong Wang,Pengliang Ji,Kaixin Li,Baolong Bi,Tao Feng,Guillaume Sartoretti*

Main category: cs.AI

TL;DR: BPO框架有效解决了大型语言模型在代理规划中面临的信用分配和计算开销问题，并在多个环境中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言推理模型难以应用于交互环境中的多轮代理规划，因为存在棘手的信用分配问题和巨大的计算开销。

Method: 提出了一种三阶段框架BPO (bootstrapping, extrapolation, and refinement)，结合规划四元数和长短链式思维融合，通过复杂度分层课程学习和奖励门控拒绝采样迭代改进模型。

Result: 在ALFWorld，ScienceWorld和WebShop数据集上取得了最先进的结果，并具有显著的标记效率。

Conclusion: BPO框架在ALFWorld，ScienceWorld和WebShop上取得了最先进的结果，并具有显著的标记效率，为代理规划中的推理模型提供了一种新的方法。

Abstract: Large Language Reasoning Models have demonstrated remarkable success on
static tasks, yet their application to multi-round agentic planning in
interactive environments faces two fundamental challenges. First, the
intractable credit assignment problem renders conventional reinforcement
learning ineffective in sparse-reward settings. Second, the computational
overhead of verbose, step-by-step reasoning histories is prohibitive. To
address these challenges, we propose BPO, a three-stage framework
(bootstrapping, extrapolation, and refinement) that establishes a
self-improving data flywheel to develop robust reasoning models for
long-horizon, sparse-reward environments. Our framework first bootstraps
efficient reasoning using the proposed planning quaternions with long-short
chain-of-thought fusion. It then extrapolates to out-of-distribution tasks
through complexity-stratified curriculum learning. Finally, the model
iteratively refines itself by learning exclusively on experiences selected via
reward-gated rejection sampling. Experiments on ALFWorld, ScienceWorld, and
WebShop demonstrate that our approach achieves state-of-the-art with
significant token efficiency, providing a new recipe for reasoning models in
agentic planning.

</details>


### [18] [Collab-Solver: Collaborative Solving Policy Learning for Mixed-Integer Linear Programming](https://arxiv.org/abs/2508.03030)
*Siyuan Li,Yifan Yu,Yanchen Deng,Zhihao Zhang,Mengjing Chen,Fangzhou Zhu,Tao Zhong,Jianye Hao,Peng Liu,Bo An*

Main category: cs.AI

TL;DR: 提出一种名为Collab-Solver的多智能体协同策略学习框架，显著提升MILP求解性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的MILP方法独立处理各模块的策略学习，忽略模块间的相互依赖性，影响求解速度和质量。

Method: 基于多智能体策略学习的Stackelberg博弈框架，两阶段学习范式（数据通信策略预训练和多模块策略学习）。

Result: 在合成和真实大型MILP数据集上，协同学习的策略显著提高了求解性能，并展现出优异的泛化能力。

Conclusion: Collab-Solver框架通过将割选择和分支策略学习制定为Stackelberg博弈，并采用两阶段学习范式，实现了MILP求解器多个模块策略的协同优化，显著提升了解决速度和质量，并在合成和真实数据集上表现出优异的泛化能力。

Abstract: Mixed-integer linear programming (MILP) has been a fundamental problem in
combinatorial optimization. Previous works have designed a plethora of
hard-coded heuristics to accomplish challenging MILP solving with domain
knowledge. Driven by the high capability of neural networks, recent research is
devoted to replacing manually designed heuristics with learned policies.
Although learning-based MILP methods have shown great promise, existing
worksindependentlytreatthepolicylearningineachmoduleofMILPsolvers without
considering their interdependence, severely hurting the solving speed and
quality. To address this issue, we propose a novel multi-agent-based policy
learning framework for MILP (Collab-Solver), which can collaboratively optimize
the policies for multiple modules. Specifically, we formulate the collaboration
of cut selection and branching in MILP solving as a Stackelberg game. Under
this formulation, we develop a two-phase learning paradigm to stabilize the
collaborative policy learning, where the first phase achieves the
data-communicated policy pretraining and the second phase further orchestrates
the policy learning for various modules. The jointly learned policy
significantly improves the solving performance on both synthetic and
large-scale real-world MILP datasets. Moreover, the policies learned by
Collab-Solver have also demonstrated excellent generalization abilities across
different instance sets.

</details>
