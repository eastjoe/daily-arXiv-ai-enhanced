{"id": "2509.12251", "categories": ["cs.AI", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.12251", "abs": "https://arxiv.org/abs/2509.12251", "authors": ["Duong Q. Nguyen", "Quy P. Nguyen", "Nguyen Van Nhon", "Quang-Thinh Bui", "H. Nguyen-Xuan"], "title": "V-Math: An Agentic Approach to the Vietnamese National High School Graduation Mathematics Exams", "comment": null, "summary": "This paper develops an autonomous agentic framework called V-Math that aims\nto assist Vietnamese high school students in preparing for the National High\nSchool Graduation Mathematics Exams (NHSGMEs). The salient framework integrates\nthree specialized AI agents: a specification-matrix-conditioned question\ngenerator, a solver/explainer for detailed step-by-step reasoning, and a\npersonalized tutor that adapts to student performance. Beyond enabling\nself-paced student practice, V-Math supports teachers by generating innovative,\ncompliant exam questions and building diverse, high-quality question banks.\nThis reduces manual workload and enriches instructional resources. We describe\nthe system architecture, focusing on practice modes for learners and\nteacher-oriented features for question generation. Preliminary evaluations\ndemonstrate that V-Math produces matrix-aligned exams with high solution\naccuracy, delivers coherent explanations, and enhances the variety of practice\nmaterials. These results highlight its potential to support scalable, equitable\nmathematics preparation aligned with national standards while also empowering\nteachers through AI-assisted exam creation.", "AI": {"tldr": "V-Math\u7cfb\u7edf\u5e2e\u52a9\u8d8a\u5357\u9ad8\u4e2d\u751f\u5907\u8003\u6570\u5b66\uff0c\u96c6\u9898\u751f\u6210\u3001\u89e3\u9898\u3001\u4e2a\u6027\u5316\u8f85\u5bfc\u4e8e\u4e00\u4f53\uff0c\u6559\u5e08\u7aef\u53ef\u751f\u6210\u7b26\u5408\u6807\u51c6\u7684\u8bd5\u9898\u3002", "motivation": "\u5e2e\u52a9\u8d8a\u5357\u9ad8\u4e2d\u751f\u5907\u8003\u5168\u56fd\u9ad8\u4e2d\u6bd5\u4e1a\u6570\u5b66\u8003\u8bd5\uff0c\u51cf\u8f7b\u6559\u5e08\u8d1f\u62c5\uff0c\u63d0\u9ad8\u6559\u5b66\u8d44\u6e90\u8d28\u91cf\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aV-Math\u7684\u81ea\u4e3b\u667a\u80fd\u4ee3\u7406\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2aAI\u667a\u80fd\u4f53\uff1a\u8bd5\u9898\u751f\u6210\u5668\u3001\u89e3\u9898/\u89e3\u91ca\u5668\u548c\u4e2a\u6027\u5316\u8f85\u5bfc\u5668\u3002", "result": "V-Math\u80fd\u751f\u6210\u7b26\u5408\u8981\u6c42\u7684\u8bd5\u5377\uff0c\u63d0\u4f9b\u51c6\u786e\u7684\u89e3\u7b54\u548c\u6e05\u6670\u7684\u89e3\u91ca\uff0c\u5e76\u4e30\u5bcc\u7ec3\u4e60\u9898\u7684\u591a\u6837\u6027\u3002", "conclusion": "V-Math\u7cfb\u7edf\u5177\u6709\u4fc3\u8fdb\u5927\u89c4\u6a21\u3001\u516c\u5e73\u7684\u6570\u5b66\u5b66\u4e60\u548c\u8f85\u52a9\u6559\u5e08\u547d\u9898\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.12254", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12254", "abs": "https://arxiv.org/abs/2509.12254", "authors": ["Oddvar Kloster", "Bj\u00f8rnar Luteberget", "Carlo Mannino", "Giorgio Sartor"], "title": "DISPLIB: a library of train dispatching problems", "comment": null, "summary": "Optimization-based decision support systems have a significant potential to\nreduce delays, and thus improve efficiency on the railways, by automatically\nre-routing and re-scheduling trains after delays have occurred. The operations\nresearch community has dedicated a lot of effort to developing optimization\nalgorithms for this problem, but each study is typically tightly connected with\na specific industrial use case. Code and data are seldom shared publicly. This\nfact hinders reproducibility, and has led to a proliferation of papers\ndescribing algorithms for more or less compatible problem definitions, without\nany real opportunity for readers to assess their relative performance. Inspired\nby the successful communities around MILP, SAT, TSP, VRP, etc., we introduce a\ncommon problem definition and file format, DISPLIB, which captures all the main\nfeatures of train re-routing and re-scheduling. We have gathered problem\ninstances from multiple real-world use cases and made them openly available. In\nthis paper, we describe the problem definition, the industrial instances, and a\nreference solver implementation. This allows any researcher or developer to\nwork on the train dispatching problem without an industrial connection, and\nenables the research community to perform empirical comparisons between\nsolvers. All materials are available online at https://displib.github.io.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aDISPLIB\u7684\u516c\u5171\u95ee\u9898\u5b9a\u4e49\u548c\u6587\u4ef6\u683c\u5f0f\uff0c\u7528\u4e8e\u706b\u8f66\u91cd\u65b0\u8c03\u5ea6\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e9b\u771f\u5b9e\u7684\u6848\u4f8b\u6570\u636e\u548c\u53c2\u8003\u6c42\u89e3\u5668\u5b9e\u73b0\uff0c\u65b9\u4fbf\u7814\u7a76\u4eba\u5458\u8fdb\u884c\u7b97\u6cd5\u6bd4\u8f83\u548c\u590d\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u4f18\u5316\u7b97\u6cd5\u7814\u7a76\u901a\u5e38\u4e0e\u5177\u4f53\u7684\u5de5\u4e1a\u6848\u4f8b\u7d27\u5bc6\u76f8\u8fde\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5f88\u5c11\u516c\u5f00\uff0c\u963b\u788d\u4e86\u53ef\u91cd\u590d\u6027\u548c\u7b97\u6cd5\u6027\u80fd\u7684\u6bd4\u8f83\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u516c\u5171\u95ee\u9898\u5b9a\u4e49\u548c\u6587\u4ef6\u683c\u5f0fDISPLIB\uff0c\u6536\u96c6\u591a\u4e2a\u771f\u5b9e\u6848\u4f8b\u7684\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u53c2\u8003\u6c42\u89e3\u5668\u5b9e\u73b0\u3002", "result": "\u521b\u5efa\u4e86DISPLIB\uff0c\u65b9\u4fbf\u7814\u7a76\u4eba\u5458\u65e0\u9700\u5de5\u4e1a\u8fde\u63a5\u5373\u53ef\u8fdb\u884c\u706b\u8f66\u8c03\u5ea6\u95ee\u9898\u7684\u7814\u7a76\uff0c\u5e76\u80fd\u591f\u8fdb\u884c\u7b97\u6cd5\u7684\u5b9e\u8bc1\u6bd4\u8f83\u3002", "conclusion": "DISPLIB\u7684\u521b\u5efa\u4fc3\u8fdb\u4e86\u706b\u8f66\u8c03\u5ea6\u95ee\u9898\u7814\u7a76\u7684\u5f00\u653e\u6027\u548c\u53ef\u91cd\u590d\u6027\uff0c\u6709\u5229\u4e8e\u7b97\u6cd5\u7684\u6539\u8fdb\u548c\u53d1\u5c55\u3002"}}
{"id": "2509.12263", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12263", "abs": "https://arxiv.org/abs/2509.12263", "authors": ["Gautam Sreekumar", "Vishnu Naresh Boddeti"], "title": "InPhyRe Discovers: Large Multimodal Models Struggle in Inductive Physical Reasoning", "comment": "35 pages including appendix", "summary": "Large multimodal models (LMMs) encode universal physical laws observed during\ntraining, such as momentum conservation, as parametric knowledge. It allows\nLMMs to answer physical reasoning queries, such as the outcome of a potential\ncollision event from visual input. However, since parametric knowledge includes\nonly the physical laws seen during training, it is insufficient for reasoning\nwhen the inference scenario violates these physical laws. In contrast, humans\npossess the skill to adapt their physical reasoning to unseen physical\nenvironments from a few visual examples. This ability, which we refer to as\ninductive physical reasoning, is indispensable for LMMs if they are to replace\nhuman agents in safety-critical applications. Despite its importance, existing\nvisual benchmarks evaluate only the parametric knowledge in LMMs, and not\ninductive physical reasoning. To this end, we propose InPhyRe, the first visual\nquestion answering benchmark to measure inductive physical reasoning in LMMs.\nInPhyRe evaluates LMMs on their ability to predict the outcome of collision\nevents in algorithmically generated synthetic collision videos. By inspecting\n13 LMMs, InPhyRe informs us that (1) LMMs struggle to apply their limited\nparametric knowledge about universal physical laws to reasoning, (2) inductive\nphysical reasoning in LMMs is weak when demonstration samples violate universal\nphysical laws, and (3) inductive physical reasoning in LMMs suffers from\nlanguage bias and largely ignores the visual inputs, questioning the\ntrustworthiness of LMMs regarding visual inputs.", "AI": {"tldr": "\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b(LMMs)\u96be\u4ee5\u8fdb\u884c\u5f52\u7eb3\u7269\u7406\u63a8\u7406\uff0c\u5c24\u5176\u5728\u8fdd\u53cd\u5df2\u77e5\u7269\u7406\u5b9a\u5f8b\u7684\u60c5\u51b5\u4e0b\u3002InPhyRe\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e8613\u4e2aLMMs\u7684\u5f52\u7eb3\u7269\u7406\u63a8\u7406\u80fd\u529b\uff0c\u7ed3\u679c\u8868\u660eLMMs\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u5bf9\u8bed\u8a00\u504f\u5dee\u654f\u611f\u4e14\u5ffd\u7565\u89c6\u89c9\u8f93\u5165\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u8bc4\u4f30LMMs\u7684\u5f52\u7eb3\u7269\u7406\u63a8\u7406\u80fd\u529b\uff0c\u800c\u8fd9\u662f\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u4e0d\u53ef\u6216\u7f3a\u7684\u3002", "method": "\u63d0\u51faInPhyRe\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u7b97\u6cd5\u751f\u6210\u7684\u5408\u6210\u78b0\u649e\u89c6\u9891\u8bc4\u4f30LMMs\u9884\u6d4b\u78b0\u649e\u7ed3\u679c\u7684\u80fd\u529b\u3002", "result": "LMMs\u96be\u4ee5\u5c06\u6709\u9650\u7684\u7269\u7406\u5b9a\u5f8b\u77e5\u8bc6\u5e94\u7528\u4e8e\u63a8\u7406\uff1b\u5728\u6f14\u793a\u6837\u672c\u8fdd\u53cd\u7269\u7406\u5b9a\u5f8b\u65f6\uff0c\u5f52\u7eb3\u7269\u7406\u63a8\u7406\u80fd\u529b\u8f83\u5f31\uff1b\u5b58\u5728\u8bed\u8a00\u504f\u5dee\u4e14\u5ffd\u7565\u89c6\u89c9\u8f93\u5165\u3002", "conclusion": "InPhyRe\u63ed\u793a\u4e86LMMs\u5728\u5f52\u7eb3\u7269\u7406\u63a8\u7406\u65b9\u9762\u7684\u5f31\u70b9\uff0c\u5bf9\u63d0\u5347LMMs\u7684\u53ef\u9760\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2509.12273", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12273", "abs": "https://arxiv.org/abs/2509.12273", "authors": ["Liangqi Yuan", "Dong-Jun Han", "Christopher G. Brinton", "Sabine Brunswicker"], "title": "LLMAP: LLM-Assisted Multi-Objective Route Planning with User Preferences", "comment": null, "summary": "The rise of large language models (LLMs) has made natural language-driven\nroute planning an emerging research area that encompasses rich user objectives.\nCurrent research exhibits two distinct approaches: direct route planning using\nLLM-as-Agent and graph-based searching strategies. However, LLMs in the former\napproach struggle to handle extensive map data, while the latter shows limited\ncapability in understanding natural language preferences. Additionally, a more\ncritical challenge arises from the highly heterogeneous and unpredictable\nspatio-temporal distribution of users across the globe. In this paper, we\nintroduce a novel LLM-Assisted route Planning (LLMAP) system that employs an\nLLM-as-Parser to comprehend natural language, identify tasks, and extract user\npreferences and recognize task dependencies, coupled with a Multi-Step Graph\nconstruction with iterative Search (MSGS) algorithm as the underlying solver\nfor optimal route finding. Our multi-objective optimization approach adaptively\ntunes objective weights to maximize points of interest (POI) quality and task\ncompletion rate while minimizing route distance, subject to three key\nconstraints: user time limits, POI opening hours, and task dependencies. We\nconduct extensive experiments using 1,000 routing prompts sampled with varying\ncomplexity across 14 countries and 27 cities worldwide. The results demonstrate\nthat our approach achieves superior performance with guarantees across multiple\nconstraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684LLM\u8f85\u52a9\u8def\u7ebf\u89c4\u5212\u7cfb\u7edfLLMAP\uff0c\u8be5\u7cfb\u7edf\u7ed3\u5408\u4e86LLM\u4f5c\u4e3a\u89e3\u6790\u5668\u548c\u591a\u6b65\u56fe\u6784\u5efa\u8fed\u4ee3\u641c\u7d22\u7b97\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u6d77\u91cf\u5730\u56fe\u6570\u636e\u548c\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u504f\u597d\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709LLM\u8def\u7ebf\u89c4\u5212\u65b9\u6cd5\u5b58\u5728\u5904\u7406\u5730\u56fe\u6570\u636e\u548c\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u504f\u597d\u7684\u5c40\u9650\u6027\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "LLMAP\u7cfb\u7edf\u4f7f\u7528LLM\u4f5c\u4e3a\u89e3\u6790\u5668\u7406\u89e3\u81ea\u7136\u8bed\u8a00\uff0c\u63d0\u53d6\u7528\u6237\u504f\u597d\u548c\u4efb\u52a1\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u7ed3\u5408\u591a\u6b65\u56fe\u6784\u5efa\u8fed\u4ee3\u641c\u7d22\u7b97\u6cd5\u8fdb\u884c\u6700\u4f18\u8def\u7ebf\u67e5\u627e\u3002\u8be5\u7cfb\u7edf\u91c7\u7528\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u8003\u8651\u7528\u6237\u65f6\u95f4\u9650\u5236\u3001POI\u5f00\u653e\u65f6\u95f4\u548c\u4efb\u52a1\u4f9d\u8d56\u5173\u7cfb\u7b49\u7ea6\u675f\u6761\u4ef6\u4e0b\uff0c\u6700\u5927\u5316POI\u8d28\u91cf\u548c\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u8def\u7ebf\u8ddd\u79bb\u3002", "result": "\u572814\u4e2a\u56fd\u5bb627\u4e2a\u57ce\u5e02\u76841000\u4e2a\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u8def\u7ebf\u89c4\u5212\u8bf7\u6c42\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u7ea6\u675f\u6761\u4ef6\u4e0b\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "LLMAP\u7cfb\u7edf\u6709\u6548\u5730\u7ed3\u5408\u4e86LLM\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\u548c\u56fe\u641c\u7d22\u7b97\u6cd5\u7684\u6548\u7387\uff0c\u4e3a\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u8def\u7ebf\u89c4\u5212\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.12274", "categories": ["cs.AI", "cs.CV", "cs.LG", "68T07, 68T45, 68U10", "I.4.8; I.2.6; I.5.4; C.3"], "pdf": "https://arxiv.org/pdf/2509.12274", "abs": "https://arxiv.org/abs/2509.12274", "authors": ["Mohammadreza Narimani", "Ali Hajiahmad", "Ali Moghimi", "Reza Alimardani", "Shahin Rafiee", "Amir Hossein Mirzabe"], "title": "Developing an aeroponic smart experimental greenhouse for controlling irrigation and plant disease detection using deep learning and IoT", "comment": "Author-accepted version. Presented at ASABE Annual International\n  Meeting (AIM) 2021 (virtual), Paper 2101252. Please cite the published\n  meeting paper: doi:10.13031/aim.202101252. Minor wording and formatting\n  updates in this preprint", "summary": "Controlling environmental conditions and monitoring plant status in\ngreenhouses is critical to promptly making appropriate management decisions\naimed at promoting crop production. The primary objective of this research\nstudy was to develop and test a smart aeroponic greenhouse on an experimental\nscale where the status of Geranium plant and environmental conditions are\ncontinuously monitored through the integration of the internet of things (IoT)\nand artificial intelligence (AI). An IoT-based platform was developed to\ncontrol the environmental conditions of plants more efficiently and provide\ninsights to users to make informed management decisions. In addition, we\ndeveloped an AI-based disease detection framework using VGG-19,\nInceptionResNetV2, and InceptionV3 algorithms to analyze the images captured\nperiodically after an intentional inoculation. The performance of the AI\nframework was compared with an expert's evaluation of disease status.\nPreliminary results showed that the IoT system implemented in the greenhouse\nenvironment is able to publish data such as temperature, humidity, water flow,\nand volume of charge tanks online continuously to users and adjust the\ncontrolled parameters to provide an optimal growth environment for the plants.\nFurthermore, the results of the AI framework demonstrate that the VGG-19\nalgorithm was able to identify drought stress and rust leaves from healthy\nleaves with the highest accuracy, 92% among the other algorithms.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7269\u8054\u7f51\u548c\u4eba\u5de5\u667a\u80fd\u7684\u667a\u80fd\u6c14\u96fe\u683d\u57f9\u6e29\u5ba4\u7cfb\u7edf\uff0c\u7528\u4e8e\u76d1\u6d4b\u690d\u7269\u72b6\u6001\u548c\u73af\u5883\u6761\u4ef6\uff0c\u5e76\u5b9e\u73b0\u75be\u75c5\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u6e29\u5ba4\u7ba1\u7406\u4f9d\u8d56\u4eba\u5de5\u76d1\u6d4b\uff0c\u6548\u7387\u4f4e\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u667a\u80fd\u7cfb\u7edf\u63d0\u9ad8\u6548\u7387\uff0c\u4fc3\u8fdb\u4f5c\u7269\u751f\u4ea7\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u7269\u8054\u7f51\u7684\u5e73\u53f0\u63a7\u5236\u73af\u5883\u6761\u4ef6\uff0c\u5e76\u4f7f\u7528VGG-19\u3001InceptionResNetV2\u548cInceptionV3\u7b97\u6cd5\u6784\u5efaAI\u75be\u75c5\u68c0\u6d4b\u6846\u67b6\u3002", "result": "\u7269\u8054\u7f51\u7cfb\u7edf\u80fd\u591f\u5b9e\u65f6\u76d1\u6d4b\u6e29\u6e7f\u5ea6\u3001\u6c34\u6d41\u7b49\uff0cAI\u6846\u67b6\u4e2dVGG-19\u7b97\u6cd5\u5bf9\u5e72\u65f1\u80c1\u8feb\u548c\u9508\u75c5\u7684\u8bc6\u522b\u51c6\u786e\u7387\u6700\u9ad8\uff0c\u8fbe92%\u3002", "conclusion": "\u8be5\u667a\u80fd\u6e29\u5ba4\u7cfb\u7edf\u6709\u6548\u63d0\u9ad8\u4e86\u6e29\u5ba4\u73af\u5883\u76d1\u63a7\u548c\u75be\u75c5\u68c0\u6d4b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u7cbe\u51c6\u519c\u4e1a\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u624b\u6bb5\u3002"}}
{"id": "2509.12282", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12282", "abs": "https://arxiv.org/abs/2509.12282", "authors": ["Sasi Kiran Gaddipati", "Farhana Keya", "Gollam Rabby", "S\u00f6ren Auer"], "title": "AIssistant: An Agentic Approach for Human--AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning", "comment": null, "summary": "Advances in AI-assisted research have introduced powerful tools for\nliterature retrieval, hypothesis generation, experimentation, and manuscript\npreparation. However, systems remain fragmented and lack human-centred\nworkflows. To address these gaps, we introduce AIssistant, an agentic,\nopen-source Human-AI collaborative framework designed to simplify the\nend-to-end creation of scientific workflows. Since our development is still in\nan early stage, we present here the first experiments with AIssistant for\nperspective and review research papers in machine learning. Our system\nintegrates modular tools and agents for literature synthesis, section-wise\nexperimentation, citation management, and automatic LaTeX paper text\ngeneration, while maintaining human oversight at every stage to ensure\naccuracy, coherence, and scholarly rigour. We conducted a comprehensive\nevaluation across three layers: (1) Independent Human Review, following NeurIPS\ndouble-blind standards; (2) Automated LLM Review, using GPT-5 as a scalable\nhuman review proxy; and (3) Program Chair Oversight, where the chair monitors\nthe entire review process and makes final validation and acceptance decisions.\nThe results demonstrate that AIssistant improves drafting efficiency and\nthematic consistency. Nonetheless, Human-AI collaboration remains essential for\nmaintaining factual correctness, methodological soundness, and ethical\ncompliance. Despite its effectiveness, we identify key limitations, including\nhallucinated citations, difficulty adapting to dynamic paper structures, and\nincomplete integration of multimodal content.", "AI": {"tldr": "AIssistant\uff0c\u4e00\u4e2a\u7528\u4e8e\u8f85\u52a9\u79d1\u5b66\u7814\u7a76\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u8bba\u6587\u64b0\u5199\u6548\u7387\u548c\u4e3b\u9898\u4e00\u81f4\u6027\uff0c\u4f46\u4ecd\u9700\u4eba\u5de5\u76d1\u7763\u4ee5\u4fdd\u8bc1\u51c6\u786e\u6027\u548c\u5408\u89c4\u6027\u3002", "motivation": "\u73b0\u6709AI\u8f85\u52a9\u7814\u7a76\u5de5\u5177\u5206\u6563\u4e14\u7f3a\u4e4f\u4ee5\u4eba\u4e3a\u672c\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0cAIssistant\u65e8\u5728\u7b80\u5316\u7aef\u5230\u7aef\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u7684\u521b\u5efa\u3002", "method": "\u6574\u5408\u6a21\u5757\u5316\u5de5\u5177\u548c\u4ee3\u7406\uff0c\u6db5\u76d6\u6587\u732e\u7efc\u8ff0\u3001\u5206\u6bb5\u5b9e\u9a8c\u3001\u6587\u732e\u7ba1\u7406\u548cLaTeX\u8bba\u6587\u6587\u672c\u81ea\u52a8\u751f\u6210\u7b49\uff0c\u5e76\u8fdb\u884c\u591a\u5c42\u8bc4\u4f30\uff08\u4eba\u5de5\u8bc4\u5ba1\u3001LLM\u8bc4\u5ba1\u548c\u7a0b\u5e8f\u4e3b\u5e2d\u76d1\u7763\uff09\u3002", "result": "AIssistant\u63d0\u9ad8\u4e86\u8bba\u6587\u64b0\u5199\u6548\u7387\u548c\u4e3b\u9898\u4e00\u81f4\u6027\uff0c\u4f46\u5b58\u5728\u865a\u6784\u5f15\u7528\u3001\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u8bba\u6587\u7ed3\u6784\u548c\u591a\u6a21\u6001\u5185\u5bb9\u6574\u5408\u4e0d\u5b8c\u6574\u7b49\u5c40\u9650\u6027\u3002", "conclusion": "AIssistant\u5c55\u73b0\u4e86AI\u8f85\u52a9\u79d1\u5b66\u7814\u7a76\u7684\u6f5c\u529b\uff0c\u4f46\u4eba\u673a\u534f\u4f5c\u5bf9\u4e8e\u4fdd\u8bc1\u51c6\u786e\u6027\u3001\u65b9\u6cd5\u8bba\u7684\u5408\u7406\u6027\u548c\u4f26\u7406\u5408\u89c4\u6027\u4ecd\u7136\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.12423", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.12423", "abs": "https://arxiv.org/abs/2509.12423", "authors": ["Danielle Cohen", "Yoni Halpern", "Noam Kahlon", "Joel Oren", "Omri Berkovitch", "Sapir Caduri", "Ido Dagan", "Anatoly Efros"], "title": "Small Models, Big Results: Achieving Superior Intent Extraction through Decomposition", "comment": null, "summary": "Understanding user intents from UI interaction trajectories remains a\nchallenging, yet crucial, frontier in intelligent agent development. While\nmassive, datacenter-based, multi-modal large language models (MLLMs) possess\ngreater capacity to handle the complexities of such sequences, smaller models\nwhich can run on-device to provide a privacy-preserving, low-cost, and\nlow-latency user experience, struggle with accurate intent inference. We\naddress these limitations by introducing a novel decomposed approach: first, we\nperform structured interaction summarization, capturing key information from\neach user action. Second, we perform intent extraction using a fine-tuned model\noperating on the aggregated summaries. This method improves intent\nunderstanding in resource-constrained models, even surpassing the base\nperformance of large MLLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5206\u89e3\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u7528\u6237\u4ea4\u4e92\u8f68\u8ff9\u4e2d\u7406\u89e3\u7528\u6237\u610f\u56fe\uff0c\u8be5\u65b9\u6cd5\u5728\u8d44\u6e90\u53d7\u9650\u7684\u6a21\u578b\u4e2d\u63d0\u9ad8\u4e86\u610f\u56fe\u7406\u89e3\u80fd\u529b\uff0c\u751a\u81f3\u8d85\u8fc7\u5927\u578bMLLMs\u7684\u57fa\u51c6\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b(MLLMs)\u5728\u5904\u7406\u7528\u6237\u4ea4\u4e92\u8f68\u8ff9\u65f6\u9762\u4e34\u7684\u9690\u79c1\u3001\u6210\u672c\u548c\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u9996\u5148\u8fdb\u884c\u7ed3\u6784\u5316\u4ea4\u4e92\u603b\u7ed3\uff0c\u6355\u6349\u6bcf\u4e2a\u7528\u6237\u64cd\u4f5c\u7684\u5173\u952e\u4fe1\u606f\uff1b\u7136\u540e\u4f7f\u7528\u5fae\u8c03\u6a21\u578b\u5bf9\u805a\u5408\u7684\u6458\u8981\u8fdb\u884c\u610f\u56fe\u63d0\u53d6\u3002", "result": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u6a21\u578b\u4e2d\u63d0\u9ad8\u4e86\u610f\u56fe\u7406\u89e3\u80fd\u529b\uff0c\u751a\u81f3\u8d85\u8fc7\u5927\u578bMLLMs\u7684\u57fa\u51c6\u6027\u80fd\u3002", "conclusion": "\u8be5\u5206\u89e3\u65b9\u6cd5\u4e3a\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8bbe\u5907\u4e0a\u8fdb\u884c\u51c6\u786e\u7684\u610f\u56fe\u63a8\u65ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.12434", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12434", "abs": "https://arxiv.org/abs/2509.12434", "authors": ["Jiahao Yu", "Zelei Cheng", "Xian Wu", "Xinyu Xing"], "title": "Building Coding Agents via Entropy-Enhanced Multi-Turn Preference Optimization", "comment": null, "summary": "Software engineering presents complex, multi-step challenges for Large\nLanguage Models (LLMs), requiring reasoning over large codebases and\ncoordinated tool use. The difficulty of these tasks is exemplified by\nbenchmarks like SWE-bench, where current LLMs still struggle to resolve\nreal-world issues.\n  A promising approach to enhance performance is test-time scaling (TTS), but\nits gains are heavily dependent on the diversity of model outputs.\n  While standard alignment methods such as Direct Preference Optimization (DPO)\nand Kahneman-Tversky Optimization (KTO) are effective at aligning model outputs\nwith human preferences, this process can come at the cost of reduced diversity,\nlimiting the effectiveness of TTS.\n  Additionally, existing preference optimization algorithms are typically\ndesigned for single-turn tasks and do not fully address the complexities of\nmulti-turn reasoning and tool integration required for interactive coding\nagents.\n  To bridge this gap, we introduce \\sys, an entropy-enhanced framework that\nadapts existing preference optimization algorithms to the multi-turn,\ntool-assisted setting.\n  \\sys augments the preference objective to explicitly preserve policy entropy\nand generalizes learning to optimize over multi-turn interactions rather than\nsingle-turn responses.\n  We validate \\sys by fine-tuning a diverse suite of models from different\nfamilies and sizes (up to 106B parameters).\n  To maximize performance gains from TTS, we further propose a hybrid\nbest-trajectory selection scheme combining a learned verifier model with model\nfree approaches.\n  On the \\swebench leaderboard, our approach establishes new state-of-the-art\nresults among open-weight models. A 30B parameter model trained with \\sys ranks\n1st on \\lite and 4th on \\verified on the open-weight leaderboard, surpassed\nonly by models with over 10x more parameters(\\eg$>$350B).", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\\sys\u7684\u71b5\u589e\u5f3a\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6539\u8fdb\u4e86\u73b0\u6709\u7684\u504f\u597d\u4f18\u5316\u7b97\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u5728SWE-bench\u6392\u884c\u699c\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u89e3\u51b3\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u590d\u6742\u95ee\u9898\uff0c\u6d4b\u8bd5\u65f6\u7f29\u653e(TTS)\u7684\u6709\u6548\u6027\u4f9d\u8d56\u4e8e\u6a21\u578b\u8f93\u51fa\u7684\u591a\u6837\u6027\uff0c\u800c\u6807\u51c6\u7684\u5bf9\u9f50\u65b9\u6cd5\u4f1a\u964d\u4f4e\u591a\u6837\u6027\uff0c\u9650\u5236TTS\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u71b5\u589e\u5f3a\u6846\u67b6\\sys\uff0c\u8be5\u6846\u67b6\u589e\u5f3a\u4e86\u504f\u597d\u76ee\u6807\u4ee5\u660e\u786e\u4fdd\u7559\u7b56\u7565\u71b5\uff0c\u5e76\u5c06\u5b66\u4e60\u63a8\u5e7f\u5230\u591a\u8f6e\u4ea4\u4e92\u7684\u4f18\u5316\u3002\u7ed3\u5408\u5b66\u4e60\u9a8c\u8bc1\u6a21\u578b\u548c\u65e0\u6a21\u578b\u65b9\u6cd5\u7684\u6df7\u5408\u6700\u4f73\u8f68\u8ff9\u9009\u62e9\u65b9\u6848\u3002", "result": "\u5728SWE-bench\u6392\u884c\u699c\u7684\u5f00\u653e\u6743\u91cd\u6a21\u578b\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u4e00\u4e2a300\u4ebf\u53c2\u6570\u7684\u6a21\u578b\u5728\\lite\u4e0a\u6392\u540d\u7b2c\u4e00\uff0c\u5728\\verified\u4e0a\u6392\u540d\u7b2c\u56db\uff0c\u4f18\u4e8e\u5927\u591a\u6570\u53c2\u6570\u89c4\u6a21\u66f4\u5927\u7684\u6a21\u578b\u3002", "conclusion": "\\sys\u6846\u67b6\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2509.12437", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12437", "abs": "https://arxiv.org/abs/2509.12437", "authors": ["Dingrui Wang", "Zhexiao Sun", "Zhouheng Li", "Cheng Wang", "Youlun Peng", "Hongyuan Ye", "Baha Zarrouki", "Wei Li", "Mattia Piccinini", "Lei Xie", "Johannes Betz"], "title": "Enhancing Physical Consistency in Lightweight World Models", "comment": "8 pages", "summary": "A major challenge in deploying world models is the trade-off between size and\nperformance. Large world models can capture rich physical dynamics but require\nmassive computing resources, making them impractical for edge devices. Small\nworld models are easier to deploy but often struggle to learn accurate physics,\nleading to poor predictions. We propose the Physics-Informed BEV World Model\n(PIWM), a compact model designed to efficiently capture physical interactions\nin bird's-eye-view (BEV) representations. PIWM uses Soft Mask during training\nto improve dynamic object modeling and future prediction. We also introduce a\nsimple yet effective technique, Warm Start, for inference to enhance prediction\nquality with a zero-shot model. Experiments show that at the same parameter\nscale (400M), PIWM surpasses the baseline by 60.6% in weighted overall score.\nMoreover, even when compared with the largest baseline model (400M), the\nsmallest PIWM (130M Soft Mask) achieves a 7.4% higher weighted overall score\nwith a 28% faster inference speed.", "AI": {"tldr": "PIWM\u6a21\u578b\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c0f\u4e86\u4e16\u754c\u6a21\u578b\u7684\u89c4\u6a21\uff0c\u5e76\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u4e16\u754c\u6a21\u578b\u5728\u89c4\u6a21\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7d27\u51d1\u7684\u7269\u7406\u4fe1\u606f\u9e1f\u77b0\u56fe\u4e16\u754c\u6a21\u578b(PIWM)\uff0c\u4f7f\u7528Soft Mask\u6539\u8fdb\u52a8\u6001\u76ee\u6807\u5efa\u6a21\u548c\u672a\u6765\u9884\u6d4b\uff0c\u5e76\u5f15\u5165Warm Start\u6280\u672f\u63d0\u9ad8\u63a8\u7406\u8d28\u91cf\u3002", "result": "\u5728\u76f8\u540c\u53c2\u6570\u89c4\u6a21\u4e0b\uff0cPIWM\u8d85\u8d8a\u57fa\u7ebf60.6%\uff1b\u5373\u4f7f\u4e0e\u6700\u5927\u7684\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0c\u6700\u5c0f\u7684PIWM\u6a21\u578b(130M Soft Mask)\u4e5f\u53d6\u5f97\u4e867.4%\u7684\u6027\u80fd\u63d0\u5347\u548c28%\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "PIWM\u6a21\u578b\u6709\u6548\u5730\u89e3\u51b3\u4e86\u4e16\u754c\u6a21\u578b\u7684\u89c4\u6a21\u4e0e\u6027\u80fd\u95ee\u9898\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.12464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12464", "abs": "https://arxiv.org/abs/2509.12464", "authors": ["Ryan Lucas", "Kayhan Behdin", "Zhipeng Wang", "Qingquan Song", "Shao Tang", "Rahul Mazumder"], "title": "Reasoning Models Can be Accurately Pruned Via Chain-of-Thought Reconstruction", "comment": null, "summary": "Reasoning language models such as DeepSeek-R1 produce long chain-of-thought\ntraces during inference time which make them costly to deploy at scale. We show\nthat using compression techniques such as neural network pruning produces\ngreater performance loss than in typical language modeling tasks, and in some\ncases can make the model slower since they cause the model to produce more\nthinking tokens but with worse performance. We show that this is partly due to\nthe fact that standard LLM pruning methods often focus on input reconstruction,\nwhereas reasoning is a decode-dominated task. We introduce a simple, drop-in\nfix: during pruning we jointly reconstruct activations from the input and the\nmodel's on-policy chain-of-thought traces. This \"Reasoning-Aware Compression\"\n(RAC) integrates seamlessly into existing pruning workflows such as SparseGPT,\nand boosts their performance significantly. Code reproducing the results in the\npaper can be found at: https://github.com/RyanLucas3/RAC", "AI": {"tldr": "\u9488\u5bf9\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\u95f4\u957f\u7684\u95ee\u9898\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u63a8\u7406\u611f\u77e5\u538b\u7f29\u65b9\u6cd5RAC\uff0c\u901a\u8fc7\u8054\u5408\u91cd\u5efa\u8f93\u5165\u548c\u6a21\u578b\u7684\u94fe\u5f0f\u601d\u8003\u8f68\u8ff9\u6765\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u5728SparseGPT\u7b49\u73b0\u6709\u526a\u679d\u65b9\u6cd5\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u65f6\u95f4\u957f\uff0c\u90e8\u7f72\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u63a8\u7406\u611f\u77e5\u538b\u7f29(RAC)\u65b9\u6cd5\uff0c\u8054\u5408\u91cd\u5efa\u8f93\u5165\u548c\u6a21\u578b\u94fe\u5f0f\u601d\u8003\u8f68\u8ff9\u8fdb\u884c\u6a21\u578b\u526a\u679d\u3002", "result": "RAC\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709\u526a\u679d\u65b9\u6cd5(\u5982SparseGPT)\u7684\u6027\u80fd\u3002", "conclusion": "RAC\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\u95f4\u957f\u7684\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u90e8\u7f72\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2509.12471", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12471", "abs": "https://arxiv.org/abs/2509.12471", "authors": ["Yiwen Lu", "Lu Li", "Dazheng Zhang", "Xinyao Jian", "Tingyin Wang", "Siqi Chen", "Yuqing Lei", "Jiayi Tong", "Zhaohan Xi", "Haitao Chu", "Chongliang Luo", "Alexis Ogdie", "Brian Athey", "Alparslan Turan", "Michael Abramoff", "Joseph C Cappelleri", "Hua Xu", "Yun Lu", "Jesse Berlin", "Daniel I. Sessler", "David A. Asch", "Xiaoqian Jiang", "Yong Chen"], "title": "Empowering Clinical Trial Design through AI: A Randomized Evaluation of PowerGPT", "comment": null, "summary": "Sample size calculations for power analysis are critical for clinical\nresearch and trial design, yet their complexity and reliance on statistical\nexpertise create barriers for many researchers. We introduce PowerGPT, an\nAI-powered system integrating large language models (LLMs) with statistical\nengines to automate test selection and sample size estimation in trial design.\nIn a randomized trial to evaluate its effectiveness, PowerGPT significantly\nimproved task completion rates (99.3% vs. 88.9% for test selection, 99.3% vs.\n77.8% for sample size calculation) and accuracy (94.1% vs. 55.4% in sample size\nestimation, p < 0.001), while reducing average completion time (4.0 vs. 9.3\nminutes, p < 0.001). These gains were consistent across various statistical\ntests and benefited both statisticians and non-statisticians as well as\nbridging expertise gaps. Already under deployment across multiple institutions,\nPowerGPT represents a scalable AI-driven approach that enhances accessibility,\nefficiency, and accuracy in statistical power analysis for clinical research.", "AI": {"tldr": "PowerGPT\u662f\u4e00\u4e2aAI\u7cfb\u7edf\uff0c\u80fd\u81ea\u52a8\u5316\u4e34\u5e8a\u8bd5\u9a8c\u8bbe\u8ba1\u4e2d\u7684\u68c0\u9a8c\u9009\u62e9\u548c\u6837\u672c\u91cf\u4f30\u8ba1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6837\u672c\u91cf\u8ba1\u7b97\u65b9\u6cd5\u590d\u6742\u4e14\u4f9d\u8d56\u7edf\u8ba1\u4e13\u4e1a\u77e5\u8bc6\uff0c\u963b\u788d\u4e86\u8bb8\u591a\u7814\u7a76\u4eba\u5458\u3002", "method": "\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u7edf\u8ba1\u5f15\u64ce\u96c6\u6210\uff0c\u81ea\u52a8\u5316\u6d4b\u8bd5\u9009\u62e9\u548c\u6837\u672c\u91cf\u4f30\u8ba1\u3002", "result": "PowerGPT\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u5e73\u5747\u5b8c\u6210\u65f6\u95f4\uff0c\u5bf9\u7edf\u8ba1\u5b66\u5bb6\u548c\u975e\u7edf\u8ba1\u5b66\u5bb6\u90fd\u6709\u76ca\u3002", "conclusion": "PowerGPT\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684AI\u9a71\u52a8\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u4e34\u5e8a\u7814\u7a76\u4e2d\u7edf\u8ba1\u529f\u6548\u5206\u6790\u7684\u53ef\u53ca\u6027\u3001\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2509.12495", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.12495", "abs": "https://arxiv.org/abs/2509.12495", "authors": ["G\u00fclce Karde\u015f", "David Krakauer", "Joshua Grochow"], "title": "Physical Complexity of a Cognitive Artifact", "comment": null, "summary": "Cognitive science and theoretical computer science both seek to classify and\nexplain the difficulty of tasks. Mechanisms of intelligence are those that\nreduce task difficulty. Here we map concepts from the computational complexity\nof a physical puzzle, the Soma Cube, onto cognitive problem-solving strategies\nthrough a ``Principle of Materiality''. By analyzing the puzzle's branching\nfactor, measured through search tree outdegree, we quantitatively assess task\ndifficulty and systematically examine how different strategies modify\ncomplexity. We incrementally refine a trial-and-error search by layering\npreprocessing (cognitive chunking), value ordering (cognitive free-sorting),\nvariable ordering (cognitive scaffolding), and pruning (cognitive inference).\nWe discuss how the competent use of artifacts reduces effective time complexity\nby exploiting physical constraints and propose a model of intelligence as a\nlibrary of algorithms that recruit the capabilities of both mind and matter.", "AI": {"tldr": "\u672c\u6587\u91cf\u5316\u8bc4\u4f30\u4e86\u4e03\u5de7\u677f\u7684\u96be\u5ea6\uff0c\u5e76\u7814\u7a76\u4e86\u4e0d\u540c\u7b56\u7565\u5982\u4f55\u6539\u53d8\u5176\u590d\u6742\u6027\u3002", "motivation": "\u8ba4\u77e5\u79d1\u5b66\u548c\u7406\u8bba\u8ba1\u7b97\u673a\u79d1\u5b66\u90fd\u8bd5\u56fe\u5bf9\u4efb\u52a1\u7684\u96be\u5ea6\u8fdb\u884c\u5206\u7c7b\u548c\u89e3\u91ca\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e03\u5de7\u677f\u641c\u7d22\u6811\u7684\u5ea6\u6765\u91cf\u5316\u8bc4\u4f30\u4efb\u52a1\u96be\u5ea6\uff0c\u5e76\u9010\u6b65\u6539\u8fdb\u8bd5\u9519\u641c\u7d22\uff0c\u52a0\u5165\u9884\u5904\u7406\u3001\u503c\u6392\u5e8f\u3001\u53d8\u91cf\u6392\u5e8f\u548c\u526a\u679d\u7b49\u7b56\u7565\u3002", "result": "\u4e0d\u540c\u7b56\u7565\u7684\u8fd0\u7528\u964d\u4f4e\u4e86\u4e03\u5de7\u677f\u7684\u6709\u6548\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u667a\u80fd\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u662f\u7b97\u6cd5\u5e93\uff0c\u5b83\u5229\u7528\u4e86\u601d\u7ef4\u548c\u7269\u8d28\u7684\u80fd\u529b\u3002"}}
{"id": "2509.12524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12524", "abs": "https://arxiv.org/abs/2509.12524", "authors": ["Rohit Chakraborty", "Subasish Das"], "title": "A Dimensionality-Reduced XAI Framework for Roundabout Crash Severity Insights", "comment": "This is the author's preprint version of a paper accepted for\n  presentation at HICSS 59 (Hawaii International Conference on System\n  Sciences), 2026, Hawaii, USA. The final published version will appear in the\n  official conference proceedings. Conference site: https://hicss.hawaii.edu/", "summary": "Roundabouts reduce severe crashes, yet risk patterns vary by conditions. This\nstudy analyzes 2017-2021 Ohio roundabout crashes using a two-step, explainable\nworkflow. Cluster Correspondence Analysis (CCA) identifies co-occurring factors\nand yields four crash patterns. A tree-based severity model is then interpreted\nwith SHAP to quantify drivers of injury within and across patterns. Results\nshow higher severity when darkness, wet surfaces, and higher posted speeds\ncoincide with fixed-object or angle events, and lower severity in clear,\nlow-speed settings. Pattern-specific explanations highlight mechanisms at\nentries (fail-to-yield, gap acceptance), within multi-lane circulation\n(improper maneuvers), and during slow-downs (rear-end). The workflow links\npattern discovery with case-level explanations, supporting site screening,\ncountermeasure selection, and audit-ready reporting. The contribution to\nInformation Systems is a practical template for usable XAI in public safety\nanalytics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u4fc4\u4ea5\u4fc4\u5dde2017-2021\u5e74\u73af\u5c9b\u4e8b\u6545\uff0c\u53d1\u73b0\u9ed1\u6697\u3001\u6e7f\u6ed1\u8def\u9762\u548c\u9ad8\u9650\u901f\u4e0e\u56fa\u5b9a\u7269\u6216\u89d2\u5ea6\u78b0\u649e\u4e8b\u4ef6\u540c\u65f6\u53d1\u751f\u65f6\uff0c\u4e8b\u6545\u4e25\u91cd\u7a0b\u5ea6\u66f4\u9ad8\uff1b\u5728\u6e05\u6670\u3001\u4f4e\u901f\u73af\u5883\u4e0b\uff0c\u4e8b\u6545\u4e25\u91cd\u7a0b\u5ea6\u8f83\u4f4e\u3002", "motivation": "\u73af\u5c9b\u867d\u7136\u51cf\u5c11\u4e86\u4e25\u91cd\u4e8b\u6545\uff0c\u4f46\u98ce\u9669\u6a21\u5f0f\u968f\u6761\u4ef6\u53d8\u5316\u800c\u5f02\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u53ef\u89e3\u91ca\u5de5\u4f5c\u6d41\u7a0b\uff1a1. \u8fd0\u7528\u805a\u7c7b\u5bf9\u5e94\u5206\u6790(CCA)\u8bc6\u522b\u5171\u73b0\u56e0\u7d20\uff0c\u5f97\u5230\u56db\u79cd\u4e8b\u6545\u6a21\u5f0f\uff1b2. \u4f7f\u7528\u57fa\u4e8e\u6811\u7684\u4e25\u91cd\u7a0b\u5ea6\u6a21\u578b\u548cSHAP\u65b9\u6cd5\u91cf\u5316\u6a21\u5f0f\u5185\u5916\u7684\u635f\u4f24\u9a71\u52a8\u56e0\u7d20\u3002", "result": "\u53d1\u73b0\u9ed1\u6697\u3001\u6e7f\u6ed1\u8def\u9762\u548c\u9ad8\u9650\u901f\u4e0e\u56fa\u5b9a\u7269\u6216\u89d2\u5ea6\u78b0\u649e\u4e8b\u4ef6\u540c\u65f6\u53d1\u751f\u65f6\uff0c\u4e8b\u6545\u4e25\u91cd\u7a0b\u5ea6\u66f4\u9ad8\uff1b\u5728\u6e05\u6670\u3001\u4f4e\u901f\u73af\u5883\u4e0b\uff0c\u4e8b\u6545\u4e25\u91cd\u7a0b\u5ea6\u8f83\u4f4e\u3002\u4e0d\u540c\u6a21\u5f0f\u4e0b\uff0c\u4e8b\u6545\u539f\u56e0\u5206\u522b\u4e0e\u5165\u53e3\u5904\u7684\u8ba9\u884c\u5931\u8d25\u3001\u591a\u8f66\u9053\u73af\u5c9b\u5185\u7684\u4e0d\u5f53\u64cd\u4f5c\u4ee5\u53ca\u51cf\u901f\u8fc7\u7a0b\u4e2d\u7684\u8ffd\u5c3e\u6709\u5173\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6d41\u7a0b\u5c06\u6a21\u5f0f\u53d1\u73b0\u4e0e\u6848\u4f8b\u7ea7\u89e3\u91ca\u76f8\u7ed3\u5408\uff0c\u53ef\u7528\u4e8e\u573a\u5730\u7b5b\u9009\u3001\u5bf9\u7b56\u9009\u62e9\u548c\u5ba1\u8ba1\u62a5\u544a\u3002\u4e3a\u516c\u5171\u5b89\u5168\u5206\u6790\u4e2d\u7684\u53ef\u7528XAI\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u6a21\u677f\u3002"}}
{"id": "2509.12541", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12541", "abs": "https://arxiv.org/abs/2509.12541", "authors": ["Nicholas Pipitone", "Ghita Houir Alami", "Advaith Avadhanam", "Anton Kaminskyi", "Ashley Khoo"], "title": "zELO: ELO-inspired Training Method for Rerankers and Embedding Models", "comment": "13 pages, 9 sections, 17 figures and tables", "summary": "We introduce a novel training methodology named zELO, which optimizes\nretrieval performance via the analysis that ranking tasks are statically\nequivalent to a Thurstone model. Based on the zELO method, we use unsupervised\ndata in order train a suite of state-of-the-art open-weight reranker models:\nzerank-1 and zerank-1-small. These models achieve the highest retrieval scores\nin multiple domains, including finance, legal, code, and STEM, outperforming\nclosed-source proprietary rerankers on both NDCG@10 and Recall. These models\nalso demonstrate great versatility, maintaining their 0-shot performance on\nout-of-domain and private customer datasets. The training data included 112,000\nqueries and 100 documents per query, and was trained end-to-end from\nunannotated queries and documents in less than 10,000 H100-hours.", "AI": {"tldr": "zELO\u65b9\u6cd5\u4f18\u5316\u68c0\u7d22\u6027\u80fd\uff0c\u8bad\u7ec3\u51fazerank-1\u548czerank-1-small\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u9886\u57df\u8d85\u8d8a\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u63d0\u5347\u68c0\u7d22\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u591a\u4e2a\u9886\u57df\u76840-shot\u6027\u80fd\u3002", "method": "\u57fa\u4e8eThurstone\u6a21\u578b\u7684zELO\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u7528\u65e0\u76d1\u7763\u6570\u636e\u8bad\u7ec3\u3002", "result": "\u5728\u91d1\u878d\u3001\u6cd5\u5f8b\u3001\u4ee3\u7801\u548cSTEM\u9886\u57df\uff0czerank\u6a21\u578b\u5728NDCG@10\u548cRecall\u4e0a\u8d85\u8d8a\u95ed\u6e90reranker\uff0c\u5e76\u5728\u8de8\u9886\u57df\u548c\u79c1\u6709\u6570\u636e\u96c6\u4e0a\u4fdd\u63010-shot\u6027\u80fd\u3002", "conclusion": "zELO\u65b9\u6cd5\u6709\u6548\uff0c\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u6027\u80fd\u4f18\u5f02\u4e14\u5177\u6709\u901a\u7528\u6027\u3002"}}
{"id": "2509.12543", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12543", "abs": "https://arxiv.org/abs/2509.12543", "authors": ["Harshit Rajgarhia", "Shivali Dalmia", "Mengyang Zhao", "Mukherji Abhishek", "Kiran Ganesh"], "title": "Human + AI for Accelerating Ad Localization Evaluation", "comment": null, "summary": "Adapting advertisements for multilingual audiences requires more than simple\ntext translation; it demands preservation of visual consistency, spatial\nalignment, and stylistic integrity across diverse languages and formats. We\nintroduce a structured framework that combines automated components with human\noversight to address the complexities of advertisement localization. To the\nbest of our knowledge, this is the first work to integrate scene text\ndetection, inpainting, machine translation (MT), and text reimposition\nspecifically for accelerating ad localization evaluation workflows. Qualitative\nresults across six locales demonstrate that our approach produces semantically\naccurate and visually coherent localized advertisements, suitable for\ndeployment in real-world workflows.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u81ea\u52a8\u5316\u7ec4\u4ef6\u548c\u4eba\u5de5\u76d1\u7763\u7684\u5e7f\u544a\u672c\u5730\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u573a\u666f\u6587\u672c\u68c0\u6d4b\u3001\u4fee\u590d\u3001\u673a\u5668\u7ffb\u8bd1\u548c\u6587\u672c\u91cd\u6392\uff0c\u63d0\u9ad8\u5e7f\u544a\u672c\u5730\u5316\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5e7f\u544a\u591a\u8bed\u8a00\u9002\u914d\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\u89c6\u89c9\u4e00\u81f4\u6027\u548c\u8bed\u8a00\u51c6\u786e\u6027\u3002", "method": "\u8be5\u6846\u67b6\u96c6\u6210\u573a\u666f\u6587\u672c\u68c0\u6d4b\u3001\u56fe\u50cf\u4fee\u590d\u3001\u673a\u5668\u7ffb\u8bd1\u548c\u6587\u672c\u91cd\u6392\u6280\u672f\uff0c\u5e76\u7ed3\u5408\u4eba\u5de5\u5ba1\u6838\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u8bed\u4e49\u51c6\u786e\u3001\u89c6\u89c9\u4e00\u81f4\u7684\u672c\u5730\u5316\u5e7f\u544a\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86\u5e7f\u544a\u672c\u5730\u5316\u6548\u7387\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
