{"id": "2509.14251", "categories": ["cs.AI", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.14251", "abs": "https://arxiv.org/abs/2509.14251", "authors": ["Qihang Chen"], "title": "Unified Crew Planning and Replanning Optimization in Multi-Line Metro Systems Considering Workforce Heterogeneity", "comment": null, "summary": "Metro crew planning is a key component of smart city development as it\ndirectly impacts the operational efficiency and service reliability of public\ntransportation. With the rapid expansion of metro networks, effective\nmulti-line scheduling and emergency management have become essential for\nlarge-scale seamless operations. However, current research focuses primarily on\nindividual metro lines,with insufficient attention on cross-line coordination\nand rapid replanning during disruptions. Here, a unified optimization framework\nis presented for multi-line metro crew planning and replanning with\nheterogeneous workforce. Specifically, a hierarchical time-space network model\nis proposed to represent the unified crew action space, and computationally\nefficient constraints and formulations are derived for the crew's heterogeneous\nqualifications and preferences. Solution algorithms based on column generation\nand shortest path adjustment are further developed, utilizing the proposed\nnetwork model. Experiments with real data from Shanghai and Beijing Metro\ndemonstrate that the proposed methods outperform benchmark heuristics in both\ncost reduction and task completion,and achieve notable efficiency gains by\nincorporating cross-line operations, particularly for urgent tasks during\ndisruptions. This work highlights the role of global optimization and\ncross-line coordination in multi-line metro system operations, providing\ninsights into the efficient and reliable functioning of public transportation\nin smart cities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u7edf\u4e00\u7684\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u7ebf\u8def\u5730\u94c1\u4eba\u5458\u8ba1\u5212\u548c\u91cd\u65b0\u8ba1\u5212\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u57fa\u51c6\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u7ebf\u5730\u94c1\uff0c\u7f3a\u4e4f\u8de8\u7ebf\u534f\u8c03\u548c\u5feb\u901f\u91cd\u65b0\u8ba1\u5212\u80fd\u529b\uff0c\u8be5\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u65f6\u7a7a\u7f51\u7edc\u6a21\u578b\uff0c\u5e76\u57fa\u4e8e\u5217\u751f\u6210\u548c\u6700\u77ed\u8def\u5f84\u8c03\u6574\u7b97\u6cd5\u8fdb\u884c\u6c42\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6210\u672c\u964d\u4f4e\u548c\u4efb\u52a1\u5b8c\u6210\u65b9\u9762\u4f18\u4e8e\u57fa\u51c6\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5c24\u5176\u5728\u5e94\u5bf9\u4e2d\u65ad\u60c5\u51b5\u4e0b\u7684\u7d27\u6025\u4efb\u52a1\u65f6\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u8de8\u7ebf\u534f\u8c03\u548c\u5168\u5c40\u4f18\u5316\u5bf9\u4e8e\u591a\u7ebf\u8def\u5730\u94c1\u7cfb\u7edf\u8fd0\u884c\u81f3\u5173\u91cd\u8981\uff0c\u5bf9\u667a\u6167\u57ce\u5e02\u516c\u5171\u4ea4\u901a\u7684\u6709\u6548\u548c\u53ef\u9760\u8fd0\u884c\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2509.14289", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14289", "abs": "https://arxiv.org/abs/2509.14289", "authors": ["Lanxiao Huang", "Daksh Dave", "Ming Jin", "Tyler Cody", "Peter Beling"], "title": "From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing", "comment": null, "summary": "Large language models (LLMs) are increasingly used to automate or augment\npenetration testing, but their effectiveness and reliability across attack\nphases remain unclear. We present a comprehensive evaluation of multiple\nLLM-based agents, from single-agent to modular designs, across realistic\npenetration testing scenarios, measuring empirical performance and recurring\nfailure patterns. We also isolate the impact of five core functional\ncapabilities via targeted augmentations: Global Context Memory (GCM),\nInter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive\nPlanning (AP), and Real-Time Monitoring (RTM). These interventions support,\nrespectively: (i) context coherence and retention, (ii) inter-component\ncoordination and state management, (iii) tool use accuracy and selective\nexecution, (iv) multi-step strategic planning, error detection, and recovery,\nand (v) real-time dynamic responsiveness. Our results show that while some\narchitectures natively exhibit subsets of these properties, targeted\naugmentations substantially improve modular agent performance, especially in\ncomplex, multi-step, and real-time penetration testing tasks.", "AI": {"tldr": "LLM\u7528\u4e8e\u6e17\u900f\u6d4b\u8bd5\u7684\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\u4ecd\u4e0d\u660e\u786e\uff0c\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u591a\u79cdLLM\u4ee3\u7406\u5728\u73b0\u5b9e\u6e17\u900f\u6d4b\u8bd5\u573a\u666f\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u589e\u5f3a\u529f\u80fd\uff08GCM\u3001IAM\u3001CCI\u3001AP\u3001RTM\uff09\u63d0\u9ad8\u4e86\u6a21\u5757\u5316\u4ee3\u7406\u7684\u6027\u80fd\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u6e17\u900f\u6d4b\u8bd5\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\uff0c\u5e76\u6539\u8fdbLLM\u4ee3\u7406\u7684\u67b6\u6784\u548c\u529f\u80fd\u3002", "method": "\u5bf9\u591a\u79cdLLM\u4ee3\u7406\uff08\u5355\u4ee3\u7406\u5230\u6a21\u5757\u5316\u8bbe\u8ba1\uff09\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u4e94\u4e2a\u6838\u5fc3\u529f\u80fd\u589e\u5f3a\uff08GCM\u3001IAM\u3001CCI\u3001AP\u3001RTM\uff09\u6765\u9694\u79bb\u5176\u5f71\u54cd\u3002", "result": "\u5b9a\u5411\u589e\u5f3a\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u5757\u5316\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u3001\u591a\u6b65\u9aa4\u548c\u5b9e\u65f6\u6e17\u900f\u6d4b\u8bd5\u4efb\u52a1\u4e2d\u3002", "conclusion": "LLM\u5728\u6e17\u900f\u6d4b\u8bd5\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u6539\u8fdb\u5176\u67b6\u6784\u548c\u529f\u80fd\u4ee5\u63d0\u9ad8\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2509.14382", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14382", "abs": "https://arxiv.org/abs/2509.14382", "authors": ["Daniel R\u00f6der", "Akhil Juneja", "Roland Roller", "Sven Schmeier"], "title": "Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents", "comment": null, "summary": "Web agents powered by large language models (LLMs) can autonomously perform\ncomplex, multistep tasks in dynamic web environments. However, current\nevaluations mostly focus on the overall success while overlooking intermediate\nerrors. This limits insight into failure modes and hinders systematic\nimprovement. This work analyzes existing benchmarks and highlights the lack of\nfine-grained diagnostic tools. To address this gap, we propose a modular\nevaluation framework that decomposes agent pipelines into interpretable stages\nfor detailed error analysis. Using the SeeAct framework and the Mind2Web\ndataset as a case study, we show how this approach reveals actionable\nweaknesses missed by standard metrics - paving the way for more robust and\ngeneralizable web agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684Web\u667a\u80fd\u4f53\u7684\u884c\u4e3a\u8fdb\u884c\u7ec6\u7c92\u5ea6\u9519\u8bef\u5206\u6790\uff0c\u4ee5\u6539\u8fdb\u5176\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8Web\u667a\u80fd\u4f53\u7684\u6574\u4f53\u6210\u529f\u7387\uff0c\u5ffd\u7565\u4e86\u4e2d\u95f4\u9519\u8bef\uff0c\u5bfc\u81f4\u96be\u4ee5\u6df1\u5165\u4e86\u89e3\u5176\u5931\u6548\u6a21\u5f0f\u5e76\u8fdb\u884c\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u6d41\u7a0b\u5206\u89e3\u6210\u53ef\u89e3\u91ca\u7684\u9636\u6bb5\uff0c\u4ee5\u4fbf\u8fdb\u884c\u8be6\u7ec6\u7684\u9519\u8bef\u5206\u6790\u3002\u4ee5SeeAct\u6846\u67b6\u548cMind2Web\u6570\u636e\u96c6\u4e3a\u4f8b\u8fdb\u884c\u4e86\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u6807\u51c6\u6307\u6807\u65e0\u6cd5\u53d1\u73b0\u7684\u5b9e\u9645\u7f3a\u9677\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u548c\u901a\u7528\u7684Web\u667a\u80fd\u4f53\u94fa\u5e73\u4e86\u9053\u8def\u3002", "conclusion": "\u7ec6\u7c92\u5ea6\u7684\u9519\u8bef\u5206\u6790\u5bf9\u4e8e\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684Web\u667a\u80fd\u4f53\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.14448", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14448", "abs": "https://arxiv.org/abs/2509.14448", "authors": ["Rick Chen", "Joseph Ternasky", "Afriyie Samuel Kwesi", "Ben Griffin", "Aaron Ontoyin Yin", "Zakari Salifu", "Kelvin Amoaba", "Xianling Mu", "Fuat Alican", "Yigit Ihlamur"], "title": "VCBench: Benchmarking LLMs in Venture Capital", "comment": null, "summary": "Benchmarks such as SWE-bench and ARC-AGI demonstrate how shared datasets\naccelerate progress toward artificial general intelligence (AGI). We introduce\nVCBench, the first benchmark for predicting founder success in venture capital\n(VC), a domain where signals are sparse, outcomes are uncertain, and even top\ninvestors perform modestly. At inception, the market index achieves a precision\nof 1.9%. Y Combinator outperforms the index by a factor of 1.7x, while tier-1\nfirms are 2.9x better. VCBench provides 9,000 anonymized founder profiles,\nstandardized to preserve predictive features while resisting identity leakage,\nwith adversarial tests showing more than 90% reduction in re-identification\nrisk. We evaluate nine state-of-the-art large language models (LLMs).\nDeepSeek-V3 delivers over six times the baseline precision, GPT-4o achieves the\nhighest F0.5, and most models surpass human benchmarks. Designed as a public\nand evolving resource available at vcbench.com, VCBench establishes a\ncommunity-driven standard for reproducible and privacy-preserving evaluation of\nAGI in early-stage venture forecasting.", "AI": {"tldr": "VCBench\uff0c\u9996\u4e2a\u9884\u6d4b\u98ce\u9669\u6295\u8d44\u521b\u59cb\u4eba\u6210\u529f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u52a0\u901fAGI\u53d1\u5c55\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u98ce\u9669\u6295\u8d44\u9886\u57df\u7a00\u758f\u4fe1\u53f7\u3001\u4e0d\u786e\u5b9a\u7ed3\u679c\u7684\u57fa\u51c6\u3002", "method": "\u6784\u5efaVCBench\u6570\u636e\u96c6\uff089000\u4e2a\u533f\u540d\u521b\u59cb\u4eba\u6863\u6848\uff09\uff0c\u5e76\u8bc4\u4f30\u4e5d\u79cd\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u3002", "result": "DeepSeek-V3\u7cbe\u786e\u5ea6\u662f\u57fa\u7ebf\u7684\u516d\u500d\u591a\uff0cGPT-4o\u7684F0.5\u6700\u9ad8\uff0c\u5927\u591a\u6570\u6a21\u578b\u4f18\u4e8e\u4eba\u7c7b\u57fa\u51c6\u3002", "conclusion": "VCBench\u4e3a\u53ef\u91cd\u590d\u548c\u9690\u79c1\u4fdd\u62a4\u7684AGI\u65e9\u671f\u98ce\u9669\u9884\u6d4b\u8bc4\u4f30\u5efa\u7acb\u4e86\u793e\u533a\u9a71\u52a8\u7684\u6807\u51c6\u3002"}}
{"id": "2509.14474", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.14474", "abs": "https://arxiv.org/abs/2509.14474", "authors": ["Meltem Subasioglu", "Nevzat Subasioglu"], "title": "From Mimicry to True Intelligence (TI) -- A New Paradigm for Artificial General Intelligence", "comment": "27 pages, 1 figure", "summary": "The debate around Artificial General Intelligence (AGI) remains open due to\ntwo fundamentally different goals: replicating human-like performance versus\nreplicating human-like cognitive processes. We argue that current\nperformance-based definitions are inadequate because they provide no clear,\nmechanism-focused roadmap for research, and they fail to properly define the\nqualitative nature of genuine intelligence. Drawing inspiration from the human\nbrain, we propose a new paradigm that shifts the focus from external mimicry to\nthe development of foundational cognitive architectures. We define True\nIntelligence (TI) as a system characterized by six core components: embodied\nsensory fusion, core directives, dynamic schemata creation, a\nhighly-interconnected multi-expert architecture, an orchestration layer, and\nlastly, the unmeasurable quality of Interconnectedness, which we hypothesize\nresults in consciousness and a subjective experience. We propose a practical,\nfive-level taxonomy of AGI based on the number of the first five measurable\ncomponents a system exhibits. This framework provides a clear path forward with\ndevelopmental milestones that directly address the challenge of building\ngenuinely intelligent systems. We contend that once a system achieves Level-5\nAGI by implementing all five measurable components, the difference between it\nand TI remains as a purely philosophical debate. For practical purposes - and\ngiven theories indicate consciousness is an emergent byproduct of integrated,\nhigher-order cognition - we conclude that a fifth-level AGI is functionally and\npractically equivalent to TI. This work synthesizes diverse insights from\nanalytical psychology, schema theory, metacognition, modern brain architectures\nand latest works in AI to provide the first holistic, mechanism-based\ndefinition of AGI that offers a clear and actionable path for the research\ncommunity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u7c7b\u5927\u8111\u8ba4\u77e5\u67b6\u6784\u7684\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u65b0\u8303\u5f0f\uff0c\u5b9a\u4e49\u4e86\u201c\u771f\u667a\u80fd\u201d\uff08TI\uff09\u7684\u516d\u4e2a\u6838\u5fc3\u7ec4\u6210\u90e8\u5206\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e94\u7ea7AGI\u5206\u7c7b\u6cd5\uff0c\u4e3aAGI\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u8def\u7ebf\u56fe\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6027\u80fd\u7684AGI\u5b9a\u4e49\u4e0d\u8db3\u4ee5\u6307\u5bfc\u7814\u7a76\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5173\u6ce8\u8ba4\u77e5\u8fc7\u7a0b\u800c\u975e\u5916\u90e8\u8868\u73b0\u6765\u5b9a\u4e49AGI\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684AGI\u5b9a\u4e49\uff0c\u8be5\u5b9a\u4e49\u57fa\u4e8e\u4eba\u7c7b\u5927\u8111\u7684\u8ba4\u77e5\u67b6\u6784\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e94\u7ea7AGI\u5206\u7c7b\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u201c\u771f\u667a\u80fd\u201d\uff08TI\uff09\u7684\u6982\u5ff5\u53ca\u5176\u516d\u4e2a\u6838\u5fc3\u7ec4\u6210\u90e8\u5206\uff0c\u4ee5\u53ca\u4e00\u4e2a\u57fa\u4e8e\u8fd9\u4e94\u4e2a\u53ef\u8861\u91cf\u7ec4\u6210\u90e8\u5206\u7684\u4e94\u7ea7AGI\u5206\u7c7b\u6cd5\u3002", "conclusion": "\u4e94\u7ea7AGI\u5728\u529f\u80fd\u4e0a\u4e0eTI\u7b49\u6548\uff0c\u4e3aAGI\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u3001\u53ef\u64cd\u4f5c\u7684\u8def\u5f84\u3002"}}
{"id": "2509.14485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14485", "abs": "https://arxiv.org/abs/2509.14485", "authors": ["Marko Tesic", "Yue Zhao", "Joel Z. Leibo", "Rakshit S. Trivedi", "Jose Hernandez-Orallo"], "title": "Beyond the high score: Prosocial ability profiles of multi-agent populations", "comment": null, "summary": "The development and evaluation of social capabilities in AI agents require\ncomplex environments where competitive and cooperative behaviours naturally\nemerge. While game-theoretic properties can explain why certain teams or agent\npopulations outperform others, more abstract behaviours, such as convention\nfollowing, are harder to control in training and evaluation settings. The\nMelting Pot contest is a social AI evaluation suite designed to assess the\ncooperation capabilities of AI systems. In this paper, we apply a Bayesian\napproach known as Measurement Layouts to infer the capability profiles of\nmulti-agent systems in the Melting Pot contest. We show that these capability\nprofiles not only predict future performance within the Melting Pot suite but\nalso reveal the underlying prosocial abilities of agents. Our analysis\nindicates that while higher prosocial capabilities sometimes correlate with\nbetter performance, this is not a universal trend-some lower-scoring agents\nexhibit stronger cooperation abilities. Furthermore, we find that\ntop-performing contest submissions are more likely to achieve high scores in\nscenarios where prosocial capabilities are not required. These findings,\ntogether with reports that the contest winner used a hard-coded solution\ntailored to specific environments, suggest that at least one top-performing\nteam may have optimised for conditions where cooperation was not necessary,\npotentially exploiting limitations in the evaluation framework. We provide\nrecommendations for improving the annotation of cooperation demands and propose\nfuture research directions to account for biases introduced by different\ntesting environments. Our results demonstrate that Measurement Layouts offer\nboth strong predictive accuracy and actionable insights, contributing to a more\ntransparent and generalisable approach to evaluating AI systems in complex\nsocial settings.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u8d1d\u53f6\u65af\u65b9\u6cd5\u8bc4\u4f30\u4e86Melting Pot\u7ade\u8d5b\u4e2d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5408\u4f5c\u80fd\u529b\uff0c\u53d1\u73b0\u9ad8\u5408\u4f5c\u80fd\u529b\u5e76\u4e0d\u603b\u662f\u4e0e\u9ad8\u6027\u80fd\u76f8\u5173\uff0c\u9876\u7ea7\u53c2\u8d5b\u4f5c\u54c1\u53ef\u80fd\u5229\u7528\u4e86\u8bc4\u4f30\u6846\u67b6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u8bc4\u4f30AI\u667a\u80fd\u4f53\u7684\u793e\u4f1a\u80fd\u529b\u9700\u8981\u590d\u6742\u7684\u7ade\u4e89\u4e0e\u5408\u4f5c\u73af\u5883\uff0c\u800cMelting Pot\u7ade\u8d5b\u65e8\u5728\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u5408\u4f5c\u80fd\u529b\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u65b9\u6cd5\uff08Measurement Layouts\uff09\u63a8\u65ad\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728Melting Pot\u7ade\u8d5b\u4e2d\u7684\u80fd\u529b\u6982\u51b5\u3002", "result": "\u9ad8\u5408\u4f5c\u80fd\u529b\u4e0e\u9ad8\u6027\u80fd\u5e76\u975e\u603b\u662f\u6b63\u76f8\u5173\uff1b\u9876\u7ea7\u53c2\u8d5b\u4f5c\u54c1\u53ef\u80fd\u5728\u4e0d\u9700\u8981\u5408\u4f5c\u7684\u573a\u666f\u4e2d\u53d6\u5f97\u9ad8\u5206\uff0c\u8fd9\u66b4\u9732\u51fa\u8bc4\u4f30\u6846\u67b6\u7684\u5c40\u9650\u6027\u3002", "conclusion": "Measurement Layouts\u65b9\u6cd5\u5177\u6709\u8f83\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u64cd\u4f5c\u6027\uff0c\u4e3a\u5728\u590d\u6742\u793e\u4f1a\u73af\u5883\u4e2d\u8bc4\u4f30AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u900f\u660e\u548c\u66f4\u666e\u9002\u7684\u65b9\u6cd5\u3002\u5efa\u8bae\u6539\u8fdb\u5408\u4f5c\u9700\u6c42\u7684\u6807\u6ce8\uff0c\u5e76\u5bf9\u4e0d\u540c\u6d4b\u8bd5\u73af\u5883\u5f15\u5165\u7684\u504f\u5dee\u8fdb\u884c\u7814\u7a76\u3002"}}
{"id": "2509.14507", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.14507", "abs": "https://arxiv.org/abs/2509.14507", "authors": ["Jian Chen", "Zhenyan Chen", "Xuming Hu", "Peilin Zhou", "Yining Hua", "Han Fang", "Cissy Hing Yee Choy", "Xinmei Ke", "Jingfeng Luo", "Zixuan Yuan"], "title": "DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction", "comment": null, "summary": "Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that\nsimplifies database access for non-technical users by converting natural\nlanguage queries into SQL commands. Recent advancements, particularly those\nintegrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)\nreasoning, have made significant strides in enhancing NL2SQL performance.\nHowever, challenges such as inaccurate task decomposition and keyword\nextraction by LLMs remain major bottlenecks, often leading to errors in SQL\ngeneration. While existing datasets aim to mitigate these issues by fine-tuning\nmodels, they struggle with over-fragmentation of tasks and lack of\ndomain-specific keyword annotations, limiting their effectiveness. To address\nthese limitations, we present DeKeyNLU, a novel dataset which contains 1,500\nmeticulously annotated QA pairs aimed at refining task decomposition and\nenhancing keyword extraction precision for the RAG pipeline. Fine-tuned with\nDeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three\ndistinct modules for user question understanding, entity retrieval, and\ngeneration to improve SQL generation accuracy. We benchmarked multiple model\nconfigurations within DeKeySQL RAG pipeline. Experimental results demonstrate\nthat fine-tuning with DeKeyNLU significantly improves SQL generation accuracy\non both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.", "AI": {"tldr": "DeKeyNLU\u6570\u636e\u96c6\u548cDeKeySQL\u6a21\u578b\u63d0\u9ad8\u4e86NL2SQL\u7684\u51c6\u786e\u6027", "motivation": "\u73b0\u6709\u7684NL2SQL\u6a21\u578b\u5728\u4efb\u52a1\u5206\u89e3\u548c\u5173\u952e\u8bcd\u63d0\u53d6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3", "method": "\u6784\u5efaDeKeyNLU\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eRAG\u7684DeKeySQL\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a\u7528\u6237\u95ee\u9898\u7406\u89e3\u3001\u5b9e\u4f53\u68c0\u7d22\u548cSQL\u751f\u6210", "result": "\u5728BIRD\u548cSpider\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5206\u522b\u4ece62.31%\u63d0\u5347\u523069.10%\u548c\u4ece84.2%\u63d0\u5347\u523088.7%", "conclusion": "DeKeyNLU\u548cDeKeySQL\u6709\u6548\u63d0\u9ad8\u4e86NL2SQL\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411"}}
{"id": "2509.14546", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14546", "abs": "https://arxiv.org/abs/2509.14546", "authors": ["Zhilun Zhou", "Jing Yi Wang", "Nicholas Sukiennik", "Chen Gao", "Fengli Xu", "Yong Li", "James Evans"], "title": "Rationality Check! Benchmarking the Rationality of Large Language Models", "comment": null, "summary": "Large language models (LLMs), a recent advance in deep learning and machine\nintelligence, have manifested astonishing capacities, now considered among the\nmost promising for artificial general intelligence. With human-like\ncapabilities, LLMs have been used to simulate humans and serve as AI assistants\nacross many applications. As a result, great concern has arisen about whether\nand under what circumstances LLMs think and behave like real human agents.\nRationality is among the most important concepts in assessing human behavior,\nboth in thinking (i.e., theoretical rationality) and in taking action (i.e.,\npractical rationality). In this work, we propose the first benchmark for\nevaluating the omnibus rationality of LLMs, covering a wide range of domains\nand LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental\nresults, and analysis that illuminates where LLMs converge and diverge from\nidealized human rationality. We believe the benchmark can serve as a\nfoundational tool for both developers and users of LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7406\u6027\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u6db5\u76d6\u591a\u4e2a\u9886\u57df\u548c\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u5de5\u5177\u5305\u548c\u5b9e\u9a8c\u7ed3\u679c\u3002", "motivation": "\u8bc4\u4f30LLM\u662f\u5426\u4ee5\u53ca\u5728\u4f55\u79cd\u60c5\u51b5\u4e0b\u50cf\u4eba\u7c7b\u4e00\u6837\u601d\u8003\u548c\u884c\u52a8\uff0c\u7406\u6027\u662f\u5173\u952e\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6db5\u76d6\u5e7f\u6cdb\u9886\u57df\u7684LLM\u7406\u6027\u8bc4\u4f30\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u6613\u4e8e\u4f7f\u7528\u7684\u5de5\u5177\u5305\u548c\u5927\u91cf\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002", "result": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86LLM\u4e0e\u7406\u60f3\u5316\u4eba\u7c7b\u7406\u6027\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u548c\u5dee\u5f02\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u53ef\u4f5c\u4e3aLLM\u5f00\u53d1\u8005\u548c\u7528\u6237\u7684\u57fa\u7840\u5de5\u5177\u3002"}}
{"id": "2509.14547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14547", "abs": "https://arxiv.org/abs/2509.14547", "authors": ["Yi Lin", "Lujin Zhao", "Yijie Shi"], "title": "(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration", "comment": null, "summary": "Recent studies have shown that carefully designed workflows coordinating\nlarge language models(LLMs) significantly enhance task-solving capabilities\ncompared to using a single model. While an increasing number of works focus on\nautonomous workflow construction, most existing approaches rely solely on\nhistorical experience, leading to limitations in efficiency and adaptability.\nWe argue that while historical experience is valuable, workflow construction\nshould also flexibly respond to the unique characteristics of each task. To\nthis end, we propose an a priori dynamic framework for automated workflow\nconstruction. Our framework first leverages Q-table learning to optimize the\ndecision space, guiding agent decisions and enabling effective use of\nhistorical experience. At the same time, agents evaluate the current task\nprogress and make a priori decisions regarding the next executing agent,\nallowing the system to proactively select the more suitable workflow structure\nfor each given task. Additionally, we incorporate mechanisms such as cold-start\ninitialization, early stopping, and pruning to further improve system\nefficiency. Experimental evaluations on four benchmark datasets demonstrate the\nfeasibility and effectiveness of our approach. Compared to state-of-the-art\nbaselines, our method achieves an average improvement of 4.05%, while reducing\nworkflow construction and inference costs to only 30.68%-48.31% of those\nrequired by existing methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u6784\u5efa\u7684\u52a8\u6001\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408Q-table\u5b66\u4e60\u548c\u4efb\u52a1\u7279\u5f81\u8bc4\u4f30\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u9002\u5e94\u6027\uff0c\u5e76\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u5e73\u5747\u9ad84.05%\u7684\u6539\u8fdb\uff0c\u4e14\u6210\u672c\u66f4\u4f4e\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5386\u53f2\u7ecf\u9a8c\u6784\u5efa\u5de5\u4f5c\u6d41\uff0c\u6548\u7387\u548c\u9002\u5e94\u6027\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7075\u6d3b\u54cd\u5e94\u4efb\u52a1\u7279\u5f81\u7684\u6846\u67b6\u3002", "method": "\u8be5\u6846\u67b6\u5229\u7528Q-table\u5b66\u4e60\u4f18\u5316\u51b3\u7b56\u7a7a\u95f4\uff0c\u5e76\u6839\u636e\u5f53\u524d\u4efb\u52a1\u8fdb\u5ea6\u8fdb\u884c\u5148\u9a8c\u51b3\u7b56\uff0c\u9009\u62e9\u5408\u9002\u7684\u6267\u884cagent\u548c\u5de5\u4f5c\u6d41\u7ed3\u6784\uff0c\u540c\u65f6\u5305\u542b\u51b7\u542f\u52a8\u521d\u59cb\u5316\u3001\u63d0\u524d\u505c\u6b62\u548c\u526a\u679d\u7b49\u673a\u5236\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5e73\u5747\u63d0\u5347\u4e864.05%\uff0c\u4e14\u5de5\u4f5c\u6d41\u6784\u5efa\u548c\u63a8\u7406\u6210\u672c\u4ec5\u4e3a\u73b0\u6709\u65b9\u6cd5\u768430.68%-48.31%\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u52a8\u6001\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86LLMs\u5de5\u4f5c\u6d41\u6784\u5efa\u7684\u6548\u7387\u548c\u9002\u5e94\u6027\uff0c\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.14594", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14594", "abs": "https://arxiv.org/abs/2509.14594", "authors": ["Yidan Sun", "Viktor Schlegel", "Srinivasan Nandakumar", "Iqra Zahid", "Yuping Wu", "Yulong Wu", "Hao Li", "Jie Zhang", "Warren Del-Pinto", "Goran Nenadic", "Siew Kei Lam", "Anil Anthony Bharath"], "title": "SynBench: A Benchmark for Differentially Private Text Generation", "comment": "15 pages", "summary": "Data-driven decision support in high-stakes domains like healthcare and\nfinance faces significant barriers to data sharing due to regulatory,\ninstitutional, and privacy concerns. While recent generative AI models, such as\nlarge language models, have shown impressive performance in open-domain tasks,\ntheir adoption in sensitive environments remains limited by unpredictable\nbehaviors and insufficient privacy-preserving datasets for benchmarking.\nExisting anonymization methods are often inadequate, especially for\nunstructured text, as redaction and masking can still allow re-identification.\nDifferential Privacy (DP) offers a principled alternative, enabling the\ngeneration of synthetic data with formal privacy assurances. In this work, we\naddress these challenges through three key contributions. First, we introduce a\ncomprehensive evaluation framework with standardized utility and fidelity\nmetrics, encompassing nine curated datasets that capture domain-specific\ncomplexities such as technical jargon, long-context dependencies, and\nspecialized document structures. Second, we conduct a large-scale empirical\nstudy benchmarking state-of-the-art DP text generation methods and LLMs of\nvarying sizes and different fine-tuning strategies, revealing that high-quality\ndomain-specific synthetic data generation under DP constraints remains an\nunsolved challenge, with performance degrading as domain complexity increases.\nThird, we develop a membership inference attack (MIA) methodology tailored for\nsynthetic text, providing first empirical evidence that the use of public\ndatasets - potentially present in pre-training corpora - can invalidate claimed\nprivacy guarantees. Our findings underscore the urgent need for rigorous\nprivacy auditing and highlight persistent gaps between open-domain and\nspecialist evaluations, informing responsible deployment of generative AI in\nprivacy-sensitive, high-stakes settings.", "AI": {"tldr": "\u672c\u6587\u63a2\u7a76\u4e86\u5728\u533b\u7597\u548c\u91d1\u878d\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u4f7f\u7528\u751f\u6210\u5f0fAI\u5408\u6210\u6570\u636e\u9762\u4e34\u7684\u9690\u79c1\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5f3a\u8c03\u4e86\u4e25\u683c\u9690\u79c1\u5ba1\u8ba1\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u89e3\u51b3\u9ad8\u98ce\u9669\u9886\u57df\u6570\u636e\u5171\u4eab\u7684\u9690\u79c1\u95ee\u9898\uff0c\u5229\u7528\u5dee\u5206\u9690\u79c1\u6280\u672f\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u6570\u636e\u3002", "method": "\u6784\u5efa\u4e86\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u51c6\u6d4b\u8bd5\u4e86\u6700\u5148\u8fdb\u7684\u5dee\u5206\u9690\u79c1\u6587\u672c\u751f\u6210\u65b9\u6cd5\u548c\u4e0d\u540c\u89c4\u6a21\u7684LLM\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u9488\u5bf9\u5408\u6210\u6587\u672c\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u6cd5\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u5728\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u7279\u5b9a\u9886\u57df\u5408\u6210\u6570\u636e\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u5e76\u4e14\u516c\u5171\u6570\u636e\u96c6\u7684\u4f7f\u7528\u53ef\u80fd\u4f1a\u4f7f\u9690\u79c1\u4fdd\u8bc1\u5931\u6548\u3002", "conclusion": "\u9700\u8981\u66f4\u4e25\u683c\u7684\u9690\u79c1\u5ba1\u8ba1\uff0c\u5e76\u5f25\u5408\u5f00\u653e\u9886\u57df\u548c\u4e13\u4e1a\u9886\u57df\u8bc4\u4f30\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4ee5\u8d1f\u8d23\u4efb\u5730\u90e8\u7f72\u751f\u6210\u5f0fAI\u3002"}}
{"id": "2509.14647", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.14647", "abs": "https://arxiv.org/abs/2509.14647", "authors": ["NVJK Kartik", "Garvit Sapra", "Rishav Hada", "Nikhil Pareek"], "title": "AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production", "comment": null, "summary": "With the growing adoption of Large Language Models (LLMs) in automating\ncomplex, multi-agent workflows, organizations face mounting risks from errors,\nemergent behaviors, and systemic failures that current evaluation methods fail\nto capture. We present AgentCompass, the first evaluation framework designed\nspecifically for post-deployment monitoring and debugging of agentic workflows.\nAgentCompass models the reasoning process of expert debuggers through a\nstructured, multi-stage analytical pipeline: error identification and\ncategorization, thematic clustering, quantitative scoring, and strategic\nsummarization. The framework is further enhanced with a dual memory\nsystem-episodic and semantic-that enables continual learning across executions.\nThrough collaborations with design partners, we demonstrate the framework's\npractical utility on real-world deployments, before establishing its efficacy\nagainst the publicly available TRAIL benchmark. AgentCompass achieves\nstate-of-the-art results on key metrics, while uncovering critical issues\nmissed in human annotations, underscoring its role as a robust,\ndeveloper-centric tool for reliable monitoring and improvement of agentic\nsystems in production.", "AI": {"tldr": "AgentCompass\u6846\u67b6\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u9a71\u52a8\u667a\u80fd\u5de5\u4f5c\u6d41\u7684\u90e8\u7f72\u540e\u76d1\u63a7\u548c\u8c03\u8bd5\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u5206\u6790\u6d41\u7a0b\u8bc6\u522b\u3001\u5206\u7c7b\u548c\u91cf\u5316\u9519\u8bef\uff0c\u5e76\u5b9e\u73b0\u6301\u7eed\u5b66\u4e60\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349LLM\u9a71\u52a8\u667a\u80fd\u5de5\u4f5c\u6d41\u7684\u9519\u8bef\u3001\u6d8c\u73b0\u884c\u4e3a\u548c\u7cfb\u7edf\u6027\u6545\u969c\u7684\u98ce\u9669\u3002", "method": "AgentCompass\u6846\u67b6\u91c7\u7528\u7ed3\u6784\u5316\u7684\u591a\u9636\u6bb5\u5206\u6790\u6d41\u7a0b\uff1a\u9519\u8bef\u8bc6\u522b\u548c\u5206\u7c7b\u3001\u4e3b\u9898\u805a\u7c7b\u3001\u5b9a\u91cf\u8bc4\u5206\u548c\u7b56\u7565\u6027\u603b\u7ed3\uff0c\u5e76\u7ed3\u5408\u60c5\u666f\u8bb0\u5fc6\u548c\u8bed\u4e49\u8bb0\u5fc6\u7684\u53cc\u91cd\u8bb0\u5fc6\u7cfb\u7edf\u3002", "result": "\u5728\u5b9e\u9645\u90e8\u7f72\u548cTRAIL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgentCompass\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u53d1\u73b0\u4e86\u4eba\u5de5\u6807\u6ce8\u4e2d\u9057\u6f0f\u7684\u5173\u952e\u95ee\u9898\u3002", "conclusion": "AgentCompass\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u3001\u4ee5\u5f00\u53d1\u8005\u4e3a\u4e2d\u5fc3\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u53ef\u9760\u5730\u76d1\u63a7\u548c\u6539\u8fdb\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2509.14662", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14662", "abs": "https://arxiv.org/abs/2509.14662", "authors": ["Ming Li", "Nan Zhang", "Chenrui Fan", "Hong Jiao", "Yanbin Fu", "Sydney Peters", "Qingshu Xu", "Robert Lissitz", "Tianyi Zhou"], "title": "Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory", "comment": "EMNLP2025 main, Camera-ready", "summary": "While Large Reasoning Models (LRMs) generate extensive chain-of-thought\nreasoning, we lack a principled framework for understanding how these thoughts\nare structured. In this paper, we introduce a novel approach by applying\nSchoenfeld's Episode Theory, a classic cognitive framework for human\nmathematical problem-solving, to analyze the reasoning traces of LRMs. We\nannotated thousands of sentences and paragraphs from model-generated solutions\nto math problems using seven cognitive labels (e.g., Plan, Implement, Verify).\nThe result is the first publicly available benchmark for the fine-grained\nanalysis of machine reasoning, including a large annotated corpus and detailed\nannotation guidebooks. Our preliminary analysis reveals distinct patterns in\nLRM reasoning, such as the transition dynamics between cognitive states. This\nframework provides a theoretically grounded methodology for interpreting LRM\ncognition and enables future work on more controllable and transparent\nreasoning systems.", "AI": {"tldr": "\u7528Schoenfeld\u7684\u9636\u6bb5\u7406\u8bba\u5206\u6790\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u5bf9\u673a\u5668\u63a8\u7406\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u6790\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u4ea7\u751f\u5927\u91cf\u7684\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\uff0c\u4f46\u7f3a\u4e4f\u7406\u89e3\u8fd9\u4e9b\u601d\u60f3\u7ed3\u6784\u7684\u539f\u5219\u6027\u6846\u67b6\u3002", "method": "\u5e94\u7528Schoenfeld\u7684\u9636\u6bb5\u7406\u8bba\uff0c\u5bf9\u6a21\u578b\u751f\u6210\u7684\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u65b9\u6848\u4e2d\u7684\u53e5\u5b50\u548c\u6bb5\u843d\u8fdb\u884c\u6807\u6ce8\uff0c\u4f7f\u7528\u4e03\u4e2a\u8ba4\u77e5\u6807\u7b7e(\u4f8b\u5982\uff0c\u8ba1\u5212\u3001\u5b9e\u65bd\u3001\u9a8c\u8bc1)\u3002", "result": "\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u516c\u5f00\u7684\u7528\u4e8e\u5bf9\u673a\u5668\u63a8\u7406\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u6790\u7684\u57fa\u51c6\uff0c\u5305\u62ec\u5927\u578b\u6807\u6ce8\u8bed\u6599\u5e93\u548c\u8be6\u7ec6\u7684\u6807\u6ce8\u6307\u5357\u3002\u521d\u6b65\u5206\u6790\u63ed\u793a\u4e86LRM\u63a8\u7406\u4e2d\u7684\u4e0d\u540c\u6a21\u5f0f\uff0c\u4f8b\u5982\u8ba4\u77e5\u72b6\u6001\u4e4b\u95f4\u7684\u8f6c\u6362\u52a8\u6001\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u89e3\u91caLRM\u8ba4\u77e5\u63d0\u4f9b\u4e86\u4e00\u79cd\u7406\u8bba\u57fa\u7840\u7684\u65b9\u6cd5\uff0c\u5e76\u4e3a\u672a\u6765\u6784\u5efa\u66f4\u53ef\u63a7\u548c\u900f\u660e\u7684\u63a8\u7406\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.14693", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14693", "abs": "https://arxiv.org/abs/2509.14693", "authors": ["Song Xu", "Yilun Liu", "Minggui He", "Mingchen Dai", "Ziang Chen", "Chunguang Zhao", "Jingzhou Du", "Shimin Tao", "Weibin Meng", "Shenglin Zhang", "Yongqian Sun", "Boxing Chen", "Daimeng Wei"], "title": "RationAnomaly: Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning", "comment": "5 pages, 3 figures", "summary": "Logs constitute a form of evidence signaling the operational status of\nsoftware systems. Automated log anomaly detection is crucial for ensuring the\nreliability of modern software systems. However, existing approaches face\nsignificant limitations: traditional deep learning models lack interpretability\nand generalization, while methods leveraging Large Language Models are often\nhindered by unreliability and factual inaccuracies. To address these issues, we\npropose RationAnomaly, a novel framework that enhances log anomaly detection by\nsynergizing Chain-of-Thought (CoT) fine-tuning with reinforcement learning. Our\napproach first instills expert-like reasoning patterns using CoT-guided\nsupervised fine-tuning, grounded in a high-quality dataset corrected through a\nrigorous expert-driven process. Subsequently, a reinforcement learning phase\nwith a multi-faceted reward function optimizes for accuracy and logical\nconsistency, effectively mitigating hallucinations. Experimentally,\nRationAnomaly outperforms state-of-the-art baselines, achieving superior\nF1-scores on key benchmarks while providing transparent, step-by-step\nanalytical outputs. We have released the corresponding resources, including\ncode and datasets.", "AI": {"tldr": "RationAnomaly\u6846\u67b6\u7ed3\u5408\u601d\u7ef4\u94fe(CoT)\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "method": "\u8be5\u6846\u67b6\u9996\u5148\u4f7f\u7528\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u8fdb\u884cCoT\u5f15\u5bfc\u7684\u76d1\u7763\u5fae\u8c03\uff0c\u7136\u540e\u4f7f\u7528\u591a\u65b9\u9762\u5956\u52b1\u51fd\u6570\u7684\u5f3a\u5316\u5b66\u4e60\u6765\u4f18\u5316\u51c6\u786e\u6027\u548c\u903b\u8f91\u4e00\u81f4\u6027\u3002", "result": "RationAnomaly\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5728\u5173\u952e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u66f4\u9ad8\u7684F1\u5206\u6570\uff0c\u5e76\u63d0\u4f9b\u4e86\u900f\u660e\u7684\u3001\u9010\u6b65\u7684\u5206\u6790\u8f93\u51fa\u3002", "conclusion": "RationAnomaly\u6846\u67b6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\u95ee\u9898\uff0c\u5e76\u5df2\u5f00\u6e90\u76f8\u5173\u8d44\u6e90\u3002"}}
{"id": "2509.14704", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14704", "abs": "https://arxiv.org/abs/2509.14704", "authors": ["Masaharu Mizumoto", "Dat Nguyen", "Zhiheng Han", "Jiyuan Fang", "Heyuan Guan", "Xingfu Li", "Naoya Shiraishi", "Xuyang Tian", "Yo Nakawake", "Le Minh Nguyen"], "title": "The NazoNazo Benchmark: A Cost-Effective and Extensible Test of Insight-Based Reasoning in LLMs", "comment": null, "summary": "Benchmark saturation and contamination undermine confidence in LLM\nevaluation. We present Nazonazo, a cost-effective and extensible benchmark\nbuilt from Japanese children's riddles to test insight-based reasoning. Items\nare short (mostly one sentence), require no specialized domain knowledge, and\ncan be generated at scale, enabling rapid refresh of blind sets when leakage is\nsuspected. We evaluate 38 frontier models and 126 adults on 120 riddles. No\nmodel except for GPT-5 is comparable to human performance, which achieves a\n52.9% mean accuracy. Model comparison on extended 201 items shows that\nreasoning models significantly outperform non-reasoning peers, while model size\nshows no reliable association with accuracy. Beyond aggregate accuracy, an\ninformal candidate-tracking analysis of thought logs reveals many cases of\nverification failure: models often produce the correct solution among\nintermediate candidates yet fail to select it as the final answer, which we\nillustrate with representative examples observed in multiple models. Nazonazo\nthus offers a cost-effective, scalable, and easily renewable benchmark format\nthat addresses the current evaluation crisis while also suggesting a recurrent\nmeta-cognitive weakness, providing clear targets for future control and\ncalibration methods.", "AI": {"tldr": "Nazonazo\u57fa\u51c6\u6d4b\u8bd5\u4f7f\u7528\u65e5\u672c\u513f\u7ae5\u8c1c\u8bed\u8bc4\u4f30LLM\u7684\u6d1e\u5bdf\u529b\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u9664GPT-5\u5916\uff0c\u73b0\u6709\u6a21\u578b\u6027\u80fd\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\uff0c\u6a21\u578b\u5927\u5c0f\u4e0e\u51c6\u786e\u7387\u65e0\u663e\u8457\u5173\u8054\uff0c\u5e76\u63ed\u793a\u6a21\u578b\u5b58\u5728\u9a8c\u8bc1\u5931\u8d25\u7684\u5143\u8ba4\u77e5\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709LLM\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u9971\u548c\u548c\u6c61\u67d3\u95ee\u9898\uff0c\u96be\u4ee5\u53ef\u9760\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\u3002", "method": "\u6784\u5efaNazonazo\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528120\u4e2a\uff08\u6269\u5c55\u5230201\u4e2a\uff09\u65e5\u672c\u513f\u7ae5\u8c1c\u8bed\u8bc4\u4f3038\u4e2a\u524d\u6cbf\u6a21\u578b\u548c126\u4e2a\u6210\u5e74\u4eba\u7684\u6d1e\u5bdf\u529b\u63a8\u7406\u80fd\u529b\u3002", "result": "\u9664GPT-5\u5916\uff0c\u6a21\u578b\u6027\u80fd\u5747\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\uff0852.9%\u5e73\u5747\u51c6\u786e\u7387\uff09\uff1b\u63a8\u7406\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u975e\u63a8\u7406\u6a21\u578b\uff1b\u6a21\u578b\u5927\u5c0f\u4e0e\u51c6\u786e\u7387\u65e0\u663e\u8457\u5173\u8054\uff1b\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u9a8c\u8bc1\u5931\u8d25\u7684\u5143\u8ba4\u77e5\u7f3a\u9677\u3002", "conclusion": "Nazonazo\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u6613\u4e8e\u66f4\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u6307\u51fa\u4e86LLM\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2509.14750", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14750", "abs": "https://arxiv.org/abs/2509.14750", "authors": ["Letian Zhang", "Guanghao Meng", "Xudong Ren", "Yiming Wang", "Shu-Tao Xia"], "title": "Enhancing Retrieval Augmentation via Adversarial Collaboration", "comment": null, "summary": "Retrieval-augmented Generation (RAG) is a prevalent approach for\ndomain-specific LLMs, yet it is often plagued by \"Retrieval Hallucinations\"--a\nphenomenon where fine-tuned models fail to recognize and act upon poor-quality\nretrieved documents, thus undermining performance. To address this, we propose\nthe Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two\nheterogeneous agents: a generalist Detector that identifies knowledge gaps, and\na domain-specialized Resolver that provides precise solutions. Guided by a\nmoderator, these agents engage in an adversarial collaboration, where the\nDetector's persistent questioning challenges the Resolver's expertise. This\ndynamic process allows for iterative problem dissection and refined knowledge\nretrieval. Extensive experiments show that AC-RAG significantly improves\nretrieval accuracy and outperforms state-of-the-art RAG methods across various\nvertical domains.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5bf9\u6297\u534f\u4f5c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08AC-RAG\uff09\u7684\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u68c0\u7d22\u5e7b\u89c9\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6a21\u578b\u5bb9\u6613\u51fa\u73b0\u201c\u68c0\u7d22\u5e7b\u89c9\u201d\u95ee\u9898\uff0c\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u91c7\u7528\u4e24\u4e2a\u5f02\u6784Agent\uff1a\u4e00\u4e2a\u901a\u7528\u7684\u68c0\u6d4b\u5668\u548c\u4e00\u4e2a\u4e13\u4e1a\u7684\u89e3\u51b3\u5668\uff0c\u901a\u8fc7\u5bf9\u6297\u534f\u4f5c\u8fed\u4ee3\u5f0f\u5730\u6539\u8fdb\u77e5\u8bc6\u68c0\u7d22\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAC-RAG\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u7cbe\u5ea6\uff0c\u4f18\u4e8e\u73b0\u6709RAG\u65b9\u6cd5\u3002", "conclusion": "AC-RAG\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u68c0\u7d22\u5e7b\u89c9\u95ee\u9898\uff0c\u4e3a\u9886\u57df\u7279\u5b9aLLM\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2509.14778", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.14778", "abs": "https://arxiv.org/abs/2509.14778", "authors": ["Yuxiao Cheng", "Jinli Suo"], "title": "OpenLens AI: Fully Autonomous Research Agent for Health Infomatics", "comment": null, "summary": "Health informatics research is characterized by diverse data modalities,\nrapid knowledge expansion, and the need to integrate insights across biomedical\nscience, data analytics, and clinical practice. These characteristics make it\nparticularly well-suited for agent-based approaches that can automate knowledge\nexploration, manage complex workflows, and generate clinically meaningful\noutputs. Recent progress in large language model (LLM)-based agents has\ndemonstrated promising capabilities in literature synthesis, data analysis, and\neven end-to-end research execution. However, existing systems remain limited\nfor health informatics because they lack mechanisms to interpret medical\nvisualizations and often overlook domain-specific quality requirements. To\naddress these gaps, we introduce OpenLens AI, a fully automated framework\ntailored to health informatics. OpenLens AI integrates specialized agents for\nliterature review, data analysis, code generation, and manuscript preparation,\nenhanced by vision-language feedback for medical visualization and quality\ncontrol for reproducibility. The framework automates the entire research\npipeline, producing publication-ready LaTeX manuscripts with transparent and\ntraceable workflows, thereby offering a domain-adapted solution for advancing\nhealth informatics research.", "AI": {"tldr": "OpenLens AI\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u63a8\u8fdb\u5065\u5eb7\u4fe1\u606f\u5b66\u7814\u7a76\uff0c\u5b83\u96c6\u6210\u4e86\u6587\u732e\u7efc\u8ff0\u3001\u6570\u636e\u5206\u6790\u3001\u4ee3\u7801\u751f\u6210\u548c\u624b\u7a3f\u51c6\u5907\u7b49\u4e13\u7528\u4ee3\u7406\uff0c\u5e76\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u53cd\u9988\u548c\u8d28\u91cf\u63a7\u5236\u6765\u589e\u5f3a\u533b\u5b66\u53ef\u89c6\u5316\u548c\u53ef\u91cd\u590d\u6027\u3002", "motivation": "\u5065\u5eb7\u4fe1\u606f\u5b66\u7814\u7a76\u9700\u8981\u6574\u5408\u751f\u7269\u533b\u5b66\u79d1\u5b66\u3001\u6570\u636e\u5206\u6790\u548c\u4e34\u5e8a\u5b9e\u8df5\u7684\u89c1\u89e3\uff0c\u800c\u57fa\u4e8e\u4ee3\u7406\u7684\u65b9\u6cd5\u53ef\u4ee5\u81ea\u52a8\u5316\u77e5\u8bc6\u63a2\u7d22\u3001\u7ba1\u7406\u590d\u6742\u7684\u5de5\u4f5c\u6d41\u7a0b\u5e76\u751f\u6210\u5177\u6709\u4e34\u5e8a\u610f\u4e49\u7684\u8f93\u51fa\u3002", "method": "OpenLens AI \u96c6\u6210\u4e86\u591a\u4e2a\u4e13\u7528\u4ee3\u7406\uff0c\u5e76\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u53cd\u9988\u548c\u8d28\u91cf\u63a7\u5236\u6765\u589e\u5f3a\u533b\u5b66\u53ef\u89c6\u5316\u548c\u53ef\u91cd\u590d\u6027\uff0c\u81ea\u52a8\u5316\u6574\u4e2a\u7814\u7a76\u6d41\u7a0b\uff0c\u751f\u6210\u53ef\u53d1\u8868\u7684 LaTeX \u624b\u7a3f\u3002", "result": "OpenLens AI \u81ea\u52a8\u5316\u4e86\u5065\u5eb7\u4fe1\u606f\u5b66\u7814\u7a76\u7684\u6574\u4e2a\u6d41\u7a0b\uff0c\u4ea7\u751f\u5177\u6709\u900f\u660e\u53ef\u8ffd\u6eaf\u5de5\u4f5c\u6d41\u7a0b\u7684\u3001\u53ef\u53d1\u8868\u7684 LaTeX \u624b\u7a3f\u3002", "conclusion": "OpenLens AI \u4e3a\u63a8\u8fdb\u5065\u5eb7\u4fe1\u606f\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u9886\u57df\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
