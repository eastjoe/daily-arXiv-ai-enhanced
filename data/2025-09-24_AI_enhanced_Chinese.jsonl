{"id": "2509.18101", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18101", "abs": "https://arxiv.org/abs/2509.18101", "authors": ["Guanzhong Pan", "Haibo Wang"], "title": "A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services", "comment": null, "summary": "Large language models (LLMs) are becoming increasingly widespread.\nOrganizations that want to use AI for productivity now face an important\ndecision. They can subscribe to commercial LLM services or deploy models on\ntheir own infrastructure. Cloud services from providers such as OpenAI,\nAnthropic, and Google are attractive because they provide easy access to\nstate-of-the-art models and are easy to scale. However, concerns about data\nprivacy, the difficulty of switching service providers, and long-term operating\ncosts have driven interest in local deployment of open-source models. This\npaper presents a cost-benefit analysis framework to help organizations\ndetermine when on-premise LLM deployment becomes economically viable compared\nto commercial subscription services. We consider the hardware requirements,\noperational expenses, and performance benchmarks of the latest open-source\nmodels, including Qwen, Llama, Mistral, and etc. Then we compare the total cost\nof deploying these models locally with the major cloud providers subscription\nfee. Our findings provide an estimated breakeven point based on usage levels\nand performance needs. These results give organizations a practical framework\nfor planning their LLM strategies.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u672c\u5730\u90e8\u7f72\u5f00\u6e90LLM\u4e0e\u8ba2\u9605\u5546\u4e1aLLM\u670d\u52a1\u7684\u6210\u672c\u6548\u76ca\uff0c\u4ee5\u5e2e\u52a9\u7ec4\u7ec7\u5236\u5b9aLLM\u7b56\u7565\u3002", "motivation": "\u4f01\u4e1a\u9700\u8981\u5728\u672c\u5730\u90e8\u7f72\u5f00\u6e90LLM\u548c\u8ba2\u9605\u5546\u4e1aLLM\u670d\u52a1\u4e4b\u95f4\u505a\u51fa\u9009\u62e9\uff0c\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u6210\u672c\u6548\u76ca\u5206\u6790\u6846\u67b6\u4ee5\u8f85\u52a9\u51b3\u7b56\u3002", "method": "\u5bf9\u5305\u62ecQwen\u3001Llama\u3001Mistral\u7b49\u5728\u5185\u7684\u6700\u65b0\u5f00\u6e90\u6a21\u578b\u7684\u786c\u4ef6\u9700\u6c42\u3001\u8fd0\u8425\u6210\u672c\u548c\u6027\u80fd\u57fa\u51c6\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u5e76\u5c06\u5176\u4e0e\u4e3b\u8981\u4e91\u63d0\u4f9b\u5546\u7684\u8ba2\u9605\u8d39\u7528\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u4ece\u800c\u5f97\u51fa\u76c8\u4e8f\u5e73\u8861\u70b9\u3002", "result": "\u57fa\u4e8e\u4f7f\u7528\u6c34\u5e73\u548c\u6027\u80fd\u9700\u6c42\uff0c\u672c\u6587\u7ed9\u51fa\u4e86\u672c\u5730\u90e8\u7f72\u5f00\u6e90LLM\u5728\u7ecf\u6d4e\u4e0a\u53ef\u884c\u7684\u4f30\u8ba1\u76c8\u4e8f\u5e73\u8861\u70b9\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7ec4\u7ec7\u89c4\u5212LLM\u6218\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2509.18123", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18123", "abs": "https://arxiv.org/abs/2509.18123", "authors": ["Yeonju Lee", "Rui Qi Chen", "Joseph Oboamah", "Po Nien Su", "Wei-zhen Liang", "Yeyin Shi", "Lu Gan", "Yongsheng Chen", "Xin Qiao", "Jing Li"], "title": "SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture", "comment": null, "summary": "Accurate interpretation of soil moisture patterns is critical for irrigation\nscheduling and crop management, yet existing approaches for soil moisture\ntime-series analysis either rely on threshold-based rules or data-hungry\nmachine learning or deep learning models that are limited in adaptability and\ninterpretability. In this study, we introduce SPADE (Soil moisture Pattern and\nAnomaly DEtection), an integrated framework that leverages large language\nmodels (LLMs) to jointly detect irrigation patterns and anomalies in soil\nmoisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced\nreasoning and instruction-following capabilities, enabling zero-shot analysis\nwithout requiring task-specific annotation or fine-tuning. By converting\ntime-series data into a textual representation and designing domain-informed\nprompt templates, SPADE identifies irrigation events, estimates net irrigation\ngains, detects, classifies anomalies, and produces structured, interpretable\nreports. Experiments were conducted on real-world soil moisture sensor data\nfrom commercial and experimental farms cultivating multiple crops across the\nUnited States. Results demonstrate that SPADE outperforms the existing method\nin anomaly detection, achieving higher recall and F1 scores and accurately\nclassifying anomaly types. Furthermore, SPADE achieved high precision and\nrecall in detecting irrigation events, indicating its strong capability to\ncapture irrigation patterns accurately. SPADE's reports provide\ninterpretability and usability of soil moisture analytics. This study\nhighlights the potential of LLMs as scalable, adaptable tools for precision\nagriculture, which is capable of integrating qualitative knowledge and\ndata-driven reasoning to produce actionable insights for accurate soil moisture\nmonitoring and improved irrigation scheduling from soil moisture time-series\ndata.", "AI": {"tldr": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u8fdb\u884c\u571f\u58e4\u6e7f\u5ea6\u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff0c\u5b9e\u73b0\u704c\u6e89\u6a21\u5f0f\u548c\u5f02\u5e38\u68c0\u6d4b\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u571f\u58e4\u6e7f\u5ea6\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u96be\u4ee5\u517c\u987e\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faSPADE\u6846\u67b6\uff0c\u5229\u7528ChatGPT-4.1\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u8f6c\u6362\u4e3a\u6587\u672c\u8868\u793a\uff0c\u8fdb\u884c\u96f6\u6837\u672c\u5206\u6790\uff0c\u8bc6\u522b\u704c\u6e89\u4e8b\u4ef6\u3001\u4f30\u8ba1\u51c0\u704c\u6e89\u589e\u76ca\u3001\u68c0\u6d4b\u548c\u5206\u7c7b\u5f02\u5e38\uff0c\u5e76\u751f\u6210\u7ed3\u6784\u5316\u62a5\u544a\u3002", "result": "SPADE\u5728\u5f02\u5e38\u68c0\u6d4b\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u53ec\u56de\u7387\u548cF1\u5206\u6570\uff0c\u5e76\u80fd\u51c6\u786e\u5206\u7c7b\u5f02\u5e38\u7c7b\u578b\uff1b\u5728\u68c0\u6d4b\u704c\u6e89\u4e8b\u4ef6\u65b9\u9762\u4e5f\u5177\u6709\u9ad8\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u6210\u4e3a\u7cbe\u51c6\u519c\u4e1a\u4e2d\u53ef\u6269\u5c55\u3001\u9002\u5e94\u6027\u5f3a\u7684\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u6574\u5408\u5b9a\u6027\u77e5\u8bc6\u548c\u6570\u636e\u9a71\u52a8\u63a8\u7406\uff0c\u4ece\u800c\u6539\u8fdb\u571f\u58e4\u6e7f\u5ea6\u76d1\u6d4b\u548c\u704c\u6e89\u8c03\u5ea6\u3002"}}
{"id": "2509.18132", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18132", "abs": "https://arxiv.org/abs/2509.18132", "authors": ["Xiuyi Fan"], "title": "Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI", "comment": "Accepted at the International Joint Conference on Neural Networks,\n  IJCNN 2025", "summary": "Uncertainty is a fundamental challenge in medical practice, but current\nmedical AI systems fail to explicitly quantify or communicate uncertainty in a\nway that aligns with clinical reasoning. Existing XAI works focus on\ninterpreting model predictions but do not capture the confidence or reliability\nof these predictions. Conversely, uncertainty estimation (UE) techniques\nprovide confidence measures but lack intuitive explanations. The disconnect\nbetween these two areas limits AI adoption in medicine. To address this gap, we\npropose Explainable Uncertainty Estimation (XUE) that integrates explainability\nwith uncertainty quantification to enhance trust and usability in medical AI.\nWe systematically map medical uncertainty to AI uncertainty concepts and\nidentify key challenges in implementing XUE. We outline technical directions\nfor advancing XUE, including multimodal uncertainty quantification,\nmodel-agnostic visualization techniques, and uncertainty-aware decision support\nsystems. Lastly, we propose guiding principles to ensure effective XUE\nrealisation. Our analysis highlights the need for AI systems that not only\ngenerate reliable predictions but also articulate confidence levels in a\nclinically meaningful way. This work contributes to the development of\ntrustworthy medical AI by bridging explainability and uncertainty, paving the\nway for AI systems that are aligned with real-world clinical complexities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5(XUE)\uff0c\u4ee5\u63d0\u9ad8\u533b\u5b66AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u548c\u53ef\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u533b\u5b66AI\u7cfb\u7edf\u65e0\u6cd5\u660e\u786e\u91cf\u5316\u6216\u4f20\u8fbe\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u4e0e\u4e34\u5e8a\u63a8\u7406\u4e0d\u7b26\u3002", "method": "\u7cfb\u7edf\u5730\u5c06\u533b\u5b66\u4e0d\u786e\u5b9a\u6027\u6620\u5c04\u5230AI\u4e0d\u786e\u5b9a\u6027\u6982\u5ff5\uff0c\u5e76\u786e\u5b9a\u5b9e\u73b0XUE\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u51fa\u6280\u672f\u65b9\u5411\uff0c\u4f8b\u5982\u591a\u6a21\u6001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3001\u6a21\u578b\u65e0\u5173\u7684\u53ef\u89c6\u5316\u6280\u672f\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53ef\u89e3\u91ca\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f3a\u533b\u5b66AI\u7684\u53ef\u4fe1\u5ea6\u3002", "conclusion": "XUE\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u53ef\u9760\u7684\u9884\u6d4b\uff0c\u5e76\u4ee5\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u65b9\u5f0f\u8868\u8fbe\u7f6e\u4fe1\u5ea6\uff0c\u4ece\u800c\u4fc3\u8fdb\u533b\u5b66AI\u7684\u4fe1\u4efb\u548c\u91c7\u7528\u3002"}}
{"id": "2509.18168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18168", "abs": "https://arxiv.org/abs/2509.18168", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics", "comment": null, "summary": "Semantic parsing of long documents remains challenging due to quadratic\ngrowth in pairwise composition and memory requirements. We introduce\n\\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that\ndecomposes an input of length $N$ into $M$ meaningful segments, constructs\n\\emph{Local Semantic Graphs} on each segment, and extracts compact\n\\emph{summary nodes} to form a \\emph{Global Graph Memory}. HSGM supports\n\\emph{incremental updates} -- only newly arrived segments incur local graph\nconstruction and summary-node integration -- while \\emph{Hierarchical Query\nProcessing} locates relevant segments via top-$K$ retrieval over summary nodes\nand then performs fine-grained reasoning within their local graphs.\n  Theoretically, HSGM reduces worst-case complexity from $O(N^2)$ to\n$O\\!\\left(N\\,k + (N/k)^2\\right)$, with segment size $k \\ll N$, and we derive\nFrobenius-norm bounds on the approximation error introduced by node\nsummarization and sparsification thresholds. Empirically, on three benchmarks\n-- long-document AMR parsing, segment-level semantic role labeling (OntoNotes),\nand legal event extraction -- HSGM achieves \\emph{2--4$\\times$ inference\nspeedup}, \\emph{$>60\\%$ reduction} in peak memory, and \\emph{$\\ge 95\\%$} of\nbaseline accuracy. Our approach unlocks scalable, accurate semantic modeling\nfor ultra-long texts, enabling real-time and resource-constrained NLP\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u5c42\u6bb5\u56fe\u8bb0\u5fc6\u7f51\u7edc\uff08HSGM\uff09\u7528\u4e8e\u957f\u6587\u6863\u8bed\u4e49\u89e3\u6790\uff0c\u5b83\u5c06\u957f\u6587\u6863\u5206\u89e3\u6210\u591a\u4e2a\u8bed\u4e49\u7247\u6bb5\uff0c\u6784\u5efa\u5c40\u90e8\u8bed\u4e49\u56fe\u5e76\u63d0\u53d6\u6458\u8981\u8282\u70b9\u5f62\u6210\u5168\u5c40\u56fe\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u63d0\u9ad8\u4e86\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u957f\u6587\u6863\u8bed\u4e49\u89e3\u6790\u65b9\u6cd5\u9762\u4e34\u4e8c\u6b21\u590d\u6742\u5ea6\u589e\u957f\u548c\u5185\u5b58\u9700\u6c42\u5927\u7684\u95ee\u9898\u3002", "method": "HSGM\u6846\u67b6\u5c06\u957f\u5ea6\u4e3aN\u7684\u8f93\u5165\u5206\u89e3\u6210M\u4e2a\u8bed\u4e49\u7247\u6bb5\uff0c\u4e3a\u6bcf\u4e2a\u7247\u6bb5\u6784\u5efa\u5c40\u90e8\u8bed\u4e49\u56fe\uff0c\u5e76\u63d0\u53d6\u7d27\u51d1\u7684\u6458\u8981\u8282\u70b9\u5f62\u6210\u5168\u5c40\u56fe\u8bb0\u5fc6\u3002\u652f\u6301\u589e\u91cf\u66f4\u65b0\u548c\u5206\u5c42\u67e5\u8be2\u5904\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHSGM\u5b9e\u73b0\u4e862-4\u500d\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\uff0c\u5cf0\u503c\u5185\u5b58\u964d\u4f4e\u8d85\u8fc760%\uff0c\u540c\u65f6\u4fdd\u6301\u4e8695%\u4ee5\u4e0a\u7684\u57fa\u51c6\u7cbe\u5ea6\u3002", "conclusion": "HSGM\u4e3a\u8d85\u957f\u6587\u672c\u7684\u8bed\u4e49\u5efa\u6a21\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u5b9e\u65f6\u548c\u8d44\u6e90\u53d7\u9650\u7684NLP\u5e94\u7528\u6210\u4e3a\u53ef\u80fd\u3002"}}
{"id": "2509.18178", "categories": ["cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18178", "abs": "https://arxiv.org/abs/2509.18178", "authors": ["Ling Yue", "Nithin Somasekharan", "Tingwen Zhang", "Yadi Cao", "Shaowu Pan"], "title": "Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM", "comment": null, "summary": "Computational Fluid Dynamics (CFD) is an essential simulation tool in\nengineering, yet its steep learning curve and complex manual setup create\nsignificant barriers. To address these challenges, we introduce Foam-Agent, a\nmulti-agent framework that automates the entire end-to-end OpenFOAM workflow\nfrom a single natural language prompt. Our key innovations address critical\ngaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation:\nFoam-Agent is the first system to manage the full simulation pipeline,\nincluding advanced pre-processing with a versatile Meshing Agent capable of\nhandling external mesh files and generating new geometries via Gmsh, automatic\ngeneration of HPC submission scripts, and post-simulation visualization via\nParaView. 2. Composable Service Architecture: Going beyond a monolithic agent,\nthe framework uses Model Context Protocol (MCP) to expose its core functions as\ndiscrete, callable tools. This allows for flexible integration and use by other\nagentic systems, such as Claude-code, for more exploratory workflows. 3.\nHigh-Fidelity Configuration Generation: We achieve superior accuracy through a\nHierarchical Multi-Index RAG for precise context retrieval and a\ndependency-aware generation process that ensures configuration consistency.\nEvaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2%\nsuccess rate with Claude 3.5 Sonnet, significantly outperforming existing\nframeworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the\nexpertise barrier for CFD, demonstrating how specialized multi-agent systems\ncan democratize complex scientific computing. The code is public at\nhttps://github.com/csml-rpi/Foam-Agent.", "AI": {"tldr": "Foam-Agent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u53ef\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u81ea\u52a8\u6267\u884cOpenFOAM\u5de5\u4f5c\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86CFD\u6a21\u62df\u7684\u6613\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684CFD\u6a21\u62df\u5de5\u5177\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u4e14\u8bbe\u7f6e\u590d\u6742\uff0c\u963b\u788d\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6Foam-Agent\uff0c\u96c6\u6210\u4e86\u7f51\u683c\u751f\u6210\u3001HPC\u63d0\u4ea4\u811a\u672c\u751f\u6210\u548c\u540e\u5904\u7406\u53ef\u89c6\u5316\u7b49\u529f\u80fd\uff0c\u5e76\u5229\u7528Hierarchical Multi-Index RAG\u63d0\u9ad8\u914d\u7f6e\u751f\u6210\u7684\u51c6\u786e\u6027\u3002", "result": "\u5728110\u4e2a\u6a21\u62df\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFoam-Agent\u7684\u6210\u529f\u7387\u8fbe\u523088.2%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002", "conclusion": "Foam-Agent\u964d\u4f4e\u4e86CFD\u7684\u4e13\u4e1a\u95e8\u69db\uff0c\u5c55\u793a\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.18180", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18180", "abs": "https://arxiv.org/abs/2509.18180", "authors": ["Yang Wang", "Kai Li"], "title": "Large Language Models and Operations Research: A Structured Survey", "comment": null, "summary": "Operations research (OR) provides fundamental methodologies for complex\nsystem decision-making, with established applications in transportation, supply\nchain management, and production scheduling. Traditional approaches, which\ndepend on expert-based modeling and manual parameter adjustment, often face\nchallenges in handling large-scale, dynamic, and multi-constraint problems.\nRecently, large language models (LLMs) have shown potential to address these\nlimitations through semantic understanding, structured generation, and\nreasoning control. LLMs can translate natural language descriptions into\nmathematical models or executable code, generate heuristics, evolve algorithms,\nand directly tackle optimization tasks. This paper surveys recent progress on\nthe integration of LLMs into OR, organizing methods into three main directions:\nautomatic modeling, auxiliary optimization, and direct solving. It further\nreviews evaluation benchmarks and domain-specific applications, and summarizes\nkey open issues such as unstable semantic-to-structure mapping, fragmented\nresearch progress, limited generalization, and insufficient evaluation systems.\nFinally, the survey outlines possible research avenues for advancing the role\nof LLMs in OR.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5728\u8fd0\u7b79\u5b66 (OR) \u4e2d\u7684\u5e94\u7528\uff0c\u5c06\u65b9\u6cd5\u5206\u4e3a\u81ea\u52a8\u5efa\u6a21\u3001\u8f85\u52a9\u4f18\u5316\u548c\u76f4\u63a5\u6c42\u89e3\u4e09\u4e2a\u65b9\u5411\uff0c\u5e76\u6307\u51fa\u4e86\u8be5\u9886\u57df\u7684\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u7684\u8fd0\u7b79\u5b66\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5927\u578b\u3001\u52a8\u6001\u548c\u591a\u7ea6\u675f\u95ee\u9898\uff0c\u800cLLM\u6709\u6f5c\u529b\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\u3002", "method": "\u5bf9\u73b0\u6709\u5c06LLM\u96c6\u6210\u5230OR\u65b9\u6cd5\u7684\u6587\u732e\u8fdb\u884c\u7efc\u8ff0\uff0c\u6309\u81ea\u52a8\u5efa\u6a21\u3001\u8f85\u52a9\u4f18\u5316\u548c\u76f4\u63a5\u6c42\u89e3\u4e09\u4e2a\u65b9\u5411\u7ec4\u7ec7\u3002", "result": "\u7efc\u8ff0\u4e86LLM\u5728OR\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u3001\u8bc4\u4f30\u57fa\u51c6\u548c\u7279\u5b9a\u9886\u57df\u5e94\u7528\uff0c\u5e76\u6307\u51fa\u4e86\u5173\u952e\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u4f8b\u5982\u8bed\u4e49\u5230\u7ed3\u6784\u6620\u5c04\u7684\u4e0d\u7a33\u5b9a\u6027\u3001\u7814\u7a76\u8fdb\u5c55\u7684\u96f6\u6563\u6027\u3001\u6cdb\u5316\u80fd\u529b\u6709\u9650\u4ee5\u53ca\u8bc4\u4f30\u4f53\u7cfb\u4e0d\u8db3\u3002", "conclusion": "\u6982\u8ff0\u4e86\u63a8\u8fdbLLM\u5728OR\u4e2d\u4f5c\u7528\u7684\u53ef\u80fd\u7814\u7a76\u9014\u5f84\u3002"}}
{"id": "2509.18181", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18181", "abs": "https://arxiv.org/abs/2509.18181", "authors": ["Mustafa Sameen", "Xiaojian Zhang", "Xilei Zhao"], "title": "Synthesizing Attitudes, Predicting Actions (SAPA): Behavioral Theory-Guided LLMs for Ridesourcing Mode Choice Modeling", "comment": null, "summary": "Accurate modeling of ridesourcing mode choices is essential for designing and\nimplementing effective traffic management policies for reducing congestion,\nimproving mobility, and allocating resources more efficiently. Existing models\nfor predicting ridesourcing mode choices often suffer from limited predictive\naccuracy due to their inability to capture key psychological factors, and are\nfurther challenged by severe class imbalance, as ridesourcing trips comprise\nonly a small fraction of individuals' daily travel. To address these\nlimitations, this paper introduces the Synthesizing Attitudes, Predicting\nActions (SAPA) framework, a hierarchical approach that uses Large Language\nModels (LLMs) to synthesize theory-grounded latent attitudes to predict\nridesourcing choices. SAPA first uses an LLM to generate qualitative traveler\npersonas from raw travel survey data and then trains a propensity-score model\non demographic and behavioral features, enriched by those personas, to produce\nan individual-level score. Next, the LLM assigns quantitative scores to\ntheory-driven latent variables (e.g., time and cost sensitivity), and a final\nclassifier integrates the propensity score, latent-variable scores (with their\ninteraction terms), and observable trip attributes to predict ridesourcing mode\nchoice. Experiments on a large-scale, multi-year travel survey show that SAPA\nsignificantly outperforms state-of-the-art baselines, improving ridesourcing\nchoice predictions by up to 75.9% in terms of PR-AUC on a held-out test set.\nThis study provides a powerful tool for accurately predicting ridesourcing mode\nchoices, and provides a methodology that is readily transferable to various\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSAPA\u7684\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5408\u6210\u7406\u8bba\u57fa\u7840\u7684\u6f5c\u5728\u6001\u5ea6\u6765\u9884\u6d4b\u51fa\u884c\u65b9\u5f0f\u9009\u62e9\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u6355\u6349\u5173\u952e\u7684\u5fc3\u7406\u56e0\u7d20\u4e14\u5b58\u5728\u4e25\u91cd\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5bfc\u81f4\u9884\u6d4b\u7cbe\u5ea6\u6709\u9650\u3002", "method": "SAPA\u6846\u67b6\u9996\u5148\u4f7f\u7528LLM\u4ece\u51fa\u884c\u8c03\u67e5\u6570\u636e\u4e2d\u751f\u6210\u5b9a\u6027\u65c5\u5ba2\u753b\u50cf\uff0c\u7136\u540e\u8bad\u7ec3\u503e\u5411\u6027\u8bc4\u5206\u6a21\u578b\uff0c\u6700\u540e\u7ed3\u5408\u6f5c\u5728\u53d8\u91cf\u5f97\u5206\u548c\u53ef\u89c2\u6d4b\u7684\u51fa\u884c\u5c5e\u6027\u6765\u9884\u6d4b\u51fa\u884c\u65b9\u5f0f\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSAPA\u6846\u67b6\u7684PR-AUC\u6307\u6807\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e8675.9%\u3002", "conclusion": "SAPA\u6846\u67b6\u4e3a\u51c6\u786e\u9884\u6d4b\u51fa\u884c\u65b9\u5f0f\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u8be5\u65b9\u6cd5\u6613\u4e8e\u8fc1\u79fb\u5230\u5176\u4ed6\u5e94\u7528\u9886\u57df\u3002"}}
{"id": "2509.18186", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18186", "abs": "https://arxiv.org/abs/2509.18186", "authors": ["Nursultan Askarbekuly", "Timur Fayzrakhmanov", "Sladjan Babarogi\u0107", "Ivan Lukovi\u0107"], "title": "An Outcome-Based Educational Recommender System", "comment": null, "summary": "Most educational recommender systems are tuned and judged on click- or\nrating-based relevance, leaving their true pedagogical impact unclear. We\nintroduce OBER-an Outcome-Based Educational Recommender that embeds learning\noutcomes and assessment items directly into the data schema, so any algorithm\ncan be evaluated on the mastery it fosters. OBER uses a minimalist\nentity-relation model, a log-driven mastery formula, and a plug-in\narchitecture. Integrated into an e-learning system in non-formal domain, it was\nevaluated trough a two-week randomized split test with over 5 700 learners\nacross three methods: fixed expert trajectory, collaborative filtering (CF),\nand knowledge-based (KB) filtering. CF maximized retention, but the fixed path\nachieved the highest mastery. Because OBER derives business, relevance, and\nlearning metrics from the same logs, it lets practitioners weigh relevance and\nengagement against outcome mastery with no extra testing overhead. The\nframework is method-agnostic and readily extensible to future adaptive or\ncontext-aware recommenders.", "AI": {"tldr": "OBER\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5b66\u4e60\u6210\u679c\u7684\u6559\u80b2\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u5b66\u4e60\u6210\u679c\u548c\u8bc4\u4f30\u9879\u76ee\u5d4c\u5165\u6570\u636e\u6a21\u5f0f\uff0c\u76f4\u63a5\u8bc4\u4f30\u63a8\u8350\u7b97\u6cd5\u5bf9\u5b66\u751f\u638c\u63e1\u77e5\u8bc6\u7684\u4fc3\u8fdb\u4f5c\u7528\u3002", "motivation": "\u73b0\u6709\u6559\u80b2\u63a8\u8350\u7cfb\u7edf\u4e3b\u8981\u57fa\u4e8e\u70b9\u51fb\u6216\u8bc4\u5206\u8fdb\u884c\u8bc4\u4f30\uff0c\u5ffd\u7565\u4e86\u5176\u771f\u6b63\u7684\u6559\u5b66\u6548\u679c\u3002", "method": "\u6784\u5efa\u4e86\u57fa\u4e8e\u5b9e\u4f53\u5173\u7cfb\u7684\u7b80\u7ea6\u6a21\u578b\u3001\u57fa\u4e8e\u65e5\u5fd7\u7684\u638c\u63e1\u5ea6\u516c\u5f0f\u548c\u63d2\u4ef6\u5f0f\u67b6\u6784\uff0c\u5e76\u8fdb\u884c\u4e86\u4e3a\u671f\u4e24\u5468\u7684\u968f\u673a\u5206\u7ec4\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e86\u56fa\u5b9a\u4e13\u5bb6\u8def\u5f84\u3001\u534f\u540c\u8fc7\u6ee4\u548c\u57fa\u4e8e\u77e5\u8bc6\u7684\u8fc7\u6ee4\u4e09\u79cd\u65b9\u6cd5\u3002", "result": "\u534f\u540c\u8fc7\u6ee4\u6700\u5927\u5316\u4e86\u77e5\u8bc6\u7684\u4fdd\u6301\u7387\uff0c\u4f46\u56fa\u5b9a\u8def\u5f84\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u638c\u63e1\u5ea6\u3002OBER\u80fd\u540c\u65f6\u8861\u91cf\u4e1a\u52a1\u3001\u76f8\u5173\u6027\u548c\u5b66\u4e60\u6307\u6807\u3002", "conclusion": "OBER\u6846\u67b6\u65b9\u6cd5\u65e0\u5173\uff0c\u6613\u4e8e\u6269\u5c55\u5230\u672a\u6765\u7684\u81ea\u9002\u5e94\u6216\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u8350\u5668\uff0c\u4e3a\u8bc4\u4f30\u6559\u80b2\u63a8\u8350\u7cfb\u7edf\u7684\u6559\u5b66\u6548\u679c\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2509.18198", "categories": ["cs.AI", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.18198", "abs": "https://arxiv.org/abs/2509.18198", "authors": ["Rui Liu", "Zikang Wang", "Peng Gao", "Yu Shen", "Pratap Tokekar", "Ming Lin"], "title": "MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation", "comment": null, "summary": "Autonomous systems have advanced significantly, but challenges persist in\naccident-prone environments where robust decision-making is crucial. A single\nvehicle's limited sensor range and obstructed views increase the likelihood of\naccidents. Multi-vehicle connected systems and multi-modal approaches,\nleveraging RGB images and LiDAR point clouds, have emerged as promising\nsolutions. However, existing methods often assume the availability of all data\nmodalities and connected vehicles during both training and testing, which is\nimpractical due to potential sensor failures or missing connected vehicles. To\naddress these challenges, we introduce a novel framework MMCD (Multi-Modal\nCollaborative Decision-making) for connected autonomy. Our framework fuses\nmulti-modal observations from ego and collaborative vehicles to enhance\ndecision-making under challenging conditions. To ensure robust performance when\ncertain data modalities are unavailable during testing, we propose an approach\nbased on cross-modal knowledge distillation with a teacher-student model\nstructure. The teacher model is trained with multiple data modalities, while\nthe student model is designed to operate effectively with reduced modalities.\nIn experiments on $\\textit{connected autonomous driving with ground vehicles}$\nand $\\textit{aerial-ground vehicles collaboration}$, our method improves\ndriving safety by up to ${\\it 20.7}\\%$, surpassing the best-existing baseline\nin detecting potential accidents and making safe driving decisions. More\ninformation can be found on our website https://ruiiu.github.io/mmcd.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aMMCD\u7684\u591a\u6a21\u6001\u534f\u540c\u51b3\u7b56\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u4e8b\u6545\u6613\u53d1\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u6240\u6709\u6570\u636e\u6a21\u5f0f\u548c\u8054\u7f51\u8f66\u8f86\u90fd\u53ef\u7528\uff0c\u8fd9\u662f\u4e0d\u5207\u5b9e\u9645\u7684\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u7684\u5e08\u751f\u6a21\u578b\u7ed3\u6784\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u6709\u6548\u5730\u5904\u7406\u7f3a\u5931\u6570\u636e\u6a21\u5f0f\u7684\u60c5\u51b5\u3002", "result": "\u5728\u5730\u9762\u8f66\u8f86\u548c\u7a7a\u5730\u8f66\u8f86\u534f\u540c\u81ea\u52a8\u9a7e\u9a76\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5c06\u9a7e\u9a76\u5b89\u5168\u6027\u63d0\u9ad8\u4e86\u6700\u591a20.7%\u3002", "conclusion": "MMCD\u6846\u67b6\u63d0\u9ad8\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u7684\u51b3\u7b56\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.18215", "categories": ["cs.AI", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.18215", "abs": "https://arxiv.org/abs/2509.18215", "authors": ["Timotheus Kampik", "Kristijonas \u010cyras", "Jos\u00e9 Ruiz Alarc\u00f3n"], "title": "Change in Quantitative Bipolar Argumentation: Sufficient, Necessary, and Counterfactual Explanations", "comment": "The publisher's version contains a notation glitch in Example 3, 5th\n  line, first sub-script G should be G'. This has always been G' in authors'\n  version. Thanks to J. Lanser for pointing this out", "summary": "This paper presents a formal approach to explaining change of inference in\nQuantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions\nfrom a QBAF and updating the QBAF to then again draw conclusions (and so on),\nour approach traces changes -- which we call strength inconsistencies -- in the\npartial order over argument strengths that a semantics establishes on some\narguments of interest, called topic arguments. We trace the causes of strength\ninconsistencies to specific arguments, which then serve as explanations. We\nidentify sufficient, necessary, and counterfactual explanations for strength\ninconsistencies and show that strength inconsistency explanations exist if and\nonly if an update leads to strength inconsistency. We define a heuristic-based\napproach to facilitate the search for strength inconsistency explanations, for\nwhich we also provide an implementation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u65b9\u6cd5\u6765\u89e3\u91ca\u5b9a\u91cf\u53cc\u6781\u8bba\u8bc1\u6846\u67b6 (QBAF) \u4e2d\u63a8\u7406\u53d8\u5316\u3002", "motivation": "\u8ffd\u8e2a QBAF \u66f4\u65b0\u524d\u540e\u8bba\u8bc1\u5f3a\u5ea6\u504f\u5e8f\u7684\u53d8\u5316\uff0c\u89e3\u91ca\u63a8\u7406\u53d8\u5316\u7684\u539f\u56e0\u3002", "method": "\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u8ffd\u8e2a\u5f3a\u5ea6\u4e0d\u4e00\u81f4\u6027\uff0c\u8bc6\u522b\u5145\u5206\u3001\u5fc5\u8981\u548c\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5e76\u63d0\u4f9b\u57fa\u4e8e\u542f\u53d1\u5f0f\u641c\u7d22\u7684\u5b9e\u73b0\u3002", "result": "\u8bc6\u522b\u4e86\u5f3a\u5ea6\u4e0d\u4e00\u81f4\u6027\u7684\u5145\u5206\u3001\u5fc5\u8981\u548c\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5e76\u8bc1\u660e\u4e86\u5f3a\u5ea6\u4e0d\u4e00\u81f4\u6027\u89e3\u91ca\u7684\u5b58\u5728\u6027\u4e0e\u66f4\u65b0\u5bfc\u81f4\u5f3a\u5ea6\u4e0d\u4e00\u81f4\u6027\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u91ca QBAF \u63a8\u7406\u53d8\u5316\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u5b9e\u73b0\uff0c\u7528\u4e8e\u5bfb\u627e\u5f3a\u5ea6\u4e0d\u4e00\u81f4\u6027\u89e3\u91ca\u3002"}}
{"id": "2509.18216", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18216", "abs": "https://arxiv.org/abs/2509.18216", "authors": ["Amitava Das"], "title": "nDNA -- the Semantic Helix of Artificial Cognition", "comment": null, "summary": "As AI foundation models grow in capability, a deeper question emerges: What\nshapes their internal cognitive identity -- beyond fluency and output?\nBenchmarks measure behavior, but the soul of a model resides in its latent\ngeometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic\nrepresentation that captures this latent identity through the intrinsic\ngeometry of belief. At its core, nDNA is synthesized from three principled and\nindispensable dimensions of latent geometry: spectral curvature, which reveals\nthe curvature of conceptual flow across layers; thermodynamic length, which\nquantifies the semantic effort required to traverse representational\ntransitions through layers; and belief vector field, which delineates the\nsemantic torsion fields that guide a model's belief directional orientations.\nLike biological DNA, it encodes ancestry, mutation, and semantic inheritance,\nfound in finetuning and alignment scars, cultural imprints, and architectural\ndrift. In naming it, we open a new field: Neural Genomics, where models are not\njust tools, but digital semantic organisms with traceable inner cognition.\n  Modeling statement. We read AI foundation models as semantic fluid--dynamics:\nmeaning is transported through layers like fluid in a shaped conduit; nDNA is\nthe physics-grade readout of that flow -- a geometry-first measure of how\nmeaning is bent, paid for, and pushed -- yielding a stable, coordinate-free\nneural DNA fingerprint tied to on-input behavior; with this fingerprint we\ncross into biology: tracing lineages across pretraining, fine-tuning,\nalignment, pruning, distillation, and merges; measuring inheritance between\ncheckpoints; detecting drift as traits shift under new data or objectives; and,\nultimately, studying the evolution of artificial cognition to compare models,\ndiagnose risks, and govern change over time.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u795e\u7ecf DNA (nDNA) \u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6355\u6349 AI \u57fa\u7840\u6a21\u578b\u7684\u6f5c\u5728\u8ba4\u77e5\u7279\u5f81\uff0c\u7c7b\u4f3c\u4e8e\u751f\u7269 DNA\uff0c\u5b83\u7f16\u7801\u6a21\u578b\u7684\u8c31\u7cfb\u3001\u7a81\u53d8\u548c\u8bed\u4e49\u7ee7\u627f\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4fa7\u91cd\u4e8e\u6a21\u578b\u884c\u4e3a\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u5185\u5728\u7684\u8ba4\u77e5\u8eab\u4efd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6a21\u578b\u6f5c\u5728\u51e0\u4f55\u7ed3\u6784\u7684\u4e09\u4e2a\u7ef4\u5ea6\uff08\u8c31\u66f2\u7387\u3001\u70ed\u529b\u5b66\u957f\u5ea6\u548c\u4fe1\u5ff5\u5411\u91cf\u573a\uff09\u6765\u5408\u6210 nDNA\u3002", "result": "nDNA \u53ef\u4ee5\u7528\u4e8e\u8ffd\u8e2a\u6a21\u578b\u7684\u6f14\u5316\u3001\u8bca\u65ad\u98ce\u9669\u4ee5\u53ca\u63a7\u5236\u6a21\u578b\u968f\u65f6\u95f4\u7684\u53d8\u5316\u3002", "conclusion": "nDNA \u7684\u63d0\u51fa\u5f00\u521b\u4e86\u795e\u7ecf\u57fa\u56e0\u7ec4\u5b66\u9886\u57df\uff0c\u5c06 AI \u6a21\u578b\u89c6\u4e3a\u5177\u6709\u53ef\u8ffd\u8e2a\u5185\u5728\u8ba4\u77e5\u7684\u6570\u5b57\u8bed\u4e49\u6709\u673a\u4f53\u3002"}}
{"id": "2509.18218", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18218", "abs": "https://arxiv.org/abs/2509.18218", "authors": ["Kei-Sing Ng"], "title": "Similarity Field Theory: A Mathematical Framework for Intelligence", "comment": null, "summary": "We posit that persisting and transforming similarity relations form the\nstructural basis of any comprehensible dynamic system. This paper introduces\nSimilarity Field Theory, a mathematical framework that formalizes the\nprinciples governing similarity values among entities and their evolution. We\ndefine: (1) a similarity field $S: U \\times U \\to [0,1]$ over a universe of\nentities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed\nrelational field (asymmetry and non-transitivity are allowed); (2) the\nevolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by\n$p=0,1,2,\\ldots$; (3) concepts $K$ as entities that induce fibers\n$F_{\\alpha}(K) = { E \\in U \\mid S(E,K) \\ge \\alpha }$, i.e., superlevel sets of\nthe unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that\nproduces new entities. Within this framework, we formalize a generative\ndefinition of intelligence: an operator $G$ is intelligent with respect to a\nconcept $K$ if, given a system containing entities belonging to the fiber of\n$K$, it generates new entities that also belong to that fiber. Similarity Field\nTheory thus offers a foundational language for characterizing, comparing, and\nconstructing intelligent systems. We prove two theorems: (i) asymmetry blocks\nmutual inclusion; and (ii) stability requires either an anchor coordinate or\neventual confinement within a level set of $f$. These results ensure that the\nevolution of similarity fields is both constrained and interpretable,\nculminating in an exploration of how the framework allows us to interpret large\nlanguage models and use them as experimental probes into societal cognition.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u76f8\u4f3c\u6027\u573a\u7406\u8bba\uff0c\u4e00\u4e2a\u5c06\u76f8\u4f3c\u6027\u5173\u7cfb\u4f5c\u4e3a\u52a8\u6001\u7cfb\u7edf\u7ed3\u6784\u57fa\u7840\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5e76\u7528\u5b83\u6765\u5b9a\u4e49\u548c\u7814\u7a76\u667a\u80fd\u7cfb\u7edf\u3002", "motivation": "\u7406\u89e3\u548c\u6784\u5efa\u667a\u80fd\u7cfb\u7edf\u7684\u57fa\u7840\u662f\u7406\u89e3\u52a8\u6001\u7cfb\u7edf\u4e2d\u6301\u7eed\u53d8\u5316\u7684\u76f8\u4f3c\u6027\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u76f8\u4f3c\u6027\u573a\u7406\u8bba\uff0c\u5b9a\u4e49\u76f8\u4f3c\u6027\u573a\u3001\u7cfb\u7edf\u6f14\u5316\u3001\u6982\u5ff5\u548c\u751f\u6210\u7b97\u5b50\uff0c\u5e76\u8bc1\u660e\u4e86\u4e24\u4e2a\u5173\u4e8e\u76f8\u4f3c\u6027\u573a\u6f14\u5316\u7684\u5b9a\u7406\u3002", "result": "\u63d0\u51fa\u4e86\u76f8\u4f3c\u6027\u573a\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u7528\u5b83\u5f62\u5f0f\u5316\u5730\u5b9a\u4e49\u4e86\u667a\u80fd\uff0c\u8bc1\u660e\u4e86\u4e24\u4e2a\u5173\u4e8e\u76f8\u4f3c\u6027\u573a\u6f14\u5316\u7684\u5b9a\u7406\uff0c\u5e76\u63a2\u8ba8\u4e86\u5982\u4f55\u7528\u8be5\u6846\u67b6\u89e3\u91ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u76f8\u4f3c\u6027\u573a\u7406\u8bba\u4e3a\u523b\u753b\u3001\u6bd4\u8f83\u548c\u6784\u5efa\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u7840\u8bed\u8a00\uff0c\u5e76\u4e3a\u7814\u7a76\u793e\u4f1a\u8ba4\u77e5\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2509.18221", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18221", "abs": "https://arxiv.org/abs/2509.18221", "authors": ["Dingxin Lu", "Shurui Wu", "Xinyi Huang"], "title": "Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models", "comment": null, "summary": "With the rising global burden of chronic diseases and the multimodal and\nheterogeneous clinical data (medical imaging, free-text recordings, wearable\nsensor streams, etc.), there is an urgent need for a unified multimodal AI\nframework that can proactively predict individual health risks. We propose\nVL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer\nwith a large language model (LLM) inference head embedded in its top layer. The\nsystem builds on the dual-stream architecture of existing visual-linguistic\nmodels (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with\ncross-modal comparison and fine-grained alignment of radiological images,\nfundus maps, and wearable device photos with corresponding clinical narratives\nusing momentum update encoders and debiased InfoNCE losses; (ii) a time fusion\nblock that integrates irregular visit sequences into the causal Transformer\ndecoder through adaptive time interval position coding; (iii) a disease\nontology map adapter that injects ICD-10 codes into visual and textual channels\nin layers and infers comorbid patterns with the help of a graph attention\nmechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an\naverage AUROC of 0.90 with an expected calibration error of 2.7 percent.", "AI": {"tldr": "VL-RiskFormer\uff0c\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u591a\u6a21\u6001AI\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u4e2a\u4eba\u5065\u5eb7\u98ce\u9669\uff0c\u5728MIMIC-IV\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86AUC 0.90\u7684\u826f\u597d\u6548\u679c\u3002", "motivation": "\u5168\u7403\u6162\u6027\u75c5\u8d1f\u62c5\u65e5\u76ca\u589e\u52a0\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u7684\u591a\u6a21\u6001AI\u6846\u67b6\u6765\u9884\u6d4b\u4e2a\u4eba\u5065\u5eb7\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u5806\u53e0\u7684\u89c6\u89c9\u8bed\u8a00\u591a\u6a21\u6001Transformer\u6a21\u578bVL-RiskFormer\uff0c\u8be5\u6a21\u578b\u7ed3\u5408\u4e86\u52a8\u91cf\u66f4\u65b0\u7f16\u7801\u5668\u3001\u53bb\u504fInfoNCE\u635f\u5931\u3001\u65f6\u95f4\u878d\u5408\u6a21\u5757\u548c\u75be\u75c5\u672c\u4f53\u6620\u5c04\u9002\u914d\u5668\u7b49\u6280\u672f\u3002", "result": "\u5728MIMIC-IV\u7eb5\u5411\u961f\u5217\u4e0a\uff0cVL-RiskFormer\u7684\u5e73\u5747AUROC\u8fbe\u52300.90\uff0c\u9884\u671f\u6821\u51c6\u8bef\u5dee\u4e3a2.7%\u3002", "conclusion": "VL-RiskFormer\u4e3a\u591a\u6a21\u6001\u5065\u5eb7\u98ce\u9669\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.18226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18226", "abs": "https://arxiv.org/abs/2509.18226", "authors": ["Yu Fu", "Linyue Cai", "Ruoyu Wu", "Yong Zhao"], "title": "From \"What to Eat?\" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation", "comment": "5 pages, 3 figures, submitted to icassp 2026", "summary": "Personalized recipe recommendation faces challenges in handling fuzzy user\nintent, ensuring semantic accuracy, and providing sufficient detail coverage.\nWe propose ChefMind, a hybrid architecture combining Chain of Exploration\n(CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large\nLanguage Model (LLM). CoE refines ambiguous queries into structured conditions,\nKG offers semantic reasoning and interpretability, RAG supplements contextual\nculinary details, and LLM integrates outputs into coherent recommendations. We\nevaluate ChefMind on the Xiachufang dataset and manually annotated queries,\ncomparing it with LLM-only, KG-only, and RAG-only baselines. Results show that\nChefMind achieves superior performance in accuracy, relevance, completeness,\nand clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models.\nMoreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in\nhandling fuzzy demands.", "AI": {"tldr": "ChefMind\uff0c\u4e00\u79cd\u6df7\u5408\u67b6\u6784\uff0c\u7ed3\u5408\u4e86\u63a2\u7d22\u94fe\u3001\u77e5\u8bc6\u56fe\u8c31\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u4e2a\u6027\u5316\u98df\u8c31\u63a8\u8350\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u3001\u5b8c\u6574\u6027\u548c\u6e05\u6670\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u4e2a\u6027\u5316\u98df\u8c31\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u5904\u7406\u6a21\u7cca\u7684\u7528\u6237\u610f\u56fe\u3001\u4fdd\u8bc1\u8bed\u4e49\u51c6\u786e\u6027\u548c\u63d0\u4f9b\u8db3\u591f\u7684\u7ec6\u8282\u8986\u76d6\u3002", "method": "\u7ed3\u5408\u63a2\u7d22\u94fe\uff08CoE\uff09\u3001\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6df7\u5408\u67b6\u6784\u3002", "result": "\u5728Xiachufang\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cChefMind\u7684\u5e73\u5747\u5f97\u5206\uff088.7\uff09\u663e\u8457\u9ad8\u4e8e\u57fa\u7ebf\u6a21\u578b\uff086.4-6.7\uff09\uff0c\u5e76\u4e14\u5c06\u672a\u5904\u7406\u67e5\u8be2\u51cf\u5c11\u52301.6%\u3002", "conclusion": "ChefMind\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u7cca\u7528\u6237\u610f\u56fe\u548c\u7ec6\u8282\u8986\u76d6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e3a\u4e2a\u6027\u5316\u98df\u8c31\u63a8\u8350\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u51c6\u786e\u3001\u5b8c\u6574\u548c\u6e05\u6670\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.18229", "categories": ["cs.AI", "70, 74, 76, 80"], "pdf": "https://arxiv.org/pdf/2509.18229", "abs": "https://arxiv.org/abs/2509.18229", "authors": ["Anthony Patera", "Rohan Abeyaratne"], "title": "An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems", "comment": null, "summary": "Generative AI, and specifically GPT, can produce a remarkable solution to a\nmechanical engineering analysis problem - but also, on occasion, a flawed\nsolution. For example, an elementary mechanics problem is solved flawlessly in\none GPT instance and incorrectly in a subsequent GPT instance, with a success\nprobability of only 85%. This unreliability renders \"out-of-the-box\" GPT\nunsuitable for deployment in education or engineering practice. We introduce an\n\"N-Plus-1\" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering\nProblem Statements. Agency first launches N instantiations of Agent Solve to\nyield N independent Proposed Problem Solution Realizations; Agency then invokes\nAgent Compare to summarize and compare the N Proposed Problem Solution\nRealizations and to provide a Recommended Problem Solution. We argue from\nCondorcet's Jury Theorem that, for a Problem Statement characterized by\nper-Solve success probability greater than 1/2 (and N sufficiently large), the\nPredominant (Agent Compare) Proposed Problem Solution will, with high\nprobability, correspond to a Correct Proposed Problem Solution. Furthermore,\nAgent Compare can also incorporate aspects of Secondary (Agent Compare)\nProposed Problem Solutions, in particular when the latter represent alternative\nProblem Statement interpretations - different Mathematical Models - or\nalternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a\ncommercial multi-agent model, show similarities in design and performance, but\nalso important differences in emphasis: our Agency focuses on transparency and\npedagogical value.", "AI": {"tldr": "\u5229\u7528\u591a\u4e2aGPT\u5b9e\u4f8b\u5206\u6790\u673a\u68b0\u5de5\u7a0b\u95ee\u9898\uff0c\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709GPT\u6a21\u578b\u5728\u673a\u68b0\u5de5\u7a0b\u95ee\u9898\u6c42\u89e3\u4e0a\u7684\u53ef\u9760\u6027\u4e0d\u8db3\uff08\u4ec585%\uff09\u3002", "method": "\u63d0\u51faN+1\u4ee3\u7406\u6a21\u578b\uff0c\u5305\u542bN\u4e2a\u72ec\u7acb\u7684\u6c42\u89e3\u4ee3\u7406\u548c\u4e00\u4e2a\u6bd4\u8f83\u4ee3\u7406\uff0c\u901a\u8fc7\u6bd4\u8f83\u591a\u4e2a\u7ed3\u679c\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "result": "\u4e0e\u5546\u4e1a\u591a\u4ee3\u7406\u6a21\u578bGrok Heavy\u76f8\u6bd4\uff0c\u5177\u6709\u76f8\u4f3c\u6027\u80fd\uff0c\u4f46\u5728\u900f\u660e\u5ea6\u548c\u6559\u5b66\u4ef7\u503c\u65b9\u9762\u6709\u6240\u4fa7\u91cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8GPT\u5728\u673a\u68b0\u5de5\u7a0b\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u5e76\u5177\u6709\u8f83\u9ad8\u7684\u6559\u5b66\u4ef7\u503c\u3002"}}
{"id": "2509.18230", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18230", "abs": "https://arxiv.org/abs/2509.18230", "authors": ["Zihan Dong", "Xinyu Fan", "Zixiang Tang", "Yunqing Li"], "title": "Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces", "comment": null, "summary": "Controlling desktop applications via software remains a fundamental yet\nunder-served problem. Existing multi-modal large language models (MLLMs) ingest\nscreenshots and task instructions to generate keystrokes and mouse events, but\nthey suffer from prohibitive inference latency, poor sample efficiency on\nlong-horizon sparse-reward tasks, and infeasible on-device deployment. We\nintroduce a lightweight hierarchical reinforcement learning framework,\nComputerAgent, that formulates OS control as a two-level option process\n(manager and subpolicy), employs a triple-modal state encoder (screenshot, task\nID, numeric state) to handle visual and contextual diversity, integrates\nmeta-actions with an early-stop mechanism to reduce wasted interactions, and\nuses a compact vision backbone plus small policy networks for on-device\ninference (15M parameters). On a suite of 135 real-world desktop tasks,\nComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on\nhard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on\nsimple scenarios while reducing model size by over four orders of magnitude and\nhalving inference time. These results demonstrate that hierarchical RL offers a\npractical, scalable alternative to monolithic MLLM-based automation for\ncomputer control.", "AI": {"tldr": "ComputerAgent\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u684c\u9762\u5e94\u7528\u8f6f\u4ef6\u63a7\u5236\u6548\u7387\uff0c\u5e76\u5728\u6a21\u578b\u5927\u5c0f\u548c\u63a8\u7406\u65f6\u95f4\u4e0a\u53d6\u5f97\u4e86\u91cd\u5927\u7a81\u7834\u3002", "motivation": "\u73b0\u6709\u8de8\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a7\u5236\u684c\u9762\u5e94\u7528\u5b58\u5728\u5ef6\u8fdf\u9ad8\u3001\u6837\u672c\u6548\u7387\u4f4e\u548c\u8bbe\u5907\u90e8\u7f72\u56f0\u96be\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6ComputerAgent\uff0c\u5305\u542b\u53cc\u5c42\u9009\u9879\u8fc7\u7a0b\uff08\u7ba1\u7406\u5668\u548c\u5b50\u7b56\u7565\uff09\u3001\u4e09\u6a21\u6001\u72b6\u6001\u7f16\u7801\u5668\uff08\u5c4f\u5e55\u622a\u56fe\u3001\u4efb\u52a1ID\u3001\u6570\u503c\u72b6\u6001\uff09\u3001\u5143\u52a8\u4f5c\u4e0e\u63d0\u524d\u505c\u6b62\u673a\u5236\u4ee5\u53ca\u7d27\u51d1\u578b\u89c6\u89c9\u4e3b\u5e72\u7f51\u7edc\u548c\u5c0f\u578b\u7b56\u7565\u7f51\u7edc\u3002", "result": "\u5728135\u4e2a\u771f\u5b9e\u4e16\u754c\u684c\u9762\u4efb\u52a1\u4e2d\uff0cComputerAgent\u5728\u7b80\u5355\u4efb\u52a1\uff08<8\u6b65\uff09\u4e0a\u7684\u6210\u529f\u7387\u8fbe\u523092.1%\uff0c\u5728\u56f0\u96be\u4efb\u52a1\uff08>=8\u6b65\uff09\u4e0a\u7684\u6210\u529f\u7387\u8fbe\u523058.8%\uff0c\u4e0e2000\u4ebf\u53c2\u6570\u7684MLLM\u57fa\u7ebf\u5728\u7b80\u5355\u573a\u666f\u4e0b\u6027\u80fd\u76f8\u5f53\u751a\u81f3\u66f4\u597d\uff0c\u540c\u65f6\u6a21\u578b\u5927\u5c0f\u51cf\u5c11\u4e86\u56db\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\uff0c\u63a8\u7406\u65f6\u95f4\u51cf\u5c11\u4e86\u4e00\u534a\u3002", "conclusion": "\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u4e3a\u8ba1\u7b97\u673a\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u5355\u4f53MLLM\u65b9\u6cd5\u3002"}}
