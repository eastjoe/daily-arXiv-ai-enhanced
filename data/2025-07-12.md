<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
*Javal Vyas,Mehmet Mercangoz*

Main category: cs.AI

TL;DR: 利用大型语言模型 (LLM) 结合有限状态机 (FSM) 和反馈循环，实现化学过程的离散故障恢复规划和连续过程控制的统一框架，取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 现代化学过程的复杂性日益增加，以及劳动力短缺和复杂的故障场景，对结合符号推理和自适应控制的新型自动化范式提出了需求。

Method: 该研究采用了一种基于大型语言模型 (LLM) 的代理框架，该框架包含三个主要组件：规划代理、模拟代理和验证-重提示循环。规划代理利用 LLM 规划 FSM 中的恢复序列，模拟代理执行并检查每个转换，验证-重提示循环迭代地细化无效的计划。

Result: 在案例研究 1 中，GPT-4o 和 GPT-4o-mini 在 180 个随机生成的 FSM 中实现了 100% 的有效路径成功率。在案例研究 2 中，该框架在实验室 TCLab 平台上实现了与经典 PID 控制类似的性能，同时展现了提示循环在处理非线性动力学中的关键作用。

Conclusion: 该研究提出了一种利用大型语言模型 (LLM) 统一离散故障恢复规划和连续过程控制的框架，并在化学工程自动化中取得了成功。该框架结合了有限状态机 (FSM) 和反馈循环，提高了系统的鲁棒性和适应性。

Abstract: The increasing complexity of modern chemical processes, coupled with
workforce shortages and intricate fault scenarios, demands novel automation
paradigms that blend symbolic reasoning with adaptive control. In this work, we
introduce a unified agentic framework that leverages large language models
(LLMs) for both discrete fault-recovery planning and continuous process control
within a single architecture. We adopt Finite State Machines (FSMs) as
interpretable operating envelopes: an LLM-driven planning agent proposes
recovery sequences through the FSM, a Simulation Agent executes and checks each
transition, and a Validator-Reprompting loop iteratively refines invalid plans.
In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25
states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path
success within five reprompts-outperforming open-source LLMs in both accuracy
and latency. In Case Study 2, the same framework modulates dual-heater inputs
on a laboratory TCLab platform (and its digital twin) to maintain a target
average temperature under persistent asymmetric disturbances. Compared to
classical PID control, our LLM-based controller attains similar performance,
while ablation of the prompting loop reveals its critical role in handling
nonlinear dynamics. We analyze key failure modes-such as instruction following
lapses and coarse ODE approximations. Our results demonstrate that, with
structured feedback and modular agents, LLMs can unify high-level symbolic
planningand low-level continuous control, paving the way towards resilient,
language-driven automation in chemical engineering.

</details>


### [2] [BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks](https://arxiv.org/abs/2507.07134)
*Mridula Vijendran,Shuang Chen,Jingjing Deng,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: BOOST 方法有效降低了艺术分类中 AI 模型的偏差，提高了公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的 AI 模型在艺术分类任务中存在偏差问题，尤其是在处理 OOD 数据时，这些偏差会影响模型的公平性和准确性。

Method: 提出了一种名为 BOOST 的 OOD 感知模型偏差自适应采样方法，该方法通过动态调整温度缩放和采样概率来促进所有类别的更公平表示。并提出了一种新的指标 SODC 来评估类间分离和每个类的偏差减少。

Result: BOOST 方法能够有效降低艺术分类模型的类间偏差，并在 KaoKore 和 PACS 数据集上取得了良好的效果，该方法能够在高性能和公平性之间取得平衡。

Conclusion: 提出了一种新的 OOD 感知模型偏差自适应采样方法 BOOST，用于解决 AI 模型在艺术分类中存在的偏差问题，并在 KaoKore 和 PACS 数据集上进行了评估，结果表明该方法能够在高性能和公平性之间取得平衡。

Abstract: The pervasive issue of bias in AI presents a significant challenge to
painting classification, and is getting more serious as these systems become
increasingly integrated into tasks like art curation and restoration. Biases,
often arising from imbalanced datasets where certain artistic styles dominate,
compromise the fairness and accuracy of model predictions, i.e., classifiers
are less accurate on rarely seen paintings. While prior research has made
strides in improving classification performance, it has largely overlooked the
critical need to address these underlying biases, that is, when dealing with
out-of-distribution (OOD) data. Our insight highlights the necessity of a more
robust approach to bias mitigation in AI models for art classification on
biased training data. We propose a novel OOD-informed model bias adaptive
sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It
addresses these challenges by dynamically adjusting temperature scaling and
sampling probabilities, thereby promoting a more equitable representation of
all classes. We evaluate our proposed approach to the KaoKore and PACS
datasets, focusing on the model's ability to reduce class-wise bias. We further
propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to
assess class-wise separation and per-class bias reduction. Our method
demonstrates the ability to balance high performance with fairness, making it a
robust solution for unbiasing AI models in the art domain.

</details>


### [3] [State-Inference-Based Prompting for Natural Language Trading with Game NPCs](https://arxiv.org/abs/2507.07203)
*Minkyung Kim,Junsik Kim,Hwidong Bae,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: SIBP improves large language model reliability in game trading through state inference and context-aware prompting, achieving high accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: Current large language models struggle with rule-governed trading systems due to rule violations like item hallucinations and calculation errors, eroding player trust.

Method: Decomposes trading into six states within a unified prompt framework, implementing context-aware item referencing and placeholder-based price calculations.

Result: Evaluation across 100 trading dialogues demonstrates >97% state compliance, >95% referencing accuracy, and 99.7% calculation precision. SIBP outperforms baseline approaches while maintaining computational efficiency.

Conclusion: State-Inference-Based Prompting (SIBP) enables reliable and trustworthy NPC interactions in commercial games by addressing rule violations in large language models during dynamic game interactions, achieving high accuracy in state compliance, referencing, and calculation.

Abstract: Large Language Models enable dynamic game interactions but struggle with
rule-governed trading systems. Current implementations suffer from rule
violations, such as item hallucinations and calculation errors, that erode
player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable
trading through autonomous dialogue state inference and context-specific rule
adherence. The approach decomposes trading into six states within a unified
prompt framework, implementing context-aware item referencing and
placeholder-based price calculations. Evaluation across 100 trading dialogues
demonstrates >97% state compliance, >95% referencing accuracy, and 99.7%
calculation precision. SIBP maintains computational efficiency while
outperforming baseline approaches, establishing a practical foundation for
trustworthy NPC interactions in commercial games.

</details>


### [4] [Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains](https://arxiv.org/abs/2507.07217)
*Zili Wang,Frank Montabon,Kristin Yvonne Rozier*

Main category: cs.AI

TL;DR: 利用神经符号方法和LLM，结合问题树方法，有效识别非法供应链活动，并比较人工与机器分类的差异。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法需要大量数据，而非法供应链数据稀疏且不可靠，因此需要一种能够自动检测新模式的方法。

Method: 神经符号方法、问题树方法、LLM查询

Result: 提出了一种基于问题树的LLM查询方法，用于系统地评估人工和机器对新闻文章中强迫劳动相关信息的分类差异，并探究了神经符号方法在识别供应链非法活动中的有效性。

Conclusion: 本文探究了神经符号方法在识别供应链非法活动中的应用，并比较了人工和自动特征提取的有效性，提出了一种基于问题树的LLM查询方法，用于评估新闻文章中强迫劳动相关信息的分类差异。

Abstract: Supply chain networks are complex systems that are challenging to analyze;
this problem is exacerbated when there are illicit activities involved in the
supply chain, such as counterfeit parts, forced labor, or human trafficking.
While machine learning (ML) can find patterns in complex systems like supply
chains, traditional ML techniques require large training data sets. However,
illicit supply chains are characterized by very sparse data, and the data that
is available is often (purposely) corrupted or unreliable in order to hide the
nature of the activities. We need to be able to automatically detect new
patterns that correlate with such illegal activity over complex, even temporal
data, without requiring large training data sets. We explore neurosymbolic
methods for identifying instances of illicit activity in supply chains and
compare the effectiveness of manual and automated feature extraction from news
articles accurately describing illicit activities uncovered by authorities. We
propose a question tree approach for querying a large language model (LLM) to
identify and quantify the relevance of articles. This enables a systematic
evaluation of the differences between human and machine classification of news
articles related to forced labor in supply chains.

</details>


### [5] [Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](https://arxiv.org/abs/2507.07257)
*Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekiou,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet*

Main category: cs.AI

TL;DR: 多智能体系统cmbagent自动化科学研究，在宇宙学参数测量任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动化科学研究任务，提高效率。

Method: 采用规划与控制策略协调代理工作流程，每个代理负责不同的任务（例如，检索科学论文和代码库、编写代码、解释结果、评论其他代理的输出）。

Result: 在博士级别的宇宙学任务（使用超新星数据测量宇宙学参数）中取得成功，并在两个基准测试集上表现优于最先进的LLM。

Conclusion: cmbagent，一个由约30个大型语言模型(LLM)代理组成的多智能体系统，成功地自动化了科学研究任务，并在宇宙学参数测量任务中表现优于最先进的LLM。

Abstract: We present a multi-agent system for automation of scientific research tasks,
cmbagent. The system is formed by about 30 Large Language Model (LLM) agents
and implements a Planning & Control strategy to orchestrate the agentic
workflow, with no human-in-the-loop at any point. Each agent specializes in a
different task (performing retrieval on scientific papers and codebases,
writing code, interpreting results, critiquing the output of other agents) and
the system is able to execute code locally. We successfully apply cmbagent to
carry out a PhD level cosmology task (the measurement of cosmological
parameters using supernova data) and evaluate its performance on two benchmark
sets, finding superior performance over state-of-the-art LLMs. The source code
is available on GitHub, demonstration videos are also available, and the system
is deployed on HuggingFace and will be available on the cloud.

</details>


### [6] [Application of LLMs to Multi-Robot Path Planning and Task Allocation](https://arxiv.org/abs/2507.07302)
*Ashish Kumar*

Main category: cs.AI

TL;DR: 利用大型语言模型提升多智能体强化学习的探索效率


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中高效探索是一个挑战，本文研究利用专家探索来解决这个问题。

Method: 将大型语言模型用作专家规划器，以改进多智能体强化学习中的探索。

Result: 研究了大型语言模型在多智能体基于规划的任务中的应用，以提高探索效率。

Conclusion: 本文研究了利用大型语言模型作为专家规划器来提高多智能体强化学习中基于规划的任务的探索效率。

Abstract: Efficient exploration is a well known problem in deep reinforcement learning
and this problem is exacerbated in multi-agent reinforcement learning due the
intrinsic complexities of such algorithms. There are several approaches to
efficiently explore an environment to learn to solve tasks by multi-agent
operating in that environment, of which, the idea of expert exploration is
investigated in this work. More specifically, this work investigates the
application of large-language models as expert planners for efficient
exploration in planning based tasks for multiple agents.

</details>


### [7] [ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning](https://arxiv.org/abs/2507.07306)
*Yichen Lu,Wei Dai,Jiaen Liu,Ching Wing Kwok,Zongheng Wu,Xudong Xiao,Ao Sun,Sheng Fu,Jianyuan Zhan,Yian Wang,Takatomo Saito,Sicheng Lai*

Main category: cs.AI

TL;DR: ViDove是一个多模态翻译代理系统，利用视觉和上下文信息，显著提高了翻译质量，并创建了新的基准测试DoveBench。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的翻译代理通常仅限于文本输入，ViDove旨在解决这一问题，以实现多模态输入。

Method: ViDove利用视觉和上下文背景信息来增强翻译过程，集成了多模态记忆系统和长短期记忆模块，并加入了领域特定知识。

Result: BLEU分数提高28%，SubER提高15%，并创建了新的基准测试DoveBench。

Conclusion: ViDove系统在字幕生成和通用翻译任务中取得了显著更高的翻译质量，BLEU分数提高了28%，SubER提高了15%。

Abstract: LLM-based translation agents have achieved highly human-like translation
results and are capable of handling longer and more complex contexts with
greater efficiency. However, they are typically limited to text-only inputs. In
this paper, we introduce ViDove, a translation agent system designed for
multimodal input. Inspired by the workflow of human translators, ViDove
leverages visual and contextual background information to enhance the
translation process. Additionally, we integrate a multimodal memory system and
long-short term memory modules enriched with domain-specific knowledge,
enabling the agent to perform more accurately and adaptively in real-world
scenarios. As a result, ViDove achieves significantly higher translation
quality in both subtitle generation and general translation tasks, with a 28%
improvement in BLEU scores and a 15% improvement in SubER compared to previous
state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark
for long-form automatic video subtitling and translation, featuring 17 hours of
high-quality, human-annotated data. Our code is available here:
https://github.com/pigeonai-org/ViDove

</details>


### [8] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

Main category: cs.AI

TL;DR: 外部过滤器无法保证大型语言模型的安全，需要考虑模型内部的安全机制。


<details>
  <summary>Details</summary>
Motivation: 关注LLM潜在的滥用以生成有害内容。

Method: 研究了对大型语言模型(LLM)进行安全过滤的计算挑战。

Result: 证明了在过滤提示和输出方面都存在计算挑战。

Conclusion: 安全无法通过设计LLM内部(架构和权重)外部的过滤器来实现;特别是，对LLM的黑盒访问是不够的。

Abstract: With the increased deployment of large language models (LLMs), one concern is
their potential misuse for generating harmful content. Our work studies the
alignment challenge, with a focus on filters to prevent the generation of
unsafe information. Two natural points of intervention are the filtering of the
input prompt before it reaches the model, and filtering the output after
generation. Our main results demonstrate computational challenges in filtering
both prompts and outputs. First, we show that there exist LLMs for which there
are no efficient prompt filters: adversarial prompts that elicit harmful
behavior can be easily constructed, which are computationally indistinguishable
from benign prompts for any efficient filter. Our second main result identifies
a natural setting in which output filtering is computationally intractable. All
of our separation results are under cryptographic hardness assumptions. In
addition to these core findings, we also formalize and study relaxed mitigation
approaches, demonstrating further computational barriers. We conclude that
safety cannot be achieved by designing filters external to the LLM internals
(architecture and weights); in particular, black-box access to the LLM will not
suffice. Based on our technical results, we argue that an aligned AI system's
intelligence cannot be separated from its judgment.

</details>


### [9] [Supply Chain Optimization via Generative Simulation and Iterative Decision Policies](https://arxiv.org/abs/2507.07355)
*Haoyue Bai,Haoyu Wang,Nanxu Gong,Xinyuan Wang,Wangyang Ying,Haifeng Chen,Yanjie Fu*

Main category: cs.AI

TL;DR: Sim-to-Dec框架通过结合生成式模拟和智能决策算法，有效提高供应链运输的效率和利润。


<details>
  <summary>Details</summary>
Motivation: 提高供应链运输的响应速度和经济效率，寻找合适的运输模式。

Method: Sim-to-Dec框架结合了生成式模拟模块和历史-未来双感知决策模型，利用自回归建模模拟连续状态变化，并通过端到端优化迭代细化决策模型。

Result: 在三个真实世界数据集上的大量实验表明，Sim-to-Dec显著提高了准时送达率和利润。

Conclusion: Sim-to-Dec框架显著提高了准时送达率和利润。

Abstract: High responsiveness and economic efficiency are critical objectives in supply
chain transportation, both of which are influenced by strategic decisions on
shipping mode. An integrated framework combining an efficient simulator with an
intelligent decision-making algorithm can provide an observable, low-risk
environment for transportation strategy design. An ideal simulation-decision
framework must (1) generalize effectively across various settings, (2) reflect
fine-grained transportation dynamics, (3) integrate historical experience with
predictive insights, and (4) maintain tight integration between simulation
feedback and policy refinement. We propose Sim-to-Dec framework to satisfy
these requirements. Specifically, Sim-to-Dec consists of a generative
simulation module, which leverages autoregressive modeling to simulate
continuous state changes, reducing dependence on handcrafted domain-specific
rules and enhancing robustness against data fluctuations; and a history-future
dual-aware decision model, refined iteratively through end-to-end optimization
with simulator interactions. Extensive experiments conducted on three
real-world datasets demonstrate that Sim-to-Dec significantly improves timely
delivery rates and profit.

</details>


### [10] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
*Zerui Yang,Yuwei Wan,Yinqiao Li,Yudai Matsuda,Tong Xie,Linqi Song*

Main category: cs.AI

TL;DR: DrugMCTS框架通过整合RAG、多agent协作和MCTS，在药物 repurposing 任务中取得显著成果，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的方法如微调或检索增强生成在处理科学领域推理问题时，面临计算开销高或无法充分利用结构化科学数据的问题。

Method: 提出了一种名为DrugMCTS的新框架，该框架整合了RAG、多agent协作和Monte Carlo Tree Search，并使用五个专业agent检索和分析分子和蛋白质信息，实现结构化和迭代推理。

Result: DrugMCTS在DrugBank和KIBA数据集上显著提高了召回率和鲁棒性，并超过了通用LLM和深度学习基线模型。

Conclusion: DrugMCTS框架在药物 repurposing 任务上取得了比Deepseek-R1高出20%的性能，在DrugBank和KIBA数据集上展现出更高的召回率和鲁棒性，证明了结构化推理、基于agent的协作和反馈驱动搜索机制的重要性。

Abstract: Recent advances in large language models have demonstrated considerable
potential in scientific domains such as drug discovery. However, their
effectiveness remains constrained when reasoning extends beyond the knowledge
acquired during pretraining. Conventional approaches, such as fine-tuning or
retrieval-augmented generation, face limitations in either imposing high
computational overhead or failing to fully exploit structured scientific data.
To overcome these challenges, we propose DrugMCTS, a novel framework that
synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree
Search for drug repurposing. The framework employs five specialized agents
tasked with retrieving and analyzing molecular and protein information, thereby
enabling structured and iterative reasoning. Without requiring domain-specific
fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by
over 20\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate
that DrugMCTS achieves substantially higher recall and robustness compared to
both general-purpose LLMs and deep learning baselines. Our results highlight
the importance of structured reasoning, agent-based collaboration, and
feedback-driven search mechanisms in advancing LLM applications for drug
discovery.

</details>


### [11] [StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](https://arxiv.org/abs/2507.07445)
*Weihao Tan,Changjiu Jiang,Yu Duan,Mingcong Lei,Jiageng Li,Yitian Hong,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: StarDojo 基准测试揭示了 AI 代理在生产生活模拟中的不足，GPT-4.1 成功率仅 12.7%。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试很少同时评估生产活动和社会互动，StarDojo旨在弥合这一差距。

Method: 基于星露谷物语的游戏环境StarDojo，评估AI代理在生产和生活模拟中的能力，涵盖耕作、制作、探索、战斗和社交互动五大领域。

Result: GPT-4.1 等最先进 MLLM 代理在 StarDojo 上表现不佳，成功率低，凸显了在复杂生产生活环境中构建鲁棒、开放式代理的挑战。

Conclusion: StarDojo 作为基准测试，暴露了现有最先进的多模态大型语言模型 (MLLM) 代理在视觉理解、多模态推理和低级操作方面的局限性，最好的模型 GPT-4.1 成功率仅为 12.7%。

Abstract: Autonomous agents navigating human society must master both production
activities and social interactions, yet existing benchmarks rarely evaluate
these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel
benchmark based on Stardew Valley, designed to assess AI agents in open-ended
production-living simulations. In StarDojo, agents are tasked to perform
essential livelihood activities such as farming and crafting, while
simultaneously engaging in social interactions to establish relationships
within a vibrant community. StarDojo features 1,000 meticulously curated tasks
across five key domains: farming, crafting, exploration, combat, and social
interactions. Additionally, we provide a compact subset of 100 representative
tasks for efficient model evaluation. The benchmark offers a unified,
user-friendly interface that eliminates the need for keyboard and mouse
control, supports all major operating systems, and enables the parallel
execution of multiple environment instances, making it particularly well-suited
for evaluating the most capable foundation agents, powered by multimodal large
language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents
demonstrate substantial limitations, with the best-performing model, GPT-4.1,
achieving only a 12.7% success rate, primarily due to challenges in visual
understanding, multimodal reasoning and low-level manipulation. As a
user-friendly environment and benchmark, StarDojo aims to facilitate further
research towards robust, open-ended agents in complex production-living
environments.

</details>


### [12] [Position: We Need An Algorithmic Understanding of Generative AI](https://arxiv.org/abs/2507.07544)
*Oliver Eberle,Thomas McGee,Hamza Giaffar,Taylor Webb,Ida Momennejad*

Main category: cs.AI

TL;DR: AlgEval框架旨在系统研究LLM的算法机制，通过分析潜在表示、注意力和推理时间计算等，理解LLM如何解决问题，并最终提高模型性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究更关注通过扩展模型规模来提高性能，缺乏对LLM底层算法的理论和实证理解。

Method: 提出AlgEval框架，结合自顶向下假设和自底向上测试（电路级分析注意力模式和隐藏状态）对LLM算法进行研究，以案例研究（涌现搜索算法）为例。

Result: 提出了AlgEval框架，并通过案例研究展示了其有效性，为理解LLM内部运作机制、提高训练效率和开发新型架构提供了新途径。

Conclusion: 该论文提出了AlgEval框架，用于系统研究大型语言模型（LLM）学习和使用的算法，旨在通过分析潜在表示、注意力和推理时间计算等来揭示LLM解决特定任务的算法机制。

Abstract: What algorithms do LLMs actually learn and use to solve problems? Studies
addressing this question are sparse, as research priorities are focused on
improving performance through scale, leaving a theoretical and empirical gap in
understanding emergent algorithms. This position paper proposes AlgEval: a
framework for systematic research into the algorithms that LLMs learn and use.
AlgEval aims to uncover algorithmic primitives, reflected in latent
representations, attention, and inference-time compute, and their algorithmic
composition to solve task-specific problems. We highlight potential
methodological paths and a case study toward this goal, focusing on emergent
search algorithms. Our case study illustrates both the formation of top-down
hypotheses about candidate algorithms, and bottom-up tests of these hypotheses
via circuit-level analysis of attention patterns and hidden states. The
rigorous, systematic evaluation of how LLMs actually solve tasks provides an
alternative to resource-intensive scaling, reorienting the field toward a
principled understanding of underlying computations. Such algorithmic
explanations offer a pathway to human-understandable interpretability, enabling
comprehension of the model's internal reasoning performance measures. This can
in turn lead to more sample-efficient methods for training and improving
performance, as well as novel architectures for end-to-end and multi-agent
systems.

</details>


### [13] [On Trustworthy Rule-Based Models and Explanations](https://arxiv.org/abs/2507.07576)
*Mohamed Siala,Jordi Planes,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 基于规则的机器学习模型存在负面方面，现有学习方法会产生此类问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型的可解释性在高风险领域至关重要，错误的解释会误导人类决策者。基于规则的模型虽然具有可解释性，但存在负重叠和冗余等问题。

Method: 分析基于规则的机器学习模型的负面方面（例如负重叠和冗余），并开发相应的分析算法。

Result: 开发了分析基于规则机器学习模型中负面方面的算法，并得出结论：现有常用工具学习到的模型存在这些负面方面。

Conclusion: 现有学习基于规则的机器学习模型的常用工具会产生表现出一个或多个负面方面的规则集。

Abstract: A task of interest in machine learning (ML) is that of ascribing explanations
to the predictions made by ML models. Furthermore, in domains deemed high risk,
the rigor of explanations is paramount. Indeed, incorrect explanations can and
will mislead human decision makers. As a result, and even if interpretability
is acknowledged as an elusive concept, so-called interpretable models are
employed ubiquitously in high-risk uses of ML and data mining (DM). This is the
case for rule-based ML models, which encompass decision trees, diagrams, sets
and lists. This paper relates explanations with well-known undesired facets of
rule-based ML models, which include negative overlap and several forms of
redundancy. The paper develops algorithms for the analysis of these undesired
facets of rule-based systems, and concludes that well-known and widely used
tools for learning rule-based ML models will induce rule sets that exhibit one
or more negative facets.

</details>


### [14] [Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs](https://arxiv.org/abs/2507.07595)
*Zhixiang Su,Di Wang,Chunyan Miao*

Main category: cs.AI

TL;DR: 提出一种新的上下文池化方法，用于改进知识图谱链接预测，取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图神经网络的知识图谱链接预测模型的简单聚合方法效果并不显著，因此需要改进。

Method: 提出了一种名为上下文池化的图池化方法，该方法能够生成特定于查询的图，并通过邻域精度和邻域召回率指标评估邻居的逻辑相关性，从而识别出用于链接预测的逻辑相关邻居。

Result: 在三个公共数据集上，应用于两个最先进的模型，并在48个设置中的42个中取得了最先进的性能。

Conclusion: 本文提出了一种新颖的上下文池化方法，用于增强基于图神经网络的知识图谱链接预测模型的有效性，并在48个设置中的42个中取得了最先进的性能。

Abstract: Recent investigations on the effectiveness of Graph Neural Network
(GNN)-based models for link prediction in Knowledge Graphs (KGs) show that
vanilla aggregation does not significantly impact the model performance. In
this paper, we introduce a novel method, named Context Pooling, to enhance
GNN-based models' efficacy for link predictions in KGs. To our best of
knowledge, Context Pooling is the first methodology that applies graph pooling
in KGs. Additionally, Context Pooling is first-of-its-kind to enable the
generation of query-specific graphs for inductive settings, where testing
entities are unseen during training. Specifically, we devise two metrics,
namely neighborhood precision and neighborhood recall, to assess the neighbors'
logical relevance regarding the given queries, thereby enabling the subsequent
comprehensive identification of only the logically relevant neighbors for link
prediction. Our method is generic and assessed by being applied to two
state-of-the-art (SOTA) models on three public transductive and inductive
datasets, achieving SOTA performance in 42 out of 48 settings.

</details>


### [15] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

Main category: cs.AI

TL;DR: 利用微调的Llama模型有效提取急诊病历中的疫苗信息，提升疫苗安全监测效率


<details>
  <summary>Details</summary>
Motivation: 评估微调的Llama 3.2模型从急诊分诊记录中提取疫苗相关信息的能力，以支持近实时的疫苗安全监测。

Method: 微调Llama 32亿参数模型，并与提示工程模型和基于规则的方法进行比较。使用了模型量化以实现高效部署。

Result: 微调的Llama 30亿参数模型在提取疫苗名称的准确性方面优于其他模型。模型量化使其能够在资源受限的环境中高效部署。

Conclusion: 大型语言模型可用于自动化提取急诊室病历中的信息，从而支持疫苗安全监测和早期发现免疫后不良事件。

Abstract: This study evaluates fine-tuned Llama 3.2 models for extracting
vaccine-related information from emergency department triage notes to support
near real-time vaccine safety surveillance. Prompt engineering was used to
initially create a labeled dataset, which was then confirmed by human
annotators. The performance of prompt-engineered models, fine-tuned models, and
a rule-based approach was compared. The fine-tuned Llama 3 billion parameter
model outperformed other models in its accuracy of extracting vaccine names.
Model quantization enabled efficient deployment in resource-constrained
environments. Findings demonstrate the potential of large language models in
automating data extraction from emergency department notes, supporting
efficient vaccine safety surveillance and early detection of emerging adverse
events following immunization issues.

</details>


### [16] [Towards conservative inference in credal networks using belief functions: the case of credal chains](https://arxiv.org/abs/2507.07619)
*Marco Sangalli,Thomas Krak,Cassio de Campos*

Main category: cs.AI

TL;DR: 提出一种新的在链式credal网络中进行信念推理的框架，高效、保守，并与经典方法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 探索在credal网络中使用Dempster-Shafer理论进行信念推理。

Method: 在链式credal网络中传播不确定性，结合了计算速度和鲁棒的不确定性表示。将基于信念的推理与经典的灵敏度分析进行了比较。

Result: 数值结果突出了该框架内应用信念推理的优点和局限性，为了解其在链和credal网络中的实用性提供了见解。

Conclusion: 本文提出了一种新的基于Dempster-Shafer理论的框架，用于在链式credal网络中进行信念推理，该框架高效地产生保守区间，并对信念推理方法进行了形式化。

Abstract: This paper explores belief inference in credal networks using Dempster-Shafer
theory. By building on previous work, we propose a novel framework for
propagating uncertainty through a subclass of credal networks, namely chains.
The proposed approach efficiently yields conservative intervals through belief
and plausibility functions, combining computational speed with robust
uncertainty representation. Key contributions include formalizing belief-based
inference methods and comparing belief-based inference against classical
sensitivity analysis. Numerical results highlight the advantages and
limitations of applying belief inference within this framework, providing
insights into its practical utility for chains and for credal networks in
general.

</details>


### [17] [PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations](https://arxiv.org/abs/2507.07644)
*Fedor Rodionov,Abdelrahman Eldesokey,Michael Birsak,John Femiani,Bernard Ghanem,Peter Wonka*

Main category: cs.AI

TL;DR: 大型语言模型难以理解真实世界布局的空间和几何属性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型(LLM)在几何和空间推理方面的能力，并指出其不足之处。

Method: 构建PlanQA基准测试，用于评估大型语言模型中几何和空间推理能力。该基准测试基于室内场景的结构化表示（例如JSON或XML布局），包含多种问题类型，涵盖距离、可见性、最短路径等度量和拓扑推理，以及适用性、净空、平衡性和可用性等室内设计约束。

Result: 结果表明，虽然模型在浅层查询中可能成功，但在模拟物理约束、保持空间连贯性或在布局扰动下进行泛化方面常常失败。

Conclusion: PlanQA基准测试揭示了大型语言模型(LLM)在空间推理方面的不足，它们难以模拟物理约束、保持空间连贯性或在布局扰动下进行泛化。

Abstract: We introduce PlanQA, a diagnostic benchmark for evaluating geometric and
spatial reasoning in large-language models (LLMs). PlanQA is grounded in
structured representations of indoor scenes, such as kitchens, living rooms,
and bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The
benchmark includes diverse question types that test not only metric and
topological reasoning (e.g., distance, visibility, shortest paths) but also
interior design constraints such as affordance, clearance, balance, and
usability. Our results across a variety of frontier open-source and commercial
LLMs show that while models may succeed in shallow queries, they often fail to
simulate physical constraints, preserve spatial coherence, or generalize under
layout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they
do not consistently reason about real-world layouts. We hope that this
benchmark inspires new work on language models that can accurately infer and
manipulate spatial and geometric properties in practical settings.

</details>
