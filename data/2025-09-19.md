<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Unified Crew Planning and Replanning Optimization in Multi-Line Metro Systems Considering Workforce Heterogeneity](https://arxiv.org/abs/2509.14251)
*Qihang Chen*

Main category: cs.AI

TL;DR: 该论文提出了一种用于多线地铁人员规划和重新规划的统一优化框架，该框架能够有效协调多条地铁线路的运营，并在突发事件发生时快速调整计划，提高运营效率和服务可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单线地铁人员规划，缺乏对多线协调和突发事件快速重规划的考虑，而多线地铁网络的快速扩张使得有效的跨线协调和应急管理至关重要。

Method: 提出了一种基于层次时空网络模型的统一优化框架，并设计了高效的约束和公式来处理人员异质性和偏好，算法基于列生成和最短路径调整。

Result: 实验证明，该方法优于基准启发式算法，降低了成本，提高了任务完成率，尤其是在突发事件中处理紧急任务时效率显著提高。

Conclusion: 该研究强调了全局优化和跨线协调在多线地铁系统运营中的作用，为智慧城市公共交通的高效可靠运行提供了见解。

Abstract: Metro crew planning is a key component of smart city development as it
directly impacts the operational efficiency and service reliability of public
transportation. With the rapid expansion of metro networks, effective
multi-line scheduling and emergency management have become essential for
large-scale seamless operations. However, current research focuses primarily on
individual metro lines,with insufficient attention on cross-line coordination
and rapid replanning during disruptions. Here, a unified optimization framework
is presented for multi-line metro crew planning and replanning with
heterogeneous workforce. Specifically, a hierarchical time-space network model
is proposed to represent the unified crew action space, and computationally
efficient constraints and formulations are derived for the crew's heterogeneous
qualifications and preferences. Solution algorithms based on column generation
and shortest path adjustment are further developed, utilizing the proposed
network model. Experiments with real data from Shanghai and Beijing Metro
demonstrate that the proposed methods outperform benchmark heuristics in both
cost reduction and task completion,and achieve notable efficiency gains by
incorporating cross-line operations, particularly for urgent tasks during
disruptions. This work highlights the role of global optimization and
cross-line coordination in multi-line metro system operations, providing
insights into the efficient and reliable functioning of public transportation
in smart cities.

</details>


### [2] [From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing](https://arxiv.org/abs/2509.14289)
*Lanxiao Huang,Daksh Dave,Ming Jin,Tyler Cody,Peter Beling*

Main category: cs.AI

TL;DR: LLM在渗透测试中的有效性和可靠性仍不明确，该研究评估了多种基于LLM的渗透测试代理，并通过增强其核心功能（全局上下文记忆、代理间消息传递、上下文条件调用、自适应规划和实时监控）来提高其性能。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在渗透测试中的有效性和可靠性，并改进LLM代理的架构和功能。

Method: 对多种基于LLM的渗透测试代理（单代理和模块化设计）进行评估，并通过五个方面的增强来改进其性能。

Result: 定向增强显著提高了模块化代理的性能，尤其是在复杂的多步骤和实时渗透测试任务中。

Conclusion: 该研究表明，通过增强LLM代理的核心功能，可以显著提高其在渗透测试中的性能和可靠性。

Abstract: Large language models (LLMs) are increasingly used to automate or augment
penetration testing, but their effectiveness and reliability across attack
phases remain unclear. We present a comprehensive evaluation of multiple
LLM-based agents, from single-agent to modular designs, across realistic
penetration testing scenarios, measuring empirical performance and recurring
failure patterns. We also isolate the impact of five core functional
capabilities via targeted augmentations: Global Context Memory (GCM),
Inter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive
Planning (AP), and Real-Time Monitoring (RTM). These interventions support,
respectively: (i) context coherence and retention, (ii) inter-component
coordination and state management, (iii) tool use accuracy and selective
execution, (iv) multi-step strategic planning, error detection, and recovery,
and (v) real-time dynamic responsiveness. Our results show that while some
architectures natively exhibit subsets of these properties, targeted
augmentations substantially improve modular agent performance, especially in
complex, multi-step, and real-time penetration testing tasks.

</details>


### [3] [Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents](https://arxiv.org/abs/2509.14382)
*Daniel Röder,Akhil Juneja,Roland Roller,Sven Schmeier*

Main category: cs.AI

TL;DR: 该论文提出了一种模块化评估框架，用于对大型语言模型驱动的Web智能体的性能进行细粒度分析，以识别标准指标无法捕捉到的弱点。


<details>
  <summary>Details</summary>
Motivation: 当前对Web智能体的评估主要关注整体成功率，忽略了中间错误，限制了对失败模式的理解和系统的改进。

Method: 提出了一种将智能体流程分解成可解释阶段的模块化评估框架，并以SeeAct框架和Mind2Web数据集为例进行了案例研究。

Result: 该方法揭示了标准指标无法捕捉到的可操作的弱点，为构建更强大和更通用的Web智能体铺平了道路。

Conclusion: 细粒度的错误分析对于改进大型语言模型驱动的Web智能体至关重要，该论文提出的模块化评估框架为此提供了一种有效的方法。

Abstract: Web agents powered by large language models (LLMs) can autonomously perform
complex, multistep tasks in dynamic web environments. However, current
evaluations mostly focus on the overall success while overlooking intermediate
errors. This limits insight into failure modes and hinders systematic
improvement. This work analyzes existing benchmarks and highlights the lack of
fine-grained diagnostic tools. To address this gap, we propose a modular
evaluation framework that decomposes agent pipelines into interpretable stages
for detailed error analysis. Using the SeeAct framework and the Mind2Web
dataset as a case study, we show how this approach reveals actionable
weaknesses missed by standard metrics - paving the way for more robust and
generalizable web agents.

</details>


### [4] [VCBench: Benchmarking LLMs in Venture Capital](https://arxiv.org/abs/2509.14448)
*Rick Chen,Joseph Ternasky,Afriyie Samuel Kwesi,Ben Griffin,Aaron Ontoyin Yin,Zakari Salifu,Kelvin Amoaba,Xianling Mu,Fuat Alican,Yigit Ihlamur*

Main category: cs.AI

TL;DR: VCBench，首个预测风险投资创始人成功的基准测试，利用9000个匿名创始人资料，评估多个LLM模型的预测能力，结果表明顶级模型显著优于基线和人类基准。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试加速了人工智能通用发展，但缺乏针对风险投资领域稀疏信号和不确定结果的基准。

Method: 构建VCBench数据集（9000个匿名创始人资料），并用其评估9个最先进的LLM模型的预测能力。

Result: DeepSeek-V3的精度是基线的6倍多，GPT-4o的F0.5最高，大多数模型优于人类基准。

Conclusion: VCBench为风险投资领域AGI的评估提供了一个可复现且保护隐私的公共基准，推动社区协作发展。

Abstract: Benchmarks such as SWE-bench and ARC-AGI demonstrate how shared datasets
accelerate progress toward artificial general intelligence (AGI). We introduce
VCBench, the first benchmark for predicting founder success in venture capital
(VC), a domain where signals are sparse, outcomes are uncertain, and even top
investors perform modestly. At inception, the market index achieves a precision
of 1.9%. Y Combinator outperforms the index by a factor of 1.7x, while tier-1
firms are 2.9x better. VCBench provides 9,000 anonymized founder profiles,
standardized to preserve predictive features while resisting identity leakage,
with adversarial tests showing more than 90% reduction in re-identification
risk. We evaluate nine state-of-the-art large language models (LLMs).
DeepSeek-V3 delivers over six times the baseline precision, GPT-4o achieves the
highest F0.5, and most models surpass human benchmarks. Designed as a public
and evolving resource available at vcbench.com, VCBench establishes a
community-driven standard for reproducible and privacy-preserving evaluation of
AGI in early-stage venture forecasting.

</details>


### [5] [From Mimicry to True Intelligence (TI) - A New Paradigm for Artificial General Intelligence](https://arxiv.org/abs/2509.14474)
*Meltem Subasioglu,Nevzat Subasioglu*

Main category: cs.AI

TL;DR: 本文提出了一种基于认知架构的通用人工智能（AGI）新范式，并定义了可衡量的AGI等级，认为达到五级AGI即等同于真智能（TI）。


<details>
  <summary>Details</summary>
Motivation: 当前基于性能的AGI定义不足以指导研究，本文旨在提供一个机制化的AGI定义。

Method: 从人脑机制出发，定义了TI的六个核心组成部分（其中一个不可衡量），并据此提出了五级AGI分类体系。

Result: 提出了一个基于六个核心组成部分的TI定义和一个五级AGI分类体系，为AGI研究提供了清晰的路线图。

Conclusion: 达到五级AGI，即具备前五个可衡量组成部分的系统，在功能上与TI等效。

Abstract: The debate around Artificial General Intelligence (AGI) remains open due to
two fundamentally different goals: replicating human-like performance versus
replicating human-like cognitive processes. We argue that current
performance-based definitions are inadequate because they provide no clear,
mechanism-focused roadmap for research, and they fail to properly define the
qualitative nature of genuine intelligence. Drawing inspiration from the human
brain, we propose a new paradigm that shifts the focus from external mimicry to
the development of foundational cognitive architectures. We define True
Intelligence (TI) as a system characterized by six core components: embodied
sensory fusion, core directives, dynamic schemata creation, a
highly-interconnected multi-expert architecture, an orchestration layer, and
lastly, the unmeasurable quality of Interconnectedness, which we hypothesize
results in consciousness and a subjective experience. We propose a practical,
five-level taxonomy of AGI based on the number of the first five measurable
components a system exhibits. This framework provides a clear path forward with
developmental milestones that directly address the challenge of building
genuinely intelligent systems. We contend that once a system achieves Level-5
AGI by implementing all five measurable components, the difference between it
and TI remains as a purely philosophical debate. For practical purposes - and
given theories indicate consciousness is an emergent byproduct of integrated,
higher-order cognition - we conclude that a fifth-level AGI is functionally and
practically equivalent to TI. This work synthesizes diverse insights from
analytical psychology, schema theory, metacognition, modern brain architectures
and latest works in AI to provide the first holistic, mechanism-based
definition of AGI that offers a clear and actionable path for the research
community.

</details>


### [6] [Beyond the high score: Prosocial ability profiles of multi-agent populations](https://arxiv.org/abs/2509.14485)
*Marko Tesic,Yue Zhao,Joel Z. Leibo,Rakshit S. Trivedi,Jose Hernandez-Orallo*

Main category: cs.AI

TL;DR: "该论文使用贝叶斯方法评估了Melting Pot竞赛中多智能体系统的合作能力，发现高社会能力与高性能并非总是正相关，并指出顶级参赛者可能利用了评估框架的局限性。"


<details>
  <summary>Details</summary>
Motivation: "评估AI代理的社会能力需要复杂的环境，而Melting Pot竞赛旨在评估AI系统的合作能力。"

Method: "采用贝叶斯方法（Measurement Layouts）推断多智能体系统的能力特征。"

Result: "高社会能力与高性能并非总是正相关；顶级参赛者可能利用了评估框架的局限性；Measurement Layouts方法具有较高的预测准确性和可操作性。"

Conclusion: "Measurement Layouts方法为评估复杂社会环境下的AI系统提供了更透明和更普适的方法，并建议改进合作需求的标注和未来研究方向。"

Abstract: The development and evaluation of social capabilities in AI agents require
complex environments where competitive and cooperative behaviours naturally
emerge. While game-theoretic properties can explain why certain teams or agent
populations outperform others, more abstract behaviours, such as convention
following, are harder to control in training and evaluation settings. The
Melting Pot contest is a social AI evaluation suite designed to assess the
cooperation capabilities of AI systems. In this paper, we apply a Bayesian
approach known as Measurement Layouts to infer the capability profiles of
multi-agent systems in the Melting Pot contest. We show that these capability
profiles not only predict future performance within the Melting Pot suite but
also reveal the underlying prosocial abilities of agents. Our analysis
indicates that while higher prosocial capabilities sometimes correlate with
better performance, this is not a universal trend-some lower-scoring agents
exhibit stronger cooperation abilities. Furthermore, we find that
top-performing contest submissions are more likely to achieve high scores in
scenarios where prosocial capabilities are not required. These findings,
together with reports that the contest winner used a hard-coded solution
tailored to specific environments, suggest that at least one top-performing
team may have optimised for conditions where cooperation was not necessary,
potentially exploiting limitations in the evaluation framework. We provide
recommendations for improving the annotation of cooperation demands and propose
future research directions to account for biases introduced by different
testing environments. Our results demonstrate that Measurement Layouts offer
both strong predictive accuracy and actionable insights, contributing to a more
transparent and generalisable approach to evaluating AI systems in complex
social settings.

</details>


### [7] [DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction](https://arxiv.org/abs/2509.14507)
*Jian Chen,Zhenyan Chen,Xuming Hu,Peilin Zhou,Yining Hua,Han Fang,Cissy Hing Yee Choy,Xinmei Ke,Jingfeng Luo,Zixuan Yuan*

Main category: cs.AI

TL;DR: DeKeyNLU数据集和DeKeySQL模型提升了自然语言到SQL的转换准确率


<details>
  <summary>Details</summary>
Motivation: 现有的NL2SQL模型在任务分解和关键词提取方面存在不足，导致SQL生成错误率较高

Method: 构建DeKeyNLU数据集，包含1500个高质量标注的QA对；提出DeKeySQL模型，包含三个模块：用户问题理解、实体检索和SQL生成

Result: 在BIRD和Spider数据集上，DeKeySQL模型的准确率分别提升到69.10%和88.7%

Conclusion: DeKeyNLU数据集和DeKeySQL模型有效地提高了NL2SQL任务的性能

Abstract: Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that
simplifies database access for non-technical users by converting natural
language queries into SQL commands. Recent advancements, particularly those
integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)
reasoning, have made significant strides in enhancing NL2SQL performance.
However, challenges such as inaccurate task decomposition and keyword
extraction by LLMs remain major bottlenecks, often leading to errors in SQL
generation. While existing datasets aim to mitigate these issues by fine-tuning
models, they struggle with over-fragmentation of tasks and lack of
domain-specific keyword annotations, limiting their effectiveness. To address
these limitations, we present DeKeyNLU, a novel dataset which contains 1,500
meticulously annotated QA pairs aimed at refining task decomposition and
enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with
DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three
distinct modules for user question understanding, entity retrieval, and
generation to improve SQL generation accuracy. We benchmarked multiple model
configurations within DeKeySQL RAG pipeline. Experimental results demonstrate
that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy
on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.

</details>


### [8] [Rationality Check! Benchmarking the Rationality of Large Language Models](https://arxiv.org/abs/2509.14546)
*Zhilun Zhou,Jing Yi Wang,Nicholas Sukiennik,Chen Gao,Fengli Xu,Yong Li,James Evans*

Main category: cs.AI

TL;DR: 该论文提出了一种评估大型语言模型（LLM）理性性的基准测试方法，涵盖多个领域和模型，并提供了易于使用的工具包和实验结果。


<details>
  <summary>Details</summary>
Motivation: LLM展现出类人的能力，引发了LLM是否以及在什么情况下像人类一样思考和行动的担忧，因此需要评估其理性性。

Method: 提出一个涵盖广泛领域的LLM理性评估基准，包括易于使用的工具包、实验结果和分析。

Result: 创建了一个评估LLM理性性的基准，揭示了LLM与理想化人类理性的一致性和差异之处。

Conclusion: 该基准可作为开发人员和用户评估LLM理性性的基础工具。

Abstract: Large language models (LLMs), a recent advance in deep learning and machine
intelligence, have manifested astonishing capacities, now considered among the
most promising for artificial general intelligence. With human-like
capabilities, LLMs have been used to simulate humans and serve as AI assistants
across many applications. As a result, great concern has arisen about whether
and under what circumstances LLMs think and behave like real human agents.
Rationality is among the most important concepts in assessing human behavior,
both in thinking (i.e., theoretical rationality) and in taking action (i.e.,
practical rationality). In this work, we propose the first benchmark for
evaluating the omnibus rationality of LLMs, covering a wide range of domains
and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental
results, and analysis that illuminates where LLMs converge and diverge from
idealized human rationality. We believe the benchmark can serve as a
foundational tool for both developers and users of LLMs.

</details>


### [9] [(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration](https://arxiv.org/abs/2509.14547)
*Yi Lin,Lujin Zhao,Yijie Shi*

Main category: cs.AI

TL;DR: 该论文提出了一种用于自动化工作流构建的动态框架，该框架结合Q-table学习和任务特征评估，能够更高效地协调大型语言模型解决任务，并在四个基准数据集上取得了平均4.05%的改进，同时显著降低了成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖历史经验构建工作流，效率和适应性有限，该论文旨在构建一个能够灵活响应每个任务独特特征的框架。

Method: 该框架利用Q-table学习优化决策空间，并结合任务进度评估进行先验决策，选择合适的执行agent和工作流结构，同时包含冷启动初始化、提前停止和剪枝等机制。

Result: 在四个基准数据集上，该方法平均提升了4.05%，同时工作流构建和推理成本仅为现有方法的30.68%-48.31%。

Conclusion: 该论文提出的动态框架有效提高了大型语言模型工作流构建的效率和适应性，具有良好的应用前景。

Abstract: Recent studies have shown that carefully designed workflows coordinating
large language models(LLMs) significantly enhance task-solving capabilities
compared to using a single model. While an increasing number of works focus on
autonomous workflow construction, most existing approaches rely solely on
historical experience, leading to limitations in efficiency and adaptability.
We argue that while historical experience is valuable, workflow construction
should also flexibly respond to the unique characteristics of each task. To
this end, we propose an a priori dynamic framework for automated workflow
construction. Our framework first leverages Q-table learning to optimize the
decision space, guiding agent decisions and enabling effective use of
historical experience. At the same time, agents evaluate the current task
progress and make a priori decisions regarding the next executing agent,
allowing the system to proactively select the more suitable workflow structure
for each given task. Additionally, we incorporate mechanisms such as cold-start
initialization, early stopping, and pruning to further improve system
efficiency. Experimental evaluations on four benchmark datasets demonstrate the
feasibility and effectiveness of our approach. Compared to state-of-the-art
baselines, our method achieves an average improvement of 4.05%, while reducing
workflow construction and inference costs to only 30.68%-48.31% of those
required by existing methods.

</details>


### [10] [SynBench: A Benchmark for Differentially Private Text Generation](https://arxiv.org/abs/2509.14594)
*Yidan Sun,Viktor Schlegel,Srinivasan Nandakumar,Iqra Zahid,Yuping Wu,Yulong Wu,Hao Li,Jie Zhang,Warren Del-Pinto,Goran Nenadic,Siew Kei Lam,Anil Anthony Bharath*

Main category: cs.AI

TL;DR: 本文探究了在医疗和金融等高风险领域中，使用差分隐私生成合成数据用于训练生成式AI模型的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有数据脱敏方法不足以保护敏感数据，生成式AI模型在隐私保护方面也存在不足。

Method: 构建了一个全面的评估框架，基准测试了最先进的差分隐私文本生成方法和不同大小的LLM，并开发了一种针对合成文本的成员推理攻击方法。

Result: 研究发现，在差分隐私约束下生成高质量的特定领域合成数据仍然是一个挑战，并且公开数据集的使用可能会使隐私保证失效。

Conclusion: 需要更严格的隐私审核，并弥合开放领域和专业评估之间的差距，才能负责任地在隐私敏感、高风险环境中部署生成式AI。

Abstract: Data-driven decision support in high-stakes domains like healthcare and
finance faces significant barriers to data sharing due to regulatory,
institutional, and privacy concerns. While recent generative AI models, such as
large language models, have shown impressive performance in open-domain tasks,
their adoption in sensitive environments remains limited by unpredictable
behaviors and insufficient privacy-preserving datasets for benchmarking.
Existing anonymization methods are often inadequate, especially for
unstructured text, as redaction and masking can still allow re-identification.
Differential Privacy (DP) offers a principled alternative, enabling the
generation of synthetic data with formal privacy assurances. In this work, we
address these challenges through three key contributions. First, we introduce a
comprehensive evaluation framework with standardized utility and fidelity
metrics, encompassing nine curated datasets that capture domain-specific
complexities such as technical jargon, long-context dependencies, and
specialized document structures. Second, we conduct a large-scale empirical
study benchmarking state-of-the-art DP text generation methods and LLMs of
varying sizes and different fine-tuning strategies, revealing that high-quality
domain-specific synthetic data generation under DP constraints remains an
unsolved challenge, with performance degrading as domain complexity increases.
Third, we develop a membership inference attack (MIA) methodology tailored for
synthetic text, providing first empirical evidence that the use of public
datasets - potentially present in pre-training corpora - can invalidate claimed
privacy guarantees. Our findings underscore the urgent need for rigorous
privacy auditing and highlight persistent gaps between open-domain and
specialist evaluations, informing responsible deployment of generative AI in
privacy-sensitive, high-stakes settings.

</details>


### [11] [AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production](https://arxiv.org/abs/2509.14647)
*NVJK Kartik,Garvit Sapra,Rishav Hada,Nikhil Pareek*

Main category: cs.AI

TL;DR: AgentCompass框架用于大型语言模型(LLM)驱动智能工作流的监控和调试，通过多阶段分析流程识别、分类和量化错误，并支持持续学习。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法捕捉LLM驱动智能工作流的错误、涌现行为和系统性故障的风险。

Method: 构建AgentCompass框架，包含错误识别与分类、主题聚类、定量评分和策略总结等多阶段分析流程，并使用双重记忆系统(情景和语义)实现持续学习。

Result: 在真实场景和TRAIL基准测试中取得了最先进的结果，发现了人工标注中遗漏的关键问题。

Conclusion: AgentCompass是一个强大的、以开发者为中心的工具，用于可靠地监控和改进生产环境中的智能系统。

Abstract: With the growing adoption of Large Language Models (LLMs) in automating
complex, multi-agent workflows, organizations face mounting risks from errors,
emergent behaviors, and systemic failures that current evaluation methods fail
to capture. We present AgentCompass, the first evaluation framework designed
specifically for post-deployment monitoring and debugging of agentic workflows.
AgentCompass models the reasoning process of expert debuggers through a
structured, multi-stage analytical pipeline: error identification and
categorization, thematic clustering, quantitative scoring, and strategic
summarization. The framework is further enhanced with a dual memory
system-episodic and semantic-that enables continual learning across executions.
Through collaborations with design partners, we demonstrate the framework's
practical utility on real-world deployments, before establishing its efficacy
against the publicly available TRAIL benchmark. AgentCompass achieves
state-of-the-art results on key metrics, while uncovering critical issues
missed in human annotations, underscoring its role as a robust,
developer-centric tool for reliable monitoring and improvement of agentic
systems in production.

</details>


### [12] [Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory](https://arxiv.org/abs/2509.14662)
*Ming Li,Nan Zhang,Chenrui Fan,Hong Jiao,Yanbin Fu,Sydney Peters,Qingshu Xu,Robert Lissitz,Tianyi Zhou*

Main category: cs.AI

TL;DR: 该论文提出了一种利用Schoenfeld的事件理论分析大型推理模型（LRM）推理过程的新方法，构建了首个公开的细粒度机器推理分析基准。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型缺乏对推理结构的理解，该论文旨在通过认知框架分析模型推理过程。

Method: 应用Schoenfeld的事件理论，对模型生成的数学问题解答进行标注，构建数据集和标注指南。

Result: 构建了首个公开的细粒度机器推理分析基准，包含大型标注语料库和详细的标注指南，并初步揭示了LRM推理的独特模式。

Conclusion: 该框架为理解LRM认知提供了理论基础，有助于未来构建更可控、透明的推理系统。

Abstract: While Large Reasoning Models (LRMs) generate extensive chain-of-thought
reasoning, we lack a principled framework for understanding how these thoughts
are structured. In this paper, we introduce a novel approach by applying
Schoenfeld's Episode Theory, a classic cognitive framework for human
mathematical problem-solving, to analyze the reasoning traces of LRMs. We
annotated thousands of sentences and paragraphs from model-generated solutions
to math problems using seven cognitive labels (e.g., Plan, Implement, Verify).
The result is the first publicly available benchmark for the fine-grained
analysis of machine reasoning, including a large annotated corpus and detailed
annotation guidebooks. Our preliminary analysis reveals distinct patterns in
LRM reasoning, such as the transition dynamics between cognitive states. This
framework provides a theoretically grounded methodology for interpreting LRM
cognition and enables future work on more controllable and transparent
reasoning systems.

</details>


### [13] [RationAnomaly: Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning](https://arxiv.org/abs/2509.14693)
*Song Xu,Yilun Liu,Minggui He,Mingchen Dai,Ziang Chen,Chunguang Zhao,Jingzhou Du,Shimin Tao,Weibin Meng,Shenglin Zhang,Yongqian Sun,Boxing Chen,Daimeng Wei*

Main category: cs.AI

TL;DR: RationAnomaly框架结合思维链(CoT)微调和强化学习，提高了日志异常检测的准确性和可解释性，并超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在可解释性差、泛化能力弱、易产生幻觉等问题。

Method: CoT引导的监督微调和强化学习，使用高质量、人工校正的数据集。

Result: 在关键基准测试中取得了优越的F1分数，并提供透明的、逐步的分析输出。

Conclusion: RationAnomaly框架有效地提高了日志异常检测的性能和可靠性，相关代码和数据集已公开发布。

Abstract: Logs constitute a form of evidence signaling the operational status of
software systems. Automated log anomaly detection is crucial for ensuring the
reliability of modern software systems. However, existing approaches face
significant limitations: traditional deep learning models lack interpretability
and generalization, while methods leveraging Large Language Models are often
hindered by unreliability and factual inaccuracies. To address these issues, we
propose RationAnomaly, a novel framework that enhances log anomaly detection by
synergizing Chain-of-Thought (CoT) fine-tuning with reinforcement learning. Our
approach first instills expert-like reasoning patterns using CoT-guided
supervised fine-tuning, grounded in a high-quality dataset corrected through a
rigorous expert-driven process. Subsequently, a reinforcement learning phase
with a multi-faceted reward function optimizes for accuracy and logical
consistency, effectively mitigating hallucinations. Experimentally,
RationAnomaly outperforms state-of-the-art baselines, achieving superior
F1-scores on key benchmarks while providing transparent, step-by-step
analytical outputs. We have released the corresponding resources, including
code and datasets.

</details>


### [14] [The NazoNazo Benchmark: A Cost-Effective and Extensible Test of Insight-Based Reasoning in LLMs](https://arxiv.org/abs/2509.14704)
*Masaharu Mizumoto,Dat Nguyen,Zhiheng Han,Jiyuan Fang,Heyuan Guan,Xingfu Li,Naoya Shiraishi,Xuyang Tian,Yo Nakawake,Le Minh Nguyen*

Main category: cs.AI

TL;DR: Nazonazo基准测试使用日本儿童谜语评估LLM的洞察力推理能力，发现除GPT-5外，模型性能远低于人类，且模型大小与准确性无可靠关联。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估基准存在饱和和污染问题。

Method: 构建Nazonazo基准测试，包含120个谜语，评估38个前沿模型和126个成年人。

Result: GPT-5以外的模型性能远低于人类（52.9%），推理模型显著优于非推理模型，模型大小与准确性无关联。分析发现模型常犯验证错误。

Conclusion: Nazonazo提供了一个经济高效、可扩展且易于更新的基准，并揭示了模型的元认知弱点，为未来的控制和校准方法提供了明确的目标。

Abstract: Benchmark saturation and contamination undermine confidence in LLM
evaluation. We present Nazonazo, a cost-effective and extensible benchmark
built from Japanese children's riddles to test insight-based reasoning. Items
are short (mostly one sentence), require no specialized domain knowledge, and
can be generated at scale, enabling rapid refresh of blind sets when leakage is
suspected. We evaluate 38 frontier models and 126 adults on 120 riddles. No
model except for GPT-5 is comparable to human performance, which achieves a
52.9% mean accuracy. Model comparison on extended 201 items shows that
reasoning models significantly outperform non-reasoning peers, while model size
shows no reliable association with accuracy. Beyond aggregate accuracy, an
informal candidate-tracking analysis of thought logs reveals many cases of
verification failure: models often produce the correct solution among
intermediate candidates yet fail to select it as the final answer, which we
illustrate with representative examples observed in multiple models. Nazonazo
thus offers a cost-effective, scalable, and easily renewable benchmark format
that addresses the current evaluation crisis while also suggesting a recurrent
meta-cognitive weakness, providing clear targets for future control and
calibration methods.

</details>


### [15] [Enhancing Retrieval Augmentation via Adversarial Collaboration](https://arxiv.org/abs/2509.14750)
*Letian Zhang,Guanghao Meng,Xudong Ren,Yiming Wang,Shu-Tao Xia*

Main category: cs.AI

TL;DR: 该论文提出了一种名为AC-RAG的对抗性协作检索增强生成框架，以解决检索幻觉问题，显著提高了检索精度。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法容易出现检索幻觉，影响性能。

Method: 采用两个异构Agent：检测器和求解器，通过对抗性协作迭代式地改进知识检索。

Result: AC-RAG显著提高了检索准确率，优于现有RAG方法。

Conclusion: AC-RAG框架有效解决了检索幻觉问题，为领域特定LLM提供了改进方案。

Abstract: Retrieval-augmented Generation (RAG) is a prevalent approach for
domain-specific LLMs, yet it is often plagued by "Retrieval Hallucinations"--a
phenomenon where fine-tuned models fail to recognize and act upon poor-quality
retrieved documents, thus undermining performance. To address this, we propose
the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two
heterogeneous agents: a generalist Detector that identifies knowledge gaps, and
a domain-specialized Resolver that provides precise solutions. Guided by a
moderator, these agents engage in an adversarial collaboration, where the
Detector's persistent questioning challenges the Resolver's expertise. This
dynamic process allows for iterative problem dissection and refined knowledge
retrieval. Extensive experiments show that AC-RAG significantly improves
retrieval accuracy and outperforms state-of-the-art RAG methods across various
vertical domains.

</details>


### [16] [OpenLens AI: Fully Autonomous Research Agent for Health Infomatics](https://arxiv.org/abs/2509.14778)
*Yuxiao Cheng,Jinli Suo*

Main category: cs.AI

TL;DR: OpenLens AI是一个自动化框架，用于推进健康信息学研究，它集成了文献综述、数据分析、代码生成和手稿准备等专业代理，并通过视觉语言反馈和质量控制来增强医疗可视化和可重复性。


<details>
  <summary>Details</summary>
Motivation: 健康信息学研究需要整合生物医学科学、数据分析和临床实践的见解，而基于代理的方法可以自动化知识探索、管理复杂的工作流程并生成临床上有意义的输出。

Method: 开发了一个名为OpenLens AI的自动化框架，该框架集成了多个专业代理，并通过视觉语言反馈和质量控制来处理医疗可视化和可重复性问题。

Result: OpenLens AI可以自动化整个研究流程，生成具有透明和可追踪工作流程的、可供发表的LaTeX手稿。

Conclusion: OpenLens AI为推进健康信息学研究提供了一种特定领域的解决方案。

Abstract: Health informatics research is characterized by diverse data modalities,
rapid knowledge expansion, and the need to integrate insights across biomedical
science, data analytics, and clinical practice. These characteristics make it
particularly well-suited for agent-based approaches that can automate knowledge
exploration, manage complex workflows, and generate clinically meaningful
outputs. Recent progress in large language model (LLM)-based agents has
demonstrated promising capabilities in literature synthesis, data analysis, and
even end-to-end research execution. However, existing systems remain limited
for health informatics because they lack mechanisms to interpret medical
visualizations and often overlook domain-specific quality requirements. To
address these gaps, we introduce OpenLens AI, a fully automated framework
tailored to health informatics. OpenLens AI integrates specialized agents for
literature review, data analysis, code generation, and manuscript preparation,
enhanced by vision-language feedback for medical visualization and quality
control for reproducibility. The framework automates the entire research
pipeline, producing publication-ready LaTeX manuscripts with transparent and
traceable workflows, thereby offering a domain-adapted solution for advancing
health informatics research.

</details>
