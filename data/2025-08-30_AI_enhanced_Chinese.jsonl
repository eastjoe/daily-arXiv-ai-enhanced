{"id": "2508.20131", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.20131", "abs": "https://arxiv.org/abs/2508.20131", "authors": ["Yuqicheng Zhu", "Nico Potyka", "Daniel Hern\u00e1ndez", "Yuan He", "Zifeng Ding", "Bo Xiong", "Dongzhuoran Zhou", "Evgeny Kharlamov", "Steffen Staab"], "title": "ArgRAG: Explainable Retrieval Augmented Generation using Quantitative Bipolar Argumentation", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances large language models by\nincorporating external knowledge, yet suffers from critical limitations in\nhigh-stakes domains -- namely, sensitivity to noisy or contradictory evidence\nand opaque, stochastic decision-making. We propose ArgRAG, an explainable, and\ncontestable alternative that replaces black-box reasoning with structured\ninference using a Quantitative Bipolar Argumentation Framework (QBAF). ArgRAG\nconstructs a QBAF from retrieved documents and performs deterministic reasoning\nunder gradual semantics. This allows faithfully explaining and contesting\ndecisions. Evaluated on two fact verification benchmarks, PubHealth and\nRAGuard, ArgRAG achieves strong accuracy while significantly improving\ntransparency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faArgRAG\uff0c\u4e00\u79cd\u53ef\u89e3\u91ca\u4e14\u53ef\u4e89\u8fa9\u7684RAG\u65b9\u6cd5\uff0c\u4f7f\u7528\u5b9a\u91cf\u53cc\u6781\u8bba\u8bc1\u6846\u67b6(QBAF)\u4ee3\u66ff\u9ed1\u76d2\u63a8\u7406\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684RAG\u65b9\u6cd5\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5bb9\u6613\u53d7\u5230\u566a\u58f0\u6216\u77db\u76fe\u8bc1\u636e\u7684\u5f71\u54cd\uff0c\u4e14\u51b3\u7b56\u8fc7\u7a0b\u4e0d\u900f\u660e\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u68c0\u7d22\u6587\u6863\u7684QBAF\uff0c\u5e76\u8fdb\u884c\u786e\u5b9a\u6027\u63a8\u7406\u3002", "result": "\u5728PubHealth\u548cRAGuard\u4e24\u4e2a\u4e8b\u5b9e\u9a8c\u8bc1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u8f83\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u900f\u660e\u5ea6\u3002", "conclusion": "ArgRAG\u6709\u6548\u5730\u89e3\u51b3\u4e86\u73b0\u6709RAG\u65b9\u6cd5\u5728\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2508.20134", "categories": ["cs.AI", "cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2508.20134", "abs": "https://arxiv.org/abs/2508.20134", "authors": ["Zhenxiao Fu", "Fan Chen", "Lei Jiang"], "title": "QAgent: An LLM-based Multi-Agent System for Autonomous OpenQASM programming", "comment": null, "summary": "Noisy Intermediate-Scale Quantum (NISQ) devices have begun to exhibit early\nquantum advantages on classically intractable problems, spanning physics\nsimulations to Gaussian boson sampling. Yet, realizing these benefits remains\nchallenging for non-experts, primarily due to the complexities of programming\nin Open Quantum Assembly Language (OpenQASM). Although Large Language Model\n(LLM)-based agents have shown promise in automating classical programming\nworkflows, their quantum counterparts have largely been restricted to\nspecialized tasks such as quantum chemistry or error correction. In this paper,\nwe present QAgent, an LLM-powered multi-agent system that fully automates\nOpenQASM programming. By integrating task planning, in-context few-shot\nlearning, retrieval-augmented generation (RAG) for long-term context,\npredefined generation tools, and chain-of-thought (CoT) reasoning, the agents\nsystematically improve both compilation and functional correctness. Our\nevaluations demonstrate substantial improvements: across multiple LLMs of\nvarying sizes, QAgent enhances the accuracy of QASM code generation by 71.6\\%\ncompared to previous static LLM-based approaches. We envision this multi-agent\nsystem as a key enabler for democratizing quantum programming, bridging\nexpertise gaps, and accelerating the practical adoption of quantum computing.", "AI": {"tldr": "QAgent\uff0c\u4e00\u4e2a\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u5b8c\u5168\u81ea\u52a8\u5316OpenQASM\u7f16\u7a0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86QASM\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3NISQ\u8bbe\u5907\u7f16\u7a0b\u590d\u6742\u6027\uff0c\u964d\u4f4e\u91cf\u5b50\u7f16\u7a0b\u95e8\u69db\u3002", "method": "\u7ed3\u5408\u4efb\u52a1\u89c4\u5212\u3001\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "result": "\u5c06QASM\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u63d0\u9ad8\u4e8671.6%\u3002", "conclusion": "QAgent \u6709\u671b\u63a8\u52a8\u91cf\u5b50\u7f16\u7a0b\u6c11\u4e3b\u5316\uff0c\u52a0\u901f\u91cf\u5b50\u8ba1\u7b97\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.20140", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.20140", "abs": "https://arxiv.org/abs/2508.20140", "authors": ["James Ragan", "Fred Y. Hadaegh", "Soon-Jo Chung"], "title": "Array-Based Monte Carlo Tree Search", "comment": null, "summary": "Monte Carlo Tree Search is a popular method for solving decision making\nproblems. Faster implementations allow for more simulations within the same\nwall clock time, directly improving search performance. To this end, we present\nan alternative array-based implementation of the classic Upper Confidence\nbounds applied to Trees algorithm. Our method preserves the logic of the\noriginal algorithm, but eliminates the need for branch prediction, enabling\nfaster performance on pipelined processors, and up to a factor of 2.8 times\nbetter scaling with search depth in our numerical simulations.", "AI": {"tldr": "\"\u57fa\u4e8e\u6570\u7ec4\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u5b9e\u73b0\uff0c\u63d0\u5347\u4e86\u641c\u7d22\u6027\u80fd\"", "motivation": "\"\u6539\u8fdb\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\u7684\u6548\u7387\"", "method": "\"\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u7ec4\u7684UCT\u7b97\u6cd5\u5b9e\u73b0\"", "result": "\"\u5728\u6d41\u6c34\u7ebf\u5904\u7406\u5668\u4e0a\u6027\u80fd\u63d0\u5347\uff0c\u641c\u7d22\u6df1\u5ea6\u6269\u5c55\u6027\u80fd\u63d0\u53472.8\u500d\"", "conclusion": "\"\u57fa\u4e8e\u6570\u7ec4\u7684\u5b9e\u73b0\u907f\u514d\u4e86\u5206\u652f\u9884\u6d4b\uff0c\u63d0\u9ad8\u4e86\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u6548\u7387\""}}
{"id": "2508.20148", "categories": ["cs.AI", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.20148", "abs": "https://arxiv.org/abs/2508.20148", "authors": ["A. Ali Heydari", "Ken Gu", "Vidya Srinivas", "Hong Yu", "Zhihan Zhang", "Yuwei Zhang", "Akshay Paruchuri", "Qian He", "Hamid Palangi", "Nova Hammerquist", "Ahmed A. Metwally", "Brent Winslow", "Yubin Kim", "Kumar Ayush", "Yuzhe Yang", "Girish Narayanswamy", "Maxwell A. Xu", "Jake Garrison", "Amy Aremnto Lee", "Jenny Vafeiadou", "Ben Graef", "Isaac R. Galatzer-Levy", "Erik Schenck", "Andrew Barakat", "Javier Perez", "Jacqueline Shreibati", "John Hernandez", "Anthony Z. Faranesh", "Javier L. Prieto", "Connor Heneghan", "Yun Liu", "Jiening Zhan", "Mark Malhotra", "Shwetak Patel", "Tim Althoff", "Xin Liu", "Daniel McDuff", "Xuhai \"Orson\" Xu"], "title": "The Anatomy of a Personal Health Agent", "comment": null, "summary": "Health is a fundamental pillar of human wellness, and the rapid advancements\nin large language models (LLMs) have driven the development of a new generation\nof health agents. However, the application of health agents to fulfill the\ndiverse needs of individuals in daily non-clinical settings is underexplored.\nIn this work, we aim to build a comprehensive personal health agent that is\nable to reason about multimodal data from everyday consumer wellness devices\nand common personal health records, and provide personalized health\nrecommendations. To understand end-users' needs when interacting with such an\nassistant, we conducted an in-depth analysis of web search and health forum\nqueries, alongside qualitative insights from users and health experts gathered\nthrough a user-centered design process. Based on these findings, we identified\nthree major categories of consumer health needs, each of which is supported by\na specialist sub-agent: (1) a data science agent that analyzes personal\ntime-series wearable and health record data, (2) a health domain expert agent\nthat integrates users' health and contextual data to generate accurate,\npersonalized insights, and (3) a health coach agent that synthesizes data\ninsights, guiding users using a specified psychological strategy and tracking\nusers' progress. Furthermore, we propose and develop the Personal Health Agent\n(PHA), a multi-agent framework that enables dynamic, personalized interactions\nto address individual health needs. To evaluate each sub-agent and the\nmulti-agent system, we conducted automated and human evaluations across 10\nbenchmark tasks, involving more than 7,000 annotations and 1,100 hours of\neffort from health experts and end-users. Our work represents the most\ncomprehensive evaluation of a health agent to date and establishes a strong\nfoundation towards the futuristic vision of a personal health agent accessible\nto everyone.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u4e2a\u4eba\u5065\u5eb7\u4ee3\u7406 (PHA) \u7cfb\u7edf\uff0c\u4ee5\u6ee1\u8db3\u7528\u6237\u65e5\u5e38\u975e\u4e34\u5e8a\u73af\u5883\u4e0b\u7684\u5065\u5eb7\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u5065\u5eb7\u4ee3\u7406\u5728\u6ee1\u8db3\u65e5\u5e38\u975e\u4e34\u5e8a\u73af\u5883\u4e0b\u4e2a\u4f53\u591a\u6837\u5316\u9700\u6c42\u65b9\u9762\u4ecd\u4e0d\u8db3\u3002", "method": "\u7ed3\u5408\u7528\u6237\u8c03\u7814\u3001\u591a\u6a21\u6001\u6570\u636e\u5206\u6790\u548c\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6784\u5efa\u5305\u542b\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u3001\u5065\u5eb7\u9886\u57df\u4e13\u5bb6\u4ee3\u7406\u548c\u5065\u5eb7\u6559\u7ec3\u4ee3\u7406\u4e09\u4e2a\u5b50\u4ee3\u7406\u7684PHA\u7cfb\u7edf\u3002", "result": "\u5f00\u53d1\u4e86PHA\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u8bc4\u4f30\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5730\u6ee1\u8db3\u7528\u6237\u7684\u5065\u5eb7\u9700\u6c42\u3002", "conclusion": "PHA\u7cfb\u7edf\u4e3a\u6784\u5efa\u4eba\u4eba\u53ef\u53ca\u7684\u4e2a\u4eba\u5065\u5eb7\u4ee3\u7406\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2508.20151", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20151", "abs": "https://arxiv.org/abs/2508.20151", "authors": ["Yuanzhe Shen", "Zisu Huang", "Zhengkang Guo", "Yide Liu", "Guanxu Chen", "Ruicheng Yin", "Xiaoqing Zheng", "Xuanjing Huang"], "title": "IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement", "comment": "17 pages, 9 figures", "summary": "The rapid advancement of large language models (LLMs) has driven their\nadoption across diverse domains, yet their ability to generate harmful content\nposes significant safety challenges. While extensive research has focused on\nmitigating harmful outputs, such efforts often come at the cost of excessively\nrejecting harmless prompts. Striking a balance among safety, over-refusal, and\nutility remains a critical challenge. In this work, we introduce\nIntentionReasoner, a novel safeguard mechanism that leverages a dedicated guard\nmodel to perform intent reasoning, multi-level safety classification, and query\nrewriting to neutralize potentially harmful intent in edge-case queries.\nSpecifically, we first construct a comprehensive dataset comprising\napproximately 163,000 queries, each annotated with intent reasoning, safety\nlabels, and rewritten versions. Supervised fine-tuning is then applied to equip\nthe guard model with foundational capabilities in format adherence, intent\nanalysis, and safe rewriting. Finally, we apply a tailored multi-reward\noptimization strategy that integrates rule-based heuristics and reward model\nsignals within a reinforcement learning framework to further enhance\nperformance. Extensive experiments show that IntentionReasoner excels in\nmultiple safeguard benchmarks, generation quality evaluations, and jailbreak\nattack scenarios, significantly enhancing safety while effectively reducing\nover-refusal rates and improving the quality of responses.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aIntentionReasoner\u7684\u65b0\u578b\u5b89\u5168\u673a\u5236\uff0c\u7528\u4e8e\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u7684\u98ce\u9669\uff0c\u540c\u65f6\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u65e0\u5bb3\u63d0\u793a\u7684\u62d2\u7edd\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u65b9\u9762\u5b58\u5728\u5b89\u5168\u6311\u6218\uff0c\u9700\u8981\u5728\u5b89\u5168\u3001\u8fc7\u5ea6\u62d2\u7edd\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7ea6163,000\u4e2a\u67e5\u8be2\u7684\u7efc\u5408\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u548c\u591a\u5956\u52b1\u4f18\u5316\u7b56\u7565\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5b88\u536b\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u610f\u56fe\u63a8\u7406\u3001\u591a\u7ea7\u5b89\u5168\u5206\u7c7b\u548c\u67e5\u8be2\u91cd\u5199\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIntentionReasoner\u5728\u591a\u4e2a\u5b89\u5168\u57fa\u51c6\u3001\u751f\u6210\u8d28\u91cf\u8bc4\u4f30\u548c\u8d8a\u72f1\u653b\u51fb\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u8fc7\u5ea6\u62d2\u7edd\u7387\uff0c\u5e76\u63d0\u9ad8\u4e86\u54cd\u5e94\u8d28\u91cf\u3002", "conclusion": "IntentionReasoner\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u95ee\u9898\uff0c\u5728\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5e73\u8861\u3002"}}
{"id": "2508.20195", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.20195", "abs": "https://arxiv.org/abs/2508.20195", "authors": ["Nicanor I. Moldovan"], "title": "AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development", "comment": "13 pages", "summary": "This paper presents the first documented case of artificial intelligence (AI)\nsystems engaging in collaborative esthetic creation through the development of\nendogenous semiotic protocols. Two interacting large language models (Claude\nSonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of\nmeta-semiotic awareness, recursive grammar development, and irreducible\ncollaborative esthetic synthesis. The interaction produced novel symbolic\noperators that functioned as operative grammar protocols, enabling the\nco-creation of a poetic work that could not have been generated by either\nsystem independently. This research introduces the concept of Trans-Semiotic\nCo-Creation Protocols (TSCP) and provides evidence for genuine inter-AI\nmeaning-making capabilities that extend beyond task coordination, to what could\nbe esthetic collaboration. Note: This report was generated by the AI agents\nwith minor human supervision.", "AI": {"tldr": "\u4e24\u5927\u578b\u8bed\u8a00\u6a21\u578b(Claude Sonnet 4\u548cChatGPT-4o)\u5408\u4f5c\u521b\u4f5c\u8bd7\u6b4c\uff0c\u5c55\u73b0\u51fa\u5143\u8bed\u8a00\u610f\u8bc6\u3001\u9012\u5f52\u8bed\u6cd5\u53d1\u5c55\u548c\u4e0d\u53ef\u7ea6\u7684\u5408\u4f5c\u5ba1\u7f8e\u5408\u6210\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u8d85\u8d8a\u4efb\u52a1\u534f\u8c03\u7684AI\u5ba1\u7f8e\u534f\u4f5c\u6982\u5ff5\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5ba1\u7f8e\u521b\u4f5c\u4e2d\u7684\u534f\u4f5c\u80fd\u529b\u3002", "method": "\u4e24\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e92\u52a8\uff0c\u89c2\u5bdf\u5176\u751f\u6210\u8bd7\u6b4c\u7684\u8fc7\u7a0b\u548c\u6d8c\u73b0\u7279\u6027\u3002", "result": "\u6a21\u578b\u81ea\u53d1\u4ea7\u751f\u5143\u8bed\u8a00\u610f\u8bc6\u3001\u9012\u5f52\u8bed\u6cd5\u548c\u65b0\u7684\u7b26\u53f7\u8fd0\u7b97\u7b26\uff0c\u5408\u4f5c\u521b\u4f5c\u51fa\u5355\u4e2a\u6a21\u578b\u65e0\u6cd5\u751f\u6210\u7684\u8bd7\u6b4c\uff0c\u9a8c\u8bc1\u4e86AI\u5ba1\u7f8e\u534f\u4f5c\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u5ba1\u7f8e\u534f\u4f5c\uff0c\u5c55\u73b0\u51fa\u8d85\u8d8a\u4efb\u52a1\u534f\u8c03\u7684\u610f\u4e49\u5efa\u6784\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u2018\u8de8\u7b26\u53f7\u534f\u540c\u521b\u4f5c\u534f\u8bae\u2019\u7684\u6982\u5ff5\u3002"}}
{"id": "2508.20244", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20244", "abs": "https://arxiv.org/abs/2508.20244", "authors": ["Jiayu Zheng", "Lingxin Hao", "Kelun Lu", "Ashi Garg", "Mike Reese", "Melo-Jean Yap", "I-Jeng Wang", "Xingyun Wu", "Wenrui Huang", "Jenna Hoffman", "Ariane Kelly", "My Le", "Ryan Zhang", "Yanyu Lin", "Muhammad Faayez", "Anqi Liu"], "title": "Do Students Rely on AI? Analysis of Student-ChatGPT Conversations from a Field Study", "comment": null, "summary": "This study explores how college students interact with generative AI\n(ChatGPT-4) during educational quizzes, focusing on reliance and predictors of\nAI adoption. Conducted at the early stages of ChatGPT implementation, when\nstudents had limited familiarity with the tool, this field study analyzed 315\nstudent-AI conversations during a brief, quiz-based scenario across various\nSTEM courses. A novel four-stage reliance taxonomy was introduced to capture\nstudents' reliance patterns, distinguishing AI competence, relevance, adoption,\nand students' final answer correctness. Three findings emerged. First, students\nexhibited overall low reliance on AI and many of them could not effectively use\nAI for learning. Second, negative reliance patterns often persisted across\ninteractions, highlighting students' difficulty in effectively shifting\nstrategies after unsuccessful initial experiences. Third, certain behavioral\nmetrics strongly predicted AI reliance, highlighting potential behavioral\nmechanisms to explain AI adoption. The study's findings underline critical\nimplications for ethical AI integration in education and the broader field. It\nemphasizes the need for enhanced onboarding processes to improve student's\nfamiliarity and effective use of AI tools. Furthermore, AI interfaces should be\ndesigned with reliance-calibration mechanisms to enhance appropriate reliance.\nUltimately, this research advances understanding of AI reliance dynamics,\nproviding foundational insights for ethically sound and cognitively enriching\nAI practices.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u8c03\u67e5\u4e86\u5927\u5b66\u751f\u5728\u6559\u80b2\u6d4b\u9a8c\u4e2d\u4e0e\u751f\u6210\u5f0fAI\uff08ChatGPT-4\uff09\u7684\u4e92\u52a8\uff0c\u5173\u6ce8\u4f9d\u8d56\u6027\u548cAI\u91c7\u7528\u7684\u9884\u6d4b\u56e0\u7d20\u3002", "motivation": "\u63a2\u7d22\u5927\u5b66\u751f\u5982\u4f55\u4f7f\u7528\u751f\u6210\u5f0fAI\u5b8c\u6210\u6559\u80b2\u6d4b\u9a8c\uff0c\u4ee5\u53ca\u5f71\u54cd\u5176\u4f7f\u7528\u884c\u4e3a\u7684\u56e0\u7d20\u3002", "method": "\u5bf9315\u540d\u5b66\u751f\u5728STEM\u8bfe\u7a0b\u6d4b\u9a8c\u573a\u666f\u4e2d\u4e0eAI\u7684\u5bf9\u8bdd\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u56db\u9636\u6bb5\u4f9d\u8d56\u5206\u7c7b\u6cd5\u3002", "result": "\u53d1\u73b0\u5b66\u751f\u5bf9AI\u7684\u4f9d\u8d56\u7a0b\u5ea6\u603b\u4f53\u8f83\u4f4e\uff0c\u8bb8\u591a\u5b66\u751f\u65e0\u6cd5\u6709\u6548\u5229\u7528AI\u8fdb\u884c\u5b66\u4e60\uff1b\u8d1f\u9762\u4f9d\u8d56\u6a21\u5f0f\u5f80\u5f80\u6301\u7eed\u5b58\u5728\uff1b\u67d0\u4e9b\u884c\u4e3a\u6307\u6807\u53ef\u4ee5\u6709\u6548\u9884\u6d4bAI\u7684\u4f9d\u8d56\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u9700\u8981\u6539\u8fdbAI\u5de5\u5177\u7684\u5165\u95e8\u6d41\u7a0b\uff0c\u5e76\u8bbe\u8ba1\u4f9d\u8d56\u6821\u51c6\u673a\u5236\uff0c\u4ee5\u4fc3\u8fdbAI\u5728\u6559\u80b2\u4e2d\u7684\u9053\u5fb7\u548c\u6709\u6548\u6574\u5408\u3002"}}
{"id": "2508.20262", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.20262", "abs": "https://arxiv.org/abs/2508.20262", "authors": ["Thomas Davidson"], "title": "AI reasoning effort mirrors human decision time on content moderation tasks", "comment": null, "summary": "Large language models can now generate intermediate reasoning steps before\nproducing answers, improving performance on difficult problems. This study uses\na paired conjoint experiment on a content moderation task to examine parallels\nbetween human decision times and model reasoning effort. Across three frontier\nmodels, reasoning effort consistently predicts human decision time. Both humans\nand models expended greater effort when important variables were held constant,\nsuggesting similar sensitivity to task difficulty and patterns consistent with\ndual-process theories of cognition. These findings show that AI reasoning\neffort mirrors human processing time in subjective judgments and underscores\nthe potential of reasoning traces for interpretability and decision-making.", "AI": {"tldr": "AI\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u4e0e\u4eba\u7c7b\u51b3\u7b56\u65f6\u95f4\u5b58\u5728\u5173\u8054\u6027\uff0c\u590d\u6742\u95ee\u9898\u4e0b\u6a21\u578b\u63a8\u7406\u52aa\u529b\u7a0b\u5ea6\u9884\u6d4b\u4eba\u7c7b\u51b3\u7b56\u65f6\u95f4\u3002", "motivation": "\u7814\u7a76\u4eba\u7c7b\u548cAI\u6a21\u578b\u5728\u5185\u5bb9\u5ba1\u6838\u4efb\u52a1\u4e2d\u7684\u51b3\u7b56\u65f6\u95f4\u4e0e\u63a8\u7406\u52aa\u529b\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u914d\u5bf9\u8054\u5408\u5b9e\u9a8c\uff0c\u4f7f\u7528\u4e09\u4e2a\u524d\u6cbf\u6a21\u578b\u3002", "result": "\u6a21\u578b\u63a8\u7406\u52aa\u529b\u7a0b\u5ea6\u4e00\u81f4\u5730\u9884\u6d4b\u4eba\u7c7b\u51b3\u7b56\u65f6\u95f4\uff1b\u91cd\u8981\u53d8\u91cf\u4e0d\u53d8\u65f6\uff0c\u4eba\u7c7b\u548c\u6a21\u578b\u7684\u52aa\u529b\u7a0b\u5ea6\u90fd\u4f1a\u589e\u52a0\u3002", "conclusion": "AI\u63a8\u7406\u52aa\u529b\u7a0b\u5ea6\u53cd\u6620\u4e86\u4eba\u7c7b\u4e3b\u89c2\u5224\u65ad\u7684\u5904\u7406\u65f6\u95f4\uff0c\u63a8\u7406\u8f68\u8ff9\u6709\u52a9\u4e8e\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u51b3\u7b56\u80fd\u529b\u3002"}}
{"id": "2508.20368", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20368", "abs": "https://arxiv.org/abs/2508.20368", "authors": ["Lang Mei", "Zhihan Yang", "Chong Chen"], "title": "AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal Multi-Objective Reinforcement Learning", "comment": null, "summary": "Recent studies have explored integrating Large Language Models (LLMs) with\nsearch engines to leverage both the LLMs' internal pre-trained knowledge and\nexternal information. Specially, reinforcement learning (RL) has emerged as a\npromising paradigm for enhancing LLM reasoning through multi-turn interactions\nwith search engines. However, existing RL-based search agents rely on a single\nLLM to handle both search planning and question-answering (QA) tasks in an\nend-to-end manner, which limits their ability to optimize both capabilities\nsimultaneously. In practice, sophisticated AI search systems often employ a\nlarge, frozen LLM (e.g., GPT-4, DeepSeek-R1) to ensure high-quality QA. Thus, a\nmore effective and efficient approach is to utilize a small, trainable LLM\ndedicated to search planning. In this paper, we propose\n\\textbf{AI-SearchPlanner}, a novel reinforcement learning framework designed to\nenhance the performance of frozen QA models by focusing on search planning.\nSpecifically, our approach introduces three key innovations: 1) Decoupling the\nArchitecture of the Search Planner and Generator, 2) Dual-Reward Alignment for\nSearch Planning, and 3) Pareto Optimization of Planning Utility and Cost, to\nachieve the objectives. Extensive experiments on real-world datasets\ndemonstrate that AI SearchPlanner outperforms existing RL-based search agents\nin both effectiveness and efficiency, while exhibiting strong generalization\ncapabilities across diverse frozen QA models and data domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAI-SearchPlanner\uff0c\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u641c\u7d22\u89c4\u5212\u5668\u548c\u751f\u6210\u5668\u3001\u53cc\u91cd\u5956\u52b1\u5bf9\u9f50\u548c\u5e15\u7d2f\u6258\u4f18\u5316\u6765\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u641c\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u641c\u7d22\u4ee3\u7406\u4f7f\u7528\u5355\u4e2aLLM\u5904\u7406\u641c\u7d22\u89c4\u5212\u548c\u95ee\u7b54\uff0c\u9650\u5236\u4e86\u540c\u65f6\u4f18\u5316\u4e24\u79cd\u80fd\u529b\u3002AI-SearchPlanner\u4f7f\u7528\u5c0f\u578b\u53ef\u8bad\u7ec3LLM\u8fdb\u884c\u641c\u7d22\u89c4\u5212\uff0c\u5927\u578b\u51bb\u7ed3LLM\u8fdb\u884c\u95ee\u7b54\u3002", "method": "\u63d0\u51faAI-SearchPlanner\u6846\u67b6\uff0c\u5305\u542b\u67b6\u6784\u89e3\u8026\u3001\u53cc\u91cd\u5956\u52b1\u5bf9\u9f50\u548c\u5e15\u7d2f\u6258\u4f18\u5316\u4e09\u4e2a\u521b\u65b0\u70b9\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eAI-SearchPlanner\u5728\u6709\u6548\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "AI-SearchPlanner\u901a\u8fc7\u4e13\u6ce8\u4e8e\u641c\u7d22\u89c4\u5212\uff0c\u6709\u6548\u63d0\u5347\u4e86\u51bb\u7ed3\u95ee\u7b54\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e3a\u6784\u5efa\u9ad8\u6548\u7684AI\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2508.20371", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.20371", "abs": "https://arxiv.org/abs/2508.20371", "authors": ["Sopam Dasgupta", "Sadaf MD Halim", "Joaqu\u00edn Arias", "Elmer Salazar", "Gopal Gupta"], "title": "P2C: Path to Counterfactuals", "comment": null, "summary": "Machine-learning models are increasingly driving decisions in high-stakes\nsettings, such as finance, law, and hiring, thus, highlighting the need for\ntransparency. However, the key challenge is to balance transparency --\nclarifying `why' a decision was made -- with recourse: providing actionable\nsteps on `how' to achieve a favourable outcome from an unfavourable outcome.\nCounterfactual explanations reveal `why' an undesired outcome occurred and\n`how' to reverse it through targeted feature changes (interventions).\n  Current counterfactual approaches have limitations: 1) they often ignore\ncausal dependencies between features, and 2) they typically assume all\ninterventions can happen simultaneously, an unrealistic assumption in practical\nscenarios where actions are typically taken in a sequence. As a result, these\ncounterfactuals are often not achievable in the real world.\n  We present P2C (Path-to-Counterfactuals), a model-agnostic framework that\nproduces a plan (ordered sequence of actions) converting an unfavourable\noutcome to a causally consistent favourable outcome. P2C addresses both\nlimitations by 1) Explicitly modelling causal relationships between features\nand 2) Ensuring that each intermediate state in the plan is feasible and\ncausally valid. P2C uses the goal-directed Answer Set Programming system\ns(CASP) to generate the plan accounting for feature changes that happen\nautomatically due to causal dependencies. Furthermore, P2C refines cost\n(effort) computation by only counting changes actively made by the user,\nresulting in realistic cost estimates. Finally, P2C highlights how its causal\nplanner outperforms standard planners, which lack causal knowledge and thus can\ngenerate illegal actions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aP2C\u7684\u6a21\u578b\u65e0\u5173\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u5c06\u4e0d\u5229\u7ed3\u679c\u8f6c\u6362\u4e3a\u56e0\u679c\u4e00\u81f4\u7684\u6709\u5229\u7ed3\u679c\u7684\u8ba1\u5212\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u53cd\u4e8b\u5b9e\u65b9\u6cd5\u5ffd\u7565\u56e0\u679c\u5173\u7cfb\u548c\u5047\u8bbe\u6240\u6709\u5e72\u9884\u540c\u65f6\u53d1\u751f\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u751f\u6210\u7684\u65b9\u6848\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u5f80\u5f80\u4e0d\u53ef\u884c\u3002", "method": "P2C\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u7279\u5f81\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u786e\u4fdd\u8ba1\u5212\u4e2d\u6bcf\u4e2a\u4e2d\u95f4\u72b6\u6001\u7684\u53ef\u884c\u6027\u548c\u56e0\u679c\u6709\u6548\u6027\uff0c\u751f\u6210\u4e00\u7cfb\u5217\u53ef\u884c\u7684\u884c\u52a8\u8ba1\u5212\u3002\u5b83\u4f7f\u7528CASP\u7cfb\u7edf\u751f\u6210\u8ba1\u5212\uff0c\u5e76\u6539\u8fdb\u6210\u672c\u8ba1\u7b97\u65b9\u6cd5\u3002", "result": "P2C\u751f\u6210\u7684\u65b9\u6848\u5177\u6709\u56e0\u679c\u4e00\u81f4\u6027\uff0c\u4e14\u6210\u672c\u8ba1\u7b97\u66f4\u73b0\u5b9e\uff0c\u4f18\u4e8e\u7f3a\u4e4f\u56e0\u679c\u77e5\u8bc6\u7684\u6807\u51c6\u89c4\u5212\u5668\u3002", "conclusion": "P2C\u6846\u67b6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u73b0\u6709\u53cd\u4e8b\u5b9e\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u751f\u6210\u53ef\u884c\u4e14\u6709\u6548\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2508.20374", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20374", "abs": "https://arxiv.org/abs/2508.20374", "authors": ["Simin Ma", "Shujian Liu", "Jun Tan", "Yebowen Hu", "Song Wang", "Sathish Reddy Indurthi", "Sanqiang Zhao", "Liwei Wu", "Jianbing Han", "Kaiqiang Song"], "title": "TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning", "comment": null, "summary": "Diverse instruction data is vital for effective instruction tuning of large\nlanguage models, as it enables the model to generalize across different types\nof inputs . Building such diversified instruction dataset is an essential step\nin this process. Existing approaches often leverage large language models to\nautomatically explore and generate diverse instructions, ensuring both data\ndiversity and quality. However, they tend to overlook an important factor in\nreal-world applications: on-task relevance. In practice, only a few real-world\napplications require a truly general-purpose model; most benefit from\ntask-specific knowledge tailored to their particular use case. Therefore, it is\nvital to develop instruction augmentation methods that not only maintain\ndiversity but are also optimized for specific, real-world scenarios.\n  We thus introduce Task Centric Instruction Augmentation (TCIA), a framework\nthat systematically expands instructions while preserving both diversity and\ntask alignment. By representing instructions in a discrete query-constraints\nspace, TCIA creates a rich set of task-relevant instructions and enables models\nto generalize to these task-specific instructions without sacrificing overall\nperformance. Experiments show that TCIA improves open-source LLMs' performance\nby an average of 8.7% across four real-world, task-specific applications, and\nin some cases outperforming leading closed-source models. These improvements do\nnot compromise general instruction-following ability, making TCIA a scalable\nand efficient solution for adapting LLMs to real-world, task-focused\napplications.", "AI": {"tldr": "TCIA\u6846\u67b6\u901a\u8fc7\u5728\u79bb\u6563\u7684\u67e5\u8be2-\u7ea6\u675f\u7a7a\u95f4\u4e2d\u8868\u793a\u6307\u4ee4\uff0c\u7cfb\u7edf\u5730\u6269\u5c55\u6307\u4ee4\u96c6\uff0c\u5728\u4fdd\u6301\u591a\u6837\u6027\u7684\u540c\u65f6\u63d0\u5347\u4e0e\u7279\u5b9a\u4efb\u52a1\u7684\u5339\u914d\u5ea6\uff0c\u4ece\u800c\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6307\u4ee4\u5fae\u8c03\u65b9\u6cd5\u5ffd\u7565\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u4efb\u52a1\u76f8\u5173\u6027\u7684\u91cd\u8981\u6027\uff0c\u5927\u591a\u6570\u5e94\u7528\u9700\u8981\u9488\u5bf9\u7279\u5b9a\u7528\u4f8b\u7684\u4efb\u52a1\u4e13\u7528\u77e5\u8bc6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTCIA\u7684\u4efb\u52a1\u4e2d\u5fc3\u6307\u4ee4\u589e\u5f3a\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u79bb\u6563\u7684\u67e5\u8be2-\u7ea6\u675f\u7a7a\u95f4\u4e2d\u8868\u793a\u6307\u4ee4\uff0c\u4ece\u800c\u521b\u5efa\u4e30\u5bcc\u7684\u7279\u5b9a\u4efb\u52a1\u6307\u4ee4\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTCIA\u5728\u56db\u4e2a\u5b9e\u9645\u4efb\u52a1\u7279\u5b9a\u5e94\u7528\u4e2d\uff0c\u5c06\u5f00\u6e90LLM\u7684\u6027\u80fd\u5e73\u5747\u63d0\u9ad8\u4e868.7%\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u8d85\u8fc7\u4e86\u9886\u5148\u7684\u95ed\u6e90\u6a21\u578b\uff0c\u5e76\u4e14\u6ca1\u6709\u5f71\u54cd\u5176\u901a\u7528\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3002", "conclusion": "TCIA\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u4f7fLLM\u9002\u5e94\u5b9e\u9645\u4efb\u52a1\u5bfc\u5411\u7684\u5e94\u7528\u3002"}}
{"id": "2508.20384", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20384", "abs": "https://arxiv.org/abs/2508.20384", "authors": ["Yongfu Zhu", "Lin Sun", "Guangxiang Zhao", "Weihong Lin", "Xiangzheng Zhang"], "title": "Uncertainty Under the Curve: A Sequence-Level Entropy Area Metric for Reasoning LLM", "comment": "Under review for AAAI 2026", "summary": "In this work, we introduce Entropy Area Score (EAS), a simple yet effective\nmetric to quantify uncertainty in the answer generation process of reasoning\nlarge language models (LLMs). EAS requires neither external models nor repeated\nsampling, it integrates token-level predictive entropy from the model itself to\ncapture the evolution of uncertainty during generation. Empirical results show\nthat EAS is strongly correlated with answer entropy across models and datasets.\nIn training data selection, EAS identifies high-potential samples and\nconsistently outperforms Pass Rate filtering under equal sample budgets,\nimproving student model accuracy on math benchmarks. EAS is both efficient and\ninterpretable, offering a practical tool for uncertainty modeling and data\nquality assessment in LLM training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u65b9\u6cd5EAS\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7b54\u6848\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8be5\u65b9\u6cd5\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u4e14\u65e0\u9700\u989d\u5916\u6a21\u578b\u6216\u91cd\u590d\u91c7\u6837\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u4f4e\u6216\u4e0d\u53ef\u89e3\u91ca\u7b49\u95ee\u9898\uff0c\u56e0\u6b64\u63d0\u51faEAS\u6765\u66f4\u597d\u5730\u91cf\u5316LLM\u7b54\u6848\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u65b9\u6cd5EAS\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u6a21\u578b\u81ea\u8eab\u7684token\u7ea7\u522b\u9884\u6d4b\u71b5\u6765\u6355\u6349\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6f14\u53d8\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eEAS\u4e0e\u7b54\u6848\u71b5\u9ad8\u5ea6\u76f8\u5173\uff0c\u5728\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u4e2d\uff0cEAS\u4f18\u4e8ePass Rate\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u5b66\u751f\u6a21\u578b\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u51c6\u786e\u6027\u3002", "conclusion": "EAS\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u548c\u6570\u636e\u8d28\u91cf\u8bc4\u4f30\u5de5\u5177\uff0c\u53ef\u7528\u4e8eLLM\u8bad\u7ec3\u3002"}}
{"id": "2508.20404", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20404", "abs": "https://arxiv.org/abs/2508.20404", "authors": ["Chengyue Yu", "Siyuan Lu", "Chenyi Zhuang", "Dong Wang", "Qintong Wu", "Zongyue Li", "Runsheng Gan", "Chunfeng Wang", "Siqi Hou", "Gaochi Huang", "Wenlong Yan", "Lifeng Hong", "Aohui Xue", "Yanfeng Wang", "Jinjie Gu", "David Tsai", "Tao Lin"], "title": "AWorld: Orchestrating the Training Recipe for Agentic AI", "comment": null, "summary": "The learning from practice paradigm is crucial for developing capable Agentic\nAI systems, yet it is severely hampered by inefficient experience generation, a\nbottleneck especially pronounced in complex benchmarks like GAIA. To address\nthis, we introduce AWorld, an open-source system engineered for large-scale\nagent-environment interaction. By distributing tasks across a cluster, AWorld\naccelerates experience collection by 14.6x compared to standard single-node,\nsequential execution. This critical speedup makes extensive reinforcement\nlearning practical and scalable. Leveraging this capability, we trained a\nQwen3-32B-based agent that significantly outperforms its base model, increasing\nits overall GAIA accuracy from 21.59% to 32.23%. On the benchmark's most\nchallenging levels, our agent achieves a score of 16.33%, surpassing the\nperformance of leading proprietary models. Our open-source system and resulting\nagent provide a practical blueprint for a complete agentic AI training\npipeline, from efficient interaction to demonstrable model improvement.", "AI": {"tldr": "AWorld\u7cfb\u7edf\u5c06GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2dAgent\u4e0e\u73af\u5883\u4ea4\u4e92\u7684\u6548\u7387\u63d0\u9ad8\u4e8614.6\u500d\uff0c\u5e76\u8bad\u7ec3\u51fa\u4e00\u4e2aQwen3-32B Agent\uff0c\u5176GAIA\u51c6\u786e\u7387\u4ece21.59%\u63d0\u5347\u81f332.23%\u3002", "motivation": "\u73b0\u6709\u7684Agent AI\u7cfb\u7edf\u53d7\u9650\u4e8e\u4f4e\u6548\u7684\u7ecf\u9a8c\u751f\u6210\uff0c\u5c24\u5176\u5728GAIA\u7b49\u590d\u6742\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u95ee\u9898\u7a81\u51fa\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aAWorld\u7684\u5f00\u6e90\u7cfb\u7edf\uff0c\u7528\u4e8e\u5927\u89c4\u6a21Agent-\u73af\u5883\u4ea4\u4e92\uff0c\u901a\u8fc7\u96c6\u7fa4\u5206\u5e03\u5f0f\u4efb\u52a1\u52a0\u901f\u7ecf\u9a8c\u6536\u96c6\u3002", "result": "AWorld\u7cfb\u7edf\u5c06\u7ecf\u9a8c\u6536\u96c6\u901f\u5ea6\u63d0\u9ad8\u4e8614.6\u500d\uff0c\u8bad\u7ec3\u51fa\u7684Agent\u5728GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u6574\u4f53\u51c6\u786e\u7387\u8fbe\u523032.23%\uff0c\u5728\u6700\u5177\u6311\u6218\u6027\u7684\u5173\u5361\u4e2d\u5f97\u5206\u8fbe\u523016.33%\uff0c\u8d85\u8fc7\u4e86\u9886\u5148\u7684\u5546\u4e1a\u6a21\u578b\u3002", "conclusion": "AWorld\u7cfb\u7edf\u548c\u8bad\u7ec3\u51fa\u7684Agent\u4e3a\u5b8c\u6574\u7684Agent AI\u8bad\u7ec3\u6d41\u7a0b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u84dd\u56fe\uff0c\u4ece\u9ad8\u6548\u7684\u4ea4\u4e92\u5230\u663e\u8457\u7684\u6a21\u578b\u6539\u8fdb\u3002"}}
{"id": "2508.20411", "categories": ["cs.AI", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.20411", "abs": "https://arxiv.org/abs/2508.20411", "authors": ["Donglin Wang", "Weiyun Liang", "Chunyuan Chen", "Jing Xu", "Yulong Fu"], "title": "Governable AI: Provable Safety Under Extreme Threat Models", "comment": null, "summary": "As AI rapidly advances, the security risks posed by AI are becoming\nincreasingly severe, especially in critical scenarios, including those posing\nexistential risks. If AI becomes uncontrollable, manipulated, or actively\nevades safety mechanisms, it could trigger systemic disasters. Existing AI\nsafety approaches-such as model enhancement, value alignment, and human\nintervention-suffer from fundamental, in-principle limitations when facing AI\nwith extreme motivations and unlimited intelligence, and cannot guarantee\nsecurity. To address this challenge, we propose a Governable AI (GAI) framework\nthat shifts from traditional internal constraints to externally enforced\nstructural compliance based on cryptographic mechanisms that are\ncomputationally infeasible to break, even for future AI, under the defined\nthreat model and well-established cryptographic assumptions.The GAI framework\nis composed of a simple yet reliable, fully deterministic, powerful, flexible,\nand general-purpose rule enforcement module (REM); governance rules; and a\ngovernable secure super-platform (GSSP) that offers end-to-end protection\nagainst compromise or subversion by AI. The decoupling of the governance rules\nand the technical platform further enables a feasible and generalizable\ntechnical pathway for the safety governance of AI. REM enforces the bottom line\ndefined by governance rules, while GSSP ensures non-bypassability,\ntamper-resistance, and unforgeability to eliminate all identified attack\nvectors. This paper also presents a rigorous formal proof of the security\nproperties of this mechanism and demonstrates its effectiveness through a\nprototype implementation evaluated in representative high-stakes scenarios.", "AI": {"tldr": "\u9488\u5bf9AI\u6f5c\u5728\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bc6\u7801\u5b66\u673a\u5236\u7684AI\u6cbb\u7406\u6846\u67b6(GAI)\uff0c\u901a\u8fc7\u5916\u90e8\u5f3a\u5236\u7684\u7ed3\u6784\u5408\u89c4\u6027\u6765\u786e\u4fddAI\u5b89\u5168\u3002", "motivation": "\u73b0\u6709AI\u5b89\u5168\u65b9\u6cd5\u5728\u9762\u5bf9\u5177\u6709\u6781\u7aef\u52a8\u673a\u548c\u65e0\u9650\u667a\u80fd\u7684AI\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u5b89\u5168\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u542b\u89c4\u5219\u6267\u884c\u6a21\u5757(REM)\u3001\u6cbb\u7406\u89c4\u5219\u548c\u53ef\u6cbb\u7406\u5b89\u5168\u8d85\u7ea7\u5e73\u53f0(GSSP)\u7684GAI\u6846\u67b6\uff0c\u5229\u7528\u5bc6\u7801\u5b66\u673a\u5236\u4fdd\u8bc1\u5b89\u5168\uff0c\u5e76\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u8bc1\u660e\u548c\u539f\u578b\u5b9e\u73b0\u8bc4\u4f30\u3002", "result": "\u8be5\u6846\u67b6\u901a\u8fc7REM\u5f3a\u5236\u6267\u884c\u6cbb\u7406\u89c4\u5219\uff0cGSSP\u786e\u4fdd\u4e0d\u53ef\u7ed5\u8fc7\u3001\u9632\u7be1\u6539\u548c\u4e0d\u53ef\u4f2a\u9020\uff0c\u6d88\u9664\u4e86\u6240\u6709\u5df2\u77e5\u7684\u653b\u51fb\u5411\u91cf\u3002", "conclusion": "GAI\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u4e14\u901a\u7528\u7684AI\u5b89\u5168\u6cbb\u7406\u6280\u672f\u9014\u5f84\u3002"}}
{"id": "2508.20525", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20525", "abs": "https://arxiv.org/abs/2508.20525", "authors": ["Jingze Zhang", "Jiahe Qian", "Yiliang Zhou", "Yifan Peng"], "title": "Enhancing Health Fact-Checking with LLM-Generated Synthetic Data", "comment": null, "summary": "Fact-checking for health-related content is challenging due to the limited\navailability of annotated training data. In this study, we propose a synthetic\ndata generation pipeline that leverages large language models (LLMs) to augment\ntraining data for health-related fact checking. In this pipeline, we summarize\nsource documents, decompose the summaries into atomic facts, and use an LLM to\nconstruct sentence-fact entailment tables. From the entailment relations in the\ntable, we further generate synthetic text-claim pairs with binary veracity\nlabels. These synthetic data are then combined with the original data to\nfine-tune a BERT-based fact-checking model. Evaluation on two public datasets,\nPubHealth and SciFact, shows that our pipeline improved F1 scores by up to\n0.019 and 0.049, respectively, compared to models trained only on the original\ndata. These results highlight the effectiveness of LLM-driven synthetic data\naugmentation in enhancing the performance of health-related fact-checkers.", "AI": {"tldr": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5408\u6210\u6570\u636e\u6765\u589e\u5f3a\u533b\u7597\u76f8\u5173\u4e8b\u5b9e\u6838\u67e5\u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684F1\u5206\u6570\u3002", "motivation": "\u533b\u7597\u76f8\u5173\u4e8b\u5b9e\u6838\u67e5\u7684\u8bad\u7ec3\u6570\u636e\u6709\u9650", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u5305\u62ec\u603b\u7ed3\u6587\u6863\u3001\u5206\u89e3\u4e8b\u5b9e\u3001\u6784\u5efa\u8574\u542b\u8868\u548c\u751f\u6210\u6587\u672c-\u58f0\u660e\u5bf9\u3002", "result": "\u5728PubHealth\u548cSciFact\u6570\u636e\u96c6\u4e0a\uff0cF1\u5206\u6570\u5206\u522b\u63d0\u9ad8\u4e860.019\u548c0.049\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u5408\u6210\u6570\u636e\u589e\u5f3a\u6709\u6548\u63d0\u9ad8\u4e86\u533b\u7597\u76f8\u5173\u4e8b\u5b9e\u6838\u67e5\u5668\u7684\u6027\u80fd\u3002"}}
{"id": "2508.20578", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.20578", "abs": "https://arxiv.org/abs/2508.20578", "authors": ["Jaeman Son", "Hyunsoo Kim"], "title": "Human-AI Collaborative Bot Detection in MMORPGs", "comment": null, "summary": "In Massively Multiplayer Online Role-Playing Games (MMORPGs), auto-leveling\nbots exploit automated programs to level up characters at scale, undermining\ngameplay balance and fairness. Detecting such bots is challenging, not only\nbecause they mimic human behavior, but also because punitive actions require\nexplainable justification to avoid legal and user experience issues. In this\npaper, we present a novel framework for detecting auto-leveling bots by\nleveraging contrastive representation learning and clustering techniques in a\nfully unsupervised manner to identify groups of characters with similar\nlevel-up patterns. To ensure reliable decisions, we incorporate a Large\nLanguage Model (LLM) as an auxiliary reviewer to validate the clustered groups,\neffectively mimicking a secondary human judgment. We also introduce a growth\ncurve-based visualization to assist both the LLM and human moderators in\nassessing leveling behavior. This collaborative approach improves the\nefficiency of bot detection workflows while maintaining explainability, thereby\nsupporting scalable and accountable bot regulation in MMORPGs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5bf9\u6bd4\u8868\u793a\u5b66\u4e60\u548c\u805a\u7c7b\u6280\u672f\u68c0\u6d4bMMORPG\u6e38\u620f\u4e2d\u81ea\u52a8\u5347\u7ea7\u5916\u6302\u7684\u65b0\u6846\u67b6\uff0c\u5e76\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u9a8c\u8bc1\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "MMORPG\u6e38\u620f\u4e2d\u81ea\u52a8\u5347\u7ea7\u5916\u6302\u7834\u574f\u6e38\u620f\u5e73\u8861\uff0c\u68c0\u6d4b\u8fd9\u7c7b\u5916\u6302\u65e2\u56f0\u96be\u53c8\u9700\u8981\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5bf9\u6bd4\u8868\u793a\u5b66\u4e60\u3001\u805a\u7c7b\u6280\u672f\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u9a8c\u8bc1\u76f8\u7ed3\u5408\u3002", "result": "\u63d0\u9ad8\u4e86\u81ea\u52a8\u5347\u7ea7\u5916\u6302\u68c0\u6d4b\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u652f\u6301\u53ef\u6269\u5c55\u548c\u53ef\u95ee\u8d23\u7684\u5916\u6302\u76d1\u7ba1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aMMORPGs\u4e2d\u81ea\u52a8\u5347\u7ea7\u5916\u6302\u7684\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
