<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: 大型语言模型平台AutoIND可将IND申请撰写时间缩短约97%，但仍需专家进行润色以达到提交标准。


<details>
  <summary>Details</summary>
Motivation: IND申请准备耗时且依赖专业知识，AutoIND旨在提高效率。

Method: 比较AutoIND生成IND非临床总结（eCTD模块2.6.2、2.6.4、2.6.6）的起草时间与人工起草时间，并由专家评估质量。

Result: AutoIND将起草时间从约100小时缩短到3.7-2.6小时，质量评分为69.6%-77.9%，未发现关键错误，但在重点、简洁性和清晰度方面存在不足。

Conclusion: AutoIND能显著加快IND起草，但仍需专家参与，后续需改进模型以提升质量。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [2] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: Boldsea架构使用可执行本体建模复杂动态系统，直接控制流程执行，克服了传统BPM系统和面向对象语义技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统BPM系统和面向对象语义技术的局限性。

Method: 提出Boldsea架构和BSL语言，直接解释语义模型为可执行算法。

Result: 实现了运行时修改事件模型、时间透明性和数据与业务逻辑的无缝融合。

Conclusion: Boldsea架构为复杂动态系统的建模和控制提供了一种新的有效方法。

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [3] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 大型语言模型和视觉语言模型可用于规划任务的反馈生成，大型模型及增强型推理方法表现更好，但复杂环境下性能下降。


<details>
  <summary>Details</summary>
Motivation: 减少规划任务中奖励函数设计和示范数据需求。

Method: 评估大型语言模型和视觉语言模型在不同环境下生成不同类型反馈的性能，包括二元反馈、偏好反馈、动作建议、目标建议和增量动作反馈，并考虑上下文学习、思维链和环境动态等推理方法。

Result: 大型模型和增强推理方法生成更高质量、更少偏差的反馈，但复杂动态或连续状态/动作空间环境下性能下降。

Conclusion: 基础模型可为不同领域的规划提供高质量反馈，模型规模和推理方法对性能有显著影响。

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [4] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 利用生成式AI从公开数据中生成能源建模数据，降低对昂贵或受限数据源的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的能源建模计算模型需要大量数据，而这些数据可能难以获取或存在隐私问题。

Method: 构建了一个模块化的多模态框架，利用生成式AI从公开的可访问的住宅信息和图像中生成数据，并提供了一个演示该框架的流程，对生成式AI组件进行了评估。

Result: 实验表明，该框架避免了生成模型的常见问题，能够生成真实、带标签的数据，降低了对昂贵或受限数据源的依赖。

Conclusion: 该框架为更易访问和可重复的能源建模研究铺平了道路。

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [5] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 本文综述了自动形式化领域的研究现状，并提出一个统一框架以促进不同领域之间的交叉研究，从而加速下一代AI系统的发展。


<details>
  <summary>Details</summary>
Motivation: 自动形式化，特别是利用大型语言模型进行数学形式化，取得了快速进展，但不同研究领域发展相对独立，缺乏共享方法、基准和理论框架。

Method: 回顾了显式或隐式自动形式化的实例，并提出了一个统一框架。

Result: 提出一个统一框架，促进不同研究领域间的交叉研究。

Conclusion: 统一框架将加速下一代AI系统的发展。

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [6] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 本文介绍了一个基于RAG的智能知识助手系统，用于支持山羊养殖健康管理，该系统融合了异构数据，在验证集和测试集上准确率分别达到87.90%和84.22%。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在畜牧业应用有限，该研究旨在构建一个用于山羊养殖健康管理的智能知识助手系统。

Method: 提出两种结构化知识处理方法（表格文本化和决策树文本化）增强LLM对异构数据的理解，构建包含五个关键领域的知识库，并集成在线搜索模块。

Result: 异构知识融合方法在验证集和测试集上准确率分别达到87.90%和84.22%，各项文本问答准确率均超过85%。

Conclusion: 该系统可靠且实用，可用于山羊养殖实践。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [7] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: 大型语言模型(LLM)能否有效帮助人类完成任务？研究人员让LLM参与UNO游戏，测试其辅助另一玩家获胜的能力，结果发现即使大型LLM也难以胜任。


<details>
  <summary>Details</summary>
Motivation: 评估LLM作为积极参与者帮助人类完成目标的能力。

Method: 让不同规模的LLM(1B到70B参数)在UNO游戏中扮演辅助角色，使用两种不同的提示策略，与随机基线进行比较。

Result: 所有模型都优于随机基线，但很少有模型能够显著帮助另一玩家获胜。

Conclusion: 大型语言模型在辅助人类完成复杂任务方面仍有局限性，尤其是在需要策略和理解他人意图的场景下。

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [8] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: AI赋能科学发现，提出智能科学工作流演化框架，潜力巨大。


<details>
  <summary>Details</summary>
Motivation: 当前科学发现依赖手动协调分布式资源，效率低下。AI代理可加速科学发现，但其应用尚不明确。

Method: 提出一个包含智能和组合两个维度的概念框架，描绘了从现有工作流管理系统到完全自主的分布式科学实验室的演化路径。并给出了一个架构蓝图。

Result: 提出一个潜在的100倍加速科学发现和改变科学工作流程的架构蓝图。

Conclusion: 该框架为利用自主科学中的机遇，实现科学发现的加速和工作流程的变革提供了方向。

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [9] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 将波函数坍缩(WFC)重新定义为马尔可夫决策过程(MDP)以优化内容生成，分离局部约束满足和全局目标优化，实验表明该方法优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 同时满足设计目标和底层图块集隐含的邻接约束是程序化内容生成的难点。

Method: 将WFC重新定义为MDP，利用外部优化算法最大化目标，同时利用WFC的传播机制保证约束满足。

Result: 与传统进化方法相比，该方法在多个领域和不同难度下都表现更好，尤其在复杂任务中优势明显。

Conclusion: 分离局部约束满足和全局目标优化能有效提高程序化内容生成的效率和效果。

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [10] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 本文提出了一种新的可解释AI工具B-ReX，并在Boolean函数预测的表格数据上进行了评估，结果表明其优于其他黑盒XAI工具。


<details>
  <summary>Details</summary>
Motivation: 评估可解释AI方法具有挑战性，本文专注于表格数据和预测布尔函数值的AI模型，提出基于实际因果关系的变量重要性度量。

Method: 提出了一种新的XAI工具B-ReX，并使用该度量评估了最先进的XAI工具。

Result: B-ReX在大型基准测试中表现优于其他黑盒XAI工具，在随机10值布尔公式上实现了0.072±0.012的Jensen-Shannon散度。

Conclusion: B-ReX是一种有效的XAI工具，能够更好地解释Boolean函数预测模型。

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [11] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: GAMA系统通过划分私有和公共工作空间并使用匿名机制保护隐私，在LLM多Agent系统中实现了隐私保护和高效任务处理。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多Agent系统在处理隐私数据时面临安全挑战。

Method: 提出了一种通用匿名多Agent系统GAMA，包含基于领域规则的知识增强(DRKE)和基于反驳的逻辑增强(DLE)模块，以减轻匿名化造成的语义损失。

Result: 在公开问答数据集和两个新设计的隐私保护数据集上，GAMA在任务处理和隐私保护方面均表现出色，优于现有模型。

Conclusion: GAMA有效解决了LLM多Agent系统中的隐私问题，并在任务性能上取得了显著提升。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [12] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents框架利用多极任务处理图和IF-THEN规则，提升了多智能体系统处理复杂任务的能力，并在知识型和逻辑型问答任务中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统在处理复杂任务时，计划能力不足，容易产生错误输出。

Method: 提出XAgents框架，利用多极任务处理图进行动态任务规划，并结合领域特定IF-THEN规则和全局规则约束智能体行为，增强协作。

Result: 在三个数据集上，XAgents在知识型和逻辑型问答任务中均优于现有单智能体和多智能体方法。

Conclusion: XAgents框架有效提升了多智能体系统处理复杂任务的能力，具有较好的应用前景。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [13] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: AI风险评估模型应以人为本，关注实际影响，AI Harmonics模型通过新的AI危害评估指标AIH，优先处理政治和人身危害。


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估模型忽略了利益相关者的观点和真实世界的影响。

Method: 提出AI Harmonics模型，使用AIH指标评估AI危害，该指标基于序数严重性数据，无需精确数值估计。

Result: 实验证明政治和人身危害最为严重，需要优先缓解。AI Harmonics模型能有效识别危害分布不均的情况。

Conclusion: AI Harmonics模型为政策制定者和组织机构提供了一种有效的方法来靶向缓解AI危害。

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [14] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: AI自主代理的快速发展催生了一种新的经济层，本文提出“沙盒经济”框架来分析该系统，并探讨其设计选择以确保安全可控。


<details>
  <summary>Details</summary>
Motivation: 分析AI自主代理快速发展带来的新型经济系统。

Method: 提出沙盒经济框架，分析其起源和与人类经济的隔离程度，并探讨拍卖机制、AI任务经济和社会技术基础设施等设计选择。

Result: 指出当前发展轨迹可能导致一个庞大且高度渗透的AI代理经济，存在系统性经济风险和加剧不平等的挑战。

Conclusion: 主张积极设计可控的代理市场，以确保技术变革符合人类长远福祉。

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [15] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 本文提出了一种名为鲁棒稀疏采样(RSS)的在线规划算法，用于解决马尔可夫决策过程(MDPs)中模型不确定性问题，该算法具有有限样本理论性能保证，并优于标准稀疏采样算法。


<details>
  <summary>Details</summary>
Motivation: 现有在线规划算法在模型不确定性下性能下降或导致不安全行为，本文旨在提出一种高效且具有理论保证的鲁棒在线规划算法。

Method: 提出鲁棒稀疏采样(RSS)算法，利用样本平均逼近(SAA)的效率和理论性质计算鲁棒价值函数，适用于无限或连续状态空间。

Result: RSS算法在具有不确定动态的环境中优于标准稀疏采样算法，具有样本和计算复杂度与状态空间大小无关的特性。

Conclusion: RSS算法为在线环境下的鲁棒MDPs规划提供了一种高效且具有理论保证的解决方案。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [16] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 利用多智能体框架和LLM自动表征多孔材料，实现力场提取和RASPA模拟设置自动化，提高效率和可重复性。


<details>
  <summary>Details</summary>
Motivation: 自动化材料表征以加速材料发现，但受模拟设置和力场选择的复杂性限制。

Method: 提出一个多智能体框架，利用基于LLM的智能体自主完成表征任务，包括规划模拟、组装力场、执行模拟和解释结果。

Result: 初步评估显示该方法具有较高的正确性和可重复性。

Conclusion: 该方法有潜力实现完全自主、可扩展的材料表征。

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>
