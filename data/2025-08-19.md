<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: 使用FAE从游戏视频中学习更精确、更通用的神经符号世界模型。


<details>
  <summary>Details</summary>
Motivation: 现有的世界模型方法难以迁移学习到的环境动态和解释性，该论文旨在学习更精确和通用的环境模型。

Method: 提出了一种有限自动机提取 (FAE) 方法，从游戏视频中学习神经符号世界模型。使用Retro Coder DSL将游戏视频表示为程序。

Result: FAE学习到比现有方法更精确的环境模型和更通用的代码。

Conclusion: 提出了一种从游戏视频中学习神经符号世界模型的方法——有限自动机提取 (FAE)，该方法使用新型领域特定语言 (DSL) Retro Coder 将游戏视频表示为程序，学习到的模型比以往方法更精确、代码更通用。

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


### [2] [EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](https://arxiv.org/abs/2508.11850)
*Milad Yazdani,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: EvoCut 自动生成整数规划加速切割，显著提升求解效率和解的质量。


<details>
  <summary>Details</summary>
Motivation: 整数规划求解的NP-hard特性导致求解困难，人工设计加速切割耗时费力且需要专业知识。

Method: 结合大型语言模型和进化搜索算法自动生成加速切割。

Result: EvoCut减少了最优性差距17-57%，求解速度提高最高达4倍，在相同时间内获得更高质量的解。

Conclusion: EvoCut框架通过结合大型语言模型和进化搜索，自动化生成加速切割，提高整数规划求解效率，减少最优性差距17-57%，速度提升最高达4倍。

Abstract: Integer programming lies at the heart of crucial combinatorial optimization
tasks but remains challenging due to its NP-hard nature. An effective approach
for practically solving integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. However, this creative
process demands deep expertise and is yet to be automated. Our proposed
framework, EvoCut, automates the generation of acceleration cuts by combining
large language models (LLMs) with an evolutionary search. EvoCut (i)
initializes a diverse population of candidate cuts via an LLM-based initializer
agent; (ii) for each cut empirically evaluates both preservation of the optimal
solution and its ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evolutionary
crossover and mutation agents. We quantify each cut's utility by its relative
reduction in the solver's optimality gap. Our comparisons against standard
integer programming practice show that EvoCut reduces optimality gap by 17-57%
within a fixed time. It obtains the same solutions up to 4 times as fast, and
obtains higher-quality solutions within the same time limit. Requiring no human
expert input, EvoCut reliably generates, improves, and empirically verifies
cuts that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.

</details>


### [3] [LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://arxiv.org/abs/2508.11860)
*Frazier N. Baker,Daniel Adu-Ampratwum,Reza Averly,Botao Yu,Huan Sun,Xia Ning*

Main category: cs.AI

TL;DR: LARC框架是一个有效的基于LLM的Agent框架，用于约束逆合成规划，其成功率高达72.9%，接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 解决约束逆合成规划这一化学领域中的难题，为科学发现提供帮助。

Method: 开发了一个名为LARC的基于LLM的Agent框架，该框架将Agent-as-a-Judge机制融入逆合成规划过程，利用基于工具的推理进行约束评估和指导路线生成。

Result: LARC在48个约束逆合成规划任务中取得了72.9%的成功率，显著优于LLM基线模型。

Conclusion: LLM驱动的框架LARC在约束逆合成规划方面取得了显著成功，成功率达到72.9%，优于基线模型，并接近人类专家的水平。

Abstract: Large language model (LLM) agent evaluators leverage specialized tools to
ground the rational decision-making of LLMs, making them well-suited to aid in
scientific discoveries, such as constrained retrosynthesis planning.
Constrained retrosynthesis planning is an essential, yet challenging, process
within chemistry for identifying synthetic routes from commercially available
starting materials to desired target molecules, subject to practical
constraints. Here, we present LARC, the first LLM-based Agentic framework for
Retrosynthesis planning under Constraints. LARC incorporates agentic constraint
evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis
planning process, using agentic feedback grounded in tool-based reasoning to
guide and constrain route generation. We rigorously evaluate LARC on a
carefully curated set of 48 constrained retrosynthesis planning tasks across 3
constraint types. LARC achieves a 72.9% success rate on these tasks, vastly
outperforming LLM baselines and approaching human expert-level success in
substantially less time. The LARC framework is extensible, and serves as a
first step towards an effective agentic tool or a co-scientist to human experts
for constrained retrosynthesis.

</details>


### [4] [QuarkMed Medical Foundation Model Technical Report](https://arxiv.org/abs/2508.11894)
*Ao Li,Bin Yan,Bingfeng Cai,Chenxi Li,Cunzhong Zhao,Fugen Yao,Gaoqiang Liu,Guanjun Jiang,Jian Xu,Liang Dong,Liansheng Sun,Rongshen Zhang,Xiaolei Gui,Xin Liu,Xin Shang,Yao Wu,Yu Cao,Zhenxin Ma,Zhuang Jia*

Main category: cs.AI

TL;DR: QuarkMed: 一个高性能的医疗基础模型，准确率高，用户众多。


<details>
  <summary>Details</summary>
Motivation: 满足医疗任务对专业知识、准确性和定制能力的需求。

Method: 利用精选的医疗数据处理、医疗内容检索增强生成 (RAG) 和大规模可验证强化学习流程。

Result: 在多个医疗基准测试中表现出强大的泛化能力，并在中华医师执业考试中达到 70% 的准确率。

Conclusion: QuarkMed 是一款高性能的医疗基础模型，在中华医师执业考试中取得了 70% 的准确率，并已服务数百万用户。

Abstract: Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.

</details>


### [5] [CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs](https://arxiv.org/abs/2508.11944)
*Hongtao Liu,Zhicheng Du,Zihe Wang,Weiran Shen*

Main category: cs.AI

TL;DR: CHBench框架是一种新的、鲁棒的LLM策略推理能力评估工具，记忆机制提升性能，聊天机制降低性能。


<details>
  <summary>Details</summary>
Motivation: 现有评估LLM策略推理能力的方法主要依赖效用性能指标，其鲁棒性不足。

Method: 提出了一种基于认知层次模型的评估框架CHBench，并通过对六个LLM在十五个精心选择的正规形式博弈中的行为数据进行三阶段系统评估。

Result: CHBench框架在不同对手间表现出一致的策略推理水平，证明了其鲁棒性和泛化能力。记忆机制增强了策略推理，而聊天机制则会降低其性能。

Conclusion: 该研究提出了一种新的评估大型语言模型（LLM）策略推理能力的框架CHBench，该框架基于认知层次模型，并通过对六个LLM在十五个博弈中的行为数据分析，评估了LLM的策略推理水平，结果表明LLM在不同对手间的策略推理水平一致，且记忆机制增强了策略推理，而聊天机制则会降低其性能。

Abstract: Game-playing ability serves as an indicator for evaluating the strategic
reasoning capability of large language models (LLMs). While most existing
studies rely on utility performance metrics, which are not robust enough due to
variations in opponent behavior and game structure. To address this limitation,
we propose \textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation
framework inspired by the cognitive hierarchy models from behavioral economics.
We hypothesize that agents have bounded rationality -- different agents behave
at varying reasoning depths/levels. We evaluate LLMs' strategic reasoning
through a three-phase systematic framework, utilizing behavioral data from six
state-of-the-art LLMs across fifteen carefully selected normal-form games.
Experiments show that LLMs exhibit consistent strategic reasoning levels across
diverse opponents, confirming the framework's robustness and generalization
capability. We also analyze the effects of two key mechanisms (Chat Mechanism
and Memory Mechanism) on strategic reasoning performance. Results indicate that
the Chat Mechanism significantly degrades strategic reasoning, whereas the
Memory Mechanism enhances it. These insights position CHBench as a promising
tool for evaluating LLM capabilities, with significant potential for future
research and practical applications.

</details>


### [6] [Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.11953)
*Yuan Li,Zhengzhong Liu,Eric Xing*

Main category: cs.AI

TL;DR: 一种新的数据混合优化方法提高了大型语言模型的监督微调性能，其结果与网格搜索相当。


<details>
  <summary>Details</summary>
Motivation: 优化用于大型语言模型监督微调的数据混合，以开发通用的模型。

Method: 该方法将数据混合建模为一个优化问题，通过参数化损失函数并利用微调缩放定律来优化数据权重。

Result: 该方法在各个领域都取得了优异的整体和个体性能，与网格搜索相比，每个领域的损失平均仅高出 0.66%。重新加权流行的 SFT 数据集也提高了验证损失和下游性能。

Conclusion: 该论文提出了一种新的数据混合优化方法，用于改进大型语言模型的监督微调，该方法通过参数化损失函数并利用微调缩放定律来最小化验证损失，实验证明该方法能有效提高模型性能，且与网格搜索结果相当。

Abstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language
models (LLMs) is critical for developing general-purpose models, yet this area
remains underexplored. In this paper, we frame data mixing as an optimization
problem and introduce a novel method designed to minimize validation loss. Our
approach parametrizes the loss by modeling effective data transferred and
leveraging scaling laws for fine-tuning. By experimenting with various
small-scale data mixtures, we fit these parameters and derive the optimal
weights. We provide both mathematical proofs and empirical results
demonstrating that our algorithm achieves excellent overall and individual
performance across all domains. Through controlled experiments, we show that
models trained with our optimized weights perform on par with those using
optimal weights determined via grid search, with per-domain loss only 0.66%
higher than the best domain loss from grid search on average. Additionally, we
show that reweighting popular SFT datasets using our method improves both
validation loss and downstream performance. Finally, we discuss how our method
can generalize to guide data selection for domain-specific models and provide
insights into SFT.

</details>


### [7] [UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting](https://arxiv.org/abs/2508.11954)
*Sehyuk Park,Soyeon Caren Han,Eduard Hovy*

Main category: cs.AI

TL;DR: UniCast是一个参数高效的多模态时间序列预测框架，它利用视觉和文本信息显著提高了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有TSFM主要在单模态环境下运行，忽略了现实场景中时间序列数据通常伴随的丰富的多模态上下文，例如视觉和文本信号。

Method: 提出了一种新颖的、参数高效的多模态框架UniCast，该框架通过软提示微调将预训练的视觉和文本编码器的模态特定嵌入与冻结的TSFM集成。

Result: 在不同的时间序列预测基准测试中，UniCast始终且显著地优于所有现有的TSFM基线。

Conclusion: UniCast模型显著优于现有TSFM基线，突出了多模态语境在发展下一代通用时间序列预测器中的关键作用。

Abstract: Time series forecasting is a foundational task across domains, such as
finance, healthcare, and environmental monitoring. While recent advances in
Time Series Foundation Models (TSFMs) have demonstrated strong generalisation
through large-scale pretraining, existing models operate predominantly in a
unimodal setting, ignoring the rich multimodal context, such as visual and
textual signals, that often accompanies time series data in real-world
scenarios. This paper introduces a novel parameter-efficient multimodal
framework, UniCast, that extends TSFMs to jointly leverage time series, vision,
and text modalities for enhanced forecasting performance. Our method integrates
modality-specific embeddings from pretrained Vision and Text Encoders with a
frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal
parameter updates. This design not only preserves the generalisation strength
of the foundation model but also enables effective cross-modal interaction.
Extensive experiments across diverse time-series forecasting benchmarks
demonstrate that UniCast consistently and significantly outperforms all
existing TSFM baselines. The findings highlight the critical role of multimodal
context in advancing the next generation of general-purpose time series
forecasters.

</details>


### [8] [Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index](https://arxiv.org/abs/2508.11959)
*Xuanxiang Huang,Olivier Létoffé,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 提出两种新的特征重要性评分方法，有效利用非WAXp集合信息，提升了特征归因的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于博弈论的特征归因方法忽略了非WAXp集合的贡献，而这些集合可能包含重要信息。

Method: 利用Shapley值和Banzhaf指数，考虑非WAXp集合计算特征贡献。

Result: 提出了两种新的特征重要性评分方法，并分析了它们的性质和计算复杂度。

Conclusion: 本文提出两种新颖的特征重要性评分方法，考虑了非WAXp集合在计算特征贡献中的作用，并量化了每个特征在排除对抗样本方面的有效性。

Abstract: Feature attribution methods based on game theory are ubiquitous in the field
of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous
feature attribution using logic-based explanations, specifically targeting
high-stakes uses of machine learning (ML) models. Typically, such works exploit
weak abductive explanation (WAXp) as the characteristic function to assign
importance to features. However, one possible downside is that the contribution
of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important
information, because of the relationship between formal explanations (XPs) and
adversarial examples (AExs). Accordingly, this paper leverages Shapley value
and Banzhaf index to devise two novel feature importance scores. We take into
account non-WAXp sets when computing feature contribution, and the novel scores
quantify how effective each feature is at excluding AExs. Furthermore, the
paper identifies properties and studies the computational complexity of the
proposed scores.

</details>


### [9] [Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering](https://arxiv.org/abs/2508.11975)
*Gongyao Jiang,Qiong Luo*

Main category: cs.AI

TL;DR: 该论文提出了一种新的合成数据生成方法和候选条件回答过程，显著提高了VLMs对图表理解任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在图表理解任务，特别是准确的图表描述和复杂的推理方面存在困难，合成数据生成是一种有前景的解决方案，但通常面临噪声标签的挑战。

Method: 该论文提出了一种图表合成流水线，通过代码生成和执行生成对齐的图表-问题-答案三元组，并设计了一种候选条件回答过程，该过程首先为每个查询生成多个响应，然后通过上下文关联这些候选答案来合成最终答案。

Result: 实验结果表明，该方法在完全自改进的范式中，无需人工标注数据或外部模型，就能显著提高VLMs的准确性，最高可达15.50个百分点。

Conclusion: 该论文提出了一种通过代码生成和执行生成图表-问题-答案三元组的合成数据生成方法，并设计了一种候选条件回答过程，以提高视觉语言模型（VLMs）对图表理解任务的准确性，实验表明该方法能显著提高VLMs的准确性，最高可达15.50个百分点。

Abstract: Vision Language Models (VLMs) often struggle with chart understanding tasks,
particularly in accurate chart description and complex reasoning. Synthetic
data generation is a promising solution, while usually facing the challenge of
noise labels. To address this challenge, we first introduce a chart synthesis
pipeline that generates aligned chart-question-answer triplets through code
generation and execution, ensuring the reliability of synthetic data without
human intervention. Furthermore, inspired by test-time scaling that increases
inference budget and thereby improves performance, we design a
candidate-conditioned answering process. The VLM first generates multiple
responses per query, and then synthesizes the final answer by contextualizing
these candidates. Experiments demonstrate significant improvements, with up to
15.50 points accuracy gain over the initial VLM, in a fully self-improving
paradigm without either human-labeled data or external models.

</details>


### [10] [FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](https://arxiv.org/abs/2508.11987)
*Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX基准用于评估LLM代理的未来预测能力，并揭示了其在该任务中的不足。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏针对LLM代理未来预测能力的大规模基准，FutureX旨在解决这个问题。

Method: 构建了一个名为FutureX的动态实时评估基准，用于评估LLM代理的未来预测能力，并对25个LLM/agent模型进行了评估。

Result: 评估了25个LLM/agent模型，分析了代理的失败模式和性能缺陷，例如对虚假网页的脆弱性和时间有效性。

Conclusion: 本文介绍了一个名为FutureX的动态实时评估基准，用于评估大型语言模型（LLM）代理在未来预测任务中的性能，并对25个模型进行了评估，分析了其不足之处。

Abstract: Future prediction is a complex task for LLM agents, requiring a high level of
analytical thinking, information gathering, contextual understanding, and
decision-making under uncertainty. Agents must not only gather and interpret
vast amounts of dynamic information but also integrate diverse data sources,
weigh uncertainties, and adapt predictions based on emerging trends, just as
human experts do in fields like politics, economics, and finance. Despite its
importance, no large-scale benchmark exists for evaluating agents on future
prediction, largely due to challenges in handling real-time updates and
retrieving timely, accurate answers. To address this, we introduce
$\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically
designed for LLM agents performing future prediction tasks. FutureX is the
largest and most diverse live benchmark for future prediction, supporting
real-time daily updates and eliminating data contamination through an automated
pipeline for question gathering and answer collection. We evaluate 25 LLM/agent
models, including those with reasoning, search capabilities, and integration of
external tools such as the open-source Deep Research Agent and closed-source
Deep Research models. This comprehensive evaluation assesses agents' adaptive
reasoning and performance in dynamic environments. Additionally, we provide
in-depth analyses of agents' failure modes and performance pitfalls in
future-oriented tasks, including the vulnerability to fake web pages and the
temporal validity. Our goal is to establish a dynamic, contamination-free
evaluation standard that drives the development of LLM agents capable of
performing at the level of professional human analysts in complex reasoning and
predictive thinking.

</details>


### [11] [Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network](https://arxiv.org/abs/2508.11991)
*Weihao Sun*

Main category: cs.AI

TL;DR: AIGer, a new model for AIG analysis, significantly improves accuracy in predicting signal probability and truth table distance.


<details>
  <summary>Details</summary>
Motivation: Existing methods lack the ability to jointly model functional and structural characteristics of AIGs and have insufficient dynamic information propagation capability.

Method: AIGer employs a heterogeneous graph convolutional network with dynamic relationship weight matrices and differentiated information aggregation approaches to model functional and structural characteristics of AIGs.

Result: AIGer improves MAE and MSE by 18.95% and 44.44% in SSP, and by 33.57% and 14.79% in TTDP, respectively, compared to state-of-the-art models.

Conclusion: AIGer, a novel model consisting of a node logic feature initialization embedding component and an AIGs feature learning network component, significantly outperforms existing models in Signal Probability Prediction (SSP) and Truth Table Distance Prediction (TTDP) tasks.

Abstract: The automation of logic circuit design enhances chip performance, energy
efficiency, and reliability, and is widely applied in the field of Electronic
Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,
optimize, and verify the functional characteristics of digital circuits,
enhancing the efficiency of EDA development.Due to the complex structure and
large scale of nodes in real-world AIGs, accurate modeling is challenging,
leading to existing work lacking the ability to jointly model functional and
structural characteristics, as well as insufficient dynamic information
propagation capability.To address the aforementioned challenges, we propose
AIGer.Specifically, AIGer consists of two components: 1) Node logic feature
initialization embedding component and 2) AIGs feature learning network
component.The node logic feature initialization embedding component projects
logic nodes, such as AND and NOT, into independent semantic spaces, to enable
effective node embedding for subsequent processing.Building upon this, the AIGs
feature learning network component employs a heterogeneous graph convolutional
network, designing dynamic relationship weight matrices and differentiated
information aggregation approaches to better represent the original structure
and information of AIGs.The combination of these two components enhances
AIGer's ability to jointly model functional and structural characteristics and
improves its message passing capability. Experimental results indicate that
AIGer outperforms the current best models in the Signal Probability Prediction
(SSP) task, improving MAE and MSE by 18.95\% and 44.44\%, respectively. In the
Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of
33.57\% and 14.79\% in MAE and MSE, respectively, compared to the
best-performing models.

</details>


### [12] [AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](https://arxiv.org/abs/2508.11995)
*Xuyang Zhao,Shiwan Zhao,Hualong Yu,Liting Zhang,Qicheng Li*

Main category: cs.AI

TL;DR: AgentCDM框架通过结构化推理和两阶段训练，有效提升了基于LLM的多代理系统中的协作决策能力，取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的多代理系统协作决策方法存在局限性，要么依赖于容易受单一代理认知偏差影响的“独裁”策略，要么依赖于无法充分利用集体智慧的“投票”方法。

Method: 提出了一种名为AgentCDM的结构化框架，该框架借鉴了认知科学中竞争性假设分析（ACH）的思想，通过两阶段训练范式（第一阶段使用显式支架指导模型进行结构化推理，第二阶段逐步去除支架以鼓励自主泛化）将决策过程从被动答案选择转变为主动假设评估和构建。

Result: AgentCDM在多个基准数据集上取得了最先进的性能，并表现出强大的泛化能力，验证了其在改进MAS协作决策质量和稳健性方面的有效性。

Conclusion: AgentCDM框架在多代理系统中提高了协作决策的质量和稳健性，并在多个基准数据集上取得了最先进的性能。

Abstract: Multi-agent systems (MAS) powered by large language models (LLMs) hold
significant promise for solving complex decision-making tasks. However, the
core process of collaborative decision-making (CDM) within these systems
remains underexplored. Existing approaches often rely on either ``dictatorial"
strategies that are vulnerable to the cognitive biases of a single agent, or
``voting-based" methods that fail to fully harness collective intelligence. To
address these limitations, we propose \textbf{AgentCDM}, a structured framework
for enhancing collaborative decision-making in LLM-based multi-agent systems.
Drawing inspiration from the Analysis of Competing Hypotheses (ACH) in
cognitive science, AgentCDM introduces a structured reasoning paradigm that
systematically mitigates cognitive biases and shifts decision-making from
passive answer selection to active hypothesis evaluation and construction. To
internalize this reasoning process, we develop a two-stage training paradigm:
the first stage uses explicit ACH-inspired scaffolding to guide the model
through structured reasoning, while the second stage progressively removes this
scaffolding to encourage autonomous generalization. Experiments on multiple
benchmark datasets demonstrate that AgentCDM achieves state-of-the-art
performance and exhibits strong generalization, validating its effectiveness in
improving the quality and robustness of collaborative decisions in MAS.

</details>


### [13] [AI Models for Depressive Disorder Detection and Diagnosis: A Review](https://arxiv.org/abs/2508.12022)
*Dorsa Macky Aleagha,Payam Zohari,Mostafa Haghir Chehreghani*

Main category: cs.AI

TL;DR: 人工智能在抑郁症诊断中的应用综述，指出了图神经网络、大型语言模型和多模态融合的趋势


<details>
  <summary>Details</summary>
Motivation: 抑郁症诊断主要依赖主观临床评估，人工智能的整合有望开发客观、可扩展和及时的诊断工具。

Method: 系统综述了55个关键研究，提出了一种新的分层分类法，并对常见公共数据集和标准评估指标进行了概述。

Result: 揭示了该领域的三大趋势，并为未来的研究提供了路线图。

Conclusion: 这篇论文对人工智能在抑郁症检测和诊断中的应用进行了综述，总结了该领域的三大趋势：图神经网络在脑连接建模中的主导地位、大型语言模型在语言和会话数据中的兴起以及对多模态融合、可解释性和算法公平性的关注。

Abstract: Major Depressive Disorder is one of the leading causes of disability
worldwide, yet its diagnosis still depends largely on subjective clinical
assessments. Integrating Artificial Intelligence (AI) holds promise for
developing objective, scalable, and timely diagnostic tools. In this paper, we
present a comprehensive survey of state-of-the-art AI methods for depression
detection and diagnosis, based on a systematic review of 55 key studies. We
introduce a novel hierarchical taxonomy that structures the field by primary
clinical task (diagnosis vs. prediction), data modality (text, speech,
neuroimaging, multimodal), and computational model class (e.g., graph neural
networks, large language models, hybrid approaches). Our in-depth analysis
reveals three major trends: the predominance of graph neural networks for
modeling brain connectivity, the rise of large language models for linguistic
and conversational data, and an emerging focus on multimodal fusion,
explainability, and algorithmic fairness. Alongside methodological insights, we
provide an overview of prominent public datasets and standard evaluation
metrics as a practical guide for researchers. By synthesizing current advances
and highlighting open challenges, this survey offers a comprehensive roadmap
for future innovation in computational psychiatry.

</details>


### [14] [Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems](https://arxiv.org/abs/2508.12026)
*Szymon Pawlonka,Mikołaj Małkiński,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: Bongard-RWR+数据集使用视觉语言模型生成了5400个包含细粒度真实世界图像的Bongard问题实例，实验结果表明现有视觉语言模型的抽象视觉推理能力仍有待提高


<details>
  <summary>Details</summary>
Motivation: 现有的Bongard问题数据集存在规模小或概念过于简单的问题，难以充分测试抽象视觉推理模型的能力。

Method: 使用Pixtral-12B描述手动策划的图像并生成与基础概念一致的新描述，使用Flux.1-dev根据这些描述合成图像，并手动验证生成的图像是否忠实地反映了预期的概念。

Result: 评估结果表明，最先进的VLMs在识别细粒度视觉概念方面存在困难，这突出了它们在推理能力方面的局限性。

Conclusion: 这项工作介绍了Bongard-RWR+，一个包含5400个实例的BP数据集，使用视觉语言模型生成的类似真实世界的图像来表示原始BP抽象概念。评估结果表明，虽然VLMs能够识别粗粒度的视觉概念，但它们在识别细粒度概念方面始终存在困难，突出了其推理能力的局限性。

Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual
reasoning (AVR), requiring models to identify visual concepts fromjust a few
examples and describe them in natural language. Early BP benchmarks featured
synthetic black-and-white drawings, which might not fully capture the
complexity of real-world scenes. Subsequent BP datasets employed real-world
images, albeit the represented concepts are identifiable from high-level image
features, reducing the task complexity. Differently, the recently released
Bongard-RWR dataset aimed at representing abstract concepts formulated in the
original BPs using fine-grained real-world images. Its manual construction,
however, limited the dataset size to just $60$ instances, constraining
evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset
composed of $5\,400$ instances that represent original BP abstract concepts
using real-world-like images generated via a vision language model (VLM)
pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually
curated images and generate new descriptions aligned with the underlying
concepts, use Flux.1-dev to synthesize images from these descriptions, and
manually verify that the generated images faithfully reflect the intended
concepts. We evaluate state-of-the-art VLMs across diverse BP formulations,
including binary and multiclass classification, as well as textual answer
generation. Our findings reveal that while VLMs can recognize coarse-grained
visual concepts, they consistently struggle with discerning fine-grained
concepts, highlighting limitations in their reasoning capabilities.

</details>


### [15] [Active inference for action-unaware agents](https://arxiv.org/abs/2508.12027)
*Filippo Torresan,Keisuke Suzuki,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 在主动推理框架下，即使不知道自身行为，智能体也能在导航任务中取得良好性能。


<details>
  <summary>Details</summary>
Motivation: 探究主动推理框架下，智能体是否需要知道自身行为才能有效规划未来行动。

Method: 通过在两个导航任务中比较知道自身行为和不知道自身行为的智能体，评估两种策略的性能。

Result: 不知道自身行为的智能体在性能上可以与知道自身行为的智能体相媲美。

Conclusion: 比较了主动推理框架下两种导航任务中，知道自身行为和不知道自身行为的智能体的性能，结果表明，不知道自身行为的智能体即使处于劣势，也能取得与知道自身行为的智能体相当的性能。

Abstract: Active inference is a formal approach to study cognition based on the notion
that adaptive agents can be seen as engaging in a process of approximate
Bayesian inference, via the minimisation of variational and expected free
energies. Minimising the former provides an account of perceptual processes and
learning as evidence accumulation, while minimising the latter describes how
agents select their actions over time. In this way, adaptive agents are able to
maximise the likelihood of preferred observations or states, given a generative
model of the environment. In the literature, however, different strategies have
been proposed to describe how agents can plan their future actions. While they
all share the notion that some kind of expected free energy offers an
appropriate way to score policies, sequences of actions, in terms of their
desirability, there are different ways to consider the contribution of past
motor experience to the agent's future behaviour. In some approaches, agents
are assumed to know their own actions, and use such knowledge to better plan
for the future. In other approaches, agents are unaware of their actions, and
must infer their motor behaviour from recent observations in order to plan for
the future. This difference reflects a standard point of departure in two
leading frameworks in motor control based on the presence, or not, of an
efference copy signal representing knowledge about an agent's own actions. In
this work we compare the performances of action-aware and action-unaware agents
in two navigations tasks, showing how action-unaware agents can achieve
performances comparable to action-aware ones while at a severe disadvantage.

</details>
