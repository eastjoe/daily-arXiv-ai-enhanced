{"id": "2507.08806", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.08806", "abs": "https://arxiv.org/abs/2507.08806", "authors": ["Daewon Choi", "Jimin Lee", "Jihoon Tack", "Woomin Song", "Saket Dingliwal", "Sai Muralidhar Jayanthi", "Bhavana Ganesh", "Jinwoo Shin", "Aram Galstyan", "Sravan Babu Bodapati"], "title": "Think Clearly: Improving Reasoning via Redundant Token Pruning", "comment": null, "summary": "Recent large language models have shown promising capabilities in long-form\nreasoning, following structured chains of thought before arriving at a final\nanswer. However, we observe that these reasoning paths tend to include\nsubstantial redundancy; analyzing attention patterns reveals that attention\nscores are widely scattered, particularly incorrect answers exhibit greater\nattention sparsity. In this paper, we demonstrate that deliberately removing\nthis redundancy in the reasoning process significantly improves performance\nthrough clear thinking, i.e., removing distraction. Specifically, we\nsystematically identify reasoning redundancy by measuring token-level attention\nscores to a special end-of-thinking token, which is appended to an explicit\ninstruction inserted to conclude each intermediate reasoning step. Furthermore,\nwe propose structure-aware pruning that prioritizes removing tokens in\nlow-contributing reasoning chunks over individual tokens. After evicting\nredundant tokens, we remove the injected end-of-thinking instruction, then\nresume the reasoning generation. We demonstrate that our method significantly\nimproves overall accuracy across reasoning-intensive benchmarks without any\ntraining involved. In particular, our method shows strong performance on\nchallenging mathematical competition benchmarks such as AIME and AMC, where\nreasoning redundancy is more prevalent.", "AI": {"tldr": "\u53bb\u9664\u5927\u578b\u8bed\u8a00\u6a21\u578b\u957f\u7bc7\u63a8\u7406\u4e2d\u7684\u5197\u4f59\u4fe1\u606f\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u957f\u7bc7\u63a8\u7406\u4e2d\u5b58\u5728\u5197\u4f59\uff0c\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6d4b\u91cf\u6807\u8bb0\u7ea7\u6ce8\u610f\u529b\u5206\u6570\u6765\u8bc6\u522b\u5197\u4f59\u7684\u63a8\u7406\u6b65\u9aa4\uff0c\u5e76\u91c7\u7528\u7ed3\u6784\u611f\u77e5\u7684\u526a\u679d\u7b56\u7565\u53bb\u9664\u5197\u4f59\u6807\u8bb0\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u6570\u5b66\u7ade\u8d5b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u53bb\u9664\u5927\u578b\u8bed\u8a00\u6a21\u578b\u957f\u7bc7\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5197\u4f59\u4fe1\u606f\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u7684\u526a\u679d\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u53bb\u9664\u4f4e\u8d21\u732e\u7684\u63a8\u7406\u7247\u6bb5\u6765\u51cf\u5c11\u5197\u4f59\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u7684\u6e05\u6670\u601d\u7ef4\u80fd\u529b\u3002"}}
{"id": "2507.08875", "categories": ["cs.AI", "90B50, 90C29, 90C08, 91A80, 91B06"], "pdf": "https://arxiv.org/pdf/2507.08875", "abs": "https://arxiv.org/abs/2507.08875", "authors": ["Fuh-Hwa Franklin Liu", "Su-Chuan Shih"], "title": "A New Approach for Multicriteria Assessment in the Ranking of Alternatives Using Cardinal and Ordinal Data", "comment": "38 pages, 6 figures, 5 table. A practice applicable method for\n  multi-criteria assessments using cardinal and ordinal data", "summary": "Modern methods for multi-criteria assessment (MCA), such as Data Envelopment\nAnalysis (DEA), Stochastic Frontier Analysis (SFA), and Multiple Criteria\nDecision-Making (MCDM), are utilized to appraise a collection of\nDecision-Making Units (DMUs), also known as alternatives, based on several\ncriteria. These methodologies inherently rely on assumptions and can be\ninfluenced by subjective judgment to effectively tackle the complex evaluation\nchallenges in various fields. In real-world scenarios, it is essential to\nincorporate both quantitative and qualitative criteria as they consist of\ncardinal and ordinal data. Despite the inherent variability in the criterion\nvalues of different alternatives, the homogeneity assumption is often employed,\nsignificantly affecting evaluations. To tackle these challenges and determine\nthe most appropriate alternative, we propose a novel MCA approach that combines\ntwo Virtual Gap Analysis (VGA) models. The VGA framework, rooted in linear\nprogramming, is pivotal in the MCA methodology. This approach improves\nefficiency and fairness, ensuring that evaluations are both comprehensive and\ndependable, thus offering a strong and adaptive solution. Two comprehensive\nnumerical examples demonstrate the accuracy and transparency of our proposed\nmethod. The goal is to encourage continued advancement and stimulate progress\nin automated decision systems and decision support systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u7ed3\u5408\u4e24\u4e2aVGA\u6a21\u578b\u7684\u591a\u51c6\u5219\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u516c\u5e73\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u4f8b\u5b50\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709MCA\u65b9\u6cd5\uff08DEA\u3001SFA\u3001MCDM\uff09\u4f9d\u8d56\u5047\u8bbe\uff0c\u53d7\u4e3b\u89c2\u5224\u65ad\u5f71\u54cd\uff0c\u4e14\u96be\u4ee5\u5904\u7406\u5b9a\u91cf\u548c\u5b9a\u6027\u6807\u51c6\u3002", "method": "\u7ed3\u5408\u4e24\u4e2a\u865a\u62df\u5dee\u8ddd\u5206\u6790\uff08VGA\uff09\u6a21\u578b\u3002VGA\u6846\u67b6\u57fa\u4e8e\u7ebf\u6027\u89c4\u5212\uff0c\u662fMCA\u65b9\u6cd5\u7684\u6838\u5fc3\u3002", "result": "\u4e24\u4e2a\u6570\u503c\u4f8b\u5b50\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\uff0c\u4e3a\u81ea\u52a8\u5316\u51b3\u7b56\u7cfb\u7edf\u548c\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e24\u4e2a\u865a\u62df\u5dee\u8ddd\u5206\u6790\uff08VGA\uff09\u6a21\u578b\u7684\u65b0\u578b\u591a\u51c6\u5219\u8bc4\u4f30\uff08MCA\uff09\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6548\u7387\u548c\u516c\u5e73\u6027\uff0c\u786e\u4fdd\u8bc4\u4f30\u5168\u9762\u53ef\u9760\u3002"}}
{"id": "2507.08892", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.08892", "abs": "https://arxiv.org/abs/2507.08892", "authors": ["Alexander Sasha Vezhnevets", "Jayd Matyas", "Logan Cross", "Davide Paglieri", "Minsuk Chang", "William A. Cunningham", "Simon Osindero", "William S. Isaac", "Joel Z. Leibo"], "title": "Multi-Actor Generative Artificial Intelligence as a Game Engine", "comment": "13 pages", "summary": "Generative AI can be used in multi-actor environments with purposes ranging\nfrom social science modeling to interactive narrative and AI evaluation.\nSupporting this diversity of use cases -- which we classify as Simulationist,\nDramatist, and Evaluationist -- demands a flexible scenario definition\nframework. We argue here that a good approach is to take inspiration from\ntabletop role-playing games (TTRPGs), where a Game Master (GM) is responsible\nfor the environment and generates all parts of the story not directly\ndetermined by the voluntary actions of player characters. We argue that the\nEntity-Component architectural pattern is useful here. In such a system, the GM\nis not a hardcoded computer game but is itself a configurable entity, composed\nof components just like any other actor. By design, the approach allows for a\nseparation between the underlying implementation details handled by an\nengineer, the creation of reusable components, and their composition and\nconfiguration managed by a designer who constructs entities from the\ncomponents. This separation of concerns is instrumental for achieving rapid\niteration, maintaining modularity, and ultimately to ensure scalability. We\ndescribe the ongoing evolution of the Concordia library in terms of this\nphilosophy, demonstrating how it allows users to effectively configure\nscenarios that align with their specific goals.", "AI": {"tldr": "\u7528TTRPG\u7684\u7406\u5ff5\u548c\u5b9e\u4f53-\u7ec4\u4ef6\u67b6\u6784\u6784\u5efa\u66f4\u7075\u6d3b\u7684\u751f\u6210\u5f0fAI\u591a\u89d2\u8272\u73af\u5883\u573a\u666f\u5b9a\u4e49\u6846\u67b6\u3002", "motivation": "\u652f\u6301\u751f\u6210\u5f0fAI\u5728\u6a21\u62df\u3001\u620f\u5267\u548c\u8bc4\u4f30\u7b49\u591a\u79cd\u7528\u9014\u4e0b\u7684\u5e94\u7528\uff0c\u9700\u8981\u4e00\u4e2a\u7075\u6d3b\u7684\u573a\u666f\u5b9a\u4e49\u6846\u67b6\u3002", "method": "\u501f\u9274TTRPG\u4e2d\u6e38\u620f\u7ba1\u7406\u5458\uff08GM\uff09\u7684\u89d2\u8272\uff0c\u91c7\u7528\u5b9e\u4f53-\u7ec4\u4ef6\uff08Entity-Component\uff09\u67b6\u6784\u6a21\u5f0f\uff0c\u5b9e\u73b0\u573a\u666f\u5b9a\u4e49\u6846\u67b6\u7684\u7075\u6d3b\u6027\u548c\u53ef\u914d\u7f6e\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b9e\u4f53-\u7ec4\u4ef6\u67b6\u6784\u548cTTRPG\u7406\u5ff5\u7684\u573a\u666f\u5b9a\u4e49\u6846\u67b6\uff0c\u5e76\u901a\u8fc7Concordia\u5e93\u7684\u4f8b\u5b50\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u652f\u6301\u5feb\u901f\u8fed\u4ee3\u3001\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u672c\u6587\u8bba\u8ff0\u4e86\u5c06\u684c\u4e0a\u89d2\u8272\u626e\u6f14\u6e38\u620f\uff08TTRPG\uff09\u7684\u8bbe\u8ba1\u7406\u5ff5\u5e94\u7528\u4e8e\u751f\u6210\u5f0fAI\u591a\u89d2\u8272\u73af\u5883\u7684\u4f18\u52bf\uff0c\u5e76\u4ecb\u7ecd\u4e86Concordia\u5e93\u7684\u6f14\u8fdb\u8fc7\u7a0b\u3002"}}
{"id": "2507.09080", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.09080", "abs": "https://arxiv.org/abs/2507.09080", "authors": ["Athanasios Trantas", "Martino Mensio", "Stylianos Stasinos", "Sebastian Gribincea", "Taimur Khan", "Damian Podareanu", "Aliene van der Veen"], "title": "BioAnalyst: A Foundation Model for Biodiversity", "comment": null, "summary": "The accelerating loss of biodiversity presents critical challenges for\necological research and conservation strategies. The preservation of\nbiodiversity is paramount for maintaining ecological balance and ensuring the\nsustainability of ecosystems. However, biodiversity faces numerous threats,\nincluding habitat loss, climate change, and the proliferation of invasive\nspecies. Addressing these and other ecology-related challenges, both at local\nand global scales, requires comprehensive monitoring, predictive and\nconservation planning capabilities. Artificial Intelligence (AI) Foundation\nModels (FMs) have gained significant momentum in numerous scientific domains by\nleveraging vast datasets to learn general-purpose representations adaptable to\nvarious downstream tasks. This paradigm holds immense promise for biodiversity\nconservation. In response, we introduce BioAnalyst, the first Foundation Model\ntailored for biodiversity analysis and conservation planning. BioAnalyst\nemploys a transformer-based architecture, pre-trained on extensive multi-modal\ndatasets encompassing species occurrence records, remote sensing indicators,\nclimate and environmental variables. BioAnalyst is designed for adaptability,\nallowing for fine-tuning of a range of downstream tasks, such as species\ndistribution modelling, habitat suitability assessments, invasive species\ndetection, and population trend forecasting. We evaluate the model's\nperformance on two downstream use cases, demonstrating its generalisability\ncompared to existing methods, particularly in data-scarce scenarios for two\ndistinct use-cases, establishing a new accuracy baseline for ecological\nforecasting. By openly releasing BioAnalyst and its fine-tuning workflows to\nthe scientific community, we aim to foster collaborative efforts in\nbiodiversity modelling and advance AI-driven solutions to pressing ecological\nchallenges.", "AI": {"tldr": "BioAnalyst\u6a21\u578b\u63d0\u9ad8\u4e86\u751f\u7269\u591a\u6837\u6027\u5206\u6790\u548c\u4fdd\u62a4\u89c4\u5212\u7684\u6548\u7387\u548c\u7cbe\u5ea6\uff0c\u5c24\u5176\u5728\u6570\u636e\u7f3a\u4e4f\u7684\u60c5\u51b5\u4e0b\u3002", "motivation": "\u65e5\u76ca\u52a0\u5267\u7684\u751f\u7269\u591a\u6837\u6027\u4e27\u5931\u5bf9\u751f\u6001\u7814\u7a76\u548c\u4fdd\u62a4\u7b56\u7565\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u7efc\u5408\u76d1\u6d4b\u3001\u9884\u6d4b\u548c\u4fdd\u62a4\u89c4\u5212\u80fd\u529b\u3002AI\u57fa\u7840\u6a21\u578b\u6709\u671b\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u57fa\u4e8eTransformer\u67b6\u6784\uff0c\u4f7f\u7528\u591a\u6a21\u6001\u6570\u636e\u96c6\uff08\u7269\u79cd\u51fa\u73b0\u8bb0\u5f55\u3001\u9065\u611f\u6307\u6807\u3001\u6c14\u5019\u548c\u73af\u5883\u53d8\u91cf\uff09\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u53ef\u5fae\u8c03\u7528\u4e8e\u7269\u79cd\u5206\u5e03\u5efa\u6a21\u3001\u6816\u606f\u5730\u9002\u5b9c\u6027\u8bc4\u4f30\u3001\u5165\u4fb5\u7269\u79cd\u68c0\u6d4b\u548c\u79cd\u7fa4\u8d8b\u52bf\u9884\u6d4b\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002", "result": "\u5728\u4e24\u4e2a\u4e0b\u6e38\u7528\u4f8b\u4e2d\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u8bc1\u660e\u5176\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u751f\u6001\u9884\u6d4b\u5efa\u7acb\u4e86\u65b0\u7684\u7cbe\u5ea6\u57fa\u51c6\u3002", "conclusion": "BioAnalyst\uff0c\u9996\u4e2a\u7528\u4e8e\u751f\u7269\u591a\u6837\u6027\u5206\u6790\u548c\u4fdd\u62a4\u89c4\u5212\u7684\u57fa\u7840\u6a21\u578b\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u751f\u6001\u9884\u6d4b\u5efa\u7acb\u4e86\u65b0\u7684\u7cbe\u5ea6\u57fa\u51c6\u3002"}}
{"id": "2507.09089", "categories": ["cs.AI", "cs.HC", "cs.SE", "I.2"], "pdf": "https://arxiv.org/pdf/2507.09089", "abs": "https://arxiv.org/abs/2507.09089", "authors": ["Joel Becker", "Nate Rush", "Elizabeth Barnes", "David Rein"], "title": "Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity", "comment": "50 pages, 8 tables, 22 figures", "summary": "Despite widespread adoption, the impact of AI tools on software development\nin the wild remains understudied. We conduct a randomized controlled trial\n(RCT) to understand how AI tools at the February-June 2025 frontier affect the\nproductivity of experienced open-source developers. 16 developers with moderate\nAI experience complete 246 tasks in mature projects on which they have an\naverage of 5 years of prior experience. Each task is randomly assigned to allow\nor disallow usage of early 2025 AI tools. When AI tools are allowed, developers\nprimarily use Cursor Pro, a popular code editor, and Claude 3.5/3.7 Sonnet.\nBefore starting tasks, developers forecast that allowing AI will reduce\ncompletion time by 24%. After completing the study, developers estimate that\nallowing AI reduced completion time by 20%. Surprisingly, we find that allowing\nAI actually increases completion time by 19%--AI tooling slowed developers\ndown. This slowdown also contradicts predictions from experts in economics (39%\nshorter) and ML (38% shorter). To understand this result, we collect and\nevaluate evidence for 20 properties of our setting that a priori could\ncontribute to the observed slowdown effect--for example, the size and quality\nstandards of projects, or prior developer experience with AI tooling. Although\nthe influence of experimental artifacts cannot be entirely ruled out, the\nrobustness of the slowdown effect across our analyses suggests it is unlikely\nto primarily be a function of our experimental design.", "AI": {"tldr": "AI\u5de5\u5177\u5e76\u672a\u63d0\u9ad8\u8f6f\u4ef6\u5f00\u53d1\u6548\u7387\uff0c\u53cd\u800c\u964d\u4f4e\u4e86\u6548\u7387\u3002", "motivation": "\u7814\u7a76AI\u5de5\u5177\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u6548\u7387\u7684\u5f71\u54cd", "method": "\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c (RCT)", "result": "AI\u5de5\u5177\u7684\u4f7f\u7528\u589e\u52a0\u4e8619%\u7684\u5b8c\u6210\u65f6\u95f4\uff0c\u4e0e\u5f00\u53d1\u8005\u9884\u6d4b\uff08\u51cf\u5c1120%\uff09\u548c\u4e13\u5bb6\u9884\u6d4b\uff08\u51cf\u5c1138%-39%\uff09\u76f8\u53cd\u3002", "conclusion": "\u4e00\u9879\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u8868\u660e\uff0c\u5c3d\u7ba1AI\u5de5\u5177\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5728\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0cAI\u5de5\u5177\u53cd\u800c\u4f7f\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u6e90\u5f00\u53d1\u8005\u5b8c\u6210\u4efb\u52a1\u7684\u65f6\u95f4\u589e\u52a0\u4e8619%\uff0c\u8fd9\u4e0e\u4e13\u5bb6\u9884\u6d4b\u76f8\u53cd\u3002"}}
{"id": "2507.09179", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.09179", "abs": "https://arxiv.org/abs/2507.09179", "authors": ["Ronghua Shi", "Yiou Liu", "Xinyu Ying", "Yang Tan", "Yuchun Feng", "Lynn Ai", "Bill Shi", "Xuhui Wang", "Zhuang Liu"], "title": "Hide-and-Shill: A Reinforcement Learning Framework for Market Manipulation Detection in Symphony-a Decentralized Multi-Agent System", "comment": null, "summary": "Decentralized finance (DeFi) has introduced a new era of permissionless\nfinancial innovation but also led to unprecedented market manipulation. Without\ncentralized oversight, malicious actors coordinate shilling campaigns and\npump-and-dump schemes across various platforms. We propose a Multi-Agent\nReinforcement Learning (MARL) framework for decentralized manipulation\ndetection, modeling the interaction between manipulators and detectors as a\ndynamic adversarial game. This framework identifies suspicious patterns using\ndelayed token price reactions as financial indicators.Our method introduces\nthree innovations: (1) Group Relative Policy Optimization (GRPO) to enhance\nlearning stability in sparse-reward and partially observable settings; (2) a\ntheory-based reward function inspired by rational expectations and information\nasymmetry, differentiating price discovery from manipulation noise; and (3) a\nmulti-modal agent pipeline that integrates LLM-based semantic features, social\ngraph signals, and on-chain market data for informed decision-making.The\nframework is integrated within the Symphony system, a decentralized multi-agent\narchitecture enabling peer-to-peer agent execution and trust-aware learning\nthrough distributed logs, supporting chain-verifiable evaluation. Symphony\npromotes adversarial co-evolution among strategic actors and maintains robust\nmanipulation detection without centralized oracles, enabling real-time\nsurveillance across global DeFi ecosystems.Trained on 100,000 real-world\ndiscourse episodes and validated in adversarial simulations, Hide-and-Shill\nachieves top performance in detection accuracy and causal attribution. This\nwork bridges multi-agent systems with financial surveillance, advancing a new\nparadigm for decentralized market intelligence. All resources are available at\nthe Hide-and-Shill GitHub repository to promote open research and\nreproducibility.", "AI": {"tldr": "\u5229\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u68c0\u6d4bDeFi\u5e02\u573a\u64cd\u7eb5\uff0c\u65e0\u9700\u4e2d\u5fc3\u5316\uff0c\u51c6\u786e\u7387\u9ad8\u3002", "motivation": "DeFi\u7684\u53bb\u4e2d\u5fc3\u5316\u7279\u6027\u5bfc\u81f4\u4e86\u524d\u6240\u672a\u6709\u7684\u5e02\u573a\u64cd\u7eb5\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u3002", "method": "\u8be5\u6846\u67b6\u91c7\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60(MARL)\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e09\u79cd\u521b\u65b0\uff1a(1) \u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\uff1b(2) \u57fa\u4e8e\u7406\u6027\u9884\u671f\u548c\u4fe1\u606f\u4e0d\u5bf9\u79f0\u7684\u5956\u52b1\u51fd\u6570\uff1b(3) \u96c6\u6210LLM\u3001\u793e\u4ea4\u56fe\u8c31\u4fe1\u53f7\u548c\u94fe\u4e0a\u6570\u636e\u7684\u591a\u6a21\u6001\u667a\u80fd\u4f53\u3002", "result": "\u63d0\u51fa\u7684Symphony\u7cfb\u7edf\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u56e0\u679c\u5f52\u56e0\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u5728\u5bf9\u6297\u6027\u6a21\u62df\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u53bb\u4e2d\u5fc3\u5316\u5e02\u573a\u64cd\u7eb5\u68c0\u6d4b\u6846\u67b6Symphony\uff0c\u80fd\u591f\u5728\u65e0\u9700\u4e2d\u5fc3\u5316\u76d1\u7ba1\u7684\u60c5\u51b5\u4e0b\u5b9e\u65f6\u76d1\u63a7\u5168\u7403DeFi\u751f\u6001\u7cfb\u7edf\uff0c\u5e76\u53d6\u5f97\u4e86\u8f83\u9ad8\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u56e0\u679c\u5f52\u56e0\u80fd\u529b\u3002"}}
{"id": "2507.09329", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.09329", "abs": "https://arxiv.org/abs/2507.09329", "authors": ["Matous Kozak", "Roshanak Zilouchian Moghaddam", "Siva Sivaraman"], "title": "When Developer Aid Becomes Security Debt: A Systematic Analysis of Insecure Behaviors in LLM Coding Agents", "comment": "15 pages", "summary": "LLM-based coding agents are rapidly being deployed in software development,\nyet their security implications remain poorly understood. These agents, while\ncapable of accelerating software development, may inadvertently introduce\ninsecure practices. We conducted the first systematic security evaluation of\nautonomous coding agents, analyzing over 12,000 actions across five\nstate-of-the-art models (GPT-4o, GPT-4.1, Claude variants) on 93 real-world\nsoftware setup tasks. Our findings reveal significant security concerns: 21% of\nagent trajectories contained insecure actions, with models showing substantial\nvariation in security behavior. We developed a high-precision detection system\nthat identified four major vulnerability categories, with information exposure\n(CWE-200) being the most prevalent one. We also evaluated mitigation strategies\nincluding feedback mechanisms and security reminders with various effectiveness\nbetween models. GPT-4.1 demonstrated exceptional security awareness with 96.8%\nmitigation success. Our work provides the first comprehensive framework for\nevaluating coding agent security and highlights the need for security-aware\ndesign of next generation LLM-based coding agents.", "AI": {"tldr": "\u81ea\u4e3b\u7f16\u7801\u4ee3\u7406\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0cGPT-4.1\u8868\u73b0\u6700\u4f73\uff0c\u9700\u5173\u6ce8\u5b89\u5168\u8bbe\u8ba1\u3002", "motivation": "LLM\u9a71\u52a8\u7684\u7f16\u7801\u4ee3\u7406\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u5176\u5b89\u5168\u9690\u60a3\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u5206\u6790\u4e86\u4e94\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\uff08GPT-4o\u3001GPT-4.1\u3001Claude \u53d8\u4f53\uff09\u572893\u4e2a\u771f\u5b9e\u8f6f\u4ef6\u8bbe\u7f6e\u4efb\u52a1\u4e0a\u768412000\u591a\u4e2a\u64cd\u4f5c\u3002", "result": "21%\u7684\u4ee3\u7406\u8f68\u8ff9\u5305\u542b\u4e0d\u5b89\u5168\u64cd\u4f5c\uff0c\u4e0d\u540c\u6a21\u578b\u7684\u5b89\u5168\u884c\u4e3a\u5dee\u5f02\u5f88\u5927\u3002\u4fe1\u606f\u6cc4\u9732\u662f\u6700\u5e38\u89c1\u6f0f\u6d1e\u3002GPT-4.1 \u7684\u7f13\u89e3\u6210\u529f\u7387\u8fbe96.8%\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86\u81ea\u4e3b\u7f16\u7801\u4ee3\u7406\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u663e\u8457\u7684\u5b89\u5168\u9690\u60a3\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u7cfb\u7edf\u548c\u591a\u79cd\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2507.09369", "categories": ["cs.AI", "68T01", "I.2.0"], "pdf": "https://arxiv.org/pdf/2507.09369", "abs": "https://arxiv.org/abs/2507.09369", "authors": ["Andrew Critch", "Jacob Tsimerman"], "title": "A Taxonomy of Omnicidal Futures Involving Artificial Intelligence", "comment": null, "summary": "This report presents a taxonomy and examples of potential omnicidal events\nresulting from AI: scenarios where all or almost all humans are killed. These\nevents are not presented as inevitable, but as possibilities that we can work\nto avoid. Insofar as large institutions require a degree of public support in\norder to take certain actions, we hope that by presenting these possibilities\nin public, we can help to support preventive measures against catastrophic\nrisks from AI.", "AI": {"tldr": "\u4eba\u5de5\u667a\u80fd\u53ef\u80fd\u5bfc\u81f4\u4eba\u7c7b\u706d\u7edd\uff0c\u4f46\u8fd9\u4e9b\u4e8b\u4ef6\u5e76\u975e\u4e0d\u53ef\u907f\u514d\uff0c\u6211\u4eec\u53ef\u4ee5\u91c7\u53d6\u63aa\u65bd\u9884\u9632\u3002", "motivation": "\u901a\u8fc7\u516c\u5f00\u8fd9\u4e9b\u53ef\u80fd\u6027\uff0c\u4ee5\u671f\u4fc3\u4f7f\u9884\u9632\u63aa\u65bd\u7684\u5b9e\u65bd\uff0c\u907f\u514d\u4eba\u5de5\u667a\u80fd\u5e26\u6765\u7684\u707e\u96be\u6027\u98ce\u9669\u3002", "method": "\u5bf9\u4eba\u5de5\u667a\u80fd\u5bfc\u81f4\u7684\u6f5c\u5728\u5927\u89c4\u6a21\u706d\u7edd\u4e8b\u4ef6\u8fdb\u884c\u5206\u7c7b\u548c\u4e3e\u4f8b\u8bf4\u660e\u3002", "result": "\u5217\u4e3e\u4e86\u4eba\u5de5\u667a\u80fd\u53ef\u80fd\u5bfc\u81f4\u4eba\u7c7b\u706d\u7edd\u7684\u591a\u79cd\u53ef\u80fd\u6027\u3002", "conclusion": "\u8fd9\u4efd\u62a5\u544a\u5217\u4e3e\u4e86\u4eba\u5de5\u667a\u80fd\u5bfc\u81f4\u7684\u6f5c\u5728\u5927\u89c4\u6a21\u706d\u7edd\u4e8b\u4ef6\u7684\u5206\u7c7b\u548c\u4f8b\u5b50\uff0c\u8fd9\u4e9b\u4e8b\u4ef6\u5e76\u975e\u4e0d\u53ef\u907f\u514d\uff0c\u800c\u662f\u6211\u4eec\u53ef\u4ee5\u52aa\u529b\u907f\u514d\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.09374", "categories": ["cs.AI", "I.2.6; I.2.10"], "pdf": "https://arxiv.org/pdf/2507.09374", "abs": "https://arxiv.org/abs/2507.09374", "authors": ["Chenglin Zhu", "Tao Zhang", "Chong Li", "Mingan Lin", "Zenan Zhou", "Jian Xie"], "title": "EduFlow: Advancing MLLMs' Problem-Solving Proficiency through Multi-Stage, Multi-Perspective Critique", "comment": "14 pages,4 figures", "summary": "Multimodal large language models (MLLMs) still perform poorly on scientific\ntasks, particularly those requiring multi-step and interpretable reasoning.\nTheir limitations include insufficient scientific reasoning patterns, lack of\nglobal coherence in multi-step inference, and the absence of reflective\nself-correction, making them unreliable in structured scientific contexts. We\nintroduce EduFlow, the first end-to-end framework that covers the full pipeline\nof educational scientific reasoning, including data selection, MCTS-based\ntrajectory construction, model training, and output optimization. At its core\nis EduPRM, a process-aware reward model that critiques reasoning steps with\ntags and justifications. EduPRM is trained via curriculum learning on three\ncomplementary supervision sources: MCTS-guided trajectories, error-injected\ncritiques, and teacher-student dialogues, enabling dynamic adaptation to\nmulti-stage problem solving and iterative refinement during inference. We\nfurther propose EduMCTS, a domain-adapted search framework that introduces\nbootstrapping actions specifically designed for educational reasoning, such as\na self-reflection mechanism that promotes reflective error correction. It\nfurther leverages EduPRM's fine-grained feedback to guide the search toward\nhigher-quality reasoning trajectories. By applying self-consistency and\nrejection sampling, we constructed EduMCTS-160K, a large-scale dataset of\neducational reasoning trajectories. Extensive experiments demonstrate that\nEduFlow enhances reasoning consistency and coherence. Code, data, and models\nwill be released.", "AI": {"tldr": "EduFlow\u6846\u67b6\u901a\u8fc7\u8fc7\u7a0b\u611f\u77e5\u5956\u52b1\u6a21\u578b\u548c\u9886\u57df\u81ea\u9002\u5e94\u641c\u7d22\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u591a\u6b65\u9aa4\u548c\u53ef\u89e3\u91ca\u63a8\u7406\u7684\u79d1\u5b66\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0cEduFlow\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u6559\u80b2\u79d1\u5b66\u63a8\u7406\u6846\u67b6EduFlow\uff0c\u5305\u542b\u6570\u636e\u9009\u62e9\u3001\u57fa\u4e8eMCTS\u7684\u8f68\u8ff9\u6784\u5efa\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u8f93\u51fa\u4f18\u5316\u7b49\u6b65\u9aa4\uff0c\u6838\u5fc3\u662f\u8fc7\u7a0b\u611f\u77e5\u5956\u52b1\u6a21\u578bEduPRM\u548c\u9886\u57df\u81ea\u9002\u5e94\u641c\u7d22\u6846\u67b6EduMCTS\u3002", "result": "\u5b9e\u9a8c\u8868\u660eEduFlow\u63d0\u9ad8\u4e86\u63a8\u7406\u4e00\u81f4\u6027\u548c\u8fde\u8d2f\u6027\u3002", "conclusion": "EduFlow\u6846\u67b6\u589e\u5f3a\u4e86\u79d1\u5b66\u63a8\u7406\u7684\u4e00\u81f4\u6027\u548c\u8fde\u8d2f\u6027\uff0c\u5e76\u5728\u6559\u80b2\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002"}}
{"id": "2507.09389", "categories": ["cs.AI", "cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.09389", "abs": "https://arxiv.org/abs/2507.09389", "authors": ["Chris Davis Jaldi", "Anmol Saini", "Elham Ghiasi", "O. Divine Eziolise", "Cogan Shimizu"], "title": "Knowledge Conceptualization Impacts RAG Efficacy", "comment": null, "summary": "Explainability and interpretability are cornerstones of frontier and\nnext-generation artificial intelligence (AI) systems. This is especially true\nin recent systems, such as large language models (LLMs), and more broadly,\ngenerative AI. On the other hand, adaptability to new domains, contexts, or\nscenarios is also an important aspect for a successful system. As such, we are\nparticularly interested in how we can merge these two efforts, that is,\ninvestigating the design of transferable and interpretable neurosymbolic AI\nsystems. Specifically, we focus on a class of systems referred to as ''Agentic\nRetrieval-Augmented Generation'' systems, which actively select, interpret, and\nquery knowledge sources in response to natural language prompts. In this paper,\nwe systematically evaluate how different conceptualizations and representations\nof knowledge, particularly the structure and complexity, impact an AI agent (in\nthis case, an LLM) in effectively querying a triplestore. We report our\nresults, which show that there are impacts from both approaches, and we discuss\ntheir impact and implications.", "AI": {"tldr": "\u7814\u7a76\u4e86\u77e5\u8bc6\u8868\u793a\u5bf9\u53ef\u89e3\u91caAI\u7cfb\u7edf\u4e2dLLM\u6709\u6548\u67e5\u8be2\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u77e5\u8bc6\u7ed3\u6784\u548c\u590d\u6742\u6027\u5747\u6709\u5f71\u54cd\u3002", "motivation": "\u63a2\u7a76\u53ef\u8fc1\u79fb\u548c\u53ef\u89e3\u91ca\u7684\u795e\u7ecf\u7b26\u53f7AI\u7cfb\u7edf\u7684\u53ef\u8fc1\u79fb\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u7279\u522b\u662f\u5982\u4f55\u5c06\u8fd9\u4e24\u79cd\u80fd\u529b\u7ed3\u5408\u3002", "method": "\u5bf9\u57fa\u4e8eAgent\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u8fdb\u884c\u8bc4\u4f30\uff0c\u8be5\u7cfb\u7edf\u4e3b\u52a8\u9009\u62e9\u3001\u89e3\u91ca\u548c\u67e5\u8be2\u77e5\u8bc6\u6e90\u4ee5\u54cd\u5e94\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u3002", "result": "\u4e0d\u540c\u77e5\u8bc6\u7ed3\u6784\u548c\u590d\u6742\u6027\u5bf9LLM\u6709\u6548\u67e5\u8be2\u4e09\u5143\u7ec4\u5b58\u50a8\u5e93\u7684\u5f71\u54cd\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u77e5\u8bc6\u7684\u4e0d\u540c\u6982\u5ff5\u5316\u548c\u8868\u793a\u65b9\u5f0f\uff08\u7279\u522b\u662f\u7ed3\u6784\u548c\u590d\u6742\u6027\uff09\u5982\u4f55\u5f71\u54cdAI\u667a\u80fd\u4f53\uff08\u6b64\u5904\u4e3aLLM\uff09\u6709\u6548\u67e5\u8be2\u4e09\u5143\u7ec4\u5b58\u50a8\u5e93\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u4f1a\u4ea7\u751f\u5f71\u54cd\uff0c\u5e76\u8ba8\u8bba\u4e86\u5b83\u4eec\u7684\u5f71\u54cd\u548c\u610f\u4e49\u3002"}}
{"id": "2507.09407", "categories": ["cs.AI", "cs.CR", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.09407", "abs": "https://arxiv.org/abs/2507.09407", "authors": ["Quanyan Zhu"], "title": "LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their Applications to Spearphishing", "comment": null, "summary": "We introduce the framework of LLM-Stackelberg games, a class of sequential\ndecision-making models that integrate large language models (LLMs) into\nstrategic interactions between a leader and a follower. Departing from\nclassical Stackelberg assumptions of complete information and rational agents,\nour formulation allows each agent to reason through structured prompts,\ngenerate probabilistic behaviors via LLMs, and adapt their strategies through\ninternal cognition and belief updates. We define two equilibrium concepts:\nreasoning and behavioral equilibrium, which aligns an agent's internal\nprompt-based reasoning with observable behavior, and conjectural reasoning\nequilibrium, which accounts for epistemic uncertainty through parameterized\nmodels over an opponent's response. These layered constructs capture bounded\nrationality, asymmetric information, and meta-cognitive adaptation. We\nillustrate the framework through a spearphishing case study, where a sender and\na recipient engage in a deception game using structured reasoning prompts. This\nexample highlights the cognitive richness and adversarial potential of\nLLM-mediated interactions. Our results show that LLM-Stackelberg games provide\na powerful paradigm for modeling decision-making in domains such as\ncybersecurity, misinformation, and recommendation systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faLLM-Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u5305\u542bLLM\u7684\u6218\u7565\u4e92\u52a8\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u7f51\u7edc\u9493\u9c7c\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u4e86\u8bf4\u660e\u3002", "motivation": "\u7ecf\u5178Stackelberg\u535a\u5f08\u5047\u8bbe\u4fe1\u606f\u5b8c\u6574\u4e14\u53c2\u4e0e\u8005\u7406\u6027\uff0c\u800c\u8be5\u6846\u67b6\u5141\u8bb8\u6bcf\u4e2a\u53c2\u4e0e\u8005\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u8fdb\u884c\u63a8\u7406\uff0c\u5e76\u901a\u8fc7LLM\u751f\u6210\u6982\u7387\u884c\u4e3a\u3002", "method": "\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u96c6\u6210\u5230\u9886\u5bfc\u8005\u548c\u8ffd\u968f\u8005\u4e4b\u95f4\u7684\u6218\u7565\u4e92\u52a8\u4e2d\uff0c\u5b9a\u4e49\u4e86\u63a8\u7406\u5747\u8861\u548c\u731c\u60f3\u63a8\u7406\u5747\u8861\u4e24\u79cd\u5747\u8861\u6982\u5ff5\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cLLM-Stackelberg\u535a\u5f08\u80fd\u591f\u6355\u6349\u6709\u9650\u7406\u6027\u3001\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u5143\u8ba4\u77e5\u9002\u5e94\u6027\u3002", "conclusion": "LLM-Stackelberg\u535a\u5f08\u6846\u67b6\u4e3a\u5efa\u6a21\u7f51\u7edc\u5b89\u5168\u3001\u865a\u5047\u4fe1\u606f\u548c\u63a8\u8350\u7cfb\u7edf\u7b49\u9886\u57df\u4e2d\u7684\u51b3\u7b56\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u8303\u5f0f\u3002"}}
{"id": "2507.09495", "categories": ["cs.AI", "cs.ET", "cs.HC", "cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.09495", "abs": "https://arxiv.org/abs/2507.09495", "authors": ["Hang Wang", "Junshan Zhang"], "title": "GenAI-based Multi-Agent Reinforcement Learning towards Distributed Agent Intelligence: A Generative-RL Agent Perspective", "comment": "Position paper", "summary": "Multi-agent reinforcement learning faces fundamental challenges that\nconventional approaches have failed to overcome: exponentially growing joint\naction spaces, non-stationary environments where simultaneous learning creates\nmoving targets, and partial observability that constrains coordination. Current\nmethods remain reactive, employing stimulus-response mechanisms that fail when\nfacing novel scenarios. We argue for a transformative paradigm shift from\nreactive to proactive multi-agent intelligence through generative AI-based\nreinforcement learning. This position advocates reconceptualizing agents not as\nisolated policy optimizers, but as sophisticated generative models capable of\nsynthesizing complex multi-agent dynamics and making anticipatory decisions\nbased on predictive understanding of future interactions. Rather than\nresponding to immediate observations, generative-RL agents can model\nenvironment evolution, predict other agents' behaviors, generate coordinated\naction sequences, and engage in strategic reasoning accounting for long-term\ndynamics. This approach leverages pattern recognition and generation\ncapabilities of generative AI to enable proactive decision-making, seamless\ncoordination through enhanced communication, and dynamic adaptation to evolving\nscenarios. We envision this paradigm shift will unlock unprecedented\npossibilities for distributed intelligence, moving beyond individual\noptimization toward emergent collective behaviors representing genuine\ncollaborative intelligence. The implications extend across autonomous systems,\nrobotics, and human-AI collaboration, promising solutions to coordination\nchallenges intractable under traditional reactive frameworks.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u8d4b\u80fd\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e3b\u52a8\u5f0f\u534f\u4f5c\uff0c\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u9762\u5bf9\u6307\u6570\u7ea7\u589e\u957f\u7684\u8054\u5408\u52a8\u4f5c\u7a7a\u95f4\u3001\u975e\u5e73\u7a33\u73af\u5883\u548c\u90e8\u5206\u53ef\u89c2\u5bdf\u6027\u65f6\uff0c\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u9884\u6d4b\u73af\u5883\u6f14\u53d8\u548c\u5176\u5b83\u667a\u80fd\u4f53\u7684\u884c\u4e3a\uff0c\u751f\u6210\u534f\u8c03\u7684\u52a8\u4f5c\u5e8f\u5217\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u53cd\u5e94\u5f0f\u5230\u4e3b\u52a8\u5f0f\u591a\u667a\u80fd\u4f53\u667a\u80fd\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5229\u7528\u751f\u6210\u5f0fAI\u7684\u80fd\u529b\u5b9e\u73b0\u9884\u6d4b\u6027\u51b3\u7b56\u3001\u65e0\u7f1d\u534f\u4f5c\u548c\u52a8\u6001\u9002\u5e94\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u589e\u5f3a\u578b\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6709\u671b\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u5728\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u95ee\u9898\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u534f\u540c\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2507.09534", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.09534", "abs": "https://arxiv.org/abs/2507.09534", "authors": ["Guanquan Wang", "Takuya Hiraoka", "Yoshimasa Tsuruoka"], "title": "Consistency Trajectory Planning: High-Quality and Efficient Trajectory Optimization for Offline Model-Based Reinforcement Learning", "comment": null, "summary": "This paper introduces Consistency Trajectory Planning (CTP), a novel offline\nmodel-based reinforcement learning method that leverages the recently proposed\nConsistency Trajectory Model (CTM) for efficient trajectory optimization. While\nprior work applying diffusion models to planning has demonstrated strong\nperformance, it often suffers from high computational costs due to iterative\nsampling procedures. CTP supports fast, single-step trajectory generation\nwithout significant degradation in policy quality. We evaluate CTP on the D4RL\nbenchmark and show that it consistently outperforms existing diffusion-based\nplanning methods in long-horizon, goal-conditioned tasks. Notably, CTP achieves\nhigher normalized returns while using significantly fewer denoising steps. In\nparticular, CTP achieves comparable performance with over $120\\times$ speedup\nin inference time, demonstrating its practicality and effectiveness for\nhigh-performance, low-latency offline planning.", "AI": {"tldr": "CTP \u662f\u4e00\u79cd\u9ad8\u6548\u7684\u79bb\u7ebf\u8f68\u8ff9\u89c4\u5212\u65b9\u6cd5\uff0c\u901f\u5ea6\u5feb\uff0c\u6027\u80fd\u597d\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u89c4\u5212\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0cCTP\u65e8\u5728\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5b9e\u73b0\u5feb\u901f\u3001\u5355\u6b65\u8f68\u8ff9\u751f\u6210\uff0c\u4e14\u4e0d\u663e\u8457\u964d\u4f4e\u7b56\u7565\u8d28\u91cf\u3002", "method": "\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u5229\u7528 Consistency Trajectory Model (CTM) \u8fdb\u884c\u8f68\u8ff9\u4f18\u5316\u3002", "result": "\u5728 D4RL \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCTP \u5728\u957f\u8303\u56f4\u3001\u76ee\u6807\u6761\u4ef6\u7684\u4efb\u52a1\u4e2d\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u6269\u6563\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5f52\u4e00\u5316\u56de\u62a5\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u8d85\u8fc7 120 \u500d\u3002", "conclusion": "Consistency Trajectory Planning (CTP) \u662f\u4e00\u79cd\u65b0\u9896\u7684\u79bb\u7ebf\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u6700\u8fd1\u63d0\u51fa\u7684 Consistency Trajectory Model (CTM) \u6765\u9ad8\u6548\u5730\u8fdb\u884c\u8f68\u8ff9\u4f18\u5316\uff0c\u5e76\u5728 D4RL \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u6269\u6563\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5f52\u4e00\u5316\u56de\u62a5\u548c\u66f4\u5feb\u7684\u63a8\u7406\u901f\u5ea6\u3002"}}
{"id": "2507.09540", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.09540", "abs": "https://arxiv.org/abs/2507.09540", "authors": ["Ali Safa", "Farida Mohsen", "Ali Al-Zawqari"], "title": "Learning to Control Dynamical Agents via Spiking Neural Networks and Metropolis-Hastings Sampling", "comment": null, "summary": "Spiking Neural Networks (SNNs) offer biologically inspired, energy-efficient\nalternatives to traditional Deep Neural Networks (DNNs) for real-time control\nsystems. However, their training presents several challenges, particularly for\nreinforcement learning (RL) tasks, due to the non-differentiable nature of\nspike-based communication. In this work, we introduce what is, to our\nknowledge, the first framework that employs Metropolis-Hastings (MH) sampling,\na Bayesian inference technique, to train SNNs for dynamical agent control in RL\nenvironments without relying on gradient-based methods. Our approach\niteratively proposes and probabilistically accepts network parameter updates\nbased on accumulated reward signals, effectively circumventing the limitations\nof backpropagation while enabling direct optimization on neuromorphic\nplatforms. We evaluated this framework on two standard control benchmarks:\nAcroBot and CartPole. The results demonstrate that our MH-based approach\noutperforms conventional Deep Q-Learning (DQL) baselines and prior SNN-based RL\napproaches in terms of maximizing the accumulated reward while minimizing\nnetwork resources and training episodes.", "AI": {"tldr": "MH\u91c7\u6837\u8bad\u7ec3SNN\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\uff0c\u6548\u679c\u4f18\u4e8eDQL\u548c\u73b0\u6709SNN\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u8109\u51b2\u795e\u7ecf\u7f51\u7edc (SNN) \u5728\u5f3a\u5316\u5b66\u4e60 (RL) \u4efb\u52a1\u4e2d\u8bad\u7ec3\u7684\u96be\u9898\uff0c\u7279\u522b\u662f\u5176\u975e\u53ef\u5fae\u6027\u3002", "method": "\u4f7f\u7528 Metropolis-Hastings (MH) \u91c7\u6837\u8fdb\u884c\u8bad\u7ec3\uff0c\u65e0\u9700\u53cd\u5411\u4f20\u64ad\u3002", "result": "\u5728 Acrobot \u548c CartPole \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u6700\u5927\u5316\u7d2f\u79ef\u5956\u52b1\u3001\u6700\u5c0f\u5316\u7f51\u7edc\u8d44\u6e90\u548c\u8bad\u7ec3\u6b21\u6570\u65b9\u9762\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u6df1\u5ea6 Q \u5b66\u4e60 (DQL) \u548c\u73b0\u6709\u7684 SNN \u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e Metropolis-Hastings (MH) \u91c7\u6837\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u7528\u4e8e\u52a8\u6001\u4ee3\u7406\u63a7\u5236\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc (SNN)\uff0c\u65e0\u9700\u68af\u5ea6\u65b9\u6cd5\uff0c\u5e76\u5728 Acrobot \u548c CartPole \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u4f20\u7edf\u6df1\u5ea6 Q \u5b66\u4e60 (DQL) \u548c\u73b0\u6709 SNN \u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u7ed3\u679c\u3002"}}
{"id": "2507.09588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.09588", "abs": "https://arxiv.org/abs/2507.09588", "authors": ["Isaac Shi", "Zeyuan Li", "Fan Liu", "Wenli Wang", "Lewei He", "Yang Yang", "Tianyu Shi"], "title": "eSapiens: A Platform for Secure and Auditable Retrieval-Augmented Generation", "comment": null, "summary": "We present eSapiens, an AI-as-a-Service (AIaaS) platform engineered around a\nbusiness-oriented trifecta: proprietary data, operational workflows, and any\nmajor agnostic Large Language Model (LLM). eSapiens gives businesses full\ncontrol over their AI assets, keeping everything in-house for AI knowledge\nretention and data security. eSapiens AI Agents (Sapiens) empower your team by\nproviding valuable insights and automating repetitive tasks, enabling them to\nfocus on high-impact work and drive better business outcomes.\n  The system integrates structured document ingestion, hybrid vector retrieval,\nand no-code orchestration via LangChain, and supports top LLMs including\nOpenAI, Claude, Gemini, and DeepSeek. A key component is the THOR Agent, which\nhandles structured SQL-style queries and generates actionable insights over\nenterprise databases.\n  To evaluate the system, we conduct two experiments. First, a retrieval\nbenchmark on legal corpora reveals that a chunk size of 512 tokens yields the\nhighest retrieval precision (Top-3 accuracy: 91.3%). Second, a generation\nquality test using TRACe metrics across five LLMs shows that eSapiens delivers\nmore context-consistent outputs with up to a 23% improvement in factual\nalignment.\n  These results demonstrate the effectiveness of eSapiens in enabling\ntrustworthy, auditable AI workflows for high-stakes domains like legal and\nfinance.", "AI": {"tldr": "eSapiens AIaaS\u5e73\u53f0\u901a\u8fc7\u7ed3\u5408\u591a\u79cdLLM\u548c\u9ad8\u6548\u7684\u68c0\u7d22\u53ca\u7f16\u6392\u6280\u672f\uff0c\u5728\u4fdd\u8bc1\u6570\u636e\u5b89\u5168\u548c\u77e5\u8bc6\u4fdd\u7559\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86AI\u5e94\u7528\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u4f01\u4e1a\u80fd\u591f\u66f4\u597d\u5730\u63a7\u5236\u5176AI\u8d44\u4ea7\uff0c\u5e76\u5229\u7528AI\u63d0\u9ad8\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u8bc1\u6570\u636e\u5b89\u5168\u548c\u77e5\u8bc6\u4fdd\u7559\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aeSapiens\u7684AIaaS\u5e73\u53f0\uff0c\u96c6\u6210\u4e86\u7ed3\u6784\u5316\u6587\u6863\u6444\u53d6\u3001\u6df7\u5408\u5411\u91cf\u68c0\u7d22\u548cLangChain\u65e0\u4ee3\u7801\u7f16\u6392\uff0c\u652f\u6301OpenAI\u3001Claude\u3001Gemini\u548cDeepSeek\u7b49\u591a\u79cdLLM\u3002", "result": "\u68c0\u7d22\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c512\u4e2atoken\u7684\u5757\u5927\u5c0f\u53ef\u5b9e\u73b0\u6700\u9ad8\u7684\u68c0\u7d22\u7cbe\u5ea6\uff08Top-3\u51c6\u786e\u7387\uff1a91.3%\uff09\uff1b\u751f\u6210\u8d28\u91cf\u6d4b\u8bd5\u663e\u793a\uff0ceSapiens\u751f\u6210\u7684\u8f93\u51fa\u5728\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff08\u6700\u9ad8\u63d0\u534723%\uff09\u3002", "conclusion": "eSapiens\u5e73\u53f0\u6709\u6548\u63d0\u5347\u4e86\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u6cd5\u5f8b\u548c\u91d1\u878d\uff09\u4e2d\u53ef\u4fe1\u8d56\u3001\u53ef\u5ba1\u8ba1\u7684AI\u5de5\u4f5c\u6d41\u7a0b\u7684\u6548\u7387\uff0c\u5728\u4fe1\u606f\u68c0\u7d22\u7cbe\u5ea6\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u5747\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2507.09611", "categories": ["cs.AI", "cs.CY", "68T01"], "pdf": "https://arxiv.org/pdf/2507.09611", "abs": "https://arxiv.org/abs/2507.09611", "authors": ["Jenis Winsta"], "title": "The Hidden Costs of AI: A Review of Energy, E-Waste, and Inequality in Model Development", "comment": "5 pages, 3 figures", "summary": "Artificial intelligence (AI) has made remarkable progress in recent years,\nyet its rapid expansion brings overlooked environmental and ethical challenges.\nThis review explores four critical areas where AI's impact extends beyond\nperformance: energy consumption, electronic waste (e-waste), inequality in\ncompute access, and the hidden energy burden of cybersecurity systems. Drawing\nfrom recent studies and institutional reports, the paper highlights systemic\nissues such as high emissions from model training, rising hardware turnover,\nglobal infrastructure disparities, and the energy demands of securing AI. By\nconnecting these concerns, the review contributes to Responsible AI discourse\nby identifying key research gaps and advocating for sustainable, transparent,\nand equitable development practices. Ultimately, it argues that AI's progress\nmust align with ethical responsibility and environmental stewardship to ensure\na more inclusive and sustainable technological future.", "AI": {"tldr": "AI\u53d1\u5c55\u9762\u4e34\u80fd\u6e90\u6d88\u8017\u3001\u7535\u5b50\u5783\u573e\u3001\u83b7\u53d6\u4e0d\u5e73\u7b49\u548c\u7f51\u7edc\u5b89\u5168\u7b49\u73af\u5883\u548c\u4f26\u7406\u6311\u6218\uff0c\u9700\u53ef\u6301\u7eed\u3001\u900f\u660e\u548c\u516c\u5e73\u53d1\u5c55\u3002", "motivation": "\u63a2\u7d22AI\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u7684\u73af\u5883\u548c\u4f26\u7406\u6311\u6218", "method": "\u6587\u732e\u7efc\u8ff0\u548c\u5236\u5ea6\u62a5\u544a", "result": "\u63ed\u793a\u4e86AI\u5728\u80fd\u6e90\u6d88\u8017\u3001\u7535\u5b50\u5783\u573e\u3001\u8ba1\u7b97\u8bbf\u95ee\u4e0d\u5e73\u7b49\u548c\u7f51\u7edc\u5b89\u5168\u7cfb\u7edf\u9690\u85cf\u7684\u80fd\u6e90\u8d1f\u62c5\u7b49\u56db\u4e2a\u5173\u952e\u9886\u57df\u7684\u7cfb\u7edf\u6027\u95ee\u9898\u3002", "conclusion": "AI\u7684\u8fdb\u6b65\u5fc5\u987b\u4e0e\u4f26\u7406\u8d23\u4efb\u548c\u73af\u5883\u7ba1\u7406\u76f8\u4e00\u81f4\uff0c\u4ee5\u786e\u4fdd\u66f4\u5177\u5305\u5bb9\u6027\u548c\u53ef\u6301\u7eed\u6027\u7684\u6280\u672f\u672a\u6765\u3002"}}
{"id": "2507.09617", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.09617", "abs": "https://arxiv.org/abs/2507.09617", "authors": ["Margherita Martorana", "Francesca Urgese", "Mark Adamik", "Ilaria Tiddi"], "title": "Bridging Bots: from Perception to Action via Multimodal-LMs and Knowledge Graphs", "comment": null, "summary": "Personal service robots are deployed to support daily living in domestic\nenvironments, particularly for elderly and individuals requiring assistance.\nThese robots must perceive complex and dynamic surroundings, understand tasks,\nand execute context-appropriate actions. However, current systems rely on\nproprietary, hard-coded solutions tied to specific hardware and software,\nresulting in siloed implementations that are difficult to adapt and scale\nacross platforms. Ontologies and Knowledge Graphs (KGs) offer a solution to\nenable interoperability across systems, through structured and standardized\nrepresentations of knowledge and reasoning. However, symbolic systems such as\nKGs and ontologies struggle with raw and noisy sensory input. In contrast,\nmultimodal language models are well suited for interpreting input such as\nimages and natural language, but often lack transparency, consistency, and\nknowledge grounding. In this work, we propose a neurosymbolic framework that\ncombines the perceptual strengths of multimodal language models with the\nstructured representations provided by KGs and ontologies, with the aim of\nsupporting interoperability in robotic applications. Our approach generates\nontology-compliant KGs that can inform robot behavior in a platform-independent\nmanner. We evaluated this framework by integrating robot perception data,\nontologies, and five multimodal models (three LLaMA and two GPT models), using\ndifferent modes of neural-symbolic interaction. We assess the consistency and\neffectiveness of the generated KGs across multiple runs and configurations, and\nperform statistical analyzes to evaluate performance. Results show that GPT-o1\nand LLaMA 4 Maverick consistently outperform other models. However, our\nfindings also indicate that newer models do not guarantee better results,\nhighlighting the critical role of the integration strategy in generating\nontology-compliant KGs.", "AI": {"tldr": "\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u7ed3\u5408\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\u63d0\u9ad8\u673a\u5668\u4eba\u4e92\u64cd\u4f5c\u6027\uff0cGPT-o1\u548cLLaMA 4 Maverick\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6574\u5408\u7b56\u7565\u66f4\u91cd\u8981\u3002", "motivation": "\u5f53\u524d\u7684\u4e2a\u4eba\u670d\u52a1\u673a\u5668\u4eba\u7cfb\u7edf\u4f9d\u8d56\u4e8e\u4e13\u6709\u7684\u786c\u7f16\u7801\u89e3\u51b3\u65b9\u6848\uff0c\u96be\u4ee5\u9002\u5e94\u548c\u6269\u5c55\u3002\u672c\u4f53\u548c\u77e5\u8bc6\u56fe\u8c31\u53ef\u4ee5\u5b9e\u73b0\u7cfb\u7edf\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\uff0c\u4f46\u5904\u7406\u539f\u59cb\u548c\u5608\u6742\u7684\u611f\u5b98\u8f93\u5165\u5b58\u5728\u56f0\u96be\u3002\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u64c5\u957f\u89e3\u91ca\u56fe\u50cf\u548c\u81ea\u7136\u8bed\u8a00\u7b49\u8f93\u5165\uff0c\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\u3001\u4e00\u81f4\u6027\u548c\u77e5\u8bc6\u57fa\u7840\u3002", "method": "\u8be5\u6846\u67b6\u6574\u5408\u4e86\u673a\u5668\u4eba\u611f\u77e5\u6570\u636e\u3001\u672c\u4f53\u548c\u4e94\u79cd\u591a\u6a21\u6001\u6a21\u578b\uff08\u4e09\u79cdLLaMA\u548c\u4e24\u79cdGPT\u6a21\u578b\uff09\uff0c\u5e76\u4f7f\u7528\u4e86\u4e0d\u540c\u7684\u795e\u7ecf\u7b26\u53f7\u4ea4\u4e92\u6a21\u5f0f\u3002", "result": "GPT-o1\u548cLLaMA 4 Maverick\u6a21\u578b\u5728\u751f\u6210\u7b26\u5408\u672c\u4f53\u7684\u77e5\u8bc6\u56fe\u8c31\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u7814\u7a76\u4e5f\u53d1\u73b0\u6a21\u578b\u7684\u7248\u672c\u5e76\u975e\u51b3\u5b9a\u6027\u80fd\u7684\u552f\u4e00\u56e0\u7d20\uff0c\u6574\u5408\u7b56\u7565\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\u7684\u4f18\u52bf\uff0c\u4ee5\u652f\u6301\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u7684\u4e92\u64cd\u4f5c\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGPT-o1\u548cLLaMA 4 Maverick\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6a21\u578b\u7684\u65b0\u65e7\u5e76\u4e0d\u76f4\u63a5\u51b3\u5b9a\u6027\u80fd\uff0c\u6574\u5408\u7b56\u7565\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.09626", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.09626", "abs": "https://arxiv.org/abs/2507.09626", "authors": ["Rodion Nazarov", "Anthony Quinn", "Robert Shorten", "Jakub Marecek"], "title": "humancompatible.interconnect: Testing Properties of Repeated Uses of Interconnections of AI Systems", "comment": null, "summary": "Artificial intelligence (AI) systems often interact with multiple agents. The\nregulation of such AI systems often requires that {\\em a priori\\/} guarantees\nof fairness and robustness be satisfied. With stochastic models of agents'\nresponses to the outputs of AI systems, such {\\em a priori\\/} guarantees\nrequire non-trivial reasoning about the corresponding stochastic systems. Here,\nwe present an open-source PyTorch-based toolkit for the use of stochastic\ncontrol techniques in modelling interconnections of AI systems and properties\nof their repeated uses. It models robustness and fairness desiderata in a\nclosed-loop fashion, and provides {\\em a priori\\/} guarantees for these\ninterconnections. The PyTorch-based toolkit removes much of the complexity\nassociated with the provision of fairness guarantees for closed-loop models of\nmulti-agent systems.", "AI": {"tldr": "\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u7528\u968f\u673a\u63a7\u5236\u6280\u672f\u5efa\u6a21\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2dAI\u7cfb\u7edf\u7684\u4ea4\u4e92\uff0c\u63d0\u4f9b\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u7684\u5148\u9a8c\u4fdd\u8bc1", "motivation": "\u73b0\u6709\u7684AI\u7cfb\u7edf\u5e38\u5e38\u4e0e\u591a\u4e2a\u667a\u80fd\u4f53\u4ea4\u4e92\uff0c\u9700\u8981\u5bf9\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u8fdb\u884c\u4fdd\u8bc1\uff0c\u800c\u5bf9\u76f8\u5e94\u968f\u673a\u7cfb\u7edf\u7684\u63a8\u7406\u5219\u8f83\u4e3a\u590d\u6742\u3002", "method": "\u8be5\u5de5\u5177\u5305\u4f7f\u7528\u968f\u673a\u63a7\u5236\u6280\u672f\uff0c\u5bf9\u667a\u80fd\u4f53\u5bf9AI\u7cfb\u7edf\u8f93\u51fa\u7684\u53cd\u5e94\u8fdb\u884c\u968f\u673a\u5efa\u6a21\uff0c\u4ee5\u95ed\u73af\u7684\u65b9\u5f0f\u5efa\u6a21\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\uff0c\u5e76\u63d0\u4f9b\u5148\u9a8c\u4fdd\u8bc1\u3002", "result": "\u8be5\u5de5\u5177\u5305\u7b80\u5316\u4e86\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u95ed\u73af\u6a21\u578b\u63d0\u4f9b\u516c\u5e73\u6027\u4fdd\u8bc1\u7684\u590d\u6742\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8ePyTorch\u7684\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u76f8\u4e92\u8fde\u63a5\u53ca\u5176\u91cd\u590d\u4f7f\u7528\u6027\u8d28\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u63d0\u4f9b\u516c\u5e73\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2507.09662", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.09662", "abs": "https://arxiv.org/abs/2507.09662", "authors": ["Jason Zhu", "Hongyu Li"], "title": "Towards Concise and Adaptive Thinking in Large Reasoning Models: A Survey", "comment": null, "summary": "Large reasoning models (LRMs) like OpenAI o1 and DeepSeek R1 have\ndemonstrated impressive performance on complex reasoning tasks like mathematics\nand programming with long Chain-of-Thought (CoT) reasoning sequences\n(slow-thinking), compared with traditional large language models\n(fast-thinking). However, these reasoning models also face a huge challenge\nthat generating unnecessarily lengthy and redundant reasoning chains even for\ntrivial questions. This phenomenon leads to a significant waste of inference\nresources, increases the response time for simple queries, and hinders the\npractical application of LRMs in real-world products. To this end, it is\ncrucial to shorten lengthy reasoning chains and learn adaptive reasoning\nbetween fast and slow thinking based on input difficulty. In this survey, we\nprovide a comprehensive overview of recent progress in concise and adaptive\nthinking for efficient reasoning of LRMs, including methodologies, benchmarks,\nand challenges for future exploration. We hope this survey can help researchers\nquickly understand the landscape of this field and inspire novel adaptive\nthinking ideas to facilitate better usage of LRMs.", "AI": {"tldr": "Survey on concise and adaptive thinking for efficient reasoning in Large Reasoning Models to address the issue of unnecessarily lengthy reasoning chains.", "motivation": "Large Reasoning Models (LRMs) generate unnecessarily lengthy reasoning chains even for trivial questions, leading to wasted resources and slow response times.  This survey aims to address this issue by exploring methods for shortening reasoning chains and adapting between fast and slow thinking.", "method": "This survey reviews existing methodologies, benchmarks, and challenges in concise and adaptive thinking for efficient reasoning of LRMs.", "result": "The survey offers a landscape of current research in concise and adaptive thinking for LRMs, hoping to inspire novel ideas for better LRM usage.", "conclusion": "This survey provides a comprehensive overview of recent progress in concise and adaptive thinking for efficient reasoning of Large Reasoning Models (LRMs), including methodologies, benchmarks, and challenges for future exploration."}}
{"id": "2507.09742", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.09742", "abs": "https://arxiv.org/abs/2507.09742", "authors": ["Xiaofeng Xiao", "Bo Shen", "Xubo Yue"], "title": "Causality-informed Anomaly Detection in Partially Observable Sensor Networks: Moving beyond Correlations", "comment": null, "summary": "Nowadays, as AI-driven manufacturing becomes increasingly popular, the volume\nof data streams requiring real-time monitoring continues to grow. However, due\nto limited resources, it is impractical to place sensors at every location to\ndetect unexpected shifts. Therefore, it is necessary to develop an optimal\nsensor placement strategy that enables partial observability of the system\nwhile detecting anomalies as quickly as possible. Numerous approaches have been\nproposed to address this challenge; however, most existing methods consider\nonly variable correlations and neglect a crucial factor: Causality. Moreover,\nalthough a few techniques incorporate causal analysis, they rely on\ninterventions-artificially creating anomalies-to identify causal effects, which\nis impractical and might lead to catastrophic losses. In this paper, we\nintroduce a causality-informed deep Q-network (Causal DQ) approach for\npartially observable sensor placement in anomaly detection. By integrating\ncausal information at each stage of Q-network training, our method achieves\nfaster convergence and tighter theoretical error bounds. Furthermore, the\ntrained causal-informed Q-network significantly reduces the detection time for\nanomalies under various settings, demonstrating its effectiveness for sensor\nplacement in large-scale, real-world data streams. Beyond the current\nimplementation, our technique's fundamental insights can be applied to various\nreinforcement learning problems, opening up new possibilities for real-world\ncausality-informed machine learning methods in engineering applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u56e0\u679c\u5173\u7cfb\u611f\u77e5\u6df1\u5ea6Q\u7f51\u7edc\u65b9\u6cd5\u7528\u4e8e\u4f18\u5316\u4f20\u611f\u5668\u653e\u7f6e\u4ee5\u52a0\u5feb\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u56e0\u679c\u5173\u7cfb\u8fd9\u4e00\u91cd\u8981\u56e0\u7d20\uff0c\u4e14\u4f9d\u8d56\u4e8e\u4eba\u5de5\u5236\u9020\u5f02\u5e38\u6765\u8bc6\u522b\u56e0\u679c\u6548\u5e94\uff0c\u8fd9\u65e2\u4e0d\u5b9e\u7528\u53c8\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u635f\u5931\u3002", "method": "\u56e0\u679c\u5173\u7cfb\u611f\u77e5\u6df1\u5ea6Q\u7f51\u7edc(Causal DQ)\u65b9\u6cd5", "result": "Causal DQ\u65b9\u6cd5\u5728\u5404\u79cd\u73af\u5883\u4e0b\u663e\u8457\u51cf\u5c11\u4e86\u5f02\u5e38\u7684\u68c0\u6d4b\u65f6\u95f4\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5927\u578b\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u6d41\u4e2d\u8fdb\u884c\u4f20\u611f\u5668\u653e\u7f6e\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u56e0\u679c\u5173\u7cfb\u611f\u77e5\u6df1\u5ea6Q\u7f51\u7edc(Causal DQ)\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u4f20\u611f\u5668\u653e\u7f6e\uff0c\u8be5\u65b9\u6cd5\u5728Q\u7f51\u7edc\u8bad\u7ec3\u7684\u6bcf\u4e2a\u9636\u6bb5\u90fd\u6574\u5408\u4e86\u56e0\u679c\u4fe1\u606f\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u4e25\u683c\u7684\u7406\u8bba\u8bef\u5dee\u754c\u9650\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5404\u79cd\u73af\u5883\u4e0b\u5f02\u5e38\u7684\u68c0\u6d4b\u65f6\u95f4\u3002"}}
