<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents](https://arxiv.org/abs/2507.10562)
*Hari Masoor*

Main category: cs.AI

TL;DR: SAMEP 框架实现了AI 智能体之间持久、安全、语义可搜索的内存共享，有效提升了协作效率和数据安全性。


<details>
  <summary>Details</summary>
Motivation: 当前AI智能体架构的短暂记忆限制阻碍了有效的跨会话和智能体边界的协作和知识共享。

Method: SAMEP框架通过构建分布式内存库、基于向量的语义搜索、加密访问控制（AES-256-GCM）以及与现有智能体通信协议（MCP, A2A）兼容的标准化API来实现持久、安全和语义可搜索的内存共享。

Result: 实验结果显示，SAMEP框架减少了73%的冗余计算，将上下文相关性评分提高了89%，并完全符合包括审计跟踪生成在内的法规要求。

Conclusion: SAMEP框架有效解决了AI智能体在跨会话和智能体边界协作和知识共享方面的短暂记忆限制问题，实现了持久、安全和语义可搜索的内存共享，并在多个领域取得了显著成果，例如减少冗余计算，提高上下文相关性评分，并完全符合法规要求。

Abstract: Current AI agent architectures suffer from ephemeral memory limitations,
preventing effective collaboration and knowledge sharing across sessions and
agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a
novel framework that enables persistent, secure, and semantically searchable
memory sharing among AI agents. Our protocol addresses three critical
challenges: (1) persistent context preservation across agent sessions, (2)
secure multi-agent collaboration with fine-grained access control, and (3)
efficient semantic discovery of relevant historical context. SAMEP implements a
distributed memory repository with vector-based semantic search, cryptographic
access controls (AES-256-GCM), and standardized APIs compatible with existing
agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness
across diverse domains including multi-agent software development, healthcare
AI with HIPAA compliance, and multi-modal processing pipelines. Experimental
results show 73% reduction in redundant computations, 89% improvement in
context relevance scores, and complete compliance with regulatory requirements
including audit trail generation. SAMEP enables a new paradigm of persistent,
collaborative AI agent ecosystems while maintaining security and privacy
guarantees.

</details>


### [2] [AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems](https://arxiv.org/abs/2507.10566)
*Hung Ming Liu*

Main category: cs.AI

TL;DR: 无需人工归纳偏置，智能体即可通过内生符号系统实现高效的涌现式沟通。


<details>
  <summary>Details</summary>
Motivation: 解决分散式多智能体强化学习中由于联合探索困境导致的沟通真空平衡问题。

Method: 基于矢量量化变分自编码器(VQ-VAE)的AI母语(AIM)框架。

Result: 实验结果表明，AIM框架下的智能体能够自发地进行语义压缩和纳什均衡驱动的语义收敛，实现高效的符号交流，并展现出比传统方法更强的泛化性和效率。研究还提出了三个主要理论见解：神经元交流假说、工具优先原则和语义可解释性范式。

Conclusion: 该研究挑战了强化学习中人工引入归纳偏置以促进多智能体涌现式沟通的必要性，通过实验表明，当智能体拥有内生符号系统时，无需外部归纳偏置即可实现有效的符号交流。

Abstract: In Decentralized Multi-Agent Reinforcement Learning (MARL), the development
of Emergent Communication has long been constrained by the ``Joint Exploration
Dilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .
Traditional methods address this by introducing inductive biases to facilitate
communication emergence . This study fundamentally questions whether such
artificial inductive biases are, in fact, over-engineering. Through experiments
with the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized
Variational Autoencoder (VQ-VAE), we demonstrate that when agents possess an
endogenous symbol system, their neural representations naturally exhibit
spontaneous semantic compression and Nash equilibrium-driven semantic
convergence, achieving effective symbolic communication without external
inductive biases. This aligns with recent neuroscience findings suggesting that
the human brain does not directly use human language for internal thought , and
resonates with research on ``soft thinking'' capabilities in Large Language
Models (LLMs) . Compared to traditional explicit communication methods, AIM
demonstrates stronger generality and efficiency. The interpretable analysis
toolkit developed in this study confirms that symbol usage exhibits a
significant power-law distribution, leading to three major theoretical
insights: the ``Neural Communication Hypothesis'', the ``Tool-First
Principle'', and the ``Semantic Interpretability Paradigm''. Future research
will explore the integration of Hierarchical Quantized Variational Autoencoders
(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the
potential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This
discovery offers new avenues for bridging symbolism and connectionism.

</details>


### [3] [Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning](https://arxiv.org/abs/2507.10571)
*Konstantinos I. Roumeliotis,Ranjan Sapkota,Manoj Karkee,Nikolaos D. Tselikas*

Main category: cs.AI

TL;DR: 提出一种可扩展、可解释的多智能体AI视觉分类框架，在零样本苹果叶片病害诊断中准确率达85.63%，并开源了所有代码和数据。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体AI系统在零样本设置下的信任问题，特别是结合视觉和语言理解的场景。

Method: 该框架集成了通用的多模态智能体、非视觉推理协调器和RAG模块。使用了基于置信度的协调、微调的智能体以及由CLIP驱动的图像检索和重新评估循环增强的信任校准协调三种配置。

Result: 在零样本设置下，使用信任感知的协调和RAG，准确率提高了77.94%，达到85.63%。GPT-4o显示出更好的校准，而Qwen-2.5-VL则表现出过度自信。图像RAG使预测具有视觉上的相似性，从而可以通过迭代重新评估来纠正智能体的过度自信。

Conclusion: 本文介绍了一种新颖的模块化智能体AI视觉分类框架，该框架将通用的多模态智能体与非视觉推理协调器和检索增强生成（RAG）模块相结合，并在苹果叶片病害诊断中取得了显著成果，尤其是在零样本设置下，通过信任感知的协调和RAG，准确率提高了77.94%，达到85.63%。该系统将感知（视觉智能体）与元推理（协调器）分离，实现了可扩展和可解释的多智能体AI。

Abstract: Modern Artificial Intelligence (AI) increasingly relies on multi-agent
architectures that blend visual and language understanding. Yet, a pressing
challenge remains: How can we trust these agents especially in zero-shot
settings with no fine-tuning? We introduce a novel modular Agentic AI visual
classification framework that integrates generalist multimodal agents with a
non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)
module. Applied to apple leaf disease diagnosis, we benchmark three
configurations: (I) zero-shot with confidence-based orchestration, (II)
fine-tuned agents with improved performance, and (III) trust-calibrated
orchestration enhanced by CLIP-based image retrieval and re-evaluation loops.
Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator
modulates trust across agents. Our results demonstrate a 77.94\% accuracy
improvement in the zero-shot setting using trust-aware orchestration and RAG,
achieving 85.63\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL
displayed overconfidence. Furthermore, image-RAG grounded predictions with
visually similar cases, enabling correction of agent overconfidence via
iterative re-evaluation. The proposed system separates perception (vision
agents) from meta-reasoning (orchestrator), enabling scalable and interpretable
multi-agent AI. This blueprint is extensible to diagnostics, biology, and other
trust-critical domains. All models, prompts, results, and system components
including the complete software source code are openly released to support
reproducibility, transparency, and community benchmarking at Github:
https://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust

</details>


### [4] [Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning](https://arxiv.org/abs/2507.10624)
*Zheng Zhang*

Main category: cs.AI

TL;DR: LLM擅长模式匹配，但缺乏进行有原则推理的架构。


<details>
  <summary>Details</summary>
Motivation: 诊断LLM在符号推理、算术精度和逻辑一致性等任务上的失败原因。

Method: 通过控制实验和架构分析，研究人员揭示了LLM中理解和能力之间的差距。

Result: LLM存在计算上的“裂脑综合征”，指令和行为路径分离，模型行为脆弱，难以进行有原则的组合式推理。

Conclusion: 大型语言模型(LLM)在需要符号推理、算术精度和逻辑一致性的任务中系统性地失败，其根本原因并非知识获取，而是计算执行上的缺陷，表现为指令和行为路径的几何和功能分离，这限制了模型进行有原则的、组合式推理。

Abstract: Large Language Models (LLMs) display striking surface fluency yet
systematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,
and logical consistency. This paper offers a structural diagnosis of such
failures, revealing a persistent gap between \textit{comprehension} and
\textit{competence}. Through controlled experiments and architectural analysis,
we demonstrate that LLMs often articulate correct principles without reliably
applying them--a failure rooted not in knowledge access, but in computational
execution. We term this phenomenon the computational \textit{split-brain
syndrome}, where instruction and action pathways are geometrically and
functionally dissociated. This core limitation recurs across domains, from
mathematical operations to relational inferences, and explains why model
behavior remains brittle even under idealized prompting. We argue that LLMs
function as powerful pattern completion engines, but lack the architectural
scaffolding for principled, compositional reasoning. Our findings delineate the
boundary of current LLM capabilities and motivate future models with
metacognitive control, principle lifting, and structurally grounded execution.
This diagnosis also clarifies why mechanistic interpretability findings may
reflect training-specific pattern coordination rather than universal
computational principles, and why the geometric separation between instruction
and execution pathways suggests limitations in neural introspection and
mechanistic analysis.

</details>


### [5] [Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs](https://arxiv.org/abs/2507.10630)
*Ye Yang,Xue Xiao,Ping Yin,Taotao Xie*

Main category: cs.AI

TL;DR: KG2data利用知识图谱增强LLM的数据分析能力，在气象领域取得显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统在知识密集型领域（如气象学）利用API调用进行数据分析的能力不足，KG2data旨在解决这个问题。

Method: KG2data系统集成了知识图谱、大型语言模型、ReAct智能体和工具使用技术。通过虚拟API评估了API调用准确性，在三个指标上均表现出色。

Result: KG2data在API调用准确性方面显著优于基线系统，分别在名称识别失败率、幻觉失败率和调用正确率上取得了1.43%、0%和88.57%的优异结果。

Conclusion: KG2data系统在气象领域智能数据获取和查询处理方面取得了优越性能，显著优于RAG2data和chat2data系统。

Abstract: API calls by large language models (LLMs) offer a cutting-edge approach for
data analysis. However, their ability to effectively utilize tools via API
calls remains underexplored in knowledge-intensive domains like meteorology.
This paper introduces KG2data, a system that integrates knowledge graphs, LLMs,
ReAct agents, and tool-use technologies to enable intelligent data acquisition
and query handling in the meteorological field. Using a virtual API, we
evaluate API call accuracy across three metrics: name recognition failure,
hallucination failure, and call correctness. KG2data achieves superior
performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and
chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based
systems by addressing their limited access to domain-specific knowledge, which
hampers performance on complex or terminology-rich queries. By using a
knowledge graph as persistent memory, our system enhances content retrieval,
complex query handling, domain-specific reasoning, semantic relationship
resolution, and heterogeneous data integration. It also mitigates the high cost
of fine-tuning LLMs, making the system more adaptable to evolving domain
knowledge and API structures. In summary, KG2data provides a novel solution for
intelligent, knowledge-based question answering and data analysis in domains
with high knowledge demands.

</details>


### [6] [From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents](https://arxiv.org/abs/2507.10644)
*Tatiana Petrova,Aleksandr Puzikov,Boris Bliznukov,Radu State*

Main category: cs.AI

TL;DR: The Web of Agents is evolving towards LLM-powered agents, but needs better decentralized identity, economic models, security, and governance.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive evolutionary overview of the WoA, bridging the gap between contemporary LLM-powered frameworks and the historical context of MAS and the Semantic Web.

Method: A four-axis taxonomy (semantic foundation, communication paradigm, locus of intelligence, discovery mechanism) is used to analyze the evolution of WoA, comparing agent architectures across generations.

Result: A unified analytical lens revealing a paradigm shift in the 'locus of intelligence' and highlighting the need to address socio-technical challenges for a robust WoA ecosystem.

Conclusion: The Web of Agents (WoA) is evolving, shifting from external data or platform-based intelligence to LLM-embedded intelligence.  Future research should focus on socio-technical challenges like decentralized identity, economic models, security, and governance.

Abstract: The concept of the Web of Agents (WoA), which transforms the static,
document-centric Web into an environment of autonomous agents acting on users'
behalf, has attracted growing interest as large language models (LLMs) become
more capable. However, research in this area is still fragmented across
different communities. Contemporary surveys catalog the latest LLM-powered
frameworks, while the rich histories of Multi-Agent Systems (MAS) and the
Semantic Web are often treated as separate, legacy domains. This fragmentation
obscures the intellectual lineage of modern systems and hinders a holistic
understanding of the field's trajectory. We present the first comprehensive
evolutionary overview of the WoA. We show that modern protocols like A2A and
the MCP, are direct evolutionary responses to the well-documented limitations
of earlier standards like FIPA standards and OWL-based semantic agents. To
systematize this analysis, we introduce a four-axis taxonomy (semantic
foundation, communication paradigm, locus of intelligence, discovery
mechanism). This framework provides a unified analytical lens for comparing
agent architectures across all generations, revealing a clear line of descent
where others have seen a disconnect. Our analysis identifies a paradigm shift
in the 'locus of intelligence': from being encoded in external data (Semantic
Web) or the platform (MAS) to being embedded within the agent's core model
(LLM). This shift is foundational to modern Agentic AI, enabling the scalable
and adaptive systems the WoA has long envisioned. We conclude that while new
protocols are essential, they are insufficient for building a robust, open,
trustworthy ecosystem. Finally, we argue that the next research frontier lies
in solving persistent socio-technical challenges, and we map out a new agenda
focused on decentralized identity, economic models, security, and governance
for the emerging WoA.

</details>


### [7] [Parsing Musical Structure to Enable Meaningful Variations](https://arxiv.org/abs/2507.10740)
*Maziar Kanani,Sean O Leary,James McDermott*

Main category: cs.AI

TL;DR: 基于规则的音乐变奏生成方法，通过对曲调的语法进行突变生成新的曲调，并分析了突变效果。


<details>
  <summary>Details</summary>
Motivation: 现有音乐生成方法的不足，提出一种新的基于规则的变奏生成方法。

Method: 该方法基于规则，使用Sequitur算法解析曲调的PA结构，然后对语法进行19种类型的突变操作，最后扩展语法生成新的曲调。

Result: 实验结果表明，该方法能够生成与原始曲调相关的新的曲调，并分析了不同突变类型对曲调的影响。

Conclusion: 本文提出一种新颖的基于规则的音乐生成方法，通过对现有曲调进行变奏生成新的曲调。该方法使用Sequitur算法解析曲调，找到其Pathway Assembly (PA)结构，然后对该语法进行突变操作，而非直接对曲调进行突变。实验分析了不同突变类型对曲调的影响，并从编辑距离、结构复杂度和长度等方面评估了突变效果，最后对生成的曲调的音乐性进行了评价。

Abstract: This paper presents a novel rule-based approach for generating music by
varying existing tunes. We parse each tune to find the Pathway Assembly (PA) [
1], that is a structure representing all repetitions in the tune. The Sequitur
algorithm [2 ] is used for this. The result is a grammar. We then carry out
mutation on the grammar, rather than on a tune directly. There are potentially
19 types of mutations such as adding, removing, swapping or reversing parts of
the grammar that can be applied to the grammars. The system employs one of the
mutations randomly in this step to automatically manipulate the grammar.
Following the mutation, we need to expand the grammar which returns a new tune.
The output after 1 or more mutations will be a new tune related to the original
tune. Our study examines how tunes change gradually over the course of multiple
mutations. Edit distances, structural complexity and length of the tunes are
used to show how a tune is changed after multiple mutations. In addition, the
size of effect of each mutation type is analyzed. As a final point, we review
the musical aspect of the output tunes. It should be noted that the study only
focused on generating new pitch sequences. The study is based on an Irish
traditional tune dataset and a list of integers has been used to represent each
tune's pitch values.

</details>


### [8] [AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition](https://arxiv.org/abs/2507.10750)
*Pandu Devarakota,Nicolas Tsesmetzis,Faruk O. Alpak,Apurva Gala,Detlef Hohl*

Main category: cs.AI

TL;DR: AI短期增排，长期减排


<details>
  <summary>Details</summary>
Motivation: 探讨AI对CO2排放的净影响，以及AI在能源生产、供应和消费领域提高效率的潜力。

Method: 技术综述文章，分析数据中心能耗及对温室气体排放的影响，并探讨AI在节能减排方面的潜力。

Result: 短期内AI会增加能耗和CO2排放，但长期来看，AI优化各行各业流程的能力将超过其初始排放的影响，最终减少碳足迹。

Conclusion: AI对环境的影响在短期内可能是负面的，但长期来看可能对气候变化缓解工作有积极作用。

Abstract: Thanks to the availability of massive amounts of data, computing resources,
and advanced algorithms, AI has entered nearly every sector. This has sparked
significant investment and interest, particularly in building data centers with
the necessary hardware and software to develop and operate AI models and
AI-based workflows. In this technical review article, we present energy
consumption scenarios of data centers and impact on GHG emissions, considering
both near-term projections (up to 2030) and long-term outlook (2035 and
beyond). We address the quintessential question of whether AI will have a net
positive, neutral, or negative impact on CO2 emissions by 2035. Additionally,
we discuss AI's potential to automate, create efficient and disruptive
workflows across various fields related to energy production, supply and
consumption. In the near-term scenario, the growing demand for AI will likely
strain computing resources, lead to increase in electricity consumption and
therefore associated CO2 emissions. This is due to the power-hungry nature of
big data centers and the requirements for training and running of large and
complex AI models, as well as the penetration of AI assistant search and
applications for public use. However, the long-term outlook could be more
promising. AI has the potential to be a game-changer in CO2 reduction. Its
ability to further automate and optimize processes across industries, from
energy production to logistics, could significantly decrease our carbon
footprint. This positive impact is anticipated to outweigh the initial
emissions bump, creating value for businesses and society in areas where
traditional solutions have fallen short. In essence, AI might cause some
initial growing pains for the environment, but it has the potential to support
climate mitigation efforts.

</details>


### [9] [IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models](https://arxiv.org/abs/2507.10758)
*Nikesh Prajapati,Bimal Karki,Saroj Gopali,Akbar Siami Namin*

Main category: cs.AI

TL;DR: BERT模型在物联网恶意攻击检测中表现最佳，准确率高达99.94%。


<details>
  <summary>Details</summary>
Motivation: 检测物联网恶意攻击。

Method: 使用GraphSAGE、BERT、TCN、多头注意力机制、BI-LSTM和LSTM等多种深度学习和图模型对物联网恶意网络流量进行检测。

Result: BERT模型准确率达99.94%，其他模型各有优劣，训练时间和准确率存在权衡。

Conclusion: BERT模型在物联网恶意攻击检测中表现最佳，准确率达到99.94%，其他指标也极其优秀。GraphSAGE模型训练速度最快，但准确率最低。

Abstract: This paper intends to detect IoT malicious attacks through deep learning
models and demonstrates a comprehensive evaluation of the deep learning and
graph-based models regarding malicious network traffic detection. The models
particularly are based on GraphSAGE, Bidirectional encoder representations from
transformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head
Attention, together with Bidirectional Long Short-Term Memory (BI-LSTM)
Multi-Head Attention and BI-LSTM and LSTM models. The chosen models
demonstrated great performance to model temporal patterns and detect feature
significance. The observed performance are mainly due to the fact that IoT
system traffic patterns are both sequential and diverse, leaving a rich set of
temporal patterns for the models to learn. Experimental results showed that
BERT maintained the best performance. It achieved 99.94% accuracy rate
alongside high precision and recall, F1-score and AUC-ROC score of 99.99% which
demonstrates its capabilities through temporal dependency capture. The
Multi-Head Attention offered promising results by providing good detection
capabilities with interpretable results. On the other side, the Multi-Head
Attention model required significant processing time like BI-LSTM variants. The
GraphSAGE model achieved good accuracy while requiring the shortest training
time but yielded the lowest accuracy, precision, and F1 score compared to the
other models

</details>


### [10] [Detecting AI Assistance in Abstract Complex Tasks](https://arxiv.org/abs/2507.10761)
*Tyler King,Nikolos Gurney,John H. Miller,Volkan Ustun*

Main category: cs.AI

TL;DR: 利用神经网络对AI辅助进行分类，通过数据预处理和不同模型结构提升了抽象任务中AI辅助检测的有效性。


<details>
  <summary>Details</summary>
Motivation: 检测人工智能的辅助作用越来越重要，尤其是在文本生成、医学诊断和自动驾驶等复杂任务中。然而，对人类来说，特别是当查看抽象任务数据时，辅助检测具有挑战性。

Method: 构建四种不同的神经网络友好型图像公式和一种显式编码用户探索/利用的时间序列公式，并使用三种经典深度学习架构和一种并行CNN-RNN架构进行基准测试。

Result: 结果表明，对时间和空间量进行编码对于检测抽象任务中的AI辅助至关重要。

Conclusion: 本文通过构建四种不同的神经网络友好型图像公式和一种显式编码用户探索/利用的时间序列公式，证明了常用模型在对抽象任务数据进行适当预处理后可以有效地进行分类。

Abstract: Detecting assistance from artificial intelligence is increasingly important
as they become ubiquitous across complex tasks such as text generation, medical
diagnosis, and autonomous driving. Aid detection is challenging for humans,
especially when looking at abstract task data. Artificial neural networks excel
at classification thanks to their ability to quickly learn from and process
large amounts of data -- assuming appropriate preprocessing. We posit detecting
help from AI as a classification task for such models. Much of the research in
this space examines the classification of complex but concrete data classes,
such as images. Many AI assistance detection scenarios, however, result in data
that is not machine learning-friendly. We demonstrate that common models can
effectively classify such data when it is appropriately preprocessed. To do so,
we construct four distinct neural network-friendly image formulations along
with an additional time-series formulation that explicitly encodes the
exploration/exploitation of users, which allows for generalizability to other
abstract tasks. We benchmark the quality of each image formulation across three
classical deep learning architectures, along with a parallel CNN-RNN
architecture that leverages the additional time series to maximize testing
performance, showcasing the importance of encoding temporal and spatial
quantities for detecting AI aid in abstract tasks.

</details>


### [11] [Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions](https://arxiv.org/abs/2507.10798)
*Asim H. Gazi,Bhanu T. Gullapalli,Daiqi Gao,Benjamin M. Marlin,Vivek Shetty,Susan A. Murphy*

Main category: cs.AI

TL;DR: Dynamic scheduling of decision points in mHealth improves intervention timeliness, particularly for irregular routines, as shown by a real-world trial of SigmaScheduling.


<details>
  <summary>Details</summary>
Motivation: Current fixed-interval scheduling in mHealth interventions is ineffective for individuals with irregular routines.  This paper aims to improve the timeliness of interventions for habitual behaviors by dynamically adjusting decision point scheduling based on the uncertainty of predicted behavior times.

Method: The paper proposes SigmaScheduling, a method that dynamically schedules decision points based on the uncertainty of predicted behavior times.  It uses real-world data from a 10-week trial to evaluate its effectiveness.

Result: SigmaScheduling increased the likelihood of decision points preceding brushing events in at least 70% of cases, demonstrating its effectiveness in improving the timeliness of interventions and its potential to advance precision mHealth.

Conclusion: SigmaScheduling, a dynamic decision point scheduling method for mHealth interventions, significantly improves the timeliness of interventions, especially for individuals with irregular routines.  It adapts scheduling based on the uncertainty of predicted behavior times, ensuring timely support before target behaviors.

Abstract: Timely decision making is critical to the effectiveness of mobile health
(mHealth) interventions. At predefined timepoints called "decision points,"
intelligent mHealth systems such as just-in-time adaptive interventions
(JITAIs) estimate an individual's biobehavioral context from sensor or survey
data and determine whether and how to intervene. For interventions targeting
habitual behavior (e.g., oral hygiene), effectiveness often hinges on
delivering support shortly before the target behavior is likely to occur.
Current practice schedules decision points at a fixed interval (e.g., one hour)
before user-provided behavior times, and the fixed interval is kept the same
for all individuals. However, this one-size-fits-all approach performs poorly
for individuals with irregular routines, often scheduling decision points after
the target behavior has already occurred, rendering interventions ineffective.
In this paper, we propose SigmaScheduling, a method to dynamically schedule
decision points based on uncertainty in predicted behavior times. When behavior
timing is more predictable, SigmaScheduling schedules decision points closer to
the predicted behavior time; when timing is less certain, SigmaScheduling
schedules decision points earlier, increasing the likelihood of timely
intervention. We evaluated SigmaScheduling using real-world data from 68
participants in a 10-week trial of Oralytics, a JITAI designed to improve daily
toothbrushing. SigmaScheduling increased the likelihood that decision points
preceded brushing events in at least 70% of cases, preserving opportunities to
intervene and impact behavior. Our results indicate that SigmaScheduling can
advance precision mHealth, particularly for JITAIs targeting time-sensitive,
habitual behaviors such as oral hygiene or dietary habits.

</details>


### [12] [Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case](https://arxiv.org/abs/2507.10803)
*JaMor Hairston,Ritvik Ranjan,Sahithi Lakamana,Anthony Spadaro,Selen Bozkurt,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.AI

TL;DR: LLM可部分自动化主题分析，辅助定性研究，但准确性仍有提升空间。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在归纳性主题分析中的可行性，以辅助对社交媒体数据的分析。

Method: 使用两个Reddit数据集，比较了五种LLM在主题分析中的表现，采用二元分类方法，并测试了零样本、单样本和少样本提示策略。

Result: GPT-4o在少样本提示下表现最佳，准确率达90.9%，F1分数为0.71。高频主题的模型结果与专家分类结果较为接近。

Conclusion: 大型语言模型(LLM)可用于辅助主题分析，尤其是在对高频主题的分析中，能有效提高效率，但仍需人工审核。

Abstract: Background Large language models (LLMs) face challenges in inductive thematic
analysis, a task requiring deep interpretive and domain-specific expertise. We
evaluated the feasibility of using LLMs to replicate expert-driven thematic
analysis of social media data. Methods Using two temporally non-intersecting
Reddit datasets on xylazine (n=286 and n=686, for model optimization and
validation, respectively) with twelve expert-derived themes, we evaluated five
LLMs against expert coding. We modeled the task as a series of binary
classifications, rather than a single, multi-label classification, employing
zero-, single-, and few-shot prompting strategies and measuring performance via
accuracy, precision, recall, and F1-score. Results On the validation set,
GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:
0.71). For high-prevalence themes, model-derived thematic distributions closely
mirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:
16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based
approaches can automate thematic analyses, offering a scalable supplement for
qualitative research. Keywords: thematic analysis, large language models,
natural language processing, qualitative analysis, social media, prompt
engineering, public health

</details>


### [13] [AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks](https://arxiv.org/abs/2507.10831)
*Yilin Xia,Heng Zheng,Shawn Bowers,Bertram Ludäscher*

Main category: cs.AI

TL;DR: AF-XRAY是一个用于分析法律推理中论证框架的开源工具，它通过可视化和关键攻击集识别来解决模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的论证框架方法难以解释论证的接受性，尤其对于非专家而言。

Method: 开发了一个名为AF-XRAY的开源工具包，该工具包利用分层可视化、攻击边分类和替代解的可视化叠加等方法，帮助用户理解和分析AFs。

Result: AF-XRAY工具有效地帮助用户识别模糊性的来源，并探索替代解决方案，支持目的论法律推理。

Conclusion: AF-XRAY工具能够帮助非专家探索、分析和可视化法律推理中的抽象论证框架 (AFs)，通过识别关键攻击集来解决模糊性问题，支持目的论法律推理。

Abstract: Argumentation frameworks (AFs) provide formal approaches for legal reasoning,
but identifying sources of ambiguity and explaining argument acceptance remains
challenging for non-experts. We present AF-XRAY, an open-source toolkit for
exploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY
introduces: (i) layered visualizations based on game-theoretic argument length
revealing well-founded derivation structures; (ii) classification of attack
edges by semantic roles (primary, secondary, blunders); (iii) overlay
visualizations of alternative 2-valued solutions on ambiguous 3-valued grounded
semantics; and (iv) identification of critical attack sets whose suspension
resolves undecided arguments. Through systematic generation of critical attack
sets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling
users to pinpoint specific causes of ambiguity and explore alternative
resolutions. We use real-world legal cases (e.g., Wild Animals as modeled by
Bench-Capon) to show that our tool supports teleological legal reasoning by
revealing how different assumptions lead to different justified conclusions.

</details>


### [14] [WhisperKit: On-device Real-time ASR with Billion-Scale Transformers](https://arxiv.org/abs/2507.10860)
*Atila Orhon,Arda Okan,Berkin Durmus,Zach Nagengast,Eduardo Pacheco*

Main category: cs.AI

TL;DR: WhisperKit实时ASR系统优于现有云端系统，延迟低，准确率高。


<details>
  <summary>Details</summary>
Motivation: 实时ASR是许多商业应用（如实时字幕、听写、会议转录和医疗速记）的基础组成部分，准确性和延迟是公司选择部署系统的最重要因素。

Method: 对WhisperKit系统的优化进行了详细描述。基准测试对象包括多种模型，包括前沿模型（OpenAI gpt-4o-transcribe）、专有模型（Deepgram nova-3）和开源模型（Fireworks large-v3-turbo）。

Result: WhisperKit匹配最低延迟0.46秒，同时实现最高准确率2.2% WER。

Conclusion: WhisperKit系统在实时ASR方面显著优于领先的云端系统，在0.46秒的最低延迟下实现了最高的准确率（2.2% WER）。

Abstract: Real-time Automatic Speech Recognition (ASR) is a fundamental building block
for many commercial applications of ML, including live captioning, dictation,
meeting transcriptions, and medical scribes. Accuracy and latency are the most
important factors when companies select a system to deploy. We present
WhisperKit, an optimized on-device inference system for real-time ASR that
significantly outperforms leading cloud-based systems. We benchmark against
server-side systems that deploy a diverse set of models, including a frontier
model (OpenAI gpt-4o-transcribe), a proprietary model (Deepgram nova-3), and an
open-source model (Fireworks large-v3-turbo).Our results show that WhisperKit
matches the lowest latency at 0.46s while achieving the highest accuracy 2.2%
WER. The optimizations behind the WhisperKit system are described in detail in
this paper.

</details>


### [15] [NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization](https://arxiv.org/abs/2507.10894)
*Zongtao He,Liuyi Wang,Lu Chen,Chengju Liu,Qijun Chen*

Main category: cs.AI

TL;DR: 提出NavComposer自动生成高质量导航指令和NavInstrCritic无标注评估系统，提升语言引导导航研究的可扩展性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有语言引导导航研究受限于专家提供的指令数量和合成标注的质量，难以进行大规模研究。

Method: NavComposer框架将语义实体分解重组生成自然语言指令，NavInstrCritic系统从对比匹配、语义一致性和语言多样性三个维度评估指令质量。

Result: NavComposer生成的指令质量高，NavInstrCritic评估系统全面有效，两者共同推动了该领域研究的进展。

Conclusion: NavComposer框架和NavInstrCritic评估系统提高了语言引导导航研究的可扩展性和泛化能力，通过自动生成高质量导航指令和无标注评估来解决现有方法的局限性。

Abstract: Language-guided navigation is a cornerstone of embodied AI, enabling agents
to interpret language instructions and navigate complex environments. However,
expert-provided instructions are limited in quantity, while synthesized
annotations often lack quality, making them insufficient for large-scale
research. To address this, we propose NavComposer, a novel framework for
automatically generating high-quality navigation instructions. NavComposer
explicitly decomposes semantic entities such as actions, scenes, and objects,
and recomposes them into natural language instructions. Its modular
architecture allows flexible integration of state-of-the-art techniques, while
the explicit use of semantic entities enhances both the richness and accuracy
of instructions. Moreover, it operates in a data-agnostic manner, supporting
adaptation to diverse navigation trajectories without domain-specific training.
Complementing NavComposer, we introduce NavInstrCritic, a comprehensive
annotation-free evaluation system that assesses navigation instructions on
three dimensions: contrastive matching, semantic consistency, and linguistic
diversity. NavInstrCritic provides a holistic evaluation of instruction
quality, addressing limitations of traditional metrics that rely heavily on
expert annotations. By decoupling instruction generation and evaluation from
specific navigation agents, our method enables more scalable and generalizable
research. Extensive experiments provide direct and practical evidence for the
effectiveness of our method.

</details>


### [16] [Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation](https://arxiv.org/abs/2507.10911)
*Yicong Wu,Ting Chen,Irit Hochberg,Zhoujian Sun,Ruth Edry,Zhengxing Huang,Mor Peleg*

Main category: cs.AI

TL;DR: LLM多智能体系统用于多病共患慢性病治疗方案推荐可行，但单智能体表现同样出色，且最佳模型仍有不足。


<details>
  <summary>Details</summary>
Motivation: 现有的决策支持系统难以应对多病共患慢性病患者的治疗方案推荐，存在治疗冲突的风险。

Method: 设计了单智能体和多智能体系统框架，模拟多学科团队的决策过程，并使用基准案例评估了系统的治疗规划任务。

Result: 单智能体系统与多学科团队的表现相当，最佳模型能满足所有临床目标，但建议可能不完整或存在不必要的药物，导致药物与疾病或药物间的冲突。

Conclusion: 使用LLM构建多智能体系统为多病共患慢性病患者安全地推荐治疗方案是可行的，但单智能体系统表现与多学科团队相当，且最佳模型仍存在建议不完整或药物冲突等问题。

Abstract: Therapy recommendation for chronic patients with multimorbidity is
challenging due to risks of treatment conflicts. Existing decision support
systems face scalability limitations. Inspired by the way in which general
practitioners (GP) manage multimorbidity patients, occasionally convening
multidisciplinary team (MDT) collaboration, this study investigated the
feasibility and value of using a Large Language Model (LLM)-based multi-agent
system (MAS) for safer therapy recommendations. We designed a single agent and
a MAS framework simulating MDT decision-making by enabling discussion among LLM
agents to resolve medical conflicts. The systems were evaluated on therapy
planning tasks for multimorbidity patients using benchmark cases. We compared
MAS performance with single-agent approaches and real-world benchmarks. An
important contribution of our study is the definition of evaluation metrics
that go beyond the technical precision and recall and allow the inspection of
clinical goals met and medication burden of the proposed advices to a gold
standard benchmark. Our results show that with current LLMs, a single agent GP
performs as well as MDTs. The best-scoring models provide correct
recommendations that address all clinical goals, yet the advices are
incomplete. Some models also present unnecessary medications, resulting in
unnecessary conflicts between medication and conditions or drug-drug
interactions.

</details>
