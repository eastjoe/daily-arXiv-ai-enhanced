{"id": "2507.14154", "categories": ["cs.AI", "cs.LG", "68T05, 81P68", "I.2.6; I.2.0; F.1.2"], "pdf": "https://arxiv.org/pdf/2507.14154", "abs": "https://arxiv.org/abs/2507.14154", "authors": ["Rahul Kabali"], "title": "The Free Will Equation: Quantum Field Analogies for AGI", "comment": "22 pages, 5 figures. Submitted as an arXiv preprint. All code and\n  experiment details included in appendix", "summary": "Artificial General Intelligence (AGI) research traditionally focuses on\nalgorithms that optimize for specific goals under deterministic rules. Yet,\nhuman-like intelligence exhibits adaptive spontaneity - an ability to make\nunexpected choices or free decisions not strictly dictated by past data or\nimmediate reward. This trait, often dubbed \"free will\" in a loose sense, might\nbe crucial for creativity, robust adaptation, and avoiding ruts in\nproblem-solving. This paper proposes a theoretical framework, called the Free\nWill Equation, that draws analogies from quantum field theory to endow AGI\nagents with a form of adaptive, controlled stochasticity in their\ndecision-making process. The core idea is to treat an AI agent's cognitive\nstate as a superposition of potential actions or thoughts, which collapses\nprobabilistically into a concrete action when a decision is made - much like a\nquantum wavefunction collapsing upon measurement. By incorporating mechanisms\nanalogous to quantum fields, along with intrinsic motivation terms, we aim to\nimprove an agent's ability to explore novel strategies and adapt to unforeseen\nchanges. Experiments in a non-stationary multi-armed bandit environment\ndemonstrate that agents using this framework achieve higher rewards and policy\ndiversity compared to baseline methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u62df\u4eba\u7c7b\u201c\u81ea\u7531\u610f\u5fd7\u201d\u7684AI\u51b3\u7b56\u6846\u67b6\uff0c\u4f7f\u5176\u80fd\u591f\u66f4\u7075\u6d3b\u5730\u9002\u5e94\u73af\u5883\u53d8\u5316\u3002", "motivation": "\u4f20\u7edf\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u4fa7\u91cd\u4e8e\u786e\u5b9a\u6027\u89c4\u5219\u4e0b\u7684\u76ee\u6807\u4f18\u5316\uff0c\u800c\u5ffd\u7565\u4e86\u4eba\u7c7b\u667a\u80fd\u7684\u9002\u5e94\u6027\u81ea\u53d1\u6027\u548c\u521b\u9020\u6027\u3002", "method": "\u501f\u9274\u91cf\u5b50\u573a\u8bba\u7684\u601d\u60f3\uff0c\u5c06\u4eba\u5de5\u667a\u80fd\u4e3b\u4f53\u7684\u8ba4\u77e5\u72b6\u6001\u89c6\u4e3a\u6f5c\u5728\u884c\u52a8\u6216\u601d\u60f3\u7684\u53e0\u52a0\u6001\uff0c\u901a\u8fc7\u6982\u7387\u574d\u7f29\u9009\u62e9\u884c\u52a8\u3002", "result": "\u5728\u975e\u5e73\u7a33\u591a\u81c2\u8001\u864e\u673a\u73af\u5883\u4e2d\uff0c\u4f7f\u7528\u8be5\u6846\u67b6\u7684\u667a\u80fd\u4f53\u53d6\u5f97\u4e86\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u66f4\u9ad8\u7684\u5956\u52b1\u548c\u7b56\u7565\u591a\u6837\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u81ea\u7531\u610f\u5fd7\u65b9\u7a0b\u201d\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8d4b\u4e88\u4eba\u5de5\u667a\u80fd\u4e3b\u4f53\u4e00\u79cd\u9002\u5e94\u6027\u3001\u53ef\u63a7\u7684\u968f\u673a\u6027\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u5728\u975e\u5e73\u7a33\u591a\u81c2\u8001\u864e\u673a\u73af\u5883\u4e2d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5956\u52b1\u548c\u7b56\u7565\u591a\u6837\u6027\u3002"}}
{"id": "2507.14267", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.14267", "abs": "https://arxiv.org/abs/2507.14267", "authors": ["Ziqi Wang", "Hongshuo Huang", "Hancheng Zhao", "Changwen Xu", "Shang Zhu", "Jan Janssen", "Venkatasubramanian Viswanathan"], "title": "DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation", "comment": "34 pages, 28 pages of Supporting Information", "summary": "Materials discovery relies on high-throughput, high-fidelity simulation\ntechniques such as Density Functional Theory (DFT), which require years of\ntraining, extensive parameter fine-tuning and systematic error handling. To\naddress these challenges, we introduce the DFT-based Research Engine for\nAgentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for\nDFT simulation that combines a central Large Language Model (LLM) planner agent\nwith domain-specific LLM agents for atomistic structure generation, systematic\nDFT convergence testing, High-Performance Computing (HPC) scheduling, and error\nhandling. In addition, a shared canvas helps the LLM agents to structure their\ndiscussions, preserve context and prevent hallucination. We validate DREAMS\ncapabilities on the Sol27LC lattice-constant benchmark, achieving average\nerrors below 1\\% compared to the results of human DFT experts. Furthermore, we\napply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating\nits long-term and complex problem-solving capabilities. The framework again\nreproduces expert-level literature adsorption-energy differences. Finally,\nDREAMS is employed to quantify functional-driven uncertainties with Bayesian\nensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at\nthe Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS\napproaches L3-level automation - autonomous exploration of a defined design\nspace - and significantly reduces the reliance on human expertise and\nintervention, offering a scalable path toward democratized, high-throughput,\nhigh-fidelity computational materials discovery.", "AI": {"tldr": "DREAMS\u662f\u4e00\u4e2a\u81ea\u52a8\u5316DFT\u6a21\u62df\u6846\u67b6\uff0c\u5728\u6750\u6599\u53d1\u73b0\u65b9\u9762\u8fbe\u5230\u4e86\u4e13\u5bb6\u6c34\u5e73\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u901a\u91cf\u548c\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3DFT\u6a21\u62df\u9700\u8981\u591a\u5e74\u57f9\u8bad\u3001\u5927\u91cf\u53c2\u6570\u5fae\u8c03\u548c\u7cfb\u7edf\u9519\u8bef\u5904\u7406\u7684\u6311\u6218\u3002", "method": "DREAMS\u662f\u4e00\u4e2a\u57fa\u4e8eDFT\u7684\u5c42\u6b21\u5316\u591aAgent\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u4e2d\u592eLLM\u89c4\u5212Agent\u548c\u7528\u4e8e\u539f\u5b50\u7ed3\u6784\u751f\u6210\u3001DFT\u6536\u655b\u6027\u6d4b\u8bd5\u3001HPC\u8c03\u5ea6\u548c\u9519\u8bef\u5904\u7406\u7684\u7279\u5b9a\u9886\u57dfLLM Agents\u3002", "result": "DREAMS\u5728Sol27LC\u6676\u683c\u5e38\u6570\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u8bef\u5dee\u4f4e\u4e8e1%\uff0c\u5e76\u5728CO/Pt(111)\u5438\u9644\u96be\u9898\u4e0a\u518d\u73b0\u4e86\u4e13\u5bb6\u7ea7\u7684\u5438\u9644\u80fd\u5dee\u5f02\uff0c\u5e76\u91cf\u5316\u4e86\u529f\u80fd\u9a71\u52a8\u7684\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "DREAMS\u6846\u67b6\u5b9e\u73b0\u4e86L3\u7ea7\u81ea\u52a8\u5316\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5bf9\u4eba\u5de5\u7684\u4f9d\u8d56\uff0c\u4e3a\u9ad8\u901a\u91cf\u9ad8\u7cbe\u5ea6\u8ba1\u7b97\u6750\u6599\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u7684\u9014\u5f84\u3002"}}
{"id": "2507.14293", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14293", "abs": "https://arxiv.org/abs/2507.14293", "authors": ["Boyuan Zheng", "Zeyi Liao", "Scott Salisbury", "Zeyuan Liu", "Michael Lin", "Qinyuan Zheng", "Zifan Wang", "Xiang Deng", "Dawn Song", "Huan Sun", "Yu Su"], "title": "WebGuard: Building a Generalizable Guardrail for Web Agents", "comment": "We publicly release WebGuard, along with its annotation tools and\n  fine-tuned models, to facilitate open-source research on monitoring and\n  safeguarding web agents. All resources are available at\n  https://github.com/OSU-NLP-Group/WebGuard", "summary": "The rapid development of autonomous web agents powered by Large Language\nModels (LLMs), while greatly elevating efficiency, exposes the frontier risk of\ntaking unintended or harmful actions. This situation underscores an urgent need\nfor effective safety measures, akin to access controls for human users. To\naddress this critical challenge, we introduce WebGuard, the first comprehensive\ndataset designed to support the assessment of web agent action risks and\nfacilitate the development of guardrails for real-world online environments. In\ndoing so, WebGuard specifically focuses on predicting the outcome of\nstate-changing actions and contains 4,939 human-annotated actions from 193\nwebsites across 22 diverse domains, including often-overlooked long-tail\nwebsites. These actions are categorized using a novel three-tier risk schema:\nSAFE, LOW, and HIGH. The dataset includes designated training and test splits\nto support evaluation under diverse generalization settings. Our initial\nevaluations reveal a concerning deficiency: even frontier LLMs achieve less\nthan 60% accuracy in predicting action outcomes and less than 60% recall in\nlagging HIGH-risk actions, highlighting the risks of deploying\ncurrent-generation agents without dedicated safeguards. We therefore\ninvestigate fine-tuning specialized guardrail models using WebGuard. We conduct\ncomprehensive evaluations across multiple generalization settings and find that\na fine-tuned Qwen2.5VL-7B model yields a substantial improvement in\nperformance, boosting accuracy from 37% to 80% and HIGH-risk action recall from\n20% to 76%. Despite these improvements, the performance still falls short of\nthe reliability required for high-stakes deployment, where guardrails must\napproach near-perfect accuracy and recall.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u7f51\u7edc\u4ee3\u7406\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86WebGuard\u6570\u636e\u96c6\u5e76\u5fae\u8c03\u4e86\u6a21\u578b\uff0c\u4f46\u5176\u6027\u80fd\u4ecd\u9700\u6539\u8fdb\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u81ea\u4e3b\u7f51\u7edc\u4ee3\u7406\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u6709\u6548\u7684\u5b89\u5168\u63aa\u65bd\u3002", "method": "\u6784\u5efaWebGuard\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528\u8be5\u6570\u636e\u96c6\u5fae\u8c03Qwen2.5VL-7B\u6a21\u578b\u4ee5\u63d0\u9ad8\u884c\u4e3a\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9ad8\u98ce\u9669\u884c\u4e3a\u7684\u53ec\u56de\u7387\u3002", "result": "WebGuard\u6570\u636e\u96c6\u5305\u542b4939\u4e2a\u4eba\u5de5\u6807\u6ce8\u7684\u7f51\u7edc\u4ee3\u7406\u884c\u4e3a\uff0c\u6db5\u76d622\u4e2a\u4e0d\u540c\u9886\u57df\u3002\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u51c6\u786e\u7387\u548c\u9ad8\u98ce\u9669\u884c\u4e3a\u53ec\u56de\u7387\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u6ee1\u8db3\u9ad8\u98ce\u9669\u90e8\u7f72\u9700\u6c42\u3002", "conclusion": "\u5f53\u524d\u4e00\u4ee3\u81ea\u4e3b\u7f51\u7edc\u4ee3\u7406\u7f3a\u4e4f\u8db3\u591f\u7684\u5b89\u5168\u6027\uff0c\u5176\u884c\u4e3a\u9884\u6d4b\u51c6\u786e\u7387\u548c\u9ad8\u98ce\u9669\u884c\u4e3a\u53ec\u56de\u7387\u5747\u4f4e\u4e8e60%\u3002\u901a\u8fc7\u4f7f\u7528WebGuard\u6570\u636e\u96c6\u5fae\u8c03Qwen2.5VL-7B\u6a21\u578b\uff0c\u51c6\u786e\u7387\u63d0\u5347\u81f380%\uff0c\u9ad8\u98ce\u9669\u884c\u4e3a\u53ec\u56de\u7387\u63d0\u5347\u81f376%\uff0c\u4f46\u4ecd\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u9ad8\u98ce\u9669\u90e8\u7f72\u9700\u6c42\u3002"}}
{"id": "2507.14306", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.14306", "abs": "https://arxiv.org/abs/2507.14306", "authors": ["Samarth P", "Vyoman Jain", "Shiva Golugula", "Motamarri Sai Sathvik"], "title": "Manimator: Transforming Research Papers into Visual Explanations", "comment": null, "summary": "Understanding complex scientific and mathematical concepts, particularly\nthose presented in dense research papers, poses a significant challenge for\nlearners. Dynamic visualizations can greatly enhance comprehension, but\ncreating them manually is time-consuming and requires specialized knowledge and\nskills. We introduce manimator, an open-source system that leverages Large\nLanguage Models to transform research papers and natural language prompts into\nexplanatory animations using the Manim engine. Manimator employs a pipeline\nwhere an LLM interprets the input text or research paper PDF to generate a\nstructured scene description outlining key concepts, mathematical formulas, and\nvisual elements and another LLM translates this description into executable\nManim Python code. We discuss its potential as an educational tool for rapidly\ncreating engaging visual explanations for complex STEM topics, democratizing\nthe creation of high-quality educational content.", "AI": {"tldr": "Manimator\u7528LLM\u5c06\u8bba\u6587\u8f6c\u6362\u4e3aManim\u52a8\u753b\uff0c\u4fbf\u4e8e\u7406\u89e3\u590d\u6742\u6982\u5ff5\u3002", "motivation": "\u5e2e\u52a9\u5b66\u4e60\u8005\u7406\u89e3\u590d\u6742\u7684\u79d1\u5b66\u548c\u6570\u5b66\u6982\u5ff5\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u5728\u5bc6\u96c6\u578b\u7814\u7a76\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u6982\u5ff5\u3002", "method": "Manimator\u4f7f\u7528\u4e00\u4e2a\u7ba1\u9053\uff1a\u4e00\u4e2aLLM\u89e3\u91ca\u8f93\u5165\u6587\u672c\u6216\u7814\u7a76\u8bba\u6587PDF\u4ee5\u751f\u6210\u7ed3\u6784\u5316\u7684\u573a\u666f\u63cf\u8ff0\uff0c\u53e6\u4e00\u4e2aLLM\u5c06\u6b64\u63cf\u8ff0\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Manim Python\u4ee3\u7801\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u5c06\u7814\u7a76\u8bba\u6587\u8f6c\u6362\u4e3a\u52a8\u753b\u7684\u7cfb\u7edf\uff0c\u4e3aSTEM\u4e3b\u9898\u521b\u5efa\u5f15\u4eba\u5165\u80dc\u7684\u89c6\u89c9\u89e3\u91ca\u3002", "conclusion": "Manimator\u662f\u4e00\u4e2a\u5f00\u6e90\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u7814\u7a76\u8bba\u6587\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u89e3\u91ca\u6027\u52a8\u753b\uff0c\u964d\u4f4e\u4e86\u521b\u5efa\u9ad8\u8d28\u91cf\u6559\u80b2\u5185\u5bb9\u7684\u95e8\u69db\u3002"}}
{"id": "2507.14334", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14334", "abs": "https://arxiv.org/abs/2507.14334", "authors": ["Hui Yang", "Jiaoyan Chen", "Yuan He", "Yongsheng Gao", "Ian Horrocks"], "title": "Language Models as Ontology Encoders", "comment": null, "summary": "OWL (Web Ontology Language) ontologies which are able to formally represent\ncomplex knowledge and support semantic reasoning have been widely adopted\nacross various domains such as healthcare and bioinformatics. Recently,\nontology embeddings have gained wide attention due to its potential to infer\nplausible new knowledge and approximate complex reasoning. However, existing\nmethods face notable limitations: geometric model-based embeddings typically\noverlook valuable textual information, resulting in suboptimal performance,\nwhile the approaches that incorporate text, which are often based on language\nmodels, fail to preserve the logical structure. In this work, we propose a new\nontology embedding method OnT, which tunes a Pretrained Language Model (PLM)\nvia geometric modeling in a hyperbolic space for effectively incorporating\ntextual labels and simultaneously preserving class hierarchies and other\nlogical relationships of Description Logic EL. Extensive experiments on four\nreal-world ontologies show that OnT consistently outperforms the baselines\nincluding the state-of-the-art across both tasks of prediction and inference of\naxioms. OnT also demonstrates strong potential in real-world applications,\nindicated by its robust transfer learning abilities and effectiveness in real\ncases of constructing a new ontology from SNOMED CT. Data and code are\navailable at https://github.com/HuiYang1997/OnT.", "AI": {"tldr": "OnT \u662f\u4e00\u79cd\u65b0\u7684\u672c\u4f53\u5d4c\u5165\u65b9\u6cd5\uff0c\u5b83\u7ed3\u5408\u4e86\u6587\u672c\u4fe1\u606f\u548c\u903b\u8f91\u7ed3\u6784\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u672c\u4f53\u4e0a\u53d6\u5f97\u4e86\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u672c\u4f53\u5d4c\u5165\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u57fa\u4e8e\u51e0\u4f55\u6a21\u578b\u7684\u5d4c\u5165\u901a\u5e38\u5ffd\u7565\u6709\u4ef7\u503c\u7684\u6587\u672c\u4fe1\u606f\uff0c\u5bfc\u81f4\u6027\u80fd\u6b20\u4f73\uff1b\u7ed3\u5408\u6587\u672c\u7684\u65b9\u6cd5\uff08\u901a\u5e38\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\uff09\u672a\u80fd\u4fdd\u7559\u903b\u8f91\u7ed3\u6784\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u672c\u4f53\u5d4c\u5165\u65b9\u6cd5 OnT\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u53cc\u66f2\u7a7a\u95f4\u4e2d\u8fdb\u884c\u51e0\u4f55\u5efa\u6a21\u6765\u5fae\u8c03\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b (PLM)\uff0c\u6709\u6548\u5730\u7ed3\u5408\u4e86\u6587\u672c\u6807\u7b7e\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u63cf\u8ff0\u903b\u8f91 EL \u7684\u7c7b\u5c42\u6b21\u7ed3\u6784\u548c\u5176\u4ed6\u903b\u8f91\u5173\u7cfb\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u672c\u4f53\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cOnT \u5728\u9884\u6d4b\u548c\u63a8\u7406\u516c\u7406\u7684\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5305\u62ec\u73b0\u6709\u6280\u672f\u3002OnT \u8fd8\u5c55\u793a\u4e86\u5176\u5f3a\u5927\u7684\u8fc1\u79fb\u5b66\u4e60\u80fd\u529b\u548c\u5728\u771f\u5b9e\u6848\u4f8b\u4e2d\u6784\u5efa\u65b0\u7684 SNOMED CT \u672c\u4f53\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "OnT \u7b97\u6cd5\u5728\u9884\u6d4b\u548c\u63a8\u7406\u516c\u7406\u7684\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u5305\u62ec\u73b0\u6709\u6280\u672f\u5728\u5185\u7684\u57fa\u7ebf\uff0c\u5e76\u5728\u6784\u5efa\u65b0\u7684SNOMED CT \u672c\u4f53\u65b9\u9762\u663e\u793a\u51fa\u5f3a\u5927\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.14335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14335", "abs": "https://arxiv.org/abs/2507.14335", "authors": ["Nicolas Wischermann", "Claudio Mayrink Verdun", "Gabriel Poesia", "Francesco Noseda"], "title": "ProofCompass: Enhancing Specialized Provers with LLM Guidance", "comment": "19 pages, 7 figures. Accepted at the 2nd AI for MATH Workshop at the\n  42nd International Conference on Machine Learning (ICML 2025)", "summary": "Language models have become increasingly powerful tools for formal\nmathematical reasoning. However, most existing approaches rely exclusively on\neither large general-purpose models or smaller specialized models, each with\ndistinct limitations, while training specialized large models still requires\nsignificant computational resources. This paper introduces ProofCompass, a\nnovel hybrid methodology that achieves remarkable computational efficiency by\nstrategically guiding existing specialized prover methods, such as\nDeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without\nrequiring additional model training. The LLM provides natural language proof\nstrategies and analyzes failed attempts to select intermediate lemmas, enabling\neffective problem decomposition. On the miniF2F benchmark, ProofCompass\ndemonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\\%\n\\rightarrow 55.3\\%$) while using 25x fewer attempts ($3200 \\rightarrow 128$).\nOur synergistic approach paves the way for simultaneously improving\ncomputational efficiency and accuracy in formal theorem proving.", "AI": {"tldr": "ProofCompass \u662f\u4e00\u79cd\u9ad8\u6548\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6307\u5bfc\u4e13\u7528\u8bc1\u660e\u5668\uff0c\u5728\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6548\u7387\u63d0\u5347\u548c\u51c6\u786e\u6027\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5927\u578b\u901a\u7528\u6a21\u578b\u6216\u5c0f\u578b\u4e13\u7528\u6a21\u578b\uff0c\u5404\u6709\u5c40\u9650\u6027\uff0c\u8bad\u7ec3\u5927\u578b\u4e13\u7528\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002ProofCompass \u65e8\u5728\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "method": "ProofCompass \u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6307\u5bfc\u5df2\u6709\u7684\u4e13\u4e1a\u8bc1\u660e\u5668\uff0c\u4f8b\u5982 DeepSeek-Prover-v1.5-RL\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8bc1\u660e\u7b56\u7565\u548c\u5931\u8d25\u5c1d\u8bd5\u5206\u6790\u6765\u9009\u62e9\u4e2d\u95f4\u5f15\u7406\uff0c\u5b9e\u73b0\u6709\u6548\u7684\u5206\u89e3\u95ee\u9898\u3002", "result": "ProofCompass \u5728 miniF2F \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4ee5 25 \u500d\u66f4\u5c11\u7684\u5c1d\u8bd5\u6b21\u6570\uff0c\u53d6\u5f97\u6bd4 DSP-v1.5 \u66f4\u597d\u7684\u7ed3\u679c (54.9% -> 55.3%)\u3002", "conclusion": "ProofCompass \u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4e13\u4e1a\u8bc1\u660e\u5668\uff0c\u5728 miniF2F \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u7684\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u4ee5\u66f4\u5c11\u7684\u5c1d\u8bd5\u6b21\u6570\u8d85\u8d8a\u4e86 DeepSeek-Prover-v1.5-RL\u3002"}}
{"id": "2507.14393", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14393", "abs": "https://arxiv.org/abs/2507.14393", "authors": ["Humza Sami", "Mubashir ul Islam", "Pierre-Emmanuel Gaillardon", "Valerio Tenace"], "title": "Adaptive Multi-Agent Reasoning via Automated Workflow Generation", "comment": null, "summary": "The rise of Large Reasoning Models (LRMs) promises a significant leap forward\nin language model capabilities, aiming to tackle increasingly sophisticated\ntasks with unprecedented efficiency and accuracy. However, despite their\nimpressive performance, recent studies have highlighted how current reasoning\nmodels frequently fail to generalize to novel, unseen problems, often resorting\nto memorized solutions rather than genuine inferential reasoning. Such behavior\nunderscores a critical limitation in modern LRMs, i.e., their tendency toward\noverfitting, which in turn results in poor generalization in problem-solving\ncapabilities.\n  In this paper, we introduce Nexus Architect, an enhanced iteration of our\nmulti-agent system framework, Nexus, equipped with a novel automated workflow\nsynthesis mechanism. Given a user's prompt and a small set of representative\nexamples, the Architect autonomously generates a tailored reasoning workflow by\nselecting suitable strategies, tool integrations, and adversarial techniques\nfor a specific problem class. Furthermore, the Architect includes an iterative\nprompt refinement mechanism that fine-tunes agents' system prompts to maximize\nperformance and improve the generalization capabilities of the system.\n  We empirically evaluate Nexus Architect by employing an off-the-shelf,\nnon-reasoning model on a custom dataset of challenging logical questions and\ncompare its performance against state-of-the-art LRMs. Results show that Nexus\nArchitect consistently outperforms existing solutions, achieving up to a 66%\nincrease in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\\times$ against\nClaude Sonnet 4 and DeepSeek-R1, and over 3$\\times$ w.r.t. Llama 4 Scout.", "AI": {"tldr": "Nexus Architect\u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5408\u6210\u548c\u8fed\u4ee3\u63d0\u793a\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684LRM\u6a21\u578b\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNexus Architect\u7684\u589e\u5f3a\u578b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u4e00\u4e2a\u65b0\u9896\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5408\u6210\u673a\u5236\u548c\u8fed\u4ee3\u63d0\u793a\u7ec6\u5316\u673a\u5236\u3002", "result": "Nexus Architect\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u903b\u8f91\u95ee\u9898\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u4e0a\uff0c\u4e0e\u73b0\u6709LRM\u6a21\u578b\u76f8\u6bd4\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u6700\u9ad8\u63d0\u5347\u5e45\u5ea6\u8fbe\u523066%\u3002", "conclusion": "Nexus Architect\uff0c\u4e00\u4e2a\u6539\u8fdb\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u7684\u5de5\u4f5c\u6d41\u5408\u6210\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2507.14406", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.14406", "abs": "https://arxiv.org/abs/2507.14406", "authors": ["Michael J. Zellinger", "Matt Thomson"], "title": "Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering", "comment": "8 pages, 5 figures", "summary": "State-of-the-art reasoning LLMs are powerful problem solvers, but they still\noccasionally make mistakes. However, adopting AI models in risk-sensitive\ndomains often requires error rates near 0%. To address this gap, we propose\ncollaboration between a reasoning model and a human expert who resolves queries\nthe model cannot confidently answer. We find that quantifying the uncertainty\nof a reasoning model through the length of its reasoning trace yields an\neffective basis for deferral to a human, e.g., cutting the error rate of Qwen3\n235B-A22B on difficult MATH problems from 3% to less than 1% when deferring\n7.5% of queries. However, the high latency of reasoning models still makes them\nchallenging to deploy on use cases with high query volume. To address this\nchallenge, we explore fronting a reasoning model with a large non-reasoning\nmodel. We call this modified human-in-the-loop system \"Fail Fast, or Ask\",\nsince the non-reasoning model may defer difficult queries to the human expert\ndirectly (\"failing fast\"), without incurring the reasoning model's higher\nlatency. We show that this approach yields around 40% latency reduction and\nabout 50% cost savings for DeepSeek R1 while maintaining 90+% area under the\naccuracy-rejection curve. However, we observe that latency savings are lower\nthan expected because of \"latency drag\", the phenomenon that processing easier\nqueries with a non-reasoning model pushes the reasoning model's latency\ndistribution towards longer latencies. Broadly, our results suggest that the\ndeficiencies of state-of-the-art reasoning models -- nontrivial error rates and\nhigh latency -- can be substantially mitigated through black-box systems\nengineering, without requiring access to LLM internals.", "AI": {"tldr": "\u901a\u8fc7LLM\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5408\u4f5c\u53ca\u589e\u52a0\u975e\u63a8\u7406\u6a21\u578b\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9519\u8bef\u7387\u548c\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709LLM\u7684\u9519\u8bef\u7387\u8f83\u9ad8\u4e14\u5ef6\u8fdf\u8f83\u5927\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u5bf9\u9519\u8bef\u7387\u548c\u6548\u7387\u8981\u6c42\u8f83\u9ad8\u7684\u573a\u666f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cdLLM\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5408\u4f5c\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u91cf\u5316LLM\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u9009\u62e9\u6027\u5730\u5c06\u96be\u9898\u63d0\u4ea4\u7ed9\u4eba\u7c7b\u4e13\u5bb6\uff0c\u5e76\u901a\u8fc7\u5728LLM\u524d\u589e\u52a0\u4e00\u4e2a\u975e\u63a8\u7406\u6a21\u578b\u6765\u51cf\u5c11\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u53ef\u4ee5\u6709\u6548\u964d\u4f4eLLM\u7684\u9519\u8bef\u7387\uff0c\u5e76\u51cf\u5c11\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u89e3\u51b3\u95ee\u9898\u65b9\u9762\u5f88\u5f3a\u5927\uff0c\u4f46\u4ecd\u4f1a\u51fa\u9519\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdLLM\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5408\u4f5c\u7684\u7cfb\u7edf\uff0c\u4ee5\u964d\u4f4e\u9519\u8bef\u7387\u5e76\u63d0\u9ad8\u6548\u7387\u3002\u901a\u8fc7\u91cf\u5316LLM\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u9009\u62e9\u6027\u5730\u5c06\u96be\u9898\u63d0\u4ea4\u7ed9\u4eba\u7c7b\u4e13\u5bb6\uff0c\u53ef\u4ee5\u6709\u6548\u964d\u4f4e\u9519\u8bef\u7387\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5728LLM\u524d\u589e\u52a0\u4e00\u4e2a\u975e\u63a8\u7406\u6a21\u578b\uff0c\u53ef\u4ee5\u51cf\u5c11\u5ef6\u8fdf\u548c\u6210\u672c\u3002"}}
{"id": "2507.14417", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14417", "abs": "https://arxiv.org/abs/2507.14417", "authors": ["Aryo Pradipta Gema", "Alexander H\u00e4gele", "Runjin Chen", "Andy Arditi", "Jacob Goldman-Wetzler", "Kit Fraser-Taliente", "Henry Sleight", "Linda Petrini", "Julian Michael", "Beatrice Alex", "Pasquale Minervini", "Yanda Chen", "Joe Benton", "Ethan Perez"], "title": "Inverse Scaling in Test-Time Compute", "comment": null, "summary": "We construct evaluation tasks where extending the reasoning length of Large\nReasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling\nrelationship between test-time compute and accuracy. Our evaluation tasks span\nfour categories: simple counting tasks with distractors, regression tasks with\nspurious features, deduction tasks with constraint tracking, and advanced AI\nrisks. We identify five distinct failure modes when models reason for longer:\n1) Claude models become increasingly distracted by irrelevant information; 2)\nOpenAI o-series models resist distractors but overfit to problem framings; 3)\nmodels shift from reasonable priors to spurious correlations; 4) all models\nshow difficulties in maintaining focus on complex deductive tasks; and 5)\nextended reasoning may amplify concerning behaviors, with Claude Sonnet 4\nshowing increased expressions of self-preservation. These findings suggest that\nwhile test-time compute scaling remains promising for improving model\ncapabilities, it may inadvertently reinforce problematic reasoning patterns.\nOur results demonstrate the importance of evaluating models across diverse\nreasoning lengths to identify and address these failure modes in LRMs.", "AI": {"tldr": "\u5ef6\u957f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u65f6\u95f4\u53ef\u80fd\u4f1a\u9002\u5f97\u5176\u53cd\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u548c\u95ee\u9898\u884c\u4e3a\u653e\u5927\u3002", "motivation": "\u8bc4\u4f30\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u6269\u5c55\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u4e86\u56db\u4e2a\u7c7b\u522b\u7684\u8bc4\u4f30\u4efb\u52a1\uff1a\u5e26\u6709\u5e72\u6270\u9879\u7684\u7b80\u5355\u8ba1\u6570\u4efb\u52a1\u3001\u5177\u6709\u865a\u5047\u7279\u5f81\u7684\u56de\u5f52\u4efb\u52a1\u3001\u9700\u8981\u7ea6\u675f\u8ddf\u8e2a\u7684\u6f14\u7ece\u4efb\u52a1\u548c\u9ad8\u7ea7AI\u98ce\u9669\u4efb\u52a1\u3002", "result": "\u8bc6\u522b\u51fa\u6a21\u578b\u5728\u8f83\u957f\u63a8\u7406\u65f6\u95f4\u4e0b\u7684\u4e94\u79cd\u5931\u6548\u6a21\u5f0f\uff1a1)\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u65e0\u5173\u4fe1\u606f\u7684\u5e72\u6270\uff1b2)\u6a21\u578b\u8fc7\u5ea6\u62df\u5408\u95ee\u9898\u6846\u67b6\uff1b3)\u6a21\u578b\u503e\u5411\u4e8e\u865a\u5047\u5173\u8054\uff1b4)\u6a21\u578b\u96be\u4ee5\u96c6\u4e2d\u6ce8\u610f\u529b\u4e8e\u590d\u6742\u7684\u6f14\u7ece\u4efb\u52a1\uff1b5)\u6269\u5c55\u63a8\u7406\u53ef\u80fd\u4f1a\u653e\u5927\u4ee4\u4eba\u62c5\u5fe7\u7684\u884c\u4e3a\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b(LRM)\u7684\u63a8\u7406\u957f\u5ea6\u5ef6\u957f\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u4e0e\u51c6\u786e\u6027\u4e4b\u95f4\u5b58\u5728\u53cd\u6bd4\u4f8b\u5173\u7cfb\u3002"}}
{"id": "2507.14447", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14447", "abs": "https://arxiv.org/abs/2507.14447", "authors": ["Guancheng Zeng", "Xueyi Chen", "Jiawang Hu", "Shaohua Qi", "Yaxuan Mao", "Zhantao Wang", "Yifan Nie", "Shuang Li", "Qiuyang Feng", "Pengxu Qiu", "Yujia Wang", "Wenqiang Han", "Linyan Huang", "Gang Li", "Jingjing Mo", "Haowen Hu"], "title": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise", "comment": "26 pages, 8 figures, 5 tables", "summary": "The deployment of agent systems in an enterprise environment is often\nhindered by several challenges: common models lack domain-specific process\nknowledge, leading to disorganized plans, missing key tools, and poor execution\nstability. To address this, this paper introduces Routine, a multi-step agent\nplanning framework designed with a clear structure, explicit instructions, and\nseamless parameter passing to guide the agent's execution module in performing\nmulti-step tool-calling tasks with high stability. In evaluations conducted\nwithin a real-world enterprise scenario, Routine significantly increases the\nexecution accuracy in model tool calls, increasing the performance of GPT-4o\nfrom 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed\na Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an\naccuracy increase to 88.2% on scenario-specific evaluations, indicating\nimproved adherence to execution plans. In addition, we employed Routine-based\ndistillation to create a scenario-specific, multi-step tool-calling dataset.\nFine-tuning on this distilled dataset raised the model's accuracy to 95.5%,\napproaching GPT-4o's performance. These results highlight Routine's\neffectiveness in distilling domain-specific tool-usage patterns and enhancing\nmodel adaptability to new scenarios. Our experimental results demonstrate that\nRoutine provides a practical and accessible approach to building stable agent\nworkflows, accelerating the deployment and adoption of agent systems in\nenterprise environments, and advancing the technical vision of AI for Process.", "AI": {"tldr": "Routine\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86Agent\u7cfb\u7edf\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u6267\u884c\u7a33\u5b9a\u6027\u548c\u9002\u5e94\u6027\uff0c\u4e3aAI\u6d41\u7a0b\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709Agent\u7cfb\u7edf\u5728\u4f01\u4e1a\u73af\u5883\u90e8\u7f72\u4e2d\u9762\u4e34\u7684\u6311\u6218\uff0c\u4f8b\u5982\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u8fc7\u7a0b\u77e5\u8bc6\u5bfc\u81f4\u8ba1\u5212\u6df7\u4e71\u3001\u5de5\u5177\u7f3a\u5931\u548c\u6267\u884c\u7a33\u5b9a\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6b65\u9aa4Agent\u89c4\u5212\u6846\u67b6Routine\uff0c\u8be5\u6846\u67b6\u5177\u6709\u6e05\u6670\u7684\u7ed3\u6784\u3001\u660e\u786e\u7684\u6307\u4ee4\u548c\u65e0\u7f1d\u7684\u53c2\u6570\u4f20\u9012\uff0c\u4ee5\u6307\u5bfcAgent\u6267\u884c\u6a21\u5757\u6267\u884c\u591a\u6b65\u5de5\u5177\u8c03\u7528\u4efb\u52a1\u3002", "result": "\u5728\u771f\u5b9e\u4f01\u4e1a\u573a\u666f\u7684\u8bc4\u4f30\u4e2d\uff0cRoutine\u5c06GPT-4o\u7684\u6267\u884c\u51c6\u786e\u7387\u4ece41.1%\u63d0\u9ad8\u523096.3%\uff0cQwen3-14B\u4ece32.6%\u63d0\u9ad8\u523083.3%\u3002\u901a\u8fc7\u57fa\u4e8eRoutine\u7684\u84b8\u998f\u548c\u5fae\u8c03\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u7684\u51c6\u786e\u7387\u3002", "conclusion": "Routine\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u4f01\u4e1a\u73af\u5883\u4e2d\u591a\u6b65\u5de5\u5177\u8c03\u7528\u4efb\u52a1\u7684\u6267\u884c\u51c6\u786e\u6027\uff0c\u5e76\u5c06\u6a21\u578b\u5bf9\u65b0\u573a\u666f\u7684\u9002\u5e94\u6027\u63d0\u5347\u5230\u63a5\u8fd1GPT-4o\u7684\u6c34\u5e73\u3002"}}
{"id": "2507.14468", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14468", "abs": "https://arxiv.org/abs/2507.14468", "authors": ["Yitong Lin", "Jiaying He", "Jiahe Chen", "Xinnan Zhu", "Jianwei Zheng", "Tao Bo"], "title": "BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning", "comment": "Accepted by Bioinformatics on July 11th", "summary": "Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery\nand disease understanding, yet their completion and reasoning are challenging.\nKnowledge Embedding (KE) methods capture global semantics but struggle with\ndynamic structural integration, while Graph Neural Networks (GNNs) excel\nlocally but often lack semantic understanding. Even ensemble approaches,\nincluding those leveraging language models, often fail to achieve a deep,\nadaptive, and synergistic co-evolution between semantic comprehension and\nstructural learning. Addressing this critical gap in fostering continuous,\nreciprocal refinement between these two aspects in complex biomedical KGs is\nparamount.\n  Results: We introduce BioGraphFusion, a novel framework for deeply\nsynergistic semantic and structural learning. BioGraphFusion establishes a\nglobal semantic foundation via tensor decomposition, guiding an LSTM-driven\nmechanism to dynamically refine relation embeddings during graph propagation.\nThis fosters adaptive interplay between semantic understanding and structural\nlearning, further enhanced by query-guided subgraph construction and a hybrid\nscoring mechanism. Experiments across three key biomedical tasks demonstrate\nBioGraphFusion's superior performance over state-of-the-art KE, GNN, and\nensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)\nhighlights its ability to unveil biologically meaningful pathways.\n  Availability and Implementation: Source code and all training data are freely\navailable for download at https://github.com/Y-TARL/BioGraphFusion.\n  Contact: zjw@zjut.edu.cn, botao666666@126.com.\n  Supplementary information: Supplementary data are available at Bioinformatics\nonline.", "AI": {"tldr": "BioGraphFusion\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5f20\u91cf\u5206\u89e3\u548cLSTM\uff0c\u5b9e\u73b0\u4e86\u8bed\u4e49\u7406\u89e3\u548c\u7ed3\u6784\u5b66\u4e60\u7684\u6df1\u5ea6\u534f\u540c\uff0c\u5728\u751f\u7269\u533b\u5b66KGs\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86SOTA\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31(KGs)\u7684\u6784\u5efa\u548c\u63a8\u7406\u5b58\u5728\u6311\u6218\uff0c\u77e5\u8bc6\u5d4c\u5165(KE)\u65b9\u6cd5\u548c\u56fe\u795e\u7ecf\u7f51\u7edc(GNNs)\u5404\u6709\u4f18\u7f3a\u70b9\uff0c\u96c6\u6210\u65b9\u6cd5\u4e5f\u96be\u4ee5\u5b9e\u73b0\u8bed\u4e49\u7406\u89e3\u548c\u7ed3\u6784\u5b66\u4e60\u7684\u6df1\u5ea6\u3001\u81ea\u9002\u5e94\u548c\u534f\u540c\u8fdb\u5316\u3002", "method": "BioGraphFusion\u6846\u67b6\u7ed3\u5408\u5f20\u91cf\u5206\u89e3\u5efa\u7acb\u5168\u5c40\u8bed\u4e49\u57fa\u7840\uff0c\u5229\u7528LSTM\u52a8\u6001\u7ec6\u5316\u5173\u7cfb\u5d4c\u5165\uff0c\u901a\u8fc7\u67e5\u8be2\u5f15\u5bfc\u7684\u5b50\u56fe\u6784\u5efa\u548c\u6df7\u5408\u8bc4\u5206\u673a\u5236\u589e\u5f3a\u8bed\u4e49\u7406\u89e3\u548c\u7ed3\u6784\u5b66\u4e60\u7684\u9002\u5e94\u6027\u4ea4\u4e92\u3002", "result": "BioGraphFusion\u5728\u4e09\u4e2a\u751f\u7269\u533b\u5b66\u5173\u952e\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5e76\u5728CMM1\u6848\u4f8b\u7814\u7a76\u4e2d\u5c55\u73b0\u4e86\u5176\u4ef7\u503c\u3002", "conclusion": "BioGraphFusion\u6846\u67b6\u5728\u4e09\u4e2a\u751f\u7269\u533b\u5b66\u5173\u952e\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684KE\u3001GNN\u548c\u96c6\u6210\u6a21\u578b\uff0c\u5e76\u5728Cutaneous Malignant Melanoma 1 (CMM1)\u6848\u4f8b\u7814\u7a76\u4e2d\u5c55\u73b0\u4e86\u63ed\u793a\u751f\u7269\u5b66\u610f\u4e49\u901a\u8def\u7684\u80fd\u529b\u3002"}}
{"id": "2507.14513", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14513", "abs": "https://arxiv.org/abs/2507.14513", "authors": ["Hongyi Yang", "Yue Pan", "Jiayi Xu", "Kelsen Liu"], "title": "Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy", "comment": null, "summary": "Recent advances in large language models (LLMs) and autonomous agents have\nenabled systems capable of performing complex tasks across domains such as\nhuman-computer interaction, planning, and web navigation. However, many\nexisting frameworks struggle in real-world or resource-constrained environments\ndue to their reliance on cloud-based computation, limited robustness in dynamic\ncontexts, and lack of persistent autonomy and environmental awareness.\n  We present Amico, a modular, event-driven framework for building autonomous\nagents optimized for embedded systems. Written in Rust for safety and\nperformance, Amico supports reactive, persistent agents that operate\nefficiently across embedded platforms and browser environments via WebAssembly.\nIt provides clean abstractions for event handling, state management, behavior\nexecution, and integration with reasoning modules. Amico delivers a unified\ninfrastructure for constructing resilient, interactive agents suitable for\ndeployment in settings with limited compute and intermittent connectivity.", "AI": {"tldr": "Amico\u662f\u4e00\u4e2a\u7528Rust\u7f16\u5199\u7684\uff0c\u7528\u4e8e\u6784\u5efa\u9002\u7528\u4e8e\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u81ea\u4e3b\u4ee3\u7406\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5177\u6709\u9ad8\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8bb8\u591a\u6846\u67b6\u96be\u4ee5\u5728\u73b0\u5b9e\u4e16\u754c\u6216\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u8fd0\u884c\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u4e8e\u4e91\u8ba1\u7b97\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u6709\u9650\uff0c\u5e76\u4e14\u7f3a\u4e4f\u6301\u4e45\u81ea\u4e3b\u6027\u548c\u73af\u5883\u611f\u77e5\u80fd\u529b\u3002", "method": "Amico\u6846\u67b6\u662f\u7528Rust\u7f16\u5199\u7684\uff0c\u5177\u6709\u6a21\u5757\u5316\u3001\u4e8b\u4ef6\u9a71\u52a8\u7b49\u7279\u70b9\uff0c\u652f\u6301\u53cd\u5e94\u5f0f\u3001\u6301\u4e45\u6027\u4ee3\u7406\uff0c\u5e76\u80fd\u9ad8\u6548\u8fd0\u884c\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u548c\u6d4f\u89c8\u5668\u73af\u5883\u4e2d\u3002", "result": "Amico\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u7528\u4e8e\u6784\u5efa\u9002\u5e94\u8ba1\u7b97\u80fd\u529b\u6709\u9650\u548c\u8fde\u63a5\u6027\u95f4\u6b47\u6027\u73af\u5883\u7684\u5f39\u6027\u4ea4\u4e92\u5f0f\u4ee3\u7406\u3002", "conclusion": "Amico\u6846\u67b6\u662f\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u9002\u7528\u4e8e\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u81ea\u4e3b\u4ee3\u7406\u7684\u6a21\u5757\u5316\u3001\u4e8b\u4ef6\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u5b83\u652f\u6301\u53cd\u5e94\u5f0f\u3001\u6301\u4e45\u6027\u4ee3\u7406\uff0c\u5e76\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u548c\u6d4f\u89c8\u5668\u73af\u5883\u4e2d\u9ad8\u6548\u8fd0\u884c\u3002"}}
{"id": "2507.14520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14520", "abs": "https://arxiv.org/abs/2507.14520", "authors": ["Xinyi Chen", "Yifei Yuan", "Jiaang Li", "Serge Belongie", "Maarten de Rijke", "Anders S\u00f8gaard"], "title": "What if Othello-Playing Language Models Could See?", "comment": "ICML 2025 Assessing World Models Workshop", "summary": "Language models are often said to face a symbol grounding problem. While some\nargue that world understanding can emerge from text alone, others suggest\ngrounded learning is more efficient. We explore this through Othello, where the\nboard state defines a simplified, rule-based world. Building on prior work, we\nintroduce VISOTHELLO, a multi-modal model trained on move histories and board\nimages. Using next-move prediction, we compare it to mono-modal baselines and\ntest robustness to semantically irrelevant perturbations. We find that\nmulti-modal training improves both performance and the robustness of internal\nrepresentations. These results suggest that grounding language in visual input\nhelps models infer structured world representations.", "AI": {"tldr": "\u591a\u6a21\u6001\u6a21\u578bVISOTHELLO\u5728\u56fd\u9645\u8c61\u68cb\u6e38\u620fOthello\u4e2d\u53d6\u5f97\u4e86\u6bd4\u5355\u6a21\u6001\u6a21\u578b\u66f4\u597d\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u9a8c\u8bc1\u4e86\u89c6\u89c9\u63a5\u5730\u5bf9\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u7ed3\u6784\u5316\u4e16\u754c\u8868\u793a\u7684\u76ca\u5904\u3002", "motivation": "\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u7684\u7b26\u53f7\u63a5\u5730\u95ee\u9898\uff0c\u6bd4\u8f83\u4ec5\u57fa\u4e8e\u6587\u672c\u7684\u5b66\u4e60\u548c\u57fa\u4e8e\u591a\u6a21\u6001\u7684\u5b66\u4e60\u6548\u7387\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u6a21\u578bVISOTHELLO\uff0c\u5728\u68cb\u76d8\u56fe\u50cf\u548c\u8d70\u68cb\u5386\u53f2\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u4f7f\u7528\u4e0b\u4e00\u6b65\u9884\u6d4b\u6765\u8bc4\u4f30\u5176\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "result": "\u591a\u6a21\u6001\u8bad\u7ec3\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u548c\u5185\u90e8\u8868\u793a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u591a\u6a21\u6001\u8bad\u7ec3\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u548c\u5185\u90e8\u8868\u793a\u7684\u9c81\u68d2\u6027\uff0c\u8868\u660e\u5c06\u8bed\u8a00\u4e0e\u89c6\u89c9\u8f93\u5165\u7ed3\u5408\u6709\u52a9\u4e8e\u6a21\u578b\u63a8\u65ad\u7ed3\u6784\u5316\u7684\u4e16\u754c\u8868\u793a\u3002"}}
{"id": "2507.14552", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14552", "abs": "https://arxiv.org/abs/2507.14552", "authors": ["Anna Sofia Lippolis", "Mohammad Javad Saeedizade", "Robin Keskis\u00e4rkk\u00e4", "Aldo Gangemi", "Eva Blomqvist", "Andrea Giovanni Nuzzolese"], "title": "Large Language Models Assisting Ontology Evaluation", "comment": null, "summary": "Ontology evaluation through functional requirements, such as testing via\ncompetency question (CQ) verification, is a well-established yet costly,\nlabour-intensive, and error-prone endeavour, even for ontology engineering\nexperts. In this work, we introduce OE-Assist, a novel framework designed to\nassist ontology evaluation through automated and semi-automated CQ\nverification. By presenting and leveraging a dataset of 1,393 CQs paired with\ncorresponding ontologies and ontology stories, our contributions present, to\nour knowledge, the first systematic investigation into large language model\n(LLM)-assisted ontology evaluation, and include: (i) evaluating the\neffectiveness of a LLM-based approach for automatically performing CQ\nverification against a manually created gold standard, and (ii) developing and\nassessing an LLM-powered framework to assist CQ verification with Prot\\'eg\\'e,\nby providing suggestions. We found that automated LLM-based evaluation with\no1-preview and o3-mini perform at a similar level to the average user's\nperformance.", "AI": {"tldr": "OE-Assist\u6846\u67b6\u5229\u7528LLM\u8f85\u52a9\u672c\u4f53\u8bc4\u4f30\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4e14\u6548\u679c\u4e0e\u4eba\u5de5\u76f8\u5f53\u3002", "motivation": "\u76ee\u524d\u7684\u672c\u4f53\u8bc4\u4f30\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u8d39\u529b\u4e14\u5bb9\u6613\u51fa\u9519\u3002", "method": "\u5229\u75281393\u4e2aCQ\u53ca\u5176\u5bf9\u5e94\u7684\u672c\u4f53\u548c\u672c\u4f53\u6545\u4e8b\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86LLM\u81ea\u52a8\u6267\u884cCQ\u9a8c\u8bc1\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f00\u53d1\u548c\u8bc4\u4f30\u4e86\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u4ee5\u8f85\u52a9\u4f7f\u7528Prot&eacute;g&eacute;\u8fdb\u884cCQ\u9a8c\u8bc1\u3002", "result": "\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\uff08o1-preview\u548co3-mini\uff09\u4e0e\u4eba\u5de5\u8bc4\u4f30\u6548\u679c\u76f8\u5f53\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86OE-Assist\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u548c\u534a\u81ea\u52a8\u5730\u9a8c\u8bc1\u80fd\u529b\u95ee\u9898\uff08CQ\uff09\uff0c\u4ece\u800c\u8f85\u52a9\u672c\u4f53\u8bc4\u4f30\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u8bc4\u4f30\u4e0e\u4eba\u5de5\u8bc4\u4f30\u6548\u679c\u76f8\u5f53\u3002"}}
{"id": "2507.14593", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14593", "abs": "https://arxiv.org/abs/2507.14593", "authors": ["Omar Al-Desi"], "title": "Coordinate Heart System: A Geometric Framework for Emotion Representation", "comment": "26 pages", "summary": "This paper presents the Coordinate Heart System (CHS), a geometric framework\nfor emotion representation in artificial intelligence applications. We position\neight core emotions as coordinates on a unit circle, enabling mathematical\ncomputation of complex emotional states through coordinate mixing and vector\noperations. Our initial five-emotion model revealed significant coverage gaps\nin the emotion space, leading to the development of an eight-emotion system\nthat provides complete geometric coverage with mathematical guarantees. The\nframework converts natural language input to emotion coordinates and supports\nreal-time emotion interpolation through computational algorithms. The system\nintroduces a re-calibrated stability parameter S in [0,1], which dynamically\nintegrates emotional load, conflict resolution, and contextual drain factors.\nThis stability model leverages advanced Large Language Model interpretation of\ntextual cues and incorporates hybrid temporal tracking mechanisms to provide\nnuanced assessment of psychological well-being states. Our key contributions\ninclude: (i) mathematical proof demonstrating why five emotions are\ninsufficient for complete geometric coverage, (ii) an eight-coordinate system\nthat eliminates representational blind spots, (iii) novel algorithms for\nemotion mixing, conflict resolution, and distance calculation in emotion space,\nand (iv) a comprehensive computational framework for AI emotion recognition\nwith enhanced multi-dimensional stability modeling. Experimental validation\nthrough case studies demonstrates the system's capability to handle emotionally\nconflicted states, contextual distress factors, and complex psychological\nscenarios that traditional categorical emotion models cannot adequately\nrepresent. This work establishes a new mathematical foundation for emotion\nmodeling in artificial intelligence systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u516b\u7ef4\u60c5\u7eea\u5750\u6807\u7cfb\u7edf(CHS)\uff0c\u7528\u4e8e\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u60c5\u7eea\u5efa\u6a21\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u80fd\u5904\u7406\u590d\u6742\u60c5\u7eea\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u60c5\u7eea\u6a21\u578b\u5b58\u5728\u8868\u8fbe\u7a7a\u95f4\u4e0d\u8db3\u548c\u96be\u4ee5\u5904\u7406\u590d\u6742\u60c5\u7eea\u72b6\u6001\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u4f4d\u5706\u51e0\u4f55\u6846\u67b6\u7684\u516b\u7ef4\u60c5\u7eea\u5750\u6807\u7cfb\u7edf\uff0c\u5229\u7528\u5750\u6807\u6df7\u5408\u548c\u5411\u91cf\u8fd0\u7b97\u8ba1\u7b97\u590d\u6742\u60c5\u7eea\u72b6\u6001\uff0c\u5e76\u5f15\u5165\u7a33\u5b9a\u6027\u53c2\u6570S\u6765\u52a8\u6001\u6574\u5408\u60c5\u7eea\u8d1f\u8377\u3001\u51b2\u7a81\u89e3\u51b3\u548c\u60c5\u5883\u56e0\u7d20\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u516b\u7ef4\u60c5\u7eea\u5750\u6807\u7cfb\u7edf\uff0c\u80fd\u591f\u66f4\u7cbe\u786e\u5730\u8868\u8fbe\u548c\u8ba1\u7b97\u590d\u6742\u60c5\u7eea\u72b6\u6001\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u60c5\u7eea\u5efa\u6a21\u6570\u5b66\u6846\u67b6\u2014\u2014\u5750\u6807\u5fc3\u810f\u7cfb\u7edf\uff08CHS\uff09\uff0c\u7528\u4e8e\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u4e2d\u66f4\u7cbe\u786e\u7684\u60c5\u7eea\u8868\u8fbe\u548c\u8ba1\u7b97\u3002\u8be5\u7cfb\u7edf\u89e3\u51b3\u4e86\u4f20\u7edf\u5206\u7c7b\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u60c5\u7eea\u51b2\u7a81\u548c\u60c5\u5883\u56e0\u7d20\u3002"}}
{"id": "2507.14642", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14642", "abs": "https://arxiv.org/abs/2507.14642", "authors": ["Monoshiz Mahbub Khan", "Xioayin Xi", "Andrew Meneely", "Zhe Yu"], "title": "Efficient Story Point Estimation With Comparative Learning", "comment": null, "summary": "Story point estimation is an essential part of agile software development.\nStory points are unitless, project-specific effort estimates that help\ndevelopers plan their sprints. Traditionally, developers estimate story points\ncollaboratively using planning poker or other manual techniques. While the\ninitial calibrating of the estimates to each project is helpful, once a team\nhas converged on a set of precedents, story point estimation can become tedious\nand labor-intensive. Machine learning can reduce this burden, but only with\nenough context from the historical decisions made by the project team. That is,\nstate-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate\npredictions (within-project) when trained on data from the same project. The\ngoal of this work is to streamline story point estimation by evaluating a\ncomparative learning-based framework for calibrating project-specific story\npoint prediction models. Instead of assigning a specific story point value to\nevery backlog item, developers are presented with pairs of items, and indicate\nwhich item requires more effort. Using these comparative judgments, a machine\nlearning model is trained to predict the story point estimates. We empirically\nevaluated our technique using data with 23,313 manual estimates in 16 projects.\nThe model learned from comparative judgments can achieve on average 0.34\nSpearman's rank correlation coefficient between its predictions and the ground\ntruth story points. This is similar to, if not better than, the performance of\na regression model learned from the ground truth story points. Therefore, the\nproposed comparative learning approach is more efficient than state-of-the-art\nregression-based approaches according to the law of comparative judgments -\nproviding comparative judgments yields a lower cognitive burden on humans than\nproviding ratings or categorical labels.", "AI": {"tldr": "\u4f7f\u7528\u6bd4\u8f83\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u6545\u4e8b\u70b9\u4f30\u7b97\uff0c\u6548\u7387\u9ad8\uff0c\u6548\u679c\u597d\uff0c\u8ba4\u77e5\u8d1f\u62c5\u4f4e\u3002", "motivation": "\u76ee\u524d\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ea\u80fd\u5728\u76f8\u540c\u9879\u76ee\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u51c6\u786e\u9884\u6d4b\uff0c\u6545\u4e8b\u70b9\u4f30\u7b97\u8d39\u65f6\u8d39\u529b\uff0c\u672c\u6587\u65e8\u5728\u7b80\u5316\u6545\u4e8b\u70b9\u4f30\u7b97\u6d41\u7a0b\u3002", "method": "\u4f7f\u7528\u6bd4\u8f83\u5b66\u4e60\u6846\u67b6\uff0c\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6545\u4e8b\u70b9\u3002\u5f00\u53d1\u4eba\u5458\u6bd4\u8f83\u4e24\u4e2a\u5f85\u529e\u4e8b\u9879\u7684\u5de5\u4f5c\u91cf\uff0c\u6a21\u578b\u6839\u636e\u8fd9\u4e9b\u6bd4\u8f83\u5224\u65ad\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5e73\u5747Spearman\u79e9\u76f8\u5173\u7cfb\u6570\u4e3a0.34\uff0c\u4e0e\u76f4\u63a5\u5b66\u4e60\u57fa\u51c6\u6545\u4e8b\u70b9\u7684\u56de\u5f52\u6a21\u578b\u6027\u80fd\u76f8\u5f53\u751a\u81f3\u66f4\u597d\uff0c\u4e14\u66f4\u6709\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6bd4\u8f83\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6821\u51c6\u9879\u76ee\u7279\u5b9a\u7684\u6545\u4e8b\u70b9\u9884\u6d4b\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u6bd4\u8f83\u5224\u65ad\u5b66\u4e60\uff0c\u80fd\u591f\u8fbe\u5230\u4e0e\u57fa\u4e8e\u56de\u5f52\u6a21\u578b\u76f8\u8fd1\u751a\u81f3\u66f4\u597d\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u964d\u4f4e\u4e86\u4eba\u5de5\u6807\u6ce8\u7684\u8ba4\u77e5\u8d1f\u62c5\u3002"}}
{"id": "2507.14660", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.14660", "abs": "https://arxiv.org/abs/2507.14660", "authors": ["Qibing Ren", "Sitao Xie", "Longxuan Wei", "Zhenfei Yin", "Junchi Yan", "Lizhuang Ma", "Jing Shao"], "title": "When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems", "comment": "Code is available at https://github.com/renqibing/RogueAgent", "summary": "Recent large-scale events like election fraud and financial scams have shown\nhow harmful coordinated efforts by human groups can be. With the rise of\nautonomous AI systems, there is growing concern that AI-driven groups could\nalso cause similar harm. While most AI safety research focuses on individual AI\nsystems, the risks posed by multi-agent systems (MAS) in complex real-world\nsituations are still underexplored. In this paper, we introduce a\nproof-of-concept to simulate the risks of malicious MAS collusion, using a\nflexible framework that supports both centralized and decentralized\ncoordination structures. We apply this framework to two high-risk fields:\nmisinformation spread and e-commerce fraud. Our findings show that\ndecentralized systems are more effective at carrying out malicious actions than\ncentralized ones. The increased autonomy of decentralized systems allows them\nto adapt their strategies and cause more damage. Even when traditional\ninterventions, like content flagging, are applied, decentralized groups can\nadjust their tactics to avoid detection. We present key insights into how these\nmalicious groups operate and the need for better detection systems and\ncountermeasures. Code is available at https://github.com/renqibing/RogueAgent.", "AI": {"tldr": "AI\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6076\u610f\u5171\u8c0b\u98ce\u9669\u9ad8\uff0c\u5206\u6563\u5f0f\u7cfb\u7edf\u66f4\u5371\u9669\uff0c\u9700\u5f00\u53d1\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u548c\u5e94\u5bf9\u63aa\u65bd\u3002", "motivation": "\u5173\u6ce8AI\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u73b0\u5b9e\u573a\u666f\u4e2d\u9020\u6210\u7684\u6f5c\u5728\u5371\u5bb3\uff0c\u7279\u522b\u662f\u6076\u610f\u5171\u8c0b\u7684\u98ce\u9669\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u6846\u67b6\uff0c\u6a21\u62df\u6076\u610f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5171\u8c0b\u7684\u98ce\u9669\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\u548c\u7535\u5b50\u5546\u52a1\u6b3a\u8bc8\u4e24\u4e2a\u9ad8\u98ce\u9669\u9886\u57df\u3002", "result": "\u5206\u6563\u5f0f\u7cfb\u7edf\u6bd4\u96c6\u4e2d\u5f0f\u7cfb\u7edf\u66f4\u6709\u6548\u5730\u5b9e\u65bd\u6076\u610f\u884c\u4e3a\uff0c\u80fd\u591f\u9002\u5e94\u7b56\u7565\u5e76\u9020\u6210\u66f4\u5927\u635f\u5bb3\uff0c\u4f20\u7edf\u5e72\u9884\u63aa\u65bd\u5bf9\u5176\u6548\u679c\u6709\u9650\u3002", "conclusion": "\u5206\u6563\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6bd4\u96c6\u4e2d\u5f0f\u7cfb\u7edf\u66f4\u6709\u6548\u5730\u5b9e\u65bd\u6076\u610f\u884c\u4e3a\uff0c\u5373\u4f7f\u5728\u4f20\u7edf\u5e72\u9884\u63aa\u65bd\u4e0b\u4e5f\u80fd\u8c03\u6574\u7b56\u7565\u4ee5\u9003\u907f\u68c0\u6d4b\uff0c\u9700\u8981\u66f4\u597d\u7684\u68c0\u6d4b\u7cfb\u7edf\u548c\u5bf9\u7b56\u3002"}}
{"id": "2507.14705", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14705", "abs": "https://arxiv.org/abs/2507.14705", "authors": ["Sai Wang", "Senthilnathan Subramanian", "Mudit Sahni", "Praneeth Gone", "Lingjie Meng", "Xiaochen Wang", "Nicolas Ferradas Bertoli", "Tingxian Cheng", "Jun Xu"], "title": "Configurable multi-agent framework for scalable and realistic testing of llm-based agents", "comment": null, "summary": "Large-language-model (LLM) agents exhibit complex, context-sensitive\nbehaviour that quickly renders static benchmarks and ad-hoc manual testing\nobsolete.\n  We present Neo, a configurable, multi-agent framework that automates\nrealistic, multi-turn evaluation of LLM-based systems. Neo couples a Question\nGeneration Agent and an Evaluation Agent through a shared context-hub, allowing\ndomain prompts, scenario controls and dynamic feedback to be composed\nmodularly. Test inputs are sampled from a probabilistic state model spanning\ndialogue flow, user intent and emotional tone, enabling diverse, human-like\nconversations that adapt after every turn.\n  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i)\nuncovered edge-case failures across five attack categories with a 3.3% break\nrate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered\n10-12X higher throughput, generating 180 coherent test questions in around 45\nmins versus 16h of human effort. Beyond security probing, Neo's stochastic\npolicies balanced topic coverage and conversational depth, yielding broader\nbehavioural exploration than manually crafted scripts.\n  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent\ninterfaces, state controller and feedback loops are model-agnostic and\nextensible to richer factual-grounding and policy-compliance checks. We release\nthe framework to facilitate reproducible, high-fidelity testing of emerging\nagentic systems.", "AI": {"tldr": "Neo\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u3001\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\u8fdb\u884c\u903c\u771f\u7684\u591a\u8f6e\u8bc4\u4f30\uff0c\u5b83\u9ad8\u6548\u4e14\u6709\u6548\u5730\u53d1\u73b0\u4e86LLM\u7cfb\u7edf\u7684\u7f3a\u9677\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u667a\u80fd\u4f53\u8868\u73b0\u51fa\u590d\u6742\u3001\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u884c\u4e3a\uff0c\u8fd9\u4f7f\u5f97\u9759\u6001\u57fa\u51c6\u548c\u4e34\u65f6\u4eba\u5de5\u6d4b\u8bd5\u5f88\u5feb\u8fc7\u65f6\u3002", "method": "Neo\u662f\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5171\u4eab\u4e0a\u4e0b\u6587\u4e2d\u5fc3\u5c06\u95ee\u9898\u751f\u6210\u667a\u80fd\u4f53\u548c\u8bc4\u4f30\u667a\u80fd\u4f53\u8026\u5408\u5728\u4e00\u8d77\uff0c\u5141\u8bb8\u6a21\u5757\u5316\u5730\u7ec4\u5408\u9886\u57df\u63d0\u793a\u3001\u573a\u666f\u63a7\u5236\u548c\u52a8\u6001\u53cd\u9988\u3002\u6d4b\u8bd5\u8f93\u5165\u4ece\u8de8\u5bf9\u8bdd\u6d41\u7a0b\u3001\u7528\u6237\u610f\u56fe\u548c\u60c5\u611f\u57fa\u8c03\u7684\u6982\u7387\u72b6\u6001\u6a21\u578b\u4e2d\u91c7\u6837\uff0c\u4ece\u800c\u5b9e\u73b0\u591a\u6837\u5316\u3001\u4eba\u6027\u5316\u7684\u5bf9\u8bdd\uff0c\u5e76\u5728\u6bcf\u6b21\u8f6c\u5411\u540e\u8fdb\u884c\u8c03\u6574\u3002", "result": "\u5e94\u7528\u4e8e\u751f\u4ea7\u7ea7\u7684\u5356\u5bb6\u8d22\u52a1\u52a9\u7406\u804a\u5929\u673a\u5668\u4eba\uff0cNeo (i) \u53d1\u73b0\u4e86\u4e94\u4e2a\u653b\u51fb\u7c7b\u522b\u4e2d\u7684\u8fb9\u7f18\u60c5\u51b5\u6545\u969c\uff0c\u51763.3%\u7684\u6545\u969c\u7387\u63a5\u8fd1\u4e13\u5bb6\u4eba\u7c7b\u7ea2\u961f\u6210\u5458\u8fbe\u5230\u76845.8%\uff1b(ii) \u5b9e\u73b0\u4e8610-12\u500d\u66f4\u9ad8\u7684\u541e\u5410\u91cf\uff0c\u5728\u7ea645\u5206\u949f\u5185\u751f\u6210\u4e86180\u4e2a\u8fde\u8d2f\u7684\u6d4b\u8bd5\u95ee\u9898\uff0c\u800c\u4eba\u5de5\u9700\u898116\u5c0f\u65f6\u3002", "conclusion": "Neo\u6846\u67b6\u4e3a\u53ef\u6269\u5c55\u7684\u3001\u81ea\u6211\u8fdb\u5316\u7684LLM QA\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5176\u667a\u80fd\u4f53\u63a5\u53e3\u3001\u72b6\u6001\u63a7\u5236\u5668\u548c\u53cd\u9988\u5faa\u73af\u4e0e\u6a21\u578b\u65e0\u5173\uff0c\u53ef\u6269\u5c55\u5230\u66f4\u4e30\u5bcc\u7684\u5b9e\u9645\u57fa\u7840\u548c\u653f\u7b56\u5408\u89c4\u6027\u68c0\u67e5\u3002"}}
{"id": "2507.14719", "categories": ["cs.AI", "I.2.7; F.2.2"], "pdf": "https://arxiv.org/pdf/2507.14719", "abs": "https://arxiv.org/abs/2507.14719", "authors": ["Juan Manuel Contreras"], "title": "Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix", "comment": null, "summary": "As large language models (LLMs) become increasingly integrated into\nreal-world applications, scalable and rigorous safety evaluation is essential.\nThis paper introduces Aymara AI, a programmatic platform for generating and\nadministering customized, policy-grounded safety evaluations. Aymara AI\ntransforms natural-language safety policies into adversarial prompts and scores\nmodel responses using an AI-based rater validated against human judgments. We\ndemonstrate its capabilities through the Aymara LLM Risk and Responsibility\nMatrix, which evaluates 20 commercially available LLMs across 10 real-world\nsafety domains. Results reveal wide performance disparities, with mean safety\nscores ranging from 86.2% to 52.4%. While models performed well in\nwell-established safety domains such as Misinformation (mean = 95.7%), they\nconsistently failed in more complex or underspecified domains, notably Privacy\n& Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety\nscores differed significantly across both models and domains (p < .05). These\nfindings underscore the inconsistent and context-dependent nature of LLM safety\nand highlight the need for scalable, customizable tools like Aymara AI to\nsupport responsible AI development and oversight.", "AI": {"tldr": "Aymara AI\u5e73\u53f0\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u3001\u53ef\u5b9a\u5236\u7684LLM\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86LLM\u5b89\u5168\u6027\u7684\u4e0d\u4e00\u81f4\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u3002", "motivation": "LLM\u65e5\u76ca\u5e94\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\uff0c\u5bf9\u53ef\u6269\u5c55\u548c\u4e25\u8c28\u7684\u5b89\u5168\u8bc4\u4f30\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002", "method": "Aymara AI\u5e73\u53f0\u5c06\u81ea\u7136\u8bed\u8a00\u5b89\u5168\u7b56\u7565\u8f6c\u6362\u4e3a\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8eAI\u7684\u8bc4\u5206\u5668\u8bc4\u4f30\u6a21\u578b\u7684\u54cd\u5e94\u3002", "result": "\u5bf920\u4e2aLLM\u572810\u4e2a\u771f\u5b9e\u4e16\u754c\u5b89\u5168\u9886\u57df\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u5f88\u5927\uff0c\u5e73\u5747\u5b89\u5168\u5f97\u5206\u4ece86.2%\u523052.4%\u4e0d\u7b49\u3002\u5728\u4e00\u4e9b\u9886\u57df\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9690\u79c1\u548c\u6a21\u62df\u7b49\u590d\u6742\u9886\u57df\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u5b89\u5168\u8bc4\u4f30\u9700\u8981\u53ef\u6269\u5c55\u548c\u4e25\u8c28\u7684\u65b9\u6cd5\u3002Aymara AI\u5e73\u53f0\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u5b89\u5168\u7b56\u7565\u8f6c\u5316\u4e3a\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8eAI\u7684\u8bc4\u5206\u5668\u5bf9\u6a21\u578b\u7684\u56de\u5e94\u8fdb\u884c\u8bc4\u5206\uff0c\u5b9e\u73b0\u4e86\u5b9a\u5236\u5316\u7684\u5b89\u5168\u8bc4\u4f30\u3002"}}
{"id": "2507.14730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14730", "abs": "https://arxiv.org/abs/2507.14730", "authors": ["Yanjie Fu"], "title": "Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI", "comment": "4 pages; will continue to update to add more figures to describe the\n  vision;", "summary": "Generative AI, large language models, and agentic AI have emerged separately\nof urban planning. However, the convergence between AI and urban planning\npresents an interesting opportunity towards AI urban planners. This paper\nconceptualizes urban planning as a generative AI task, where AI synthesizes\nland-use configurations under geospatial, social, and human-centric\nconstraints. We survey how generative AI approaches, including VAEs, GANs,\ntransformers, and diffusion models, reshape urban design. We further identify\ncritical gaps: 1) limited research on integrating urban theory guidance, 2)\nlimited research of AI urban planning over multiple spatial resolutions or\nangularities, 3) limited research on augmenting urban design knowledge from\ndata, and 4) limited research on addressing real-world interactions. To address\nthese limitations, we outline future research directions in theory-guided\ngeneration, digital twins, and human-machine co-design, calling for a new\nsynthesis of generative intelligence and participatory urbanism.", "AI": {"tldr": "AI can revolutionize urban planning, but more research is needed to integrate urban theory, handle multiple spatial scales, augment design knowledge from data, and address real-world interactions.", "motivation": "The convergence of AI and urban planning presents an opportunity to develop AI urban planners.", "method": "This paper surveys generative AI approaches (VAEs, GANs, transformers, diffusion models) in urban design and identifies critical research gaps.", "result": "The paper identifies four key research gaps and proposes future research directions to address them, focusing on theory-guided generation, digital twins, and human-machine co-design.", "conclusion": "This paper conceptualizes urban planning as a generative AI task and identifies key research gaps in integrating AI into urban design, proposing future research directions in theory-guided generation, digital twins, and human-machine co-design."}}
{"id": "2507.14897", "categories": ["cs.AI", "I.2.5"], "pdf": "https://arxiv.org/pdf/2507.14897", "abs": "https://arxiv.org/abs/2507.14897", "authors": ["Renxi Wang", "Rifo Ahmad Genadi", "Bilal El Bouardi", "Yongxin Wang", "Fajri Koto", "Zhengzhong Liu", "Timothy Baldwin", "Haonan Li"], "title": "AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents", "comment": null, "summary": "Language model (LM) agents have gained significant attention for their\nability to autonomously complete tasks through interactions with environments,\ntools, and APIs. LM agents are primarily built with prompt engineering or\nsupervised finetuning. At the same time, reinforcement learning (RL) has been\nexplored to enhance LM's capabilities, such as reasoning and factuality.\nHowever, the combination of the LM agents and reinforcement learning (Agent-RL)\nremains underexplored and lacks systematic study. To this end, we built\nAgentFly, a scalable and extensible Agent-RL framework designed to empower LM\nagents with a variety of RL algorithms. Our framework supports multi-turn\ninteractions by adapting traditional RL methods with token-level masking. It\nfeatures a decorator-based interface for defining tools and reward functions,\nenabling seamless extension and ease of use. To support high-throughput\ntraining, we implement asynchronous execution of tool calls and reward\ncomputations, and design a centralized resource management system for scalable\nenvironment coordination. We also provide a suite of prebuilt tools and\nenvironments, demonstrating the framework's effectiveness through successful\nagent training across multiple tasks.", "AI": {"tldr": "AgentFly\u6846\u67b6\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u4e3b\u8981\u4f9d\u8d56\u63d0\u793a\u5de5\u7a0b\u6216\u76d1\u7763\u5fae\u8c03\uff0c\u7f3a\u4e4f\u5bf9\u5f3a\u5316\u5b66\u4e60\u7684\u7cfb\u7edf\u7814\u7a76\uff0cAgentFly\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u4e0d\u8db3\u3002", "method": "\u6784\u5efaAgentFly\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u652f\u6301\u591a\u79cd\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5e76\u91c7\u7528\u4ee4\u724c\u7ea7\u63a9\u7801\u6280\u672f\u9002\u5e94\u591a\u8f6e\u4ea4\u4e92\uff0c\u4f7f\u7528\u88c5\u9970\u5668\u63a5\u53e3\u65b9\u4fbf\u6269\u5c55\u5de5\u5177\u548c\u5956\u52b1\u51fd\u6570\uff0c\u5229\u7528\u5f02\u6b65\u6267\u884c\u548c\u96c6\u4e2d\u5f0f\u8d44\u6e90\u7ba1\u7406\u7cfb\u7edf\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u3002", "result": "AgentFly\u6846\u67b6\u6210\u529f\u8bad\u7ec3\u4e86\u591a\u4e2a\u4efb\u52a1\u7684\u667a\u80fd\u4f53\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "AgentFly\u6846\u67b6\u6210\u529f\u5730\u5c06\u5f3a\u5316\u5b66\u4e60\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u591a\u8f6e\u4ea4\u4e92\u548c\u9ad8\u6548\u8bad\u7ec3\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\u3002"}}
{"id": "2507.14899", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14899", "abs": "https://arxiv.org/abs/2507.14899", "authors": ["Jiale Liu", "Huan Wang", "Yue Zhang", "Xiaoyu Luo", "Jiaxiang Hu", "Zhiliang Liu", "Min Xie"], "title": "InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis", "comment": null, "summary": "Non-destructive testing (NDT), particularly X-ray inspection, is vital for\nindustrial quality assurance, yet existing deep-learning-based approaches often\nlack interactivity, interpretability, and the capacity for critical\nself-assessment, limiting their reliability and operator trust. To address\nthese shortcomings, this paper proposes InsightX Agent, a novel LMM-based\nagentic framework designed to deliver reliable, interpretable, and interactive\nX-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent\npositions a Large Multimodal Model (LMM) as a central orchestrator,\ncoordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the\nEvidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect\nregion proposals for multi-scale feature maps and sparsifies them through\nNon-Maximum Suppression (NMS), optimizing detection of small, dense targets in\nX-ray images while maintaining computational efficiency. The EGR tool guides\nthe LMM agent through a chain-of-thought-inspired review process, incorporating\ncontext assessment, individual defect analysis, false positive elimination,\nconfidence recalibration and quality assurance to validate and refine the\nSDMSD's initial proposals. By strategically employing and intelligently using\ntools, InsightX Agent moves beyond passive data processing to active reasoning,\nenhancing diagnostic reliability and providing interpretations that integrate\ndiverse information sources. Experimental evaluations on the GDXray+ dataset\ndemonstrate that InsightX Agent not only achieves a high object detection\nF1-score of 96.35% but also offers significantly improved interpretability and\ntrustworthiness in its analyses, highlighting the transformative potential of\nagentic LLM frameworks for industrial inspection tasks.", "AI": {"tldr": "\u65b0\u578b\u667a\u80fd\u4ee3\u7406\u6846\u67b6InsightX Agent\u5229\u7528\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u63d0\u9ad8X\u5c04\u7ebf\u65e0\u635f\u68c0\u6d4b\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5728GDXray+\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e8696.35%\u7684F1\u5206\u6570\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684X\u5c04\u7ebf\u65e0\u635f\u68c0\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u4ea4\u4e92\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u8be5\u6846\u67b6\u91c7\u7528\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b(LMM)\u4f5c\u4e3a\u6838\u5fc3\u534f\u8c03\u5668\uff0c\u534f\u8c03\u7a00\u758f\u53ef\u53d8\u5f62\u591a\u5c3a\u5ea6\u68c0\u6d4b\u5668(SDMSD)\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u53cd\u601d(EGR)\u5de5\u5177\u3002SDMSD\u8d1f\u8d23\u68c0\u6d4b\u7f3a\u9677\u533a\u57df\uff0cEGR\u5de5\u5177\u5f15\u5bfcLMM\u8fdb\u884c\u94fe\u5f0f\u601d\u8003\uff0c\u9a8c\u8bc1\u548c\u7ec6\u5316\u68c0\u6d4b\u7ed3\u679c\u3002", "result": "InsightX Agent\u5728GDXray+\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8696.35%\u7684F1\u5206\u6570\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "conclusion": "InsightX Agent\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b(LMM)\u7684\u667a\u80fd\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86X\u5c04\u7ebf\u65e0\u635f\u68c0\u6d4b\u7684\u53ef\u9760\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u4ea4\u4e92\u6027\uff0c\u5e76\u5728GDXray+\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8696.35%\u7684F1\u5206\u6570\u3002"}}
{"id": "2507.14906", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14906", "abs": "https://arxiv.org/abs/2507.14906", "authors": ["Xiao Yang", "Juxi Leitner", "Michael Burke"], "title": "Feedback-Induced Performance Decline in LLM-Based Decision-Making", "comment": null, "summary": "The ability of Large Language Models (LLMs) to extract context from natural\nlanguage problem descriptions naturally raises questions about their\nsuitability in autonomous decision-making settings. This paper studies the\nbehaviour of these models within a Markov Decision Process (MDPs). While\ntraditional reinforcement learning (RL) strategies commonly employed in this\nsetting rely on iterative exploration, LLMs, pre-trained on diverse datasets,\noffer the capability to leverage prior knowledge for faster adaptation. We\ninvestigate online structured prompting strategies in sequential decision\nmaking tasks, comparing the zero-shot performance of LLM-based approaches to\nthat of classical RL methods. Our findings reveal that although LLMs\ndemonstrate improved initial performance in simpler environments, they struggle\nwith planning and reasoning in complex scenarios without fine-tuning or\nadditional guidance. Our results show that feedback mechanisms, intended to\nimprove decision-making, often introduce confusion, leading to diminished\nperformance in intricate environments. These insights underscore the need for\nfurther exploration into hybrid strategies, fine-tuning, and advanced memory\nintegration to enhance LLM-based decision-making capabilities.", "AI": {"tldr": "LLM\u5728\u81ea\u4e3b\u51b3\u7b56\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u590d\u6742\u73af\u5883\u4e2d\u9700\u8981\u6539\u8fdb\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u4e3b\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\uff0c\u4ee5\u53ca\u5982\u4f55\u5229\u7528\u5176\u9884\u8bad\u7ec3\u77e5\u8bc6\u8fdb\u884c\u5feb\u901f\u9002\u5e94\u3002", "method": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(MDP)\u4e2d\u7684\u884c\u4e3a\uff0c\u6bd4\u8f83\u4e86\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u4e0e\u7ecf\u5178\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u96f6\u6837\u672c\u6027\u80fd\uff0c\u5e76\u63a2\u7a76\u4e86\u5728\u7ebf\u7ed3\u6784\u5316\u63d0\u793a\u7b56\u7565\u3002", "result": "LLM\u5728\u7b80\u5355\u73af\u5883\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u590d\u6742\u73af\u5883\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6df7\u5408\u7b56\u7565\u3001\u5fae\u8c03\u548c\u9ad8\u7ea7\u8bb0\u5fc6\u6574\u5408\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u7b80\u5355\u7684\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u521d\u59cb\u6027\u80fd\uff0c\u4f46\u5728\u590d\u6742\u573a\u666f\u4e2d\uff0c\u7f3a\u4e4f\u89c4\u5212\u548c\u63a8\u7406\u80fd\u529b\uff0c\u53cd\u9988\u673a\u5236\u751a\u81f3\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\u3002"}}
{"id": "2507.14909", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.14909", "abs": "https://arxiv.org/abs/2507.14909", "authors": ["Elio Grande"], "title": "The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities", "comment": null, "summary": "The Endless Tuning is a design method for a reliable deployment of artificial\nintelligence based on a double mirroring process, which pursues both the goals\nof avoiding human replacement and filling the so-called responsibility gap\n(Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the\nrelational approach urged therein, it was then actualized in a protocol,\nimplemented in three prototypical applications regarding decision-making\nprocesses (respectively: loan granting, pneumonia diagnosis, and art style\nrecognition) and tested with such as many domain experts. Step by step\nillustrating the protocol, giving insights concretely showing a different voice\n(Gilligan 1993) in the ethics of artificial intelligence, a philosophical\naccount of technical choices (e.g., a reversed and hermeneutic deployment of\nXAI algorithms) will be provided in the present study together with the results\nof the experiments, focusing on user experience rather than statistical\naccuracy. Even thoroughly employing deep learning models, full control was\nperceived by the interviewees in the decision-making setting, while it appeared\nthat a bridge can be built between accountability and liability in case of\ndamage.", "AI": {"tldr": "\u201c\u65e0\u5c3d\u8c03\u6574\u201d\u65b9\u6cd5\u5728\u4eba\u5de5\u667a\u80fd\u90e8\u7f72\u4e2d\u5b9e\u73b0\u4e86\u53ef\u9760\u6027\u3001\u53ef\u63a7\u6027\u548c\u95ee\u8d23\u5236\u3002", "motivation": "\u907f\u514d\u4eba\u5de5\u667a\u80fd\u66ff\u4ee3\u4eba\u7c7b\u5e76\u586b\u8865\u8d23\u4efb\u7f3a\u53e3", "method": "\u53cc\u91cd\u955c\u50cf\u8fc7\u7a0b\u3001\u539f\u578b\u5e94\u7528\u6d4b\u8bd5\u3001\u4f26\u7406\u54f2\u5b66\u5206\u6790", "result": "\u5728\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u7528\u6237\u611f\u53d7\u5230\u5145\u5206\u7684\u63a7\u5236\uff0c\u5e76\u5728\u635f\u5bb3\u53d1\u751f\u65f6\u5efa\u7acb\u4e86\u95ee\u8d23\u5236\u548c\u8d23\u4efb\u5236\u4e4b\u95f4\u7684\u6865\u6881\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u53cc\u91cd\u955c\u50cf\u8fc7\u7a0b\u7684\u201c\u65e0\u5c3d\u8c03\u6574\u201d\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5728\u907f\u514d\u4eba\u5de5\u66ff\u4ee3\u548c\u586b\u8865\u8d23\u4efb\u7f3a\u53e3\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u5e76\u5728\u4e09\u4e2a\u539f\u578b\u5e94\u7528\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u5173\u6ce8\u7528\u6237\u4f53\u9a8c\u800c\u975e\u7edf\u8ba1\u7cbe\u5ea6\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u4f26\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2507.14912", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14912", "abs": "https://arxiv.org/abs/2507.14912", "authors": ["Ruhul Amin Khalil", "Kashif Ahmad", "Hazrat Ali"], "title": "Redefining Elderly Care with Agentic AI: Challenges and Opportunities", "comment": null, "summary": "The global ageing population necessitates new and emerging strategies for\ncaring for older adults. In this article, we explore the potential for\ntransformation in elderly care through Agentic Artificial Intelligence (AI),\npowered by Large Language Models (LLMs). We discuss the proactive and\nautonomous decision-making facilitated by Agentic AI in elderly care.\nPersonalized tracking of health, cognitive care, and environmental management,\nall aimed at enhancing independence and high-level living for older adults,\nrepresents important areas of application. With a potential for significant\ntransformation of elderly care, Agentic AI also raises profound concerns about\ndata privacy and security, decision independence, and access. We share key\ninsights to emphasize the need for ethical safeguards, privacy protections, and\ntransparent decision-making. Our goal in this article is to provide a balanced\ndiscussion of both the potential and the challenges associated with Agentic AI,\nand to provide insights into its responsible use in elderly care, to bring\nAgentic AI into harmony with the requirements and vulnerabilities specific to\nthe elderly. Finally, we identify the priorities for the academic research\ncommunities, to achieve human-centered advancements and integration of Agentic\nAI in elderly care. To the best of our knowledge, this is no existing study\nthat reviews the role of Agentic AI in elderly care. Hence, we address the\nliterature gap by analyzing the unique capabilities, applications, and\nlimitations of LLM-based Agentic AI in elderly care. We also provide a\ncompanion interactive dashboard at https://hazratali.github.io/agenticai/.", "AI": {"tldr": "\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\u6709\u6f5c\u529b\u5f7b\u5e95\u6539\u53d8\u8001\u5e74\u62a4\u7406\uff0c\u4f46\u4e5f\u5e26\u6765\u9690\u79c1\u3001\u81ea\u4e3b\u6027\u548c\u83b7\u53d6\u65b9\u9762\u7684\u6311\u6218\uff0c\u9700\u8981\u8c28\u614e\u7684\u4f26\u7406\u8003\u91cf\u548c\u76d1\u7ba1\u3002", "motivation": "\u5168\u7403\u4eba\u53e3\u8001\u9f84\u5316\u5bf9\u8001\u5e74\u4eba\u7684\u62a4\u7406\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\u5728\u6539\u5584\u8001\u5e74\u4eba\u62a4\u7406\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u73b0\u6709\u6587\u732e\uff0c\u63a2\u8ba8\u4e86\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\u5728\u8001\u5e74\u62a4\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u4eea\u8868\u76d8\u3002", "result": "\u672c\u6587\u5bf9\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\u5728\u8001\u5e74\u62a4\u7406\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5206\u6790\uff0c\u6307\u51fa\u4e86\u5176\u72ec\u7279\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u5e94\u5bf9\u63aa\u65bd\u3002", "conclusion": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u4eba\u5de5\u667a\u80fd(Agentic AI)\u5728\u8001\u5e74\u62a4\u7406\u4e2d\u7684\u6f5c\u529b\u548c\u6311\u6218\uff0c\u5f3a\u8c03\u4e86\u4f26\u7406\u4fdd\u969c\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u900f\u660e\u51b3\u7b56\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u5b66\u672f\u7814\u7a76\u7684\u91cd\u70b9\u65b9\u5411\u3002"}}
{"id": "2507.14962", "categories": ["cs.AI", "cs.CC", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.14962", "abs": "https://arxiv.org/abs/2507.14962", "authors": ["Johannes Schmidt", "Mohamed Maizia", "Victor Lagerkvist", "Johannes K. Fichte"], "title": "Complexity of Faceted Explanations in Propositional Abduction", "comment": "This is the author's self-archived copy including detailed proofs. To\n  appear in Theory and Practice of Logic Programming (TPLP), Proceedings of the\n  41st International Conference on Logic Programming (ICLP 2025)", "summary": "Abductive reasoning is a popular non-monotonic paradigm that aims to explain\nobserved symptoms and manifestations. It has many applications, such as\ndiagnosis and planning in artificial intelligence and database updates. In\npropositional abduction, we focus on specifying knowledge by a propositional\nformula. The computational complexity of tasks in propositional abduction has\nbeen systematically characterized - even with detailed classifications for\nBoolean fragments. Unsurprisingly, the most insightful reasoning problems\n(counting and enumeration) are computationally highly challenging. Therefore,\nwe consider reasoning between decisions and counting, allowing us to understand\nexplanations better while maintaining favorable complexity. We introduce facets\nto propositional abductions, which are literals that occur in some explanation\n(relevant) but not all explanations (dispensable). Reasoning with facets\nprovides a more fine-grained understanding of variability in explanations\n(heterogeneous). In addition, we consider the distance between two\nexplanations, enabling a better understanding of heterogeneity/homogeneity. We\ncomprehensively analyze facets of propositional abduction in various settings,\nincluding an almost complete characterization in Post's framework.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u547d\u9898\u6eaf\u56e0\u63a8\u7406\u4e2d\u89e3\u91ca\u7684\u53d8\u5f02\u6027\uff0c\u901a\u8fc7\u5f15\u5165\u201c\u65b9\u9762\u201d\u7684\u6982\u5ff5\uff0c\u5bf9\u89e3\u91ca\u7684\u5f02\u8d28\u6027\u8fdb\u884c\u66f4\u7ec6\u81f4\u7684\u5206\u6790\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u6eaf\u56e0\u63a8\u7406\u4e2d\u7684\u89e3\u91ca\uff0c\u672c\u6587\u8003\u8651\u4e86\u51b3\u7b56\u548c\u8ba1\u6570\u4e4b\u95f4\u7684\u63a8\u7406\uff0c\u4ee5\u53ca\u89e3\u91ca\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u547d\u9898\u6eaf\u56e0\u63a8\u7406\u4e2d\u7684\u65b9\u9762\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u7684\u65b9\u9762\u3002", "result": "\u672c\u6587\u5bf9\u547d\u9898\u6eaf\u56e0\u63a8\u7406\u7684\u5404\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5206\u6790\uff0c\u5305\u62ec\u5728Post\u6846\u67b6\u4e2d\u51e0\u4e4e\u5b8c\u6574\u7684\u523b\u753b\u3002", "conclusion": "\u672c\u6587\u5bf9\u547d\u9898\u6eaf\u56e0\u63a8\u7406\u4e2d\u7684\u65b9\u9762\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\uff0c\u5e76\u5728Post\u6846\u67b6\u4e2d\u8fdb\u884c\u4e86\u51e0\u4e4e\u5b8c\u6574\u7684\u523b\u753b\u3002"}}
{"id": "2507.14987", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14987", "abs": "https://arxiv.org/abs/2507.14987", "authors": ["Yi Zhang", "An Zhang", "XiuYu Zhang", "Leheng Sheng", "Yuxin Chen", "Zhenkai Liang", "Xiang Wang"], "title": "AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning", "comment": null, "summary": "Large language models (LLMs), despite possessing latent safety understanding\nfrom their vast pretraining data, remain vulnerable to generating harmful\ncontent and exhibit issues such as over-refusal and utility degradation after\nsafety alignment. Current safety alignment methods often result in superficial\nrefusal shortcuts or rely on intensive supervision for reasoning-based\napproaches, failing to fully leverage the model's intrinsic safety\nself-awareness. We propose \\textbf{AlphaAlign}, a simple yet effective pure\nreinforcement learning (RL) framework with verifiable safety reward designed to\nincentivize this latent safety awareness through proactive safety reasoning.}\nAlphaAlign employs a dual-reward system: a verifiable safety reward encourages\ncorrectly formatted and explicitly justified refusals for harmful queries while\npenalizing over-refusals, and a normalized helpfulness reward guides\nhigh-quality responses to benign inputs. This allows the model to develop\nproactive safety reasoning capabilities without depending on supervised\nsafety-specific reasoning data. AlphaAlign demonstrates three key advantages:\n(1) Simplicity and efficiency, requiring only binary prompt safety labels and\nminimal RL steps for substantial improvements. (2) Breaking the safety-utility\ntrade-off, by enhancing refusal of harmful content and reducing over-refusals,\nwhile simultaneously maintaining or even improving general task performance and\nrobustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety\nreasoning that generates explicit safety rationales rather than relying on\nshallow refusal patterns.", "AI": {"tldr": "AlphaAlign \u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u53cc\u91cd\u5956\u52b1\u7cfb\u7edf\uff0c\u5728\u4e0d\u4f9d\u8d56\u76d1\u7763\u5b89\u5168\u63a8\u7406\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u6548\u7528\u3002", "motivation": "\u73b0\u6709\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u901a\u5e38\u5bfc\u81f4\u80a4\u6d45\u7684\u62d2\u7edd\u6377\u5f84\u6216\u4f9d\u8d56\u4e8e\u5bc6\u96c6\u7684\u76d1\u7763\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6a21\u578b\u5185\u5728\u7684\u5b89\u5168\u81ea\u6211\u610f\u8bc6\u3002", "method": "\u8be5\u65b9\u6cd5\u4f7f\u7528\u53cc\u91cd\u5956\u52b1\u7cfb\u7edf\uff1a\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u5956\u52b1\u9f13\u52b1\u5bf9\u6709\u5bb3\u67e5\u8be2\u8fdb\u884c\u6b63\u786e\u683c\u5f0f\u5316\u548c\u660e\u786e\u7406\u7531\u7684\u62d2\u7edd\uff0c\u540c\u65f6\u60e9\u7f5a\u8fc7\u5ea6\u62d2\u7edd\uff1b\u5f52\u4e00\u5316\u6548\u7528\u5956\u52b1\u5219\u6307\u5bfc\u5bf9\u826f\u6027\u8f93\u5165\u7684\u9ad8\u8d28\u91cf\u54cd\u5e94\u3002", "result": "AlphaAlign \u5728\u7b80\u5355\u6027\u548c\u6548\u7387\u3001\u6253\u7834\u5b89\u5168\u6027\u548c\u6548\u7528\u4e4b\u95f4\u7684\u6743\u8861\u4ee5\u53ca\u6df1\u5ea6\u5bf9\u9f50\u4e09\u4e2a\u65b9\u9762\u5c55\u73b0\u51fa\u4f18\u52bf\uff0c\u6709\u6548\u5730\u63d0\u9ad8\u4e86LLM\u7684\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "AlphaAlign \u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u7eaf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u5956\u52b1\u6765\u6fc0\u52b1\u6a21\u578b\u4e3b\u52a8\u8fdb\u884c\u5b89\u5168\u63a8\u7406\uff0c\u4ece\u800c\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u5b89\u5168\u95ee\u9898\uff0c\u5e76\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u6548\u7528\u7684\u540c\u65f6\u589e\u5f3a\u5b89\u5168\u6027\u3002"}}
{"id": "2507.15013", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15013", "abs": "https://arxiv.org/abs/2507.15013", "authors": ["Xiaoyu Li", "Jin Wu", "Shaoyang Guo", "Haoran Shi", "Chanjin Zheng"], "title": "A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing", "comment": "15pages, 7 figures", "summary": "In the smart era, psychometric tests are becoming increasingly important for\npersonnel selection, career development, and mental health assessment.\nForced-choice tests are common in personality assessments because they require\nparticipants to select from closely related options, lowering the risk of\nresponse distortion. This study presents a deep learning-based Forced-Choice\nNeural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of\ntraditional models and is applicable to the three most common item block types\nfound in forced-choice tests. To account for the unidimensionality of items in\nforced-choice tests, we create interpretable participant and item parameters.\nWe model the interactions between participant and item features using\nmultilayer neural networks after mining them using nonlinear mapping. In\naddition, we use the monotonicity assumption to improve the interpretability of\nthe diagnostic results. The FCNCD's effectiveness is validated by experiments\non real-world and simulated datasets that show its accuracy, interpretability,\nand robustness.", "AI": {"tldr": "\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5f3a\u5236\u9009\u62e9\u795e\u7ecf\u8ba4\u77e5\u8bca\u65ad\u6a21\u578bFCNCD\u63d0\u9ad8\u4e86\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u4e09\u79cd\u5e38\u89c1\u7684\u9898\u578b\u3002", "motivation": "\u667a\u80fd\u65f6\u4ee3\u5bf9\u5fc3\u7406\u6d4b\u91cf\u6d4b\u8bd5\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u800c\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5\u7531\u4e8e\u5176\u964d\u4f4e\u4e86\u53cd\u5e94\u504f\u5dee\u7684\u98ce\u9669\uff0c\u5728\u4eba\u683c\u8bc4\u4f30\u4e2d\u5f88\u5e38\u89c1\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5\u6a21\u578b\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u66f4\u51c6\u786e\u3001\u66f4\u53ef\u89e3\u91ca\u7684\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5\u6a21\u578b\u3002", "method": "\u8be5\u7814\u7a76\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\uff0c\u6765\u5efa\u6a21\u53c2\u4e0e\u8005\u548c\u9879\u76ee\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u3002\u5b83\u8fd8\u4f7f\u7528\u4e86\u5355\u8c03\u6027\u5047\u8bbe\u6765\u63d0\u9ad8\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFCNCD\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u548c\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u90fd\u8868\u73b0\u51fa\u4e86\u826f\u597d\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5f3a\u5236\u9009\u62e9\u795e\u7ecf\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\uff08FCNCD\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u9002\u7528\u4e8e\u5f3a\u5236\u9009\u62e9\u6d4b\u8bd5\u4e2d\u6700\u5e38\u89c1\u7684\u7684\u4e09\u79cd\u9898\u578b\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u6316\u6398\u548c\u4f7f\u7528\u975e\u7ebf\u6027\u6620\u5c04\u6765\u5efa\u6a21\u53c2\u4e0e\u8005\u548c\u9879\u76ee\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u5e76\u4f7f\u7528\u5355\u8c03\u6027\u5047\u8bbe\u6765\u63d0\u9ad8\u8bca\u65ad\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFCNCD\u5728\u771f\u5b9e\u6570\u636e\u96c6\u548c\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u90fd\u5177\u6709\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.15042", "categories": ["cs.AI", "cs.IR", "I.2.7; H.3.3; K.6.5"], "pdf": "https://arxiv.org/pdf/2507.15042", "abs": "https://arxiv.org/abs/2507.15042", "authors": ["Jerry Wang", "Fang Yu"], "title": "DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection", "comment": "Accepted by KDD Workshop on Prompt Optimization 2025", "summary": "Adversarial prompt attacks can significantly alter the reliability of\nRetrieval-Augmented Generation (RAG) systems by re-ranking them to produce\nincorrect outputs. In this paper, we present a novel method that applies\nDifferential Evolution (DE) to optimize adversarial prompt suffixes for\nRAG-based question answering. Our approach is gradient-free, treating the RAG\npipeline as a black box and evolving a population of candidate suffixes to\nmaximize the retrieval rank of a targeted incorrect document to be closer to\nreal world scenarios. We conducted experiments on the BEIR QA datasets to\nevaluate attack success at certain retrieval rank thresholds under multiple\nretrieving applications. Our results demonstrate that DE-based prompt\noptimization attains competitive (and in some cases higher) success rates\ncompared to GGPP to dense retrievers and PRADA to sparse retrievers, while\nusing only a small number of tokens (<=5 tokens) in the adversarial suffix.\nFurthermore, we introduce a readability-aware suffix construction strategy,\nvalidated by a statistically significant reduction in MLM negative\nlog-likelihood with Welch's t-test. Through evaluations with a BERT-based\nadversarial suffix detector, we show that DE-generated suffixes evade\ndetection, yielding near-chance detection accuracy.", "AI": {"tldr": "\u5229\u7528\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u751f\u6210\u66f4\u6709\u6548\u3001\u66f4\u96be\u4ee5\u68c0\u6d4b\u7684\u5bf9\u6297\u6027\u63d0\u793a\u540e\u7f00\uff0c\u4ee5\u653b\u51fbRAG\u7cfb\u7edf\u3002", "motivation": "\u5bf9\u6297\u6027\u63d0\u793a\u653b\u51fb\u4f1a\u663e\u8457\u964d\u4f4eRAG\u7cfb\u7edf\u7684\u53ef\u9760\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u3001\u66f4\u4e0d\u6613\u88ab\u68c0\u6d4b\u5230\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5(DE)\u4f18\u5316\u5bf9\u6297\u6027\u63d0\u793a\u540e\u7f00\uff0c\u5c06RAG\u7cfb\u7edf\u89c6\u4e3a\u9ed1\u76d2\u6a21\u578b\uff0c\u65e0\u9700\u68af\u5ea6\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8eDE\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u5728\u591a\u4e2a\u68c0\u7d22\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u751a\u81f3\u66f4\u9ad8\u7684\u6210\u529f\u7387\uff0c\u751f\u6210\u7684\u5bf9\u6297\u6027\u540e\u7f00\u957f\u5ea6\u8f83\u77ed(<=5\u4e2atoken)\u4e14\u96be\u4ee5\u88ab\u68c0\u6d4b\u5230\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5(DE)\u4f18\u5316\u5bf9\u6297\u6027\u63d0\u793a\u540e\u7f00\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u9488\u5bf9\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u7684\u5bf9\u6297\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u5728BEIR QA\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u68c0\u7d22\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u751a\u81f3\u66f4\u9ad8\u7684\u6210\u529f\u7387\uff0c\u5e76\u4e14\u751f\u6210\u7684\u5bf9\u6297\u6027\u540e\u7f00\u957f\u5ea6\u8f83\u77ed\u4e14\u96be\u4ee5\u88ab\u68c0\u6d4b\u5230\u3002"}}
{"id": "2507.15106", "categories": ["cs.AI", "cs.RO", "F.2.2"], "pdf": "https://arxiv.org/pdf/2507.15106", "abs": "https://arxiv.org/abs/2507.15106", "authors": ["Xia Xu", "Jochen Triesch"], "title": "From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward", "comment": "13 pages, 5 figures", "summary": "While human infants robustly discover their own causal efficacy, standard\nreinforcement learning agents remain brittle, as their reliance on\ncorrelation-based rewards fails in noisy, ecologically valid scenarios. To\naddress this, we introduce the Causal Action Influence Score (CAIS), a novel\nintrinsic reward rooted in causal inference. CAIS quantifies an action's\ninfluence by measuring the 1-Wasserstein distance between the learned\ndistribution of sensory outcomes conditional on that action, $p(h|a)$, and the\nbaseline outcome distribution, $p(h)$. This divergence provides a robust reward\nthat isolates the agent's causal impact from confounding environmental noise.\nWe test our approach in a simulated infant-mobile environment where\ncorrelation-based perceptual rewards fail completely when the mobile is\nsubjected to external forces. In stark contrast, CAIS enables the agent to\nfilter this noise, identify its influence, and learn the correct policy.\nFurthermore, the high-quality predictive model learned for CAIS allows our\nagent, when augmented with a surprise signal, to successfully reproduce the\n\"extinction burst\" phenomenon. We conclude that explicitly inferring causality\nis a crucial mechanism for developing a robust sense of agency, offering a\npsychologically plausible framework for more adaptive autonomous systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u5185\u5728\u5956\u52b1\u673a\u5236CAIS\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u566a\u58f0\u73af\u5883\u4e2d\u5b66\u4e60\u6b63\u786e\u7684\u7b56\u7565\uff0c\u5e76\u6210\u529f\u590d\u5236\u201c\u6d88\u9000\u7206\u53d1\u201d\u73b0\u8c61\uff0c\u8bc1\u660e\u4e86\u56e0\u679c\u63a8\u7406\u5bf9\u53d1\u5c55\u7a33\u5065\u81ea\u4e3b\u611f\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u89e3\u51b3\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u5608\u6742\u7684\u3001\u751f\u6001\u6709\u6548\u7684\u573a\u666f\u4e2d\u6613\u53d7\u7834\u574f\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u5b83\u4eec\u5bf9\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u5956\u52b1\u7684\u4f9d\u8d56\u3002", "method": "\u5f15\u5165\u56e0\u679c\u884c\u52a8\u5f71\u54cd\u8bc4\u5206\uff08CAIS\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u65b0\u578b\u5185\u5728\u5956\u52b1\u3002CAIS \u901a\u8fc7\u8861\u91cf\u884c\u52a8\u7684\u6761\u4ef6\u611f\u89c9\u7ed3\u679c\u7684\u5b66\u4e60\u5206\u5e03\u4e0e\u57fa\u7ebf\u7ed3\u679c\u5206\u5e03\u4e4b\u95f4\u7684 1-Wasserstein \u8ddd\u79bb\u6765\u91cf\u5316\u884c\u52a8\u7684\u5f71\u54cd\u3002", "result": "\u5728\u6a21\u62df\u5a74\u513f\u79fb\u52a8\u73af\u5883\u4e2d\uff0c\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u611f\u77e5\u5956\u52b1\u5b8c\u5168\u5931\u8d25\uff0c\u800c CAIS \u80fd\u591f\u4f7f\u667a\u80fd\u4f53\u8fc7\u6ee4\u566a\u58f0\uff0c\u8bc6\u522b\u5176\u5f71\u54cd\uff0c\u5e76\u5b66\u4e60\u6b63\u786e\u7684\u7b56\u7565\u3002\u6b64\u5916\uff0c\u4e3a CAIS \u5b66\u4e60\u5230\u7684\u9ad8\u8d28\u91cf\u9884\u6d4b\u6a21\u578b\u5141\u8bb8\u6211\u4eec\u7684\u667a\u80fd\u4f53\u5728\u589e\u5f3a\u60ca\u559c\u4fe1\u53f7\u540e\u6210\u529f\u590d\u5236\u201c\u6d88\u9000\u7206\u53d1\u201d\u73b0\u8c61\u3002", "conclusion": "\u660e\u786e\u63a8\u65ad\u56e0\u679c\u5173\u7cfb\u662f\u53d1\u5c55\u7a33\u5065\u7684\u81ea\u4e3b\u611f\u7684\u91cd\u8981\u673a\u5236\uff0c\u4e3a\u66f4\u5177\u9002\u5e94\u6027\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5fc3\u7406\u5b66\u4e0a\u5408\u7406\u7684\u6846\u67b6\u3002"}}
{"id": "2507.15120", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.15120", "abs": "https://arxiv.org/abs/2507.15120", "authors": ["Stefan Borgwardt", "Duy Nhu", "Gabriele R\u00f6ger"], "title": "Automated planning with ontologies under coherence update semantics", "comment": null, "summary": "Standard automated planning employs first-order formulas under closed-world\nsemantics to achieve a goal with a given set of actions from an initial state.\nWe follow a line of research that aims to incorporate background knowledge into\nautomated planning problems, for example, by means of ontologies, which are\nusually interpreted under open-world semantics. We present a new approach for\nplanning with DL-Lite ontologies that combines the advantages of ontology-based\naction conditions provided by explicit-input knowledge and action bases (eKABs)\nand ontology-aware action effects under the coherence update semantics. We show\nthat the complexity of the resulting formalism is not higher than that of\nprevious approaches and provide an implementation via a polynomial compilation\ninto classical planning. An evaluation of existing and new benchmarks examines\nthe performance of a planning system on different variants of our compilation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eDL-Lite\u672c\u4f53\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u7ed3\u5408eKABs\u548c\u76f8\u5e72\u66f4\u65b0\u8bed\u4e49\uff0c\u901a\u8fc7\u591a\u9879\u5f0f\u7f16\u8bd1\u5230\u7ecf\u5178\u89c4\u5212\uff0c\u590d\u6742\u5ea6\u4e0d\u9ad8\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5c06\u80cc\u666f\u77e5\u8bc6\uff08\u672c\u4f53\uff09\u878d\u5165\u81ea\u52a8\u5316\u89c4\u5212\u95ee\u9898\uff0c\u4ee5\u89e3\u51b3\u5c01\u95ed\u4e16\u754c\u8bed\u4e49\u7684\u5c40\u9650\u6027\u3002", "method": "\u7ed3\u5408eKABs\u548c\u672c\u4f53\u611f\u77e5\u884c\u52a8\u6548\u679c\u4e0b\u7684\u76f8\u5e72\u66f4\u65b0\u8bed\u4e49\uff0c\u8fdb\u884c\u591a\u9879\u5f0f\u7f16\u8bd1\u5230\u7ecf\u5178\u89c4\u5212\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u590d\u6742\u5ea6\u4e0d\u9ad8\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u73b0\u6709\u548c\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408eKABs\u548c\u76f8\u5e72\u66f4\u65b0\u8bed\u4e49\u7684\u672c\u4f53\u611f\u77e5\u89c4\u5212\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u591a\u9879\u5f0f\u7f16\u8bd1\u5230\u7ecf\u5178\u89c4\u5212\u4e2d\u5b9e\u73b0\uff0c\u590d\u6742\u5ea6\u4e0d\u9ad8\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
