<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding](https://arxiv.org/abs/2508.21204)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 该论文研究了架构归纳偏置如何影响大型语言模型(LLM)在指令式对话中的认知行为，并提出了一种符号脚手架机制和短期记忆模式，以促进苏格拉底式教学中的自适应、结构化推理。


<details>
  <summary>Details</summary>
Motivation: 研究架构归纳偏置对大型语言模型在指令式对话中认知行为的影响。

Method: 引入符号脚手架机制和短期记忆模式，并通过控制消融实验评估模型输出。

Result: 完整系统持续优于基线变体；移除记忆或符号结构会降低关键认知行为，如抽象、自适应探测和概念连续性。

Conclusion: 架构脚手架可以可靠地塑造LLM中新兴的教学策略。

Abstract: We study how architectural inductive biases influence the cognitive behavior
of large language models (LLMs) in instructional dialogue. We introduce a
symbolic scaffolding mechanism paired with a short-term memory schema designed
to promote adaptive, structured reasoning in Socratic tutoring. Using
controlled ablation across five system variants, we evaluate model outputs via
expert-designed rubrics covering scaffolding, responsiveness, symbolic
reasoning, and conversational memory. We present preliminary results using an
LLM-based evaluation framework aligned to a cognitively grounded rubric. This
enables scalable, systematic comparisons across architectural variants in
early-stage experimentation. The preliminary results show that our full system
consistently outperforms baseline variants. Analysis reveals that removing
memory or symbolic structure degrades key cognitive behaviors, including
abstraction, adaptive probing, and conceptual continuity. These findings
support a processing-level account in which architectural scaffolds can
reliably shape emergent instructional strategies in LLMs.

</details>


### [2] [Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](https://arxiv.org/abs/2508.21238)
*Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman*

Main category: cs.AI

TL;DR: 本论文评估了两种GraphRAG系统在阿尔茨海默病领域的可靠性和可追溯性，并构建了一个易于使用的界面供研究人员测试标准RAG和GraphRAG的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM聊天机器人存在幻觉、领域知识有限和缺乏可解释性等问题，GraphRAG通过整合领域特定上下文信息提高了可靠性，但其在阿尔茨海默病等专业领域的研究有限。

Method: 构建阿尔茨海默病知识库（50篇论文，70个专家问题），使用GPT-4o作为LLM，比较GraphRAG和标准GPT-4o的回答质量，并评估多种RAG和GraphRAG系统的可追溯性。

Result: 评估了两种GraphRAG系统的质量和可追溯性，并提供了一个包含阿尔茨海默病数据库的易用型界面。

Conclusion: GraphRAG在处理需要专业知识的领域（如阿尔茨海默病）方面具有潜力，但仍需进一步研究以提高其可靠性和可解释性。

Abstract: In the past two years, large language model (LLM)-based chatbots, such as
ChatGPT, have revolutionized various domains by enabling diverse task
completion and question-answering capabilities. However, their application in
scientific research remains constrained by challenges such as hallucinations,
limited domain-specific knowledge, and lack of explainability or traceability
for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has
emerged as a promising approach to improving chatbot reliability by integrating
domain-specific contextual information before response generation, addressing
some limitations of standard LLMs. Despite its potential, there are only
limited studies that evaluate GraphRAG on specific domains that require
intensive knowledge, like Alzheimer's disease or other biomedical domains. In
this paper, we assess the quality and traceability of two popular GraphRAG
systems. We compile a database of 50 papers and 70 expert questions related to
Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as
the LLM for answering queries. We then compare the quality of responses
generated by GraphRAG with those from a standard GPT-4o model. Additionally, we
discuss and evaluate the traceability of several Retrieval-Augmented Generation
(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a
pre-built Alzheimer's disease database for researchers to test the performance
of both standard RAG and GraphRAG.

</details>


### [3] [MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems](https://arxiv.org/abs/2508.21307)
*Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala*

Main category: cs.AI

TL;DR: MultiFluxAI平台整合产品工程中大量异构数据源，利用生成式AI、向量化和自主编排技术，动态响应复杂用户查询，提升用户参与度。


<details>
  <summary>Details</summary>
Motivation: 解决产品工程中数据管理和整合难题，增强用户参与度。

Method: 利用生成式AI、向量化和自主编排等AI技术。

Result: 提供动态、上下文感知的复杂用户查询响应。

Conclusion: MultiFluxAI平台有效整合数据，提升用户体验和参与度。

Abstract: MultiFluxAI is an innovative AI platform developed to address the challenges
of managing and integrating vast, disparate data sources in product engineering
across application domains. It addresses both current and new service related
queries that enhance user engagement in the digital ecosystem. This platform
leverages advanced AI techniques, such as Generative AI, vectorization, and
agentic orchestration to provide dynamic and context-aware responses to complex
user queries.

</details>


### [4] [Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation](https://arxiv.org/abs/2508.21320)
*Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao*

Main category: cs.AI

TL;DR: LINKO框架利用大型语言模型，整合多个医学本体图，进行双轴知识传播（本体内和本体间），提升医学概念表示学习，实验结果表明其优于现有基线，尤其在数据有限和罕见病预测场景下表现更佳。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注单一或孤立的多本体知识整合，忽略了本体间的交叉连接，限制了概念表示学习。

Method: 提出LINKO框架，利用LLM增强本体概念嵌入初始化，并进行本体内垂直和本体间水平双轴知识传播。

Result: 在两个公共数据集上，LINKO优于现有基线，并在数据有限和罕见病预测场景下表现出增强的鲁棒性。

Conclusion: LINKO框架有效提升了医学概念表示学习，为电子健康记录预测模型提供了一种强大的插件式编码器。

Abstract: Medical ontology graphs map external knowledge to medical codes in electronic
health records via structured relationships. By leveraging domain-approved
connections (e.g., parent-child), predictive models can generate richer medical
concept representations by incorporating contextual information from related
concepts. However, existing literature primarily focuses on incorporating
domain knowledge from a single ontology system, or from multiple ontology
systems (e.g., diseases, drugs, and procedures) in isolation, without
integrating them into a unified learning structure. Consequently, concept
representation learning often remains limited to intra-ontology relationships,
overlooking cross-ontology connections. In this paper, we propose LINKO, a
large language model (LLM)-augmented integrative ontology learning framework
that leverages multiple ontology graphs simultaneously by enabling dual-axis
knowledge propagation both within and across heterogeneous ontology systems to
enhance medical concept representation learning. Specifically, LINKO first
employs LLMs to provide a graph-retrieval-augmented initialization for ontology
concept embedding, through an engineered prompt that includes concept
descriptions, and is further augmented with ontology context. Second, our
method jointly learns the medical concepts in diverse ontology graphs by
performing knowledge propagation in two axes: (1) intra-ontology vertical
propagation across hierarchical ontology levels and (2) inter-ontology
horizontal propagation within every level in parallel. Last, through extensive
experiments on two public datasets, we validate the superior performance of
LINKO over state-of-the-art baselines. As a plug-in encoder compatible with
existing EHR predictive models, LINKO further demonstrates enhanced robustness
in scenarios involving limited data availability and rare disease prediction.

</details>


### [5] [Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models](https://arxiv.org/abs/2508.21365)
*Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang*

Main category: cs.AI

TL;DR: 该论文提出了一种新框架Think in Games (TiG)，使大型语言模型(LLM)能够通过与游戏环境的直接交互来学习程序性知识，同时保留其固有的推理和解释能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型擅长复杂推理，但在简单的交互任务上表现不佳，该论文旨在弥合声明式知识和程序式知识之间的差距。

Method: 将基于强化学习的决策制定重新定义为语言建模任务，LLM生成语言指导策略，并通过在线强化学习迭代改进。

Result: TiG成功弥合了声明式知识和程序式知识之间的差距，在数据和计算需求方面显著优于传统强化学习方法，并能提供逐步的自然语言解释。

Conclusion: TiG框架有效地使LLM能够胜任交互式任务，具有更高的效率和可解释性。

Abstract: Large language models (LLMs) excel at complex reasoning tasks such as
mathematics and coding, yet they frequently struggle with simple interactive
tasks that young children perform effortlessly. This discrepancy highlights a
critical gap between declarative knowledge (knowing about something) and
procedural knowledge (knowing how to do something). Although traditional
reinforcement learning (RL) agents can acquire procedural knowledge through
environmental interaction, they often operate as black boxes and require
substantial training data. In contrast, LLMs possess extensive world knowledge
and reasoning capabilities, but are unable to effectively convert this static
knowledge into dynamic decision-making in interactive settings. To address this
challenge, we propose Think in Games (TiG), a novel framework that empowers
LLMs to develop procedural understanding through direct interaction with game
environments, while retaining their inherent reasoning and explanatory
abilities. Specifically, TiG reformulates RL-based decision-making as a
language modeling task: LLMs generate language-guided policies, which are
refined iteratively through online reinforcement learning based on
environmental feedback. Our experimental results show that TiG successfully
bridges the gap between declarative and procedural knowledge, achieving
competitive performance with dramatically lower data and computational demands
compared to conventional RL methods. Moreover, TiG provides step-by-step
natural language explanations for its decisions, greatly improving transparency
and interpretability in complex interactive tasks.

</details>


### [6] [AHELM: A Holistic Evaluation of Audio-Language Models](https://arxiv.org/abs/2508.21376)
*Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang*

Main category: cs.AI

TL;DR: AHELM，一个新的基准测试，评估音频语言模型的10个方面，包括公平性和安全性，发现Gemini 2.5 Pro在5个方面排名靠前，但在ASR任务中存在群体不公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的音频语言模型（ALM）评估缺乏标准化基准，难以比较不同模型。

Method: 创建AHELM基准，包含多个数据集（包括两个新的合成数据集PARADE和CoRe-Bench），对14个ALM模型进行评估，标准化提示、参数和指标。

Result: Gemini 2.5 Pro在10个方面中的5个排名第一，但存在群体不公平性；基线系统表现合理。

Conclusion: AHELM是一个持续更新的基准，旨在促进ALM的公平、安全和稳健发展。

Abstract: Evaluations of audio-language models (ALMs) -- multimodal models that take
interleaved audio and text as input and output text -- are hindered by the lack
of standardized benchmarks; most benchmarks measure only one or two
capabilities and omit evaluative aspects such as fairness or safety.
Furthermore, comparison across models is difficult as separate evaluations test
a limited number of models and use different prompting methods and inference
parameters. To address these shortfalls, we introduce AHELM, a benchmark that
aggregates various datasets -- including 2 new synthetic audio-text datasets
called PARADE, which evaluates the ALMs on avoiding stereotypes, and
CoRe-Bench, which measures reasoning over conversational audio through
inferential multi-turn question answering -- to holistically measure the
performance of ALMs across 10 aspects we have identified as important to the
development and usage of ALMs: audio perception, knowledge, reasoning, emotion
detection, bias, fairness, multilinguality, robustness, toxicity, and safety.
We also standardize the prompts, inference parameters, and evaluation metrics
to ensure equitable comparisons across models. We test 14 open-weight and
closed-API ALMs from 3 developers and 3 additional simple baseline systems each
consisting of an automatic speech recognizer and a language model. Our results
show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits
group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do
not. We also find that the baseline systems perform reasonably well on AHELM,
with one ranking 5th overall despite having only speech-to-text capabilities.
For transparency, all raw prompts, model generations, and outputs are available
on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is
intended to be a living benchmark and new datasets and models will be added
over time.

</details>


### [7] [AI Compute Architecture and Evolution Trends](https://arxiv.org/abs/2508.21394)
*Bor-Sung Liang*

Main category: cs.AI

TL;DR: 本文分析了AI发展的机遇和挑战，提出了一个七层AI计算架构模型，并探讨了AI从单一智能体到AI生态系统的演进路径以及经济因素的影响。


<details>
  <summary>Details</summary>
Motivation: AI发展已从学术研究转向实际应用，但面临诸多挑战，本文旨在多角度分析AI的机遇和挑战。

Method: 提出一个七层AI计算架构模型，并分析每一层的发展轨迹和关键技术，结合大型语言模型(LLM)的三阶段演变，探讨AI智能体和生态系统的演进，以及经济因素的影响。

Result: 建立了七层AI计算架构模型，分析了LLM的两种发展路径，探讨了上下文记忆、AI智能体和AI生态系统的影响，并对AI发展未来轨迹进行预测。

Conclusion: AI发展面临技术和经济双重挑战，构建可持续的AI生态系统至关重要，未来发展需要关注多层架构的优化和AI智能体及生态系统的演进。

Abstract: The focus of AI development has shifted from academic research to practical
applications. However, AI development faces numerous challenges at various
levels. This article will attempt to analyze the opportunities and challenges
of AI from several different perspectives using a structured approach. This
article proposes a seven-layer model for AI compute architecture, including
Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,
Orchestrator Layer, and Application Layer, from bottom to top. It also explains
how AI computing has evolved into this 7-layer architecture through the
three-stage evolution on large-scale language models (LLMs). For each layer, we
describe the development trajectory and key technologies. In Layers 1 and 2 we
discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies
on computing architecture. In Layer 3 we explore two different development
paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs
and compares it to traditional processor memory. In Layers 5 to 7 we discuss
the trends of AI agents and explore the issues in evolution from a single AI
agent to an AI-based ecosystem, and their impact on the AI industry.
Furthermore, AI development involves not only technical challenges but also the
economic issues to build self-sustainable ecosystem. This article analyzes the
internet industry to provide predictions on the future trajectory of AI
development.

</details>


### [8] [CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN](https://arxiv.org/abs/2508.21411)
*Leonard Frank Neis,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: CARJAN工具能半自动化生成和模拟城市交通场景，包含行人、自行车和自动驾驶车辆等多种交互代理。


<details>
  <summary>Details</summary>
Motivation: 现有工具难以对包含多种交互代理的城市交通场景进行用户友好的建模和虚拟仿真。

Method: 基于多智能体工程框架AJAN和驾驶模拟器CARLA，使用SPARQL行为树进行代理决策和交互，提供可视化用户界面进行建模、存储和维护。

Result: CARJAN提供了一种在CARLA中进行交互式、智能化、基于代理的虚拟交通场景生成和仿真的集成方法。

Conclusion: CARJAN为在CARLA中创建复杂的城市交通场景提供了便利，有助于研究人员和工程师进行交通仿真和测试。

Abstract: User-friendly modeling and virtual simulation of urban traffic scenarios with
different types of interacting agents such as pedestrians, cyclists and
autonomous vehicles remains a challenge. We present CARJAN, a novel tool for
semi-automated generation and simulation of such scenarios based on the
multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN
provides a visual user interface for the modeling, storage and maintenance of
traffic scenario layouts, and leverages SPARQL Behavior Tree-based
decision-making and interactions for agents in dynamic scenario simulations in
CARLA. CARJAN provides a first integrated approach for interactive, intelligent
agent-based generation and simulation of virtual traffic scenarios in CARLA.

</details>


### [9] [A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions](https://arxiv.org/abs/2508.21441)
*Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald*

Main category: cs.AI

TL;DR: 本文研究了知识库中“遗忘”操作的语义和公理性质，特别关注基于Spohn排序函数的认知状态下的遗忘操作。


<details>
  <summary>Details</summary>
Motivation: 现有的遗忘操作主要基于经典逻辑，本文旨在将遗忘操作提升到认知层面，研究更丰富的语义结构。

Method: 本文提出了五种类型的认知遗忘操作，并基于Spohn排序函数给出了七个具体的遗忘操作实例，并用一组公理对这些操作进行了评估。

Result: 对七个具体的遗忘操作进行了全面的评估，揭示了它们之间的异同。

Conclusion: 本文为认知状态下的遗忘操作提供了全面的概述，有助于理解和应用遗忘操作。

Abstract: Forgetting as a knowledge management operation deliberately ignores parts of
the knowledge and beliefs of an agent, for various reasons. Forgetting has many
facets, one may want to forget parts of the syntax, a proposition, or a
conditional. In the literature, two main operators suitable for performing
forgetting have been proposed and investigated in depth: First, variable
elimination is a syntactical method that blends out certain atomic variables to
focus on the rest of the language. It has been mainly used in the area of logic
programming and answer set programming. Second, contraction in AGM belief
revision theory effectively removes propositions from belief sets under logical
deduction. Both operations rely mainly on classical logics. In this article, we
take an epistemic perspective and study forgetting operations in epistemic
states with richer semantic structures, but with clear links to propositional
logic. This allows us to investigate what forgetting in the epistemic
background means, thereby lifting well-known and novel forgetting operations to
the epistemic level. We present five general types of epistemic forgetting and
instantiate them with seven concrete forgetting operations for Spohn's ranking
functions. We take inspiration from postulates of forgetting both from logic
programming and AGM theory to propose a rich landscape of axioms for evaluating
forgetting operations. Finally, we evaluate all concrete forgetting operations
according to all postulates, leading to a novel comprehensive overview
highlighting differences and commonalities among the forgetting operators.

</details>


### [10] [Learning Lifted Action Models From Traces of Incomplete Actions and States](https://arxiv.org/abs/2508.21449)
*Niklas Jansen,Jonas Gösgens,Hector Geffner*

Main category: cs.AI

TL;DR: 本文提出了一种学习滑动块拼图提升STRIPS模型的新方法SYNTH，该方法能够处理状态和动作信息不完整的情况。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设动作或状态信息完整，本文考虑更真实的场景，即状态和动作信息不完整。

Method: 提出一种STRIPS+模型和相应的学习算法SYNTH，该算法通过构建分层查询来推断隐式动作参数。

Result: 证明了SYNTH算法的正确性和完整性，并在现有STRIPS领域导出的STRIPS+模型上测试了其可扩展性。

Conclusion: SYNTH算法有效解决了从不完整状态动作轨迹中学习提升STRIPS模型的问题，为更真实的模型学习提供了新的思路。

Abstract: Consider the problem of learning a lifted STRIPS model of the sliding-tile
puzzle from random state-action traces where the states represent the location
of the tiles only, and the actions are the labels up, down, left, and right,
with no arguments. Two challenges are involved in this problem. First, the
states are not full STRIPS states, as some predicates are missing, like the
atoms representing the position of the ``blank''. Second, the actions are not
full STRIPS either, as they do not reveal all the objects involved in the
actions effects and preconditions. Previous approaches have addressed different
versions of this model learning problem, but most assume that actions in the
traces are full STRIPS actions or that the domain predicates are all
observable. The new setting considered in this work is more ``realistic'', as
the atoms observed convey the state of the world but not full STRIPS states,
and the actions reveal the arguments needed for selecting the action but not
the ones needed for modeling it in STRIPS. For formulating and addressing the
learning problem, we introduce a variant of STRIPS, which we call STRIPS+,
where certain STRIPS action arguments can be left implicit in preconditions
which can also involve a limited form of existential quantification. The
learning problem becomes the problem of learning STRIPS+ models from STRIPS+
state-action traces. For this, the proposed learning algorithm, called SYNTH,
constructs a stratified sequence (conjunction) of precondition expressions or
``queries'' for each action, that denote unique objects in the state and ground
the implicit action arguments in STRIPS+. The correctness and completeness of
SYNTH is established, and its scalability is tested on state-action traces
obtained from STRIPS+ models derived from existing STRIPS domains.

</details>


### [11] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: MMSearch-Plus，一个包含311个任务的新基准，用于评估大型多模态语言模型（MLLMs）在复杂网络浏览任务中的能力，强调细粒度视觉推理、来源验证和长视野工具使用。


<details>
  <summary>Details</summary>
Motivation: 现有基准容易被简单的固定流程解决，MMSearch-Plus旨在评估MLLMs真正意义上的多模态理解能力。

Method: 构建包含多个弱视觉信号的任务，要求模型进行迭代文本图像搜索和交叉验证，并使用空间-时间外推法进行问题设计，答案需要从空间线索（微文本、局部外观、布局、标志）和时间痕迹（广播叠加、季节性背景）推断出图像外的信息。

Result: 最强模型（o3）在无搜索情况下准确率为15.1%，使用框架后准确率为36.0%；一个强大的开源模型（Qwen-2.5-VL-72B-Instruct）在无搜索情况下准确率为0.0%，搜索20轮后准确率为6.9%。此外，评估了边界框生成和裁剪图像搜索，并进行了错误分析。

Conclusion: MMSearch-Plus为评估MLLMs的多模态理解能力提供了一个更具挑战性的基准，揭示了现有模型在来源验证、基于部分的推理和长视野规划方面的不足。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [12] [Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis](https://arxiv.org/abs/2508.21517)
*Sweta Kaman,Ankita Sharma,Romi Banerjee*

Main category: cs.AI

TL;DR: 该论文提出了一种基于模糊推理系统和Z数的智慧评估框架，该框架能够捕捉智慧的多维度和不确定性，并在概念验证研究中展现出良好的效度。


<details>
  <summary>Details</summary>
Motivation: 现有智慧测量方法依赖于自我报告且难以反映智慧推理中固有的谦逊和不确定性，因此需要一种新的计算框架。

Method: 使用Z数模糊推理系统，将参与者的语言回应映射到智慧的五个组成部分，并使用21条规则结合各个组成部分的得分，最终生成智慧得分和置信度得分。

Result: 概念验证研究表明，该系统生成的智慧表征与既有量表具有显著的相关性，且与无关特质的相关性可忽略不计，支持其收敛效度和区分效度。

Conclusion: 该研究将智慧形式化为一个多维度、不确定性敏感的结构，并通过Z数进行操作化，这不仅促进了心理学测量的发展，也为人工智能系统提供了可解释的、置信度敏感的推理方法。

Abstract: Background: Wisdom is a superordinate construct that embraces perspective
taking, reflectiveness, prosocial orientation, reflective empathetic action,
and intellectual humility. Unlike conventional models of reasoning that are
rigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,
requiring both graded evaluation and self-reflective humility. Current measures
depend on self-reports and seldom reflect the humility and uncertainty inherent
in wise reasoning. A computational framework that takes into account both
multidimensionality and confidence has the potential to improve psychological
science and allow humane AI. Method: We present a fuzzy inference system with Z
numbers, each of the decisions being expressed in terms of a wisdom score
(restriction) and confidence score (certainty). As part of this study,
participants (N = 100) were exposed to culturally neutral pictorial moral
dilemma tasks to which they generated think-aloud linguistic responses, which
were mapped into five theoretically based components of wisdom. The scores of
each individual component were combined using a base of 21 rules, with
membership functions tuned via Gaussian kernel density estimation. Results: In
a proof of concept study, the system produced dual attribute wisdom
representations that correlated modestly but significantly with established
scales while showing negligible relations with unrelated traits, supporting
convergent and divergent validity. Contribution: The contribution is to
formalize wisdom as a multidimensional, uncertainty-conscious construct,
operationalized in the form of Z-numbers. In addition to progressing
measurement in psychology, it calculates how fuzzy Z numbers can provide AI
systems with interpretable, confidence-sensitive reasoning that affords a safe,
middle ground between rigorous computation and human-like judgment.

</details>


### [13] [Counterfactual Scenarios for Automated Planning](https://arxiv.org/abs/2508.21521)
*Nicola Gigante,Francesco Leofante,Andrea Micheli*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实场景的新型解释范式，用于解释规划问题，通过最小化修改规划问题使其满足给定的性质。


<details>
  <summary>Details</summary>
Motivation: 现有的反事实解释方法未能捕捉到规划问题的高层特性。

Method: 提出了一种基于反事实场景的解释范式，并给出了两种定性实例，分析了生成反事实场景的计算复杂度。

Result: 证明生成反事实场景的代价通常与计算规划问题的代价相同，表明该方法具有实用性。

Conclusion: 该研究提供了一个构建实用算法的框架。

Abstract: Counterfactual Explanations (CEs) are a powerful technique used to explain
Machine Learning models by showing how the input to a model should be minimally
changed for the model to produce a different output. Similar proposals have
been made in the context of Automated Planning, where CEs have been
characterised in terms of minimal modifications to an existing plan that would
result in the satisfaction of a different goal. While such explanations may
help diagnose faults and reason about the characteristics of a plan, they fail
to capture higher-level properties of the problem being solved. To address this
limitation, we propose a novel explanation paradigm that is based on
counterfactual scenarios. In particular, given a planning problem $P$ and an
\ltlf formula $\psi$ defining desired properties of a plan, counterfactual
scenarios identify minimal modifications to $P$ such that it admits plans that
comply with $\psi$. In this paper, we present two qualitative instantiations of
counterfactual scenarios based on an explicit quantification over plans that
must satisfy $\psi$. We then characterise the computational complexity of
generating such counterfactual scenarios when different types of changes are
allowed on $P$. We show that producing counterfactual scenarios is often only
as expensive as computing a plan for $P$, thus demonstrating the practical
viability of our proposal and ultimately providing a framework to construct
practical algorithms in this area.

</details>


### [14] [HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining](https://arxiv.org/abs/2508.21540)
*Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi*

Main category: cs.AI

TL;DR: HealthProcessAI框架简化医疗流程挖掘应用，集成LLM实现自动化报告生成，提升可访问性。


<details>
  <summary>Details</summary>
Motivation: 现有流程挖掘技术应用受限于技术复杂性、缺乏标准化方法和培训资源。

Method: 开发HealthProcessAI框架，集成Python (PM4PY) 和R (bupaR)库，并整合多个LLM进行自动化流程图解读和报告生成。

Result: 成功处理败血症数据，验证了框架的鲁棒性和自动化报告生成能力；LLM评估显示Claude Sonnet-4和Gemini 2.5-Pro表现最佳。

Conclusion: HealthProcessAI框架通过结合结构化分析和AI驱动解读，将复杂的流程挖掘结果转化为可操作的医疗应用见解，是方法学上的创新。

Abstract: Process mining has emerged as a powerful analytical technique for
understanding complex healthcare workflows. However, its application faces
significant barriers, including technical complexity, a lack of standardized
approaches, and limited access to practical training resources. We introduce
HealthProcessAI, a GenAI framework designed to simplify process mining
applications in healthcare and epidemiology by providing a comprehensive
wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address
unfamiliarity and improve accessibility, the framework integrates multiple
Large Language Models (LLMs) for automated process map interpretation and
report generation, helping translate technical analyses into outputs that
diverse users can readily understand. We validated the framework using sepsis
progression data as a proof-of-concept example and compared the outputs of five
state-of-the-art LLM models through the OpenRouter platform. To test its
functionality, the framework successfully processed sepsis data across four
proof-of-concept scenarios, demonstrating robust technical performance and its
capability to generate reports through automated LLM analysis. LLM evaluation
using five independent LLMs as automated evaluators revealed distinct model
strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency
scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By
integrating multiple Large Language Models (LLMs) for automated interpretation
and report generation, the framework addresses widespread unfamiliarity with
process mining outputs, making them more accessible to clinicians, data
scientists, and researchers. This structured analytics and AI-driven
interpretation combination represents a novel methodological advance in
translating complex process mining results into potentially actionable insights
for healthcare applications.

</details>


### [15] [Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances](https://arxiv.org/abs/2508.21564)
*Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt*

Main category: cs.AI

TL;DR: 提出一种新的框架用于发现可自动泛化到整个领域的landmarks。


<details>
  <summary>Details</summary>
Motivation: 传统的landmark提取算法在解决某些规划问题时存在不足。

Method: 学习一组已解决实例中的泛化landmarks，这些landmarks使用与特定问题对象无关的状态函数来描述规划问题的中间目标，并捕获重复性。构建一个有向泛化landmark图来定义landmark的进展，包括循环可能性。

Result: 实验结果表明，从少量小实例学习到的泛化landmark图对同一领域的大型实例也同样有效。如果识别到表示重复的循环，则启发式性能比基线有显著提高。

Conclusion: 泛化landmarks捕获了可解释且对自动规划器有用的领域信息，这些信息可以从同一领域的少量计划中发现。

Abstract: We propose a new framework for discovering landmarks that automatically
generalize across a domain. These generalized landmarks are learned from a set
of solved instances and describe intermediate goals for planning problems where
traditional landmark extraction algorithms fall short. Our generalized
landmarks extend beyond the predicates of a domain by using state functions
that are independent of the objects of a specific problem and apply to all
similar objects, thus capturing repetition. Based on these functions, we
construct a directed generalized landmark graph that defines the landmark
progression, including loop possibilities for repetitive subplans. We show how
to use this graph in a heuristic to solve new problem instances of the same
domain. Our results show that the generalized landmark graphs learned from a
few small instances are also effective for larger instances in the same domain.
If a loop that indicates repetition is identified, we see a significant
improvement in heuristic performance over the baseline. Generalized landmarks
capture domain information that is interpretable and useful to an automated
planner. This information can be discovered from a small set of plans for the
same domain.

</details>


### [16] [Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics](https://arxiv.org/abs/2508.21595)
*Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes*

Main category: cs.AI

TL;DR: 针对具有确定性动作和观测结果的多智能体规划问题，提出了一种确定性分散式POMDP(Det-Dec-POMDP)模型和一种名为IDPP的求解器。


<details>
  <summary>Details</summary>
Motivation: 现有Dec-POMDP求解器难以有效处理大规模问题。

Method: 提出Det-Dec-POMDP模型，并基于联合均衡搜索策略框架，设计了IDPP求解器。

Result: IDPP求解器能够有效处理大规模Det-Dec-POMDP问题。

Conclusion: Det-Dec-POMDP模型和IDPP求解器为解决大规模多智能体规划问题提供了一种有效方法。

Abstract: Many high-level multi-agent planning problems, including multi-robot
navigation and path planning, can be effectively modeled using deterministic
actions and observations.
  In this work, we focus on such domains and introduce the class of
Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of
Dec-POMDPs characterized by deterministic transitions and observations
conditioned on the state and joint actions.
  We then propose a practical solver called Iterative Deterministic POMDP
Planning (IDPP). This method builds on the classic Joint Equilibrium Search for
Policies framework and is specifically optimized to handle large-scale
Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address
efficiently.

</details>


### [17] [Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study](https://arxiv.org/abs/2508.21622)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 该论文提出一个集成框架，结合传统网络优化模型和大型语言模型（LLM），为供应链规划提供交互式、可解释和角色感知的决策支持。


<details>
  <summary>Details</summary>
Motivation: 弥合复杂运筹学输出与业务利益相关者理解之间的差距。

Method: 结合传统网络优化模型（混合整数规划）和大型语言模型，利用AI代理、RESTful APIs和动态用户界面。

Result: 案例研究表明，该系统通过防止缺货、降低成本和维持服务水平来改善规划结果。

Conclusion: 未来可集成私有LLM、迁移学习、强化学习和贝叶斯神经网络以增强可解释性、适应性和实时决策。

Abstract: This paper presents an integrated framework that combines traditional network
optimization models with large language models (LLMs) to deliver interactive,
explainable, and role-aware decision support for supply chain planning. The
proposed system bridges the gap between complex operations research outputs and
business stakeholder understanding by generating natural language summaries,
contextual visualizations, and tailored key performance indicators (KPIs). The
core optimization model addresses tactical inventory redistribution across a
network of distribution centers for multi-period and multi-item, using a
mixed-integer formulation. The technical architecture incorporates AI agents,
RESTful APIs, and a dynamic user interface to support real-time interaction,
configuration updates, and simulation-based insights. A case study demonstrates
how the system improves planning outcomes by preventing stockouts, reducing
costs, and maintaining service levels. Future extensions include integrating
private LLMs, transfer learning, reinforcement learning, and Bayesian neural
networks to enhance explainability, adaptability, and real-time
decision-making.

</details>
