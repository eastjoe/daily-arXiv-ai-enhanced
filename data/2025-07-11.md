<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
*Javal Vyas,Mehmet Mercangoz*

Main category: cs.AI

TL;DR: 大型语言模型可用于统一化学过程中的高级符号规划和低级连续控制，实现更高效、更鲁棒的自动化。


<details>
  <summary>Details</summary>
Motivation: 现代化学过程的复杂性、劳动力短缺和复杂的故障场景，需要将符号推理与自适应控制相结合的新型自动化范例。

Method: 该框架采用有限状态机 (FSM) 作为可解释的操作范围，结合 LLM 驱动的规划代理、模拟代理和验证-重提示循环，实现了对各种规模 FSM 的有效路径规划和对 TCLab 平台温度控制的精确调节。

Result: 在案例研究 1 中，GPT-4o 和 GPT-4o-mini 在 180 个随机生成的 FSM 中取得了 100% 的有效路径成功率；在案例研究 2 中，基于 LLM 的控制器在 TCLab 平台温度控制中达到了与经典 PID 控制相似的性能。

Conclusion: 该研究提出了一种利用大型语言模型 (LLM) 统一离散故障恢复规划和连续过程控制的框架，并在化学工程自动化中取得了成功，为实现具有弹性的语言驱动自动化铺平了道路。

Abstract: The increasing complexity of modern chemical processes, coupled with
workforce shortages and intricate fault scenarios, demands novel automation
paradigms that blend symbolic reasoning with adaptive control. In this work, we
introduce a unified agentic framework that leverages large language models
(LLMs) for both discrete fault-recovery planning and continuous process control
within a single architecture. We adopt Finite State Machines (FSMs) as
interpretable operating envelopes: an LLM-driven planning agent proposes
recovery sequences through the FSM, a Simulation Agent executes and checks each
transition, and a Validator-Reprompting loop iteratively refines invalid plans.
In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25
states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path
success within five reprompts-outperforming open-source LLMs in both accuracy
and latency. In Case Study 2, the same framework modulates dual-heater inputs
on a laboratory TCLab platform (and its digital twin) to maintain a target
average temperature under persistent asymmetric disturbances. Compared to
classical PID control, our LLM-based controller attains similar performance,
while ablation of the prompting loop reveals its critical role in handling
nonlinear dynamics. We analyze key failure modes-such as instruction following
lapses and coarse ODE approximations. Our results demonstrate that, with
structured feedback and modular agents, LLMs can unify high-level symbolic
planningand low-level continuous control, paving the way towards resilient,
language-driven automation in chemical engineering.

</details>


### [2] [BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks](https://arxiv.org/abs/2507.07134)
*Mridula Vijendran,Shuang Chen,Jingjing Deng,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: 针对AI艺术分类中模型偏差问题，提出了一种新的采样方法BOOST，有效提升了模型公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI模型在艺术分类中存在偏差问题，尤其是在处理OOD数据时，这些偏差会影响模型的公平性和准确性。

Method: 提出了一种新的OOD-informed模型偏差自适应采样方法BOOST，该方法通过动态调整温度缩放和采样概率来促进所有类别的更公平表示。并提出了一种新的评估指标SODC。

Result: BOOST方法能够有效降低类间偏差，并在保证高性能的同时提高公平性。

Conclusion: 提出了一种新的基于OOD的模型偏差自适应采样方法BOOST，用于解决AI模型在艺术分类中的偏差问题，并在KaoKore和PACS数据集上进行了评估，结果表明该方法能够在保证高性能的同时提高公平性。

Abstract: The pervasive issue of bias in AI presents a significant challenge to
painting classification, and is getting more serious as these systems become
increasingly integrated into tasks like art curation and restoration. Biases,
often arising from imbalanced datasets where certain artistic styles dominate,
compromise the fairness and accuracy of model predictions, i.e., classifiers
are less accurate on rarely seen paintings. While prior research has made
strides in improving classification performance, it has largely overlooked the
critical need to address these underlying biases, that is, when dealing with
out-of-distribution (OOD) data. Our insight highlights the necessity of a more
robust approach to bias mitigation in AI models for art classification on
biased training data. We propose a novel OOD-informed model bias adaptive
sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It
addresses these challenges by dynamically adjusting temperature scaling and
sampling probabilities, thereby promoting a more equitable representation of
all classes. We evaluate our proposed approach to the KaoKore and PACS
datasets, focusing on the model's ability to reduce class-wise bias. We further
propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to
assess class-wise separation and per-class bias reduction. Our method
demonstrates the ability to balance high performance with fairness, making it a
robust solution for unbiasing AI models in the art domain.

</details>


### [3] [State-Inference-Based Prompting for Natural Language Trading with Game NPCs](https://arxiv.org/abs/2507.07203)
*Minkyung Kim,Junsik Kim,Hwidong Bae,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: SIBP通过状态推理和上下文感知的提示，解决了LLM在游戏交易中规则违反的问题，实现了高度可靠的交易互动。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在规则驱动的交易系统中存在规则违反问题，例如物品幻觉和计算错误，影响玩家信任。

Method: 提出了一种基于状态推理的提示方法(SIBP)，将交易分解为六个状态，并利用上下文感知的物品引用和基于占位符的价格计算来确保规则遵守。

Result: 在100个交易对话中，SIBP方法实现了>97%的状态遵从率，>95%的引用准确率和99.7%的计算精度，同时保持了计算效率，优于基线方法。

Conclusion: SIBP方法显著提高了大型语言模型在规则驱动交易系统中的可靠性，实现了高准确率的物品引用和价格计算，为构建可信的NPC互动奠定了基础。

Abstract: Large Language Models enable dynamic game interactions but struggle with
rule-governed trading systems. Current implementations suffer from rule
violations, such as item hallucinations and calculation errors, that erode
player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable
trading through autonomous dialogue state inference and context-specific rule
adherence. The approach decomposes trading into six states within a unified
prompt framework, implementing context-aware item referencing and
placeholder-based price calculations. Evaluation across 100 trading dialogues
demonstrates >97% state compliance, >95% referencing accuracy, and 99.7%
calculation precision. SIBP maintains computational efficiency while
outperforming baseline approaches, establishing a practical foundation for
trustworthy NPC interactions in commercial games.

</details>


### [4] [Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains](https://arxiv.org/abs/2507.07217)
*Zili Wang,Frank Montabon,Kristin Yvonne Rozier*

Main category: cs.AI

TL;DR: 使用神经符号方法和大型语言模型检测非法供应链活动，并比较了人工和自动特征提取的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法需要大量训练数据，而非法供应链数据稀疏且易受污染，因此需要一种能够自动检测与非法活动相关的新模式的方法，即使数据复杂且随时间变化。

Method: 神经符号方法、问题树方法、大型语言模型

Result: 比较了人工和自动特征提取的有效性，提出了一种基于问题树的方法来查询大型语言模型，以识别和量化新闻文章的相关性，从而系统地评估人类和机器对供应链强迫劳动相关新闻文章的分类差异。

Conclusion: 本文探究了使用神经符号方法识别供应链中非法活动，并比较了人工和自动特征提取的有效性，提出了一种基于问题树的方法来查询大型语言模型以识别和量化新闻文章的相关性，从而系统地评估人类和机器对供应链强迫劳动相关新闻文章的分类差异。

Abstract: Supply chain networks are complex systems that are challenging to analyze;
this problem is exacerbated when there are illicit activities involved in the
supply chain, such as counterfeit parts, forced labor, or human trafficking.
While machine learning (ML) can find patterns in complex systems like supply
chains, traditional ML techniques require large training data sets. However,
illicit supply chains are characterized by very sparse data, and the data that
is available is often (purposely) corrupted or unreliable in order to hide the
nature of the activities. We need to be able to automatically detect new
patterns that correlate with such illegal activity over complex, even temporal
data, without requiring large training data sets. We explore neurosymbolic
methods for identifying instances of illicit activity in supply chains and
compare the effectiveness of manual and automated feature extraction from news
articles accurately describing illicit activities uncovered by authorities. We
propose a question tree approach for querying a large language model (LLM) to
identify and quantify the relevance of articles. This enables a systematic
evaluation of the differences between human and machine classification of news
articles related to forced labor in supply chains.

</details>
