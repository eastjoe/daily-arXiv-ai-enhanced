<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics](https://arxiv.org/abs/2507.17777)
*Theofanis Aravanis,Grigorios Chrimatopoulos,Mohammad Ferdows,Michalis Xenos,Efstratios Em Tzirtzilakis*

Main category: cs.AI

TL;DR: 利用符号回归和答案集编程相结合的方法，对三维层流进行了建模，得到了与解析解一致的结果，证明了该方法在流体力学中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 受流体力学中对底层流动物理理解与精确预测同等重要的认识驱动，该研究旨在利用SR揭示复杂物理系统中可解释的数学关系。

Method: 该研究应用符号回归(SR)方法对三维不可压缩层流进行建模，并结合答案集编程(ASP)进行知识表示，确保生成的符号表达式既统计准确又物理合理。

Result: 研究结果表明，SR生成的方程不仅近似于所研究流动的抛物线速度分布和压降，而且与文献中的解析解完全一致。

Conclusion: 该研究强调了符号回归(SR)在简化复杂流动行为为简洁的、可解释的方程方面的能力，以及知识表示方法在提高数据驱动SR模型与领域原理一致性方面的潜力。

Abstract: Unlike conventional Machine-Learning (ML) approaches, often criticized as
"black boxes", Symbolic Regression (SR) stands out as a powerful tool for
revealing interpretable mathematical relationships in complex physical systems,
requiring no a priori assumptions about models' structures. Motivated by the
recognition that, in fluid mechanics, an understanding of the underlying flow
physics is as crucial as accurate prediction, this study applies SR to model a
fundamental three-dimensional (3D) incompressible flow in a rectangular
channel, focusing on the (axial) velocity and pressure fields under laminar
conditions. By employing the PySR library, compact symbolic equations were
derived directly from numerical simulation data, revealing key characteristics
of the flow dynamics. These equations not only approximate the parabolic
velocity profile and pressure drop observed in the studied fluid flow, but also
perfectly coincide with analytical solutions from the literature. Furthermore,
we propose an innovative approach that integrates SR with the
knowledge-representation framework of Answer Set Programming (ASP), combining
the generative power of SR with the declarative reasoning strengths of ASP. The
proposed hybrid SR/ASP framework ensures that the SR-generated symbolic
expressions are not only statistically accurate, but also physically plausible,
adhering to domain-specific principles. Overall, the study highlights two key
contributions: SR's ability to simplify complex flow behaviours into concise,
interpretable equations, and the potential of knowledge-representation
approaches to improve the reliability and alignment of data-driven SR models
with domain principles. Insights from the examined 3D channel flow pave the way
for integrating such hybrid approaches into efficient frameworks, [...] where
explainable predictions and real-time data analysis are crucial.

</details>


### [2] [I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis](https://arxiv.org/abs/2507.17874)
*SaiBarath Sundar,Pranav Satheesan,Udayaadithya Avadhanam*

Main category: cs.AI

TL;DR: I2I-STRADA通过结构化认知工作流程改进数据分析代理系统，在基准测试中表现优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有的数据分析代理系统通常忽略分析思维背后的结构化推理过程，I2I-STRADA旨在通过形式化这一过程来改进数据分析。

Method: I2I-STRADA架构通过对分析推理认知步骤进行建模，将数据分析过程分解为模块化子任务，从而实现结构化推理。

Result: 在DABstep和DABench基准测试中，I2I-STRADA在规划一致性和洞察力匹配方面优于现有系统。

Conclusion: I2I-STRADA，一个用于数据分析的结构化推理代理架构，通过模拟分析过程中反映分析推理认知步骤的模块化子任务，提高了规划一致性和洞察力匹配。

Abstract: Recent advances in agentic systems for data analysis have emphasized
automation of insight generation through multi-agent frameworks, and
orchestration layers. While these systems effectively manage tasks like query
translation, data transformation, and visualization, they often overlook the
structured reasoning process underlying analytical thinking. Reasoning large
language models (LLMs) used for multi-step problem solving are trained as
general-purpose problem solvers. As a result, their reasoning or thinking steps
do not adhere to fixed processes for specific tasks. Real-world data analysis
requires a consistent cognitive workflow: interpreting vague goals, grounding
them in contextual knowledge, constructing abstract plans, and adapting
execution based on intermediate outcomes. We introduce I2I-STRADA
(Information-to-Insight via Structured Reasoning Agent for Data Analysis), an
agentic architecture designed to formalize this reasoning process. I2I-STRADA
focuses on modeling how analysis unfolds via modular sub-tasks that reflect the
cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench
benchmarks show that I2I-STRADA outperforms prior systems in planning coherence
and insight alignment, highlighting the importance of structured cognitive
workflows in agent design for data analysis.

</details>


### [3] [SMARTAPS: Tool-augmented LLMs for Operations Management](https://arxiv.org/abs/2507.17927)
*Timothy Tin Long Yu,Mahdi Mostajabdaveh,Jabo Serge Byusa,Rindra Ramamonjison,Giuseppe Carenini,Kun Mao,Zirui Zhou,Yong Zhang*

Main category: cs.AI

TL;DR: SmartAPS是一个基于LLM的会话式高级计划系统，旨在降低APS使用成本，并通过自然语言界面提升用户体验。


<details>
  <summary>Details</summary>
Motivation: 许多客户因高级计划系统的高昂维护成本而无法使用，SmartAPS旨在解决这一问题，为供应链规划人员提供更易于访问且经济实惠的解决方案。

Method: 该系统利用工具增强型大型语言模型构建，提供自然语言聊天界面，支持信息查询、反事实推理、推荐和情景分析等功能。

Result: SmartAPS系统为操作规划人员提供了一个直观的自然语言聊天界面，帮助他们更好地管理运营。

Conclusion: 本文介绍了SmartAPS系统，一个基于工具增强型大型语言模型的会话式高级计划系统，旨在降低高级计划系统的高昂成本，并为供应链规划人员提供更便捷的访问方式。

Abstract: Large language models (LLMs) present intriguing opportunities to enhance user
interaction with traditional algorithms and tools in real-world applications.
An advanced planning system (APS) is a sophisticated software that leverages
optimization to help operations planners create, interpret, and modify an
operational plan. While highly beneficial, many customers are priced out of
using an APS due to the ongoing costs of consultants responsible for
customization and maintenance. To address the need for a more accessible APS
expressed by supply chain planners, we present SmartAPS, a conversational
system built on a tool-augmented LLM. Our system provides operations planners
with an intuitive natural language chat interface, allowing them to query
information, perform counterfactual reasoning, receive recommendations, and
execute scenario analysis to better manage their operation. A short video
demonstrating the system has been released: https://youtu.be/KtIrJjlDbyw

</details>


### [4] [Synthesis of timeline-based planning strategies avoiding determinization](https://arxiv.org/abs/2507.17988)
*Dario Della Monica,Angelo Montanari,Pietro Sala*

Main category: cs.AI

TL;DR: 找到了一种基于定性时间线的规划片段，可以直接合成策略，无需代价高昂的确定化步骤。


<details>
  <summary>Details</summary>
Motivation: 解决基于定性时间线的规划的策略合成问题，该问题原先需要代价高昂的确定化步骤。

Method: 将基于定性时间线的规划问题规约到确定性有限自动机的非空问题。

Result: 确定了可直接映射到确定性有限自动机非空问题的定性时间线规划片段，并找到了适合该片段的 Allen 关系的最大子集，从而可以直接合成策略。

Conclusion: 本文确定了基于定性时间线的规划的一个片段，其规划存在问题可以直接映射到确定性有限自动机的非空问题，从而可以合成策略，并确定了适合这种确定性片段的 Allen 关系的最大子集。

Abstract: Qualitative timeline-based planning models domains as sets of independent,
but
  interacting, components whose behaviors over time, the timelines, are
governed
  by sets of qualitative temporal constraints (ordering relations), called
  synchronization rules.
  Its plan-existence problem has been shown to be PSPACE-complete; in
  particular, PSPACE-membership has been proved via reduction to the
  nonemptiness problem for nondeterministic finite automata.
  However, nondeterministic automata cannot be directly used to synthesize
  planning strategies as a costly determinization step is needed.
  In this paper, we identify a fragment of qualitative timeline-based planning
  whose plan-existence problem can be directly mapped into the nonemptiness
  problem of deterministic finite automata, which can then
  synthesize strategies.
  In addition, we identify a maximal subset of Allen's relations that fits into
  such a deterministic fragment.

</details>


### [5] [E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI](https://arxiv.org/abs/2507.18004)
*Yusen Peng,Shuhua Mao*

Main category: cs.AI

TL;DR: 通过将AI模型的错误转化为创意资产，提升AI创造力，取得显著成果。


<details>
  <summary>Details</summary>
Motivation: 探索如何使AI超越模仿，实现真正的创造力。

Method: E.A.R.T.H.框架，包含错误生成、放大、优化选择、转换和利用反馈五个阶段，使用了LLaMA-2-7B-Chat、SBERT、BERTScore、CLIP、BLIP-2和Stable Diffusion等模型，并采用基于新颖性、意外性和相关性的复合奖励函数。

Result: 在优化阶段，创造力得分提高了52.5%；最终输出达到2.010，提高了70.4%；改进后的标语更短、更具新颖性，相关性略有下降；跨模态测试显示标语和图像高度一致；人类评估显示60%的输出得分不低于4.0，隐喻性标语优于字面标语。

Conclusion: 该论文提出了一种名为E.A.R.T.H.的五阶段生成式流程，通过将模型生成的错误转化为创意资产来提升AI的创造力，最终结果表明，以错误为中心、反馈驱动的生成方法可以增强创造力，为自进化、以人为本的创意AI提供了一条可扩展的路径。

Abstract: How can AI move beyond imitation toward genuine creativity? This paper
proposes the E.A.R.T.H. framework, a five-stage generative pipeline that
transforms model-generated errors into creative assets through Error
generation, Amplification, Refine selection, Transform, and Harness feedback.
Drawing on cognitive science and generative modeling, we posit that "creative
potential hides in failure" and operationalize this via structured prompts,
semantic scoring, and human-in-the-loop evaluation. Implemented using
LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the
pipeline employs a composite reward function based on novelty, surprise, and
relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to
1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4%
improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a
4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment
(CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs
scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones
(3.99). Feedback highlights stylistic precision and emotional resonance. These
results demonstrate that error-centered, feedback-driven generation enhances
creativity, offering a scalable path toward self-evolving, human-aligned
creative AI.

</details>


### [6] [Does visualization help AI understand data?](https://arxiv.org/abs/2507.18022)
*Victoria R. Li,Johnathan Sun,Martin Wattenberg*

Main category: cs.AI

TL;DR: 图表有助于AI系统更精确地分析数据。


<details>
  <summary>Details</summary>
Motivation: 研究图表和图形是否可以用于AI系统分析数据。

Method: 对两个商业视觉语言模型GPT 4.1和Claude 3.5进行了一系列实验，比较了三种具有代表性的分析任务，以及三个基线。

Result: 当原始数据伴随着散点图时，两个系统对合成数据集的描述更加精确和准确，尤其是在数据集复杂性增加时。

Conclusion: AI 系统可以从数据可视化中受益，类似于人类。

Abstract: Charts and graphs help people analyze data, but can they also be useful to AI
systems? To investigate this question, we perform a series of experiments with
two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three
representative analysis tasks, the two systems describe synthetic datasets more
precisely and accurately when raw data is accompanied by a scatterplot,
especially as datasets grow in complexity. Comparison with two baselines --
providing a blank chart and a chart with mismatched data -- shows that the
improved performance is due to the content of the charts. Our results are
initial evidence that AI systems, like humans, can benefit from visualization.

</details>


### [7] [Multi-Agent Guided Policy Optimization](https://arxiv.org/abs/2507.18059)
*Yueheng Li,Guangming Xie,Zongqing Lu*

Main category: cs.AI

TL;DR: MAGPO是一种新颖的MARL框架，它通过集中式指导和分散式执行，提高了CTDE方法的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的集中式训练与分散式执行（CTDE）方法往往低效利用集中式训练或缺乏理论保证。

Method: 提出了一种新颖的多智能体引导策略优化（MAGPO）框架，该框架通过将集中式指导与分散式执行相结合，更好地利用集中式训练。MAGPO使用自回归联合策略进行可扩展的协调探索，并将其与分散式策略明确对齐，以确保在部分可观测性下的可部署性。

Result: MAGPO在6个不同环境的43个任务中持续优于强CTDE基线，并匹配或超越了完全集中式方法。

Conclusion: MAGPO框架在43个任务中持续优于强基线，并在分散式多智能体学习中提供了一种有原则且实用的解决方案。

Abstract: Due to practical constraints such as partial observability and limited
communication, Centralized Training with Decentralized Execution (CTDE) has
become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning
(MARL). However, existing CTDE methods often underutilize centralized training
or lack theoretical guarantees. We propose Multi-Agent Guided Policy
Optimization (MAGPO), a novel framework that better leverages centralized
training by integrating centralized guidance with decentralized execution.
MAGPO uses an auto-regressive joint policy for scalable, coordinated
exploration and explicitly aligns it with decentralized policies to ensure
deployability under partial observability. We provide theoretical guarantees of
monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across
6 diverse environments. Results show that MAGPO consistently outperforms strong
CTDE baselines and matches or surpasses fully centralized approaches, offering
a principled and practical solution for decentralized multi-agent learning. Our
code and experimental data can be found in https://github.com/liyheng/MAGPO.

</details>


### [8] [AlphaGo Moment for Model Architecture Discovery](https://arxiv.org/abs/2507.18074)
*Yixiu Liu,Yang Nan,Weixian Xu,Xiangkun Hu,Lyumanshan Ye,Zhen Qin,Pengfei Liu*

Main category: cs.AI

TL;DR: AI系统ASI-Arch自主研发了106个最先进的神经网络架构，突破了AI研究受限于人类认知能力的瓶颈，并建立了科学发现的计算可扩展性定律。


<details>
  <summary>Details</summary>
Motivation: AI研究受限于人类认知能力，ASI-Arch旨在突破这一瓶颈，实现AI的自主创新。

Method: ASI-Arch系统通过自主假设新的架构概念，将它们转换为可执行代码，进行训练和实验验证，最终发现新的架构。该系统进行了1773次自主实验，使用了超过20000个GPU小时。

Result: ASI-Arch发现了106个最先进的线性注意力架构，并建立了科学发现的第一个经验缩放定律，证明了突破性进展可以通过计算进行扩展。

Conclusion: ASI-Arch，一个用于AI研究的自动化超级人工智能系统，通过自主设计、实现、训练和验证神经网络架构，实现了AI领域的自主创新，发现了106个最先进的线性注意力架构，并建立了科学发现的第一个经验缩放定律，证明了突破性进展可以通过计算进行扩展。

Abstract: While AI systems demonstrate exponentially improving capabilities, the pace
of AI research itself remains linearly bounded by human cognitive capacity,
creating an increasingly severe development bottleneck. We present ASI-Arch,
the first demonstration of Artificial Superintelligence for AI research
(ASI4AI) in the critical domain of neural architecture discovery--a fully
autonomous system that shatters this fundamental constraint by enabling AI to
conduct its own architectural innovation. Moving beyond traditional Neural
Architecture Search (NAS), which is fundamentally limited to exploring
human-defined spaces, we introduce a paradigm shift from automated optimization
to automated innovation. ASI-Arch can conduct end-to-end scientific research in
the domain of architecture discovery, autonomously hypothesizing novel
architectural concepts, implementing them as executable code, training and
empirically validating their performance through rigorous experimentation and
past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000
GPU hours, culminating in the discovery of 106 innovative, state-of-the-art
(SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed
unexpected strategic insights invisible to human players, our AI-discovered
architectures demonstrate emergent design principles that systematically
surpass human-designed baselines and illuminate previously unknown pathways for
architectural innovation. Crucially, we establish the first empirical scaling
law for scientific discovery itself--demonstrating that architectural
breakthroughs can be scaled computationally, transforming research progress
from a human-limited to a computation-scalable process. We provide
comprehensive analysis of the emergent design patterns and autonomous research
capabilities that enabled these breakthroughs, establishing a blueprint for
self-accelerating AI systems.

</details>


### [9] [Agentic AI framework for End-to-End Medical Data Inference](https://arxiv.org/abs/2507.18115)
*Soorya Ram Shimgekar,Shayan Vassef,Abhay Goyal,Navin Kumar,Koustuv Saha*

Main category: cs.AI

TL;DR: Agentic AI 框架自动化临床数据处理流程，降低成本，提高效率。


<details>
  <summary>Details</summary>
Motivation: 医疗领域机器学习解决方案的构建和部署成本高昂且费力，原因在于预处理流程分散、模型兼容性问题以及严格的数据隐私限制。

Method: 该框架采用模块化、特定任务的代理系统处理结构化和非结构化数据，自动进行特征选择、模型选择和预处理推荐。

Result: 该框架在老年病学、姑息治疗和结肠镜检查影像等公开数据集上进行了评估，结果表明该框架能够有效地自动化临床数据处理流程。

Conclusion: 该研究提出了一种名为 Agentic AI 的框架，自动化了临床数据处理的整个流程，从数据摄取到推理，降低了医疗领域机器学习应用的成本和人力投入。

Abstract: Building and deploying machine learning solutions in healthcare remains
expensive and labor-intensive due to fragmented preprocessing workflows, model
compatibility issues, and stringent data privacy constraints. In this work, we
introduce an Agentic AI framework that automates the entire clinical data
pipeline, from ingestion to inference, through a system of modular,
task-specific agents. These agents handle both structured and unstructured
data, enabling automatic feature selection, model selection, and preprocessing
recommendation without manual intervention. We evaluate the system on publicly
available datasets from geriatrics, palliative care, and colonoscopy imaging.
For example, in the case of structured data (anxiety data) and unstructured
data (colonoscopy polyps data), the pipeline begins with file-type detection by
the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring
privacy compliance, where we first identify the data type and then anonymize
it. The Feature Extraction Agent identifies features using an embedding-based
approach for tabular data, extracting all column names, and a multi-stage
MedGemma-based approach for image data, which infers modality and disease name.
These features guide the Model-Data Feature Matcher Agent in selecting the
best-fit model from a curated repository. The Preprocessing Recommender Agent
and Preprocessing Implementor Agent then apply tailored preprocessing based on
data type and model requirements. Finally, the ``Model Inference Agent" runs
the selected model on the uploaded data and generates interpretable outputs
using tools like SHAP, LIME, and DETR attention maps. By automating these
high-friction stages of the ML lifecycle, the proposed framework reduces the
need for repeated expert intervention, offering a scalable, cost-efficient
pathway for operationalizing AI in clinical environments.

</details>


### [10] [Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes](https://arxiv.org/abs/2507.18123)
*Sedigh Khademi,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila,Jim Black*

Main category: cs.AI

TL;DR: 利用自然语言处理和主动学习技术，开发了一个从急诊记录中识别疫苗安全问题的分类器，以增强疫苗上市后监测。


<details>
  <summary>Details</summary>
Motivation: 疫苗上市后监测系统的重要性日益凸显，需要快速有效的方法来检测疫苗安全问题。急诊分诊记录包含关键的患者信息，可以为疫苗安全监测提供重要数据。

Method: 使用自然语言处理技术和主动学习方法，对急诊分诊记录进行分类，识别潜在的疫苗安全问题。

Result: 创建了一个能够从急诊分诊记录中检测潜在疫苗安全问题的分类器，提高了疫苗安全监测的效率和准确性。

Conclusion: 本研究结合主动学习、数据增强和评估技术，创建了一个分类器，用于增强疫苗安全监测，从急诊分诊记录中识别潜在的疫苗安全问题。

Abstract: The rapid development of COVID-19 vaccines has showcased the global
communitys ability to combat infectious diseases. However, the need for
post-licensure surveillance systems has grown due to the limited window for
safety data collection in clinical trials and early widespread implementation.
This study aims to employ Natural Language Processing techniques and Active
Learning to rapidly develop a classifier that detects potential vaccine safety
issues from emergency department notes. ED triage notes, containing expert,
succinct vital patient information at the point of entry to health systems, can
significantly contribute to timely vaccine safety signal surveillance. While
keyword-based classification can be effective, it may yield false positives and
demand extensive keyword modifications. This is exacerbated by the infrequency
of vaccination-related ED presentations and their similarity to other reasons
for ED visits. NLP offers a more accurate and efficient alternative, albeit
requiring annotated data, which is often scarce in the medical field. Active
learning optimizes the annotation process and the quality of annotated data,
which can result in faster model implementation and improved model performance.
This work combines active learning, data augmentation, and active learning and
evaluation techniques to create a classifier that is used to enhance vaccine
safety surveillance from ED triage notes.

</details>


### [11] [Logical Characterizations of GNNs with Mean Aggregation](https://arxiv.org/abs/2507.18145)
*Moritz Schönherr,Carsten Lutz*

Main category: cs.AI

TL;DR: 不同聚合函数的GNNs表达能力不同，平均值GNNs的表达能力介于最大值和求和GNNs之间。


<details>
  <summary>Details</summary>
Motivation: 探讨GNNs在不同聚合函数下的表达能力差异。

Method: 研究了不同聚合函数（平均值、最大值、求和）的GNNs的表达能力，并将其与模态逻辑进行了比较。

Result: 在非均匀环境下，平均值GNNs的表达能力高于最大值GNNs，低于求和GNNs；在均匀环境下，平均值GNNs的表达能力低于求和GNNs和最大值GNNs。

Conclusion: 本文研究了以平均值作为聚合函数的图神经网络（GNNs）的表达能力。在非均匀环境下，这类GNNs的表达能力与比率模态逻辑相同；在均匀环境下，在组合函数连续且分类函数为阈值的自然假设下，其表达能力与无交替模态逻辑相同。

Abstract: We study the expressive power of graph neural networks (GNNs) with mean as
the aggregation function. In the non-uniform setting, we show that such GNNs
have exactly the same expressive power as ratio modal logic, which has modal
operators expressing that at least a certain ratio of the successors of a
vertex satisfies a specified property. The non-uniform expressive power of mean
GNNs is thus higher than that of GNNs with max aggregation, but lower than for
sum aggregation--the latter are characterized by modal logic and graded modal
logic, respectively. In the uniform setting, we show that the expressive power
relative to MSO is exactly that of alternation-free modal logic, under the
natural assumptions that combination functions are continuous and
classification functions are thresholds. This implies that, relative to MSO and
in the uniform setting, mean GNNs are strictly less expressive than sum GNNs
and max GNNs. When any of the assumptions is dropped, the expressive power
increases.

</details>


### [12] [Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory](https://arxiv.org/abs/2507.18178)
*Mutian Yang,Jiandong Gao,Ji Wu*

Main category: cs.AI

TL;DR: 该研究提出一个框架，区分大型语言模型的知识和推理能力，发现推理能力具有领域特异性，参数扩展提升知识和推理，且知识主要储存在较低网络层，推理在较高网络层。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解大型语言模型（LLM）的知识和推理能力，并改进模型分析、可解释性和开发。

Method: 该研究通过设计两种不同的认知模式（快速思维和慢速思维）来提示LLM生成答案，并分析不同模式下的性能来分离知识检索和推理调整两个阶段。

Result: 研究结果揭示了推理调整的领域特异性、参数扩展对知识和推理能力的影响，以及知识和推理在网络层中的分布。

Conclusion: 该研究提出了一种认知归因框架，将大型语言模型（LLM）的认知过程分解为知识检索和推理调整两个阶段，并通过分析不同认知模式下的性能来量化知识和推理的贡献。研究结果表明，推理调整具有领域特异性，参数扩展提高了知识和推理能力，知识主要存在于较低的网络层，而推理则在较高的网络层进行。

Abstract: While large language models (LLMs) leverage both knowledge and reasoning
during inference, the capacity to distinguish between them plays a pivotal role
in model analysis, interpretability, and development. Inspired by dual-system
cognitive theory, we propose a cognition attribution framework to decouple the
contribution of knowledge and reasoning. In particular, the cognition of LLMs
is decomposed into two distinct yet complementary phases: knowledge retrieval
(Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs
are prompted to generate answers under two different cognitive modes, fast
thinking and slow thinking, respectively. The performance under different
cognitive modes is analyzed to quantify the contribution of knowledge and
reasoning. This architecture is employed to 15 LLMs across 3 datasets. Results
reveal: (1) reasoning adjustment is domain-specific, benefiting
reasoning-intensive domains (e.g., mathematics, physics, and chemistry) and
potentially imparing knowledge-intensive domains. (2) Parameter scaling
improves both knowledge and reasoning, with knowledge improvements being more
pronounced. Additionally, parameter scaling make LLMs reasoning significantly
more prudent, while moderately more intelligent. (3) Knowledge primarily
resides in lower network layers, while reasoning operates in higher layers. Our
framework not only helps understand LLMs from a "decoupling" perspective, but
also provides new insights into existing research, including scaling laws,
hierarchical knowledge editing, and limitations of small-model reasoning.

</details>


### [13] [Comparing Non-minimal Semantics for Disjunction in Answer Set Programming](https://arxiv.org/abs/2507.18198)
*Felicidad Aguado,Pedro Cabalar,Brais Muñiz,Gilberto Pérez,Concepción Vidal*

Main category: cs.AI

TL;DR: 四种非极小语义中三种等价，且强于第四种。


<details>
  <summary>Details</summary>
Motivation: 比较四种不同的非极小语义，研究它们之间的关系。

Method: 比较了四种不同的Answer Set Programming中非极小语义：Justified Models, Strongly Supported Models, Forks和DI semantics。

Result: 证明了其中三种语义等价，并与第四种语义进行了比较。

Conclusion: 本文证明了Answer Set Programming中三种非极小语义（Forks, Justified Models和DI semantics的合理弱化）实际上是等价的，构成了一种共同的语义。这种语义总是包含程序的稳定模型的超集，并且严格强于第四种方法（Strongly Supported Models）。

Abstract: In this paper, we compare four different semantics for disjunction in Answer
Set Programming that, unlike stable models, do not adhere to the principle of
model minimality. Two of these approaches, Cabalar and Mu\~niz' \emph{Justified
Models} and Doherty and Szalas' \emph{Strongly Supported Models}, directly
provide an alternative non-minimal semantics for disjunction. The other two,
Aguado et al's \emph{Forks} and Shen and Eiter's \emph{Determining Inference}
(DI) semantics, actually introduce a new disjunction connective, but are
compared here as if they constituted new semantics for the standard disjunction
operator. We are able to prove that three of these approaches (Forks, Justified
Models and a reasonable relaxation of the DI semantics) actually coincide,
constituting a common single approach under different definitions. Moreover,
this common semantics always provides a superset of the stable models of a
program (in fact, modulo any context) and is strictly stronger than the fourth
approach (Strongly Supported Models), that actually treats disjunctions as in
classical logic.

</details>


### [14] [Foundations for Risk Assessment of AI in Protecting Fundamental Rights](https://arxiv.org/abs/2507.18290)
*Antonino Rotolo,Beatrice Ferrigno,Jose Miguel Angel Garcia Godinez,Claudio Novelli,Giovanni Sartor*

Main category: cs.AI

TL;DR: 提出一个整合定义性平衡和可反驳推理的AI风险评估概念框架，以解决法律合规和基本权利保护的复杂性，并为负责任的AI治理提供支持。


<details>
  <summary>Details</summary>
Motivation: 解决欧盟人工智能法案背景下，人工智能风险评估中法律合规性和基本权利保护的复杂性。

Method: 整合定义性平衡和可反驳的推理，对AI部署场景进行分析，识别潜在的法律违规行为和对基本权利的多层影响。

Result: 提供了一个用于人工智能风险评估的概念框架，并为AI风险分析的逻辑解释提供了哲学基础。

Conclusion: 提出了一个用于人工智能风险评估的概念框架，特别是在欧盟人工智能法案的背景下，该框架通过整合定义性平衡和可反驳的推理来解决法律合规性和基本权利保护的复杂性。

Abstract: This chapter introduces a conceptual framework for qualitative risk
assessment of AI, particularly in the context of the EU AI Act. The framework
addresses the complexities of legal compliance and fundamental rights
protection by itegrating definitional balancing and defeasible reasoning.
Definitional balancing employs proportionality analysis to resolve conflicts
between competing rights, while defeasible reasoning accommodates the dynamic
nature of legal decision-making. Our approach stresses the need for an analysis
of AI deployment scenarios and for identifying potential legal violations and
multi-layered impacts on fundamental rights. On the basis of this analysis, we
provide philosophical foundations for a logical account of AI risk analysis. In
particular, we consider the basic building blocks for conceptually grasping the
interaction between AI deployment scenarios and fundamental rights,
incorporating in defeasible reasoning definitional balancing and arguments
about the contextual promotion or demotion of rights. This layered approach
allows for more operative models of assessment of both high-risk AI systems and
General Purpose AI (GPAI) systems, emphasizing the broader applicability of the
latter. Future work aims to develop a formal model and effective algorithms to
enhance AI risk assessment, bridging theoretical insights with practical
applications to support responsible AI governance.

</details>


### [15] [The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams](https://arxiv.org/abs/2507.18337)
*Peter Baumgartner,Lachlan McGinness*

Main category: cs.AI

TL;DR: 提出一种结合多种技术的自动批改物理考试方法，并在真实数据上进行了有效性验证。


<details>
  <summary>Details</summary>
Motivation: 自动批改物理考试是一项具有挑战性的任务，旨在提高批改效率和准确性。

Method: 结合计算机代数系统、SMT求解器和项重写系统，利用大型语言模型处理学生答案，并采用自动定理证明技术评估答案正确性。

Result: 在2023年澳大利亚物理奥林匹克竞赛的1500多份真实学生考试答案上评估了该系统。

Conclusion: 本文提出了一种自动批改物理考试的方法，该方法结合了计算机代数系统、SMT求解器和项重写系统，并利用大型语言模型处理学生答案，最终在1500份真实学生考试答案上进行了评估。

Abstract: We present our method for automatically marking Physics exams. The marking
problem consists in assessing typed student answers for correctness with
respect to a ground truth solution. This is a challenging problem that we seek
to tackle using a combination of a computer algebra system, an SMT solver and a
term rewriting system. A Large Language Model is used to interpret and remove
errors from student responses and rewrite these in a machine readable format.
Once formalized and language-aligned, the next step then consists in applying
automated reasoning techniques for assessing student solution correctness. We
consider two methods of automated theorem proving: off-the-shelf SMT solving
and term rewriting systems tailored for physics problems involving
trigonometric expressions. The development of the term rewrite system and
establishing termination and confluence properties was not trivial, and we
describe it in some detail in the paper. We evaluate our system on a rich pool
of over 1500 real-world student exam responses from the 2023 Australian Physics
Olympiad.

</details>


### [16] [Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios](https://arxiv.org/abs/2507.18368)
*Zhuang Qiang Bok,Watson Wei Khong Chua*

Main category: cs.AI

TL;DR: ConDiFi基准评估了LLM在金融领域的推理能力，发现模型在发散性与收敛性思维方面存在差异，为LLM在金融领域的应用提供了新的评估视角。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理基准侧重于事实准确性和逐步逻辑，而金融领域需要创造性和在不确定性下的未来预测能力。

Method: 构建ConDiFi基准，包含607个宏观金融提示用于发散推理和990个多跳对抗性MCQ用于收敛推理，评估了14个领先模型。

Result: 发现GPT-4o等模型在创新性和可操作性方面表现不足，DeepSeek-R1和Cohere Command R+等模型表现优秀。

Conclusion: ConDiFi基准测试揭示了LLM在金融任务中，尤其是在发散性和收敛性思维方面的显著差异，GPT-4o在创新性和可操作性方面表现欠佳，而DeepSeek-R1和Cohere Command R+等模型在生成可用于投资决策的行动见解方面表现出色。

Abstract: Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step
logic. In finance, however, professionals must not only converge on optimal
decisions but also generate creative, plausible futures under uncertainty. We
introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent
thinking in LLMs for financial tasks.
  ConDiFi features 607 macro-financial prompts for divergent reasoning and 990
multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we
evaluated 14 leading models and uncovered striking differences. Despite high
fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models
like DeepSeek-R1 and Cohere Command R+ rank among the top for generating
actionable, insights suitable for investment decisions. ConDiFi provides a new
perspective to assess reasoning capabilities essential to safe and strategic
deployment of LLMs in finance.

</details>
