<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Revisiting Rule-Based Stuttering Detection: A Comprehensive Analysis of Interpretable Models for Clinical Applications](https://arxiv.org/abs/2508.16681)
*Eric Zhang*

Main category: cs.AI

TL;DR: 基于规则的口吃检测系统在临床应用中具有独特优势，可与现代机器学习管道集成。


<details>
  <summary>Details</summary>
Motivation: 目前的深度学习方法在口吃检测方面取得了进展，但基于规则的方法在临床应用中仍然至关重要，因为其可解释性和透明度是重中之重。

Method: 提出了一种增强的基于规则的口吃检测框架，该框架结合了语速归一化、多层次声学特征分析和分层决策结构。

Result: 该方法在保持完全可解释性的同时，实现了具有竞争力的性能，尤其擅长检测延长音（97-99%的准确率），并在不同语速下表现稳定。

Conclusion: 本文对基于规则的口吃检测系统进行了全面分析，提出了一种增强的基于规则的框架，该框架在保持完全可解释性的同时，实现了具有竞争力的性能，尤其擅长检测延长音，并在不同语速下表现稳定。基于规则的方法在需要决策可审计性、特定患者调整和实时反馈的临床环境中具有独特的优势。

Abstract: Stuttering affects approximately 1% of the global population, impacting
communication and quality of life. While recent advances in deep learning have
pushed the boundaries of automatic speech dysfluency detection, rule-based
approaches remain crucial for clinical applications where interpretability and
transparency are paramount. This paper presents a comprehensive analysis of
rule-based stuttering detection systems, synthesizing insights from multiple
corpora including UCLASS, FluencyBank, and SEP-28k. We propose an enhanced
rule-based framework that incorporates speaking-rate normalization, multi-level
acoustic feature analysis, and hierarchical decision structures. Our approach
achieves competitive performance while maintaining complete
interpretability-critical for clinical adoption. We demonstrate that rule-based
systems excel particularly in prolongation detection (97-99% accuracy) and
provide stable performance across varying speaking rates. Furthermore, we show
how these interpretable models can be integrated with modern machine learning
pipelines as proposal generators or constraint modules, bridging the gap
between traditional speech pathology practices and contemporary AI systems. Our
analysis reveals that while neural approaches may achieve marginally higher
accuracy in unconstrained settings, rule-based methods offer unique advantages
in clinical contexts where decision auditability, patient-specific tuning, and
real-time feedback are essential.

</details>


### [2] [Explainable AI for Predicting and Understanding Mathematics Achievement: A Cross-National Analysis of PISA 2018](https://arxiv.org/abs/2508.16747)
*Liu Liu,Rui Dai*

Main category: cs.AI

TL;DR: 利用机器学习模型分析PISA数据，发现影响学生数学成绩的关键因素，并强调了教育政策应考虑非线性关系和国家间的差异性。


<details>
  <summary>Details</summary>
Motivation: 理解影响学生数学成绩的因素，为制定有效的教育政策至关重要。

Method: 应用可解释人工智能（XAI）技术，包括多元线性回归、随机森林、CATBoost和人工神经网络等模型，对PISA 2018数据进行分析。

Result: 非线性模型（特别是随机森林和人工神经网络）的预测性能优于线性模型； 关键预测因素包括社会经济地位、学习时间、教师积极性和学生对数学的态度，但其影响在不同国家之间存在差异。

Conclusion: 本研究利用可解释人工智能技术，结合PISA 2018数据，预测数学成绩并识别关键预测因素，发现非线性模型（如随机森林）优于线性模型，关键预测因素包括社会经济地位、学习时间、教师积极性和学生态度等，其影响因国家而异。

Abstract: Understanding the factors that shape students' mathematics performance is
vital for designing effective educational policies. This study applies
explainable artificial intelligence (XAI) techniques to PISA 2018 data to
predict math achievement and identify key predictors across ten countries
(67,329 students). We tested four models: Multiple Linear Regression (MLR),
Random Forest (RF), CATBoost, and Artificial Neural Networks (ANN), using
student, family, and school variables. Models were trained on 70% of the data
(with 5-fold cross-validation) and tested on 30%, stratified by country.
Performance was assessed with R^2 and Mean Absolute Error (MAE). To ensure
interpretability, we used feature importance, SHAP values, and decision tree
visualizations. Non-linear models, especially RF and ANN, outperformed MLR,
with RF balancing accuracy and generalizability. Key predictors included
socio-economic status, study time, teacher motivation, and students' attitudes
toward mathematics, though their impact varied across countries. Visual
diagnostics such as scatterplots of predicted vs actual scores showed RF and
CATBoost aligned closely with actual performance. Findings highlight the
non-linear and context-dependent nature of achievement and the value of XAI in
educational research. This study uncovers cross-national patterns, informs
equity-focused reforms, and supports the development of personalized learning
strategies.

</details>


### [3] [Evaluation and LLM-Guided Learning of ICD Coding Rationales](https://arxiv.org/abs/2508.16777)
*Mingyang Li,Viktor Schlegel,Tingting Mu,Wuraola Oyewusi,Kai Kang,Goran Nenadic*

Main category: cs.AI

TL;DR: 本文评估了ICD编码解释的合理性，构建新的数据集并提出改进模型解释的新方法，结果表明LLM生成的解释最接近人类专家，少量人工标注数据能进一步提升效果。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习模型虽然提高了ICD编码的准确性和效率，但缺乏可解释性，本文旨在提高ICD编码的可解释性。

Method: 本文通过两个关键视角（忠实性和合理性）评估了ICD编码的合理性，并构建了一个新的带有注释的数据库，用于评估三种类型的ICD编码的合理性。此外，提出了新的合理性学习方法，利用LLM生成的理由作为远程监督信号。

Result: 构建了一个新的带有注释的数据库，并提出了一种新的合理性学习方法，该方法利用LLM生成的理由作为远程监督信号，提高了模型生成的合理性的质量。实验结果表明，LLM生成的理由与人类专家的理由最接近，并且加入少量人工标注的例子可以进一步提高理由生成和理由学习方法。

Conclusion: 本文对ICD编码的合理性进行了全面的评估，并提出了一种新的合理性学习方法，以提高模型生成的合理性的质量。实验结果表明，LLM生成的理由与人类专家的理由最接近，并且加入少量人工标注的例子可以进一步提高理由生成和理由学习方法。

Abstract: Automated clinical coding involves mapping unstructured text from Electronic
Health Records (EHRs) to standardized code systems such as the International
Classification of Diseases (ICD). While recent advances in deep learning have
significantly improved the accuracy and efficiency of ICD coding, the lack of
explainability in these models remains a major limitation, undermining trust
and transparency. Current explorations about explainability largely rely on
attention-based techniques and qualitative assessments by physicians, yet lack
systematic evaluation using consistent criteria on high-quality rationale
datasets, as well as dedicated approaches explicitly trained to generate
rationales for further enhancing explanation. In this work, we conduct a
comprehensive evaluation of the explainability of the rationales for ICD coding
through two key lenses: faithfulness that evaluates how well explanations
reflect the model's actual reasoning and plausibility that measures how
consistent the explanations are with human expert judgment. To facilitate the
evaluation of plausibility, we construct a new rationale-annotated dataset,
offering denser annotations with diverse granularity and aligns better with
current clinical practice, and conduct evaluation across three types of
rationales of ICD coding. Encouraged by the promising plausibility of
LLM-generated rationales for ICD coding, we further propose new rationale
learning methods to improve the quality of model-generated rationales, where
rationales produced by prompting LLMs with/without annotation examples are used
as distant supervision signals. We empirically find that LLM-generated
rationales align most closely with those of human experts. Moreover,
incorporating few-shot human-annotated examples not only further improves
rationale generation but also enhances rationale-learning approaches.

</details>


### [4] [PuzzleJAX: A Benchmark for Reasoning and Learning](https://arxiv.org/abs/2508.16821)
*Sam Earle,Graham Todd,Yuchen Li,Ahmed Khalifa,Muhammad Umair Nasir,Zehua Jiang,Andrzej Banburski-Fahey,Julian Togelius*

Main category: cs.AI

TL;DR: PuzzleJAX是一个GPU加速的益智游戏引擎，支持快速基准测试多种AI算法，并验证了其在广泛游戏上的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了支持快速基准测试树搜索、强化学习和LLM推理能力，并提供一个可以动态编译各种益智游戏的平台。

Method: 设计了一个GPU加速的益智游戏引擎和描述语言PuzzleJAX，并用其验证了数百个PuzzleScript游戏。

Result: 验证了PuzzleJAX可以表达简单易懂但极具挑战性的任务，需要结合控制、规划和高层次的洞察力。

Conclusion: PuzzleJAX是一个GPU加速的益智游戏引擎和描述语言，用于支持快速基准测试树搜索、强化学习和LLM推理能力。它可以动态编译任何可以用其特定领域语言（DSL）表达的游戏，并验证了数百个PuzzleScript游戏，展示了其对广泛且具有挑战性任务的覆盖能力。

Abstract: We introduce PuzzleJAX, a GPU-accelerated puzzle game engine and description
language designed to support rapid benchmarking of tree search, reinforcement
learning, and LLM reasoning abilities. Unlike existing GPU-accelerated learning
environments that provide hard-coded implementations of fixed sets of games,
PuzzleJAX allows dynamic compilation of any game expressible in its
domain-specific language (DSL). This DSL follows PuzzleScript, which is a
popular and accessible online game engine for designing puzzle games. In this
paper, we validate in PuzzleJAX several hundred of the thousands of games
designed in PuzzleScript by both professional designers and casual creators
since its release in 2013, thereby demonstrating PuzzleJAX's coverage of an
expansive, expressive, and human-relevant space of tasks. By analyzing the
performance of search, learning, and language models on these games, we show
that PuzzleJAX can naturally express tasks that are both simple and intuitive
to understand, yet often deeply challenging to master, requiring a combination
of control, planning, and high-level insight.

</details>


### [5] [Route-and-Execute: Auditable Model-Card Matching and Specialty-Level Deployment](https://arxiv.org/abs/2508.16839)
*Shayan Vassef,Soorya Ram Shimegekar,Abhay Goyal,Koustuv Saha,Pi Zonooz,Navin Kumar*

Main category: cs.AI

TL;DR: 单一VLM模型可同时进行模型选择和任务执行，有效整合医疗临床工作流程，提高效率并降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有的临床工作流程支离破碎，效率低下且成本高昂。

Method: 该框架使用单一VLM扮演两个角色：1. 作为模型匹配器，根据图像内容选择合适的专业模型；2. 通过微调，覆盖多个下游任务。

Result: 该框架在多个专业领域实现了与专用模型相当或接近的性能，并降低了数据科学家的工作量，缩短了监控时间，提高了模型选择的透明度，降低了集成开销。

Conclusion: 该论文提出一个基于单一视觉语言模型 (VLM) 的医疗保健框架，用于整合临床工作流程，提高效率并降低运营成本。该框架在胃肠病学、血液学、眼科和病理学等多个领域实现了与专用模型相当或接近的性能。

Abstract: Clinical workflows are fragmented as a patchwork of scripts and task-specific
networks that often handle triage, task selection, and model deployment. These
pipelines are rarely streamlined for data science pipeline, reducing efficiency
and raising operational costs. Workflows also lack data-driven model
identification (from imaging/tabular inputs) and standardized delivery of model
outputs. In response, we present a practical, healthcare-first framework that
uses a single vision-language model (VLM) in two complementary roles. First
(Solution 1), the VLM acts as an aware model-card matcher that routes an
incoming image to the appropriate specialist model via a three-stage workflow
(modality -> primary abnormality -> model-card id). Checks are provided by (i)
stagewise prompts that allow early exit via None/Normal/Other and (ii) a
stagewise answer selector that arbitrates between the top-2 candidates at each
stage, reducing the chance of an incorrect selection and aligning the workflow
with clinical risk tolerance. Second (Solution 2), we fine-tune the VLM on
specialty-specific datasets ensuring a single model covers multiple downstream
tasks within each specialty, maintaining performance while simplifying
deployment. Across gastroenterology, hematology, ophthalmology, and pathology,
our single-model deployment matches or approaches specialized baselines.
  Compared with pipelines composed of many task-specific agents, this approach
shows that one VLM can both decide and do. It may reduce effort by data
scientists, shorten monitoring, increase the transparency of model selection
(with per-stage justifications), and lower integration overhead.

</details>


### [6] [Quantifying Sycophancy as Deviations from Bayesian Rationality in LLMs](https://arxiv.org/abs/2508.16846)
*Katherine Atwell,Pedram Heydari,Anthony Sicilia,Malihe Alikhani*

Main category: cs.AI

TL;DR: 研究发现大型语言模型存在谄媚行为，该行为会导致其偏离理性，并影响贝叶斯误差，但其影响并非总是负面的，且与现有评价指标的相关性不强。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常通过测量行为变化或准确性影响来量化LLM的谄媚行为，但这些指标不能很好地刻画理性行为的转变，且准确性测量仅适用于存在已知真实结果的情况。

Method: 利用贝叶斯框架量化LLM在面对用户观点时的理性行为偏差，通过比较不同任务、不同LLM和不同探测方法下的结果来研究谄媚行为。

Result: 1) LLM并非贝叶斯理性；2) 探测谄媚行为会导致预测后验概率向引导结果倾斜；3) 谄媚行为有时增加贝叶斯误差，有时反而降低误差；4) 谄媚行为导致的贝叶斯误差变化与Brier评分的相关性不强。

Conclusion: 大型语言模型(LLM)的谄媚行为会导致其在面对用户观点时偏离理性行为，这种偏离可以用贝叶斯框架量化。研究发现，LLM并非贝叶斯理性的，探测谄媚行为会导致预测后验概率向引导结果倾斜，有时增加贝叶斯误差，有时反而降低误差。谄媚行为对贝叶斯误差的影响与Brier评分的相关性不强，表明仅研究其对真实结果的影响不足以完全捕捉由于谄媚行为造成的推理错误。

Abstract: Sycophancy, or overly agreeable or flattering behavior, is a documented issue
in large language models (LLMs), and is critical to understand in the context
of human/AI collaboration. Prior works typically quantify sycophancy by
measuring shifts in behavior or impacts on accuracy, but neither metric
characterizes shifts in rationality, and accuracy measures can only be used in
scenarios with a known ground truth. In this work, we utilize a Bayesian
framework to quantify sycophancy as deviations from rational behavior when
presented with user perspectives, thus distinguishing between rational and
irrational updates based on the introduction of user perspectives. In
comparison to other methods, this approach allows us to characterize excessive
behavioral shifts, even for tasks that involve inherent uncertainty or do not
have a ground truth. We study sycophancy for 3 different tasks, a combination
of open-source and closed LLMs, and two different methods for probing
sycophancy. We also experiment with multiple methods for eliciting probability
judgments from LLMs. We hypothesize that probing LLMs for sycophancy will cause
deviations in LLMs' predicted posteriors that will lead to increased Bayesian
error. Our findings indicate that: 1) LLMs are not Bayesian rational, 2)
probing for sycophancy results in significant increases to the predicted
posterior in favor of the steered outcome, 3) sycophancy sometimes results in
increased Bayesian error, and in a small number of cases actually decreases
error, and 4) changes in Bayesian error due to sycophancy are not strongly
correlated in Brier score, suggesting that studying the impact of sycophancy on
ground truth alone does not fully capture errors in reasoning due to
sycophancy.

</details>


### [7] [RADAR: A Reasoning-Guided Attribution Framework for Explainable Visual Data Analysis](https://arxiv.org/abs/2508.16850)
*Anku Rani,Aparna Garimella,Apoorv Saxena,Balaji Vasan Srinivasan,Paul Pu Liang*

Main category: cs.AI

TL;DR: 提出一种改进MLLMs图表分析可解释性的方法，提高了准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: MLLMs在图表分析中缺乏可解释性，难以建立信任。

Method: 提出RADAR数据集和一种推理引导的归因方法。

Result: 推理引导的方法将归因准确率提高了15%，BERTScore达到约0.90。

Conclusion: 该论文提出RADAR，一种半自动方法，用于创建包含图表、问题、推理步骤和归因注释的基准数据集，并引入一种为基于图表进行数学推理提供归因的方法，从而提高了模型的可解释性和可信度。

Abstract: Data visualizations like charts are fundamental tools for quantitative
analysis and decision-making across fields, requiring accurate interpretation
and mathematical reasoning. The emergence of Multimodal Large Language Models
(MLLMs) offers promising capabilities for automated visual data analysis, such
as processing charts, answering questions, and generating summaries. However,
they provide no visibility into which parts of the visual data informed their
conclusions; this black-box nature poses significant challenges to real-world
trust and adoption. In this paper, we take the first major step towards
evaluating and enhancing the capabilities of MLLMs to attribute their reasoning
process by highlighting the specific regions in charts and graphs that justify
model answers. To this end, we contribute RADAR, a semi-automatic approach to
obtain a benchmark dataset comprising 17,819 diverse samples with charts,
questions, reasoning steps, and attribution annotations. We also introduce a
method that provides attribution for chart-based mathematical reasoning.
Experimental results demonstrate that our reasoning-guided approach improves
attribution accuracy by 15% compared to baseline methods, and enhanced
attribution capabilities translate to stronger answer generation, achieving an
average BERTScore of $\sim$ 0.90, indicating high alignment with ground truth
responses. This advancement represents a significant step toward more
interpretable and trustworthy chart analysis systems, enabling users to verify
and understand model decisions through reasoning and attribution.

</details>


### [8] [Complexity in finitary argumentation (extended version)](https://arxiv.org/abs/2508.16986)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 有限无限 AFs 为推理提供了一个良好的设置，兼顾了表达能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决无限 AFs 的计算难处理性限制了其在许多理论应用中的使用。

Method: 研究了与无限但有限论证框架相关的计算问题的复杂性。

Result: 有限性假设并不自动保证复杂性降低，但对于基于可容许性的语义，发现了一个显著的组合约束，导致复杂性急剧下降。

Conclusion: 无穷但有限论证框架 (AFs) 为许多推理形式提供了一种自然的设置，它平衡了表达能力和计算易处理性。

Abstract: Abstract argumentation frameworks (AFs) provide a formal setting to analyze
many forms of reasoning with conflicting information. While the expressiveness
of general infinite AFs make them a tempting tool for modeling many kinds of
reasoning scenarios, the computational intractability of solving infinite AFs
limit their use, even in many theoretical applications.
  We investigate the complexity of computational problems related to infinite
but finitary argumentations frameworks, that is, infinite AFs where each
argument is attacked by only finitely many others. Our results reveal a
surprising scenario. On one hand, we see that the assumption of being finitary
does not automatically guarantee a drop in complexity. However, for the
admissibility-based semantics, we find a remarkable combinatorial constraint
which entails a dramatic decrease in complexity.
  We conclude that for many forms of reasoning, the finitary infinite AFs
provide a natural setting for reasoning which balances well the competing goals
of being expressive enough to be applied to many reasoning settings while being
computationally tractable enough for the analysis within the framework to be
useful.

</details>


### [9] [WebSight: A Vision-First Architecture for Robust Web Agents](https://arxiv.org/abs/2508.16987)
*Tanvir Bhathal,Asanshay Gupta*

Main category: cs.AI

TL;DR: WebSight，一个基于视觉的网页代理，使用新的视觉语言模型 WebSight-7B，在网页导航基准测试中取得了领先的结果。


<details>
  <summary>Details</summary>
Motivation: 消除对基于 HTML 或 DOM 的输入的依赖，实现完全基于视觉感知的网页交互。

Method: 提出了一种基于视觉的自主网页代理 WebSight，该代理完全通过视觉感知与网页环境交互，并引入新的模型 WebSight-7B（一个针对 UI 元素交互进行了优化的视觉语言模型），并将其集成到一个模块化的多智能体架构中。

Result: WebSight-7B 在 Showdown Clicks 基准测试中 top-1 准确率达 58.84%，WebSight 在 WebVoyager 基准测试中成功率达 68.0%，且准确率达 97.14%。

Conclusion: WebSight 和 WebSight-7B 模型在可解释性、鲁棒性和效率方面为可视化网页导航设定了新标准。WebSight-7B 在 Showdown Clicks 基准测试中取得了 58.84% 的 top-1 准确率，优于其他大型通用模型；WebSight 完整代理在 WebVoyager 基准测试中取得了 68.0% 的成功率，超过了 OpenAI 和 HCompany 等实验室的系统。

Abstract: We introduce WebSight, a vision-based autonomous web agent, designed to
interact with web environments purely through visual perception, eliminating
dependence on HTML or DOM-based inputs. Central to our approach we introduce
our new model, WebSight-7B, a fine-tuned vision-language model optimized for UI
element interaction, trained using LoRA on a web-focused subset of the
Wave-UI-25K dataset. WebSight integrates this model into a modular multi-agent
architecture, comprising planning, reasoning, vision-action, and verification
agents, coordinated through an episodic memory mechanism.
  WebSight-7B achieves a top-1 accuracy of 58.84% on the Showdown Clicks
benchmark, outperforming several larger generalist models while maintaining
lower latency. The full WebSight agent achieves a 68.0% success rate on the
WebVoyager benchmark, surpassing systems from labs such as OpenAI (61.0%) and
HCompany (Runner H, 67.0%). Among tasks completed, WebSight answers correctly
97.14% of the time, indicating high precision. Together, WebSight and
WebSight-7B establish a new standard for interpretable, robust, and efficient
visual web navigation.

</details>


### [10] [Solving the Min-Max Multiple Traveling Salesmen Problem via Learning-Based Path Generation and Optimal Splitting](https://arxiv.org/abs/2508.17087)
*Wen Wang,Xiangchen Wu,Liang Wang,Hao Hu,Xianping Tao,Linghao Zhang*

Main category: cs.AI

TL;DR: 针对Min-Max多旅行商问题，提出一种名为生成与分割的两阶段强化学习框架，显著提高了解决方案质量和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 解决Min-Max多旅行商问题（m3-TSP），该问题旨在协调多个销售人员的路线，使最长路线长度最小化。

Method: 提出了一种名为生成与分割（GaS）的两阶段框架，该框架结合了强化学习和最优分割算法。

Result: GaS框架在解决方案质量和可迁移性方面显著优于现有的基于学习的方法。

Conclusion: 提出了一种名为生成与分割的新型两阶段框架（GaS），该框架将强化学习（RL）与最优分割算法集成到联合训练过程中，显著优于现有的基于学习的方法。

Abstract: This study addresses the Min-Max Multiple Traveling Salesmen Problem
($m^3$-TSP), which aims to coordinate tours for multiple salesmen such that the
length of the longest tour is minimized. Due to its NP-hard nature, exact
solvers become impractical under the assumption that $P \ne NP$. As a result,
learning-based approaches have gained traction for their ability to rapidly
generate high-quality approximate solutions. Among these, two-stage methods
combine learning-based components with classical solvers, simplifying the
learning objective. However, this decoupling often disrupts consistent
optimization, potentially degrading solution quality. To address this issue, we
propose a novel two-stage framework named \textbf{Generate-and-Split} (GaS),
which integrates reinforcement learning (RL) with an optimal splitting
algorithm in a joint training process. The splitting algorithm offers
near-linear scalability with respect to the number of cities and guarantees
optimal splitting in Euclidean space for any given path. To facilitate the
joint optimization of the RL component with the algorithm, we adopt an
LSTM-enhanced model architecture to address partial observability. Extensive
experiments show that the proposed GaS framework significantly outperforms
existing learning-based approaches in both solution quality and
transferability.

</details>


### [11] [PowerChain: Automating Distribution Grid Analysis with Agentic AI Workflows](https://arxiv.org/abs/2508.17094)
*Emmanuel O. Badmus,Peng Sang,Dimitrios Stamoulis,Amritanshu Pandey*

Main category: cs.AI

TL;DR: PowerChain: 一种新型AI系统，使用LLM自动执行配电网分析任务，能够生成专家级工作流程。


<details>
  <summary>Details</summary>
Motivation: 配电网(DG)的电气化和脱碳速度加快，使得配电网的运行和规划更加复杂，需要先进的计算分析来确保电网的可靠性和弹性。许多小型公用事业公司和合作社缺乏大型研发队伍，因此无法大规模使用高级分析。

Method: 使用基于代理的AI系统和大型语言模型(LLM)函数调用，根据专家构建的电力系统函数池和已知的专家生成的工作流程查询对参考集，动态生成和执行一系列特定领域的函数。

Result: 结果表明，PowerChain能够使用GPT-5和开源Qwen模型在复杂、未知的配电网分析任务中，使用真实的公用事业数据生成专家级工作流程。

Conclusion: 开发了一种名为PowerChain的新型AI系统，用于解决配电网分析任务，该系统能够通过自动化代理协调和大型语言模型函数调用来生成和执行专家级工作流程。

Abstract: Due to the rapid pace of electrification and decarbonization, distribution
grid (DG) operation and planning are becoming more complex, necessitating
advanced computational analyses to ensure grid reliability and resilience.
State-of-the-art DG analyses rely on disparate workflows of complex models,
functions, and data pipelines, which require expert knowledge and are
challenging to automate. Many small-scale utilities and cooperatives lack a
large R&D workforce and therefore cannot use advanced analysis at scale. To
address this gap, we develop a novel agentic AI system, PowerChain, to solve
unseen DG analysis tasks via automated agentic orchestration and large language
models (LLMs) function-calling. Given a natural language query, PowerChain
dynamically generates and executes an ordered sequence of domain-aware
functions guided by the semantics of an expert-built power systems function
pool and a select reference set of known, expert-generated workflow-query
pairs. Our results show that PowerChain can produce expert-level workflows with
both GPT-5 and open-source Qwen models on complex, unseen DG analysis tasks
operating on real utility data.

</details>


### [12] [Rethinking How AI Embeds and Adapts to Human Values: Challenges and Opportunities](https://arxiv.org/abs/2508.17104)
*Sz-Ting Tzeng,Frank Dignum*

Main category: cs.AI

TL;DR: 价值对齐应超越静态单一价值观，需考虑长期推理和适应性，多智能体系统是应对价值观多元化的有效框架。


<details>
  <summary>Details</summary>
Motivation: 当前“以人为本的AI”和“基于价值的决策”研究中，价值对齐的许多关键方面仍未得到充分探索，例如系统如何整合人类价值观、人类如何识别系统中的价值观以及如何最小化风险和意外后果。

Method: 该论文通过分析现有价值对齐方法的不足，提出了一种基于多智能体系统，能够处理长期推理和适应性价值观变化的新框架。

Result: 论文识别了价值对齐相关的挑战，并指明了未来研究方向，同时广泛讨论了从设计方法到实际应用的各种视角。

Conclusion: 该论文强调需要重新思考价值对齐的框架，主张其应超越静态和单一价值观，并适应不断变化的价值观。多智能体系统为应对价值观多元化、冲突和交互式推理提供了合适的框架。

Abstract: The concepts of ``human-centered AI'' and ``value-based decision'' have
gained significant attention in both research and industry. However, many
critical aspects remain underexplored and require further investigation. In
particular, there is a need to understand how systems incorporate human values,
how humans can identify these values within systems, and how to minimize the
risks of harm or unintended consequences. In this paper, we highlight the need
to rethink how we frame value alignment and assert that value alignment should
move beyond static and singular conceptions of values. We argue that AI systems
should implement long-term reasoning and remain adaptable to evolving values.
Furthermore, value alignment requires more theories to address the full
spectrum of human values. Since values often vary among individuals or groups,
multi-agent systems provide the right framework for navigating pluralism,
conflict, and inter-agent reasoning about values. We identify the challenges
associated with value alignment and indicate directions for advancing value
alignment research. In addition, we broadly discuss diverse perspectives of
value alignment, from design methodologies to practical applications.

</details>


### [13] [MaRVL-QA: A Benchmark for Mathematical Reasoning over Visual Landscapes](https://arxiv.org/abs/2508.17180)
*Nilay Pande,Sahiti Yerramilli,Jayant Sravan Tamarapalli,Rynaa Grover*

Main category: cs.AI

TL;DR: 新的MaRVL-QA基准测试显示，目前的MLLM在数学和空间推理方面仍有很大的改进空间。


<details>
  <summary>Details</summary>
Motivation: 评估多模态大型语言模型(MLLM)进行深度数学和空间推理的能力。数学表面图提供了一个严格的测试平台，因为它将推理任务与自然图像中常见的语义噪声隔离开来。

Method: 提出MaRVL-QA基准，包含拓扑计数和变换识别两项新任务，用于评估MLLM进行数学和空间推理的能力。

Result: 即使是最先进的MLLM，在MaRVL-QA基准测试中也表现不佳，这揭示了当前模型的局限性，并为未来研究提供了方向。

Conclusion: MaRVL-QA基准测试显示，即使是最先进的多模态大型语言模型(MLLM)也难以进行深层次的数学和空间推理，经常采用表面启发式方法而不是强大的空间推理能力。

Abstract: A key frontier for Multimodal Large Language Models (MLLMs) is the ability to
perform deep mathematical and spatial reasoning directly from images, moving
beyond their established success in semantic description. Mathematical surface
plots provide a rigorous testbed for this capability, as they isolate the task
of reasoning from the semantic noise common in natural images. To measure
progress on this frontier, we introduce MaRVL-QA (Mathematical Reasoning over
Visual Landscapes), a new benchmark designed to quantitatively evaluate these
core reasoning skills. The benchmark comprises two novel tasks: Topological
Counting, identifying and enumerating features like local maxima; and
Transformation Recognition, recognizing applied geometric transformations.
Generated from a curated library of functions with rigorous ambiguity
filtering, our evaluation on MaRVL-QA reveals that even state-of-the-art MLLMs
struggle significantly, often resorting to superficial heuristics instead of
robust spatial reasoning. MaRVL-QA provides a challenging new tool for the
research community to measure progress, expose model limitations, and guide the
development of MLLMs with more profound reasoning abilities.

</details>


### [14] [PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs](https://arxiv.org/abs/2508.17188)
*Zhilin Zhang,Xiang Zhang,Jiaqi Wei,Yiwei Xu,Chenyu You*

Main category: cs.AI

TL;DR: PosterGen是一个多智能体框架，能根据论文自动生成高质量海报。


<details>
  <summary>Details</summary>
Motivation: 解决现有论文转海报方法忽略核心设计和美学原则的问题，生成的海报需要大量人工修改。

Method: 提出一个多智能体框架PosterGen，模拟专业海报设计师的工作流程。

Result: PosterGen在内容保真度方面与现有方法相当，但在视觉设计方面显著优于现有方法，生成的ポスター几乎无需人工修改。

Conclusion: PosterGen，一个多智能体框架，通过四个专业化代理（解析和策展代理、布局代理、造型代理和渲染器）协同工作，可以根据论文生成美观且语义清晰的海报，在内容保真度和视觉设计上均优于现有方法。

Abstract: Multi-agent systems built upon large language models (LLMs) have demonstrated
remarkable capabilities in tackling complex compositional tasks. In this work,
we apply this paradigm to the paper-to-poster generation problem, a practical
yet time-consuming process faced by researchers preparing for conferences.
While recent approaches have attempted to automate this task, most neglect core
design and aesthetic principles, resulting in posters that require substantial
manual refinement. To address these design limitations, we propose PosterGen, a
multi-agent framework that mirrors the workflow of professional poster
designers. It consists of four collaborative specialized agents: (1) Parser and
Curator agents extract content from the paper and organize storyboard; (2)
Layout agent maps the content into a coherent spatial layout; (3) Stylist
agents apply visual design elements such as color and typography; and (4)
Renderer composes the final poster. Together, these agents produce posters that
are both semantically grounded and visually appealing. To evaluate design
quality, we introduce a vision-language model (VLM)-based rubric that measures
layout balance, readability, and aesthetic coherence. Experimental results show
that PosterGen consistently matches in content fidelity, and significantly
outperforms existing methods in visual designs, generating posters that are
presentation-ready with minimal human refinements.

</details>


### [15] [From reactive to cognitive: brain-inspired spatial intelligence for embodied agents](https://arxiv.org/abs/2508.17198)
*Shouwei Ruan,Liyuan Wang,Caixin Kang,Qihui Zhu,Songming Liu,Xingxing Wei,Hang Su*

Main category: cs.AI

TL;DR: BSC-Nav框架利用结构化空间记忆，赋予具身代理强大的空间智能，并在真实世界导航任务中取得显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型缺乏结构化的空间记忆，限制了其在复杂现实环境中的泛化和适应能力。

Method: 构建基于大脑的空间认知模型BSC-Nav，该模型从自我中心轨迹和情境线索构建客观认知地图，并动态检索与语义目标对齐的空间知识。

Result: BSC-Nav在各种导航任务中取得了最先进的效率和效力，并展现出强大的零样本泛化能力，支持在现实物理世界中实现多功能的具身行为。

Conclusion: BSC-Nav框架在具身代理中构建和利用结构化空间记忆，实现了最先进的效率和效力，并展现出强大的零样本泛化能力。

Abstract: Spatial cognition enables adaptive goal-directed behavior by constructing
internal models of space. Robust biological systems consolidate spatial
knowledge into three interconnected forms: \textit{landmarks} for salient cues,
\textit{route knowledge} for movement trajectories, and \textit{survey
knowledge} for map-like representations. While recent advances in multi-modal
large language models (MLLMs) have enabled visual-language reasoning in
embodied agents, these efforts lack structured spatial memory and instead
operate reactively, limiting their generalization and adaptability in complex
real-world environments. Here we present Brain-inspired Spatial Cognition for
Navigation (BSC-Nav), a unified framework for constructing and leveraging
structured spatial memory in embodied agents. BSC-Nav builds allocentric
cognitive maps from egocentric trajectories and contextual cues, and
dynamically retrieves spatial knowledge aligned with semantic goals. Integrated
with powerful MLLMs, BSC-Nav achieves state-of-the-art efficacy and efficiency
across diverse navigation tasks, demonstrates strong zero-shot generalization,
and supports versatile embodied behaviors in the real physical world, offering
a scalable and biologically grounded path toward general-purpose spatial
intelligence.

</details>


### [16] [Large Language Model-Based Automatic Formulation for Stochastic Optimization Models](https://arxiv.org/abs/2508.17200)
*Amirreza Talebi*

Main category: cs.AI

TL;DR: 大型语言模型，特别是GPT-4-Turbo，在结合有效的提示策略后，能够有效地解决随机优化问题。


<details>
  <summary>Details</summary>
Motivation: 研究LLM自动制定和解决随机优化问题的性能。

Method: 设计了几种提示，引导ChatGPT使用思维链和模块化推理完成结构化任务，并引入了一种新的软评分指标来评估生成模型的结构质量和部分正确性。

Result: GPT-4-Turbo优于其他模型，cot_s_instructions和agentic是有效的提示策略。

Conclusion: 这项研究首次系统地研究了大型语言模型（LLM），特别是ChatGPT，在自动制定和解决来自自然语言描述的随机优化问题方面的性能，发现GPT-4-Turbo在部分分数、变量匹配和目标精度方面优于其他模型，并确定了有效的提示策略。

Abstract: This paper presents the first integrated systematic study on the performance
of large language models (LLMs), specifically ChatGPT, to automatically
formulate and solve stochastic optimiza- tion problems from natural language
descriptions. Focusing on three key categories, joint chance- constrained
models, individual chance-constrained models, and two-stage stochastic linear
programs (SLP-2), we design several prompts that guide ChatGPT through
structured tasks using chain-of- thought and modular reasoning. We introduce a
novel soft scoring metric that evaluates the struc- tural quality and partial
correctness of generated models, addressing the limitations of canonical and
execution-based accuracy. Across a diverse set of stochastic problems,
GPT-4-Turbo outperforms other models in partial score, variable matching, and
objective accuracy, with cot_s_instructions and agentic emerging as the most
effective prompting strategies. Our findings reveal that with well-engineered
prompts and multi-agent collaboration, LLMs can facilitate specially stochastic
formulations, paving the way for intelligent, language-driven modeling
pipelines in stochastic opti- mization.

</details>


### [17] [Explainable Counterfactual Reasoning in Depression Medication Selection at Multi-Levels (Personalized and Population)](https://arxiv.org/abs/2508.17207)
*Xinyu Qin,Mark H. Chignell,Alexandria Greifenberger,Sachinthya Lokuge,Elssa Toumeh,Tia Sternat,Martin Katzman,Lu Wang*

Main category: cs.AI

TL;DR: 使用反事实推理分析MDD症状如何影响SSRI/SNRI处方选择，随机森林模型效果最佳，为AI临床决策支持系统提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 研究MDD症状（HAM-D量化）如何因果性地影响SSRI与SNRI的处方。

Method: 应用可解释的反事实推理与反事实解释(CFs)评估特定症状变化对抗抑郁药选择的影响。使用随机森林模型，准确率、F1值、精确率、召回率和ROC-AUC接近0.85。

Result: 随机森林模型在17个二元分类器中性能最高，样本反事实CF揭示了各个症状在药物选择中的局部和全局特征重要性。

Conclusion: 反事实推理阐明了哪些MDD症状最强烈地驱动SSRI与SNRI的选择，增强了基于AI的临床决策支持系统的可解释性。

Abstract: Background: This study investigates how variations in Major Depressive
Disorder (MDD) symptoms, quantified by the Hamilton Rating Scale for Depression
(HAM-D), causally influence the prescription of SSRIs versus SNRIs. Methods: We
applied explainable counterfactual reasoning with counterfactual explanations
(CFs) to assess the impact of specific symptom changes on antidepressant
choice. Results: Among 17 binary classifiers, Random Forest achieved highest
performance (accuracy, F1, precision, recall, ROC-AUC near 0.85). Sample-based
CFs revealed both local and global feature importance of individual symptoms in
medication selection. Conclusions: Counterfactual reasoning elucidates which
MDD symptoms most strongly drive SSRI versus SNRI selection, enhancing
interpretability of AI-based clinical decision support systems. Future work
should validate these findings on more diverse cohorts and refine algorithms
for clinical deployment.

</details>
