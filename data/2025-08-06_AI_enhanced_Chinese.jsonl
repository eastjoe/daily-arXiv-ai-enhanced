{"id": "2508.02694", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.02694", "abs": "https://arxiv.org/abs/2508.02694", "authors": ["Ningning Wang", "Xavier Hu", "Pai Liu", "He Zhu", "Yue Hou", "Heyuan Huang", "Shengyu Zhang", "Jian Yang", "Jiaheng Liu", "Ge Zhang", "Changwang Zhang", "Jun Wang", "Yuchen Eleanor Jiang", "Wangchunshu Zhou"], "title": "Efficient Agents: Building Effective Agents While Reducing Cost", "comment": "Work in progress. For GitHub repository, see\n  https://github.com/OPPO-PersonalAI/OAgents", "summary": "The remarkable capabilities of Large Language Model (LLM)-driven agents have\nenabled sophisticated systems to tackle complex, multi-step tasks, but their\nescalating costs threaten scalability and accessibility. This work presents the\nfirst systematic study of the efficiency-effectiveness trade-off in modern\nagent systems, addressing the critical need for cost-effective designs without\nsacrificing performance. We investigate three key questions: (1) How much\ncomplexity do agentic tasks inherently require? (2) When do additional modules\nyield diminishing returns? (3) How much efficiency can be gained through the\ndesign of efficient agent frameworks? Through an empirical analysis on the GAIA\nbenchmark, we evaluate the impact of LLM backbone selection, agent framework\ndesigns, and test-time scaling strategies. Using the cost-of-pass metric, we\nquantify the efficiency-performance trade-off across these dimensions. Our\nfindings inform the development of Efficient Agents , a novel agent framework\nthat has an optimal complexity to task requirements. Efficient Agents retains\n96.7% of the performance of OWL, one leading open-source agent framework, while\nreducing operational costs from $0.398 to $0.228, resulting in a 28.4%\nimprovement in cost-of-pass. Our work provides actionable insights for\ndesigning efficient, high-performing agent systems, advancing the accessibility\nand sustainability of AI-driven solutions.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u9ad8\u6548\u7684\u667a\u80fd\u4f53\u6846\u67b6\u8bbe\u8ba1\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u7684\u663e\u8457\u80fd\u529b\u4f7f\u5f97\u590d\u6742\u7684\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u591a\u6b65\u9aa4\u4efb\u52a1\uff0c\u4f46\u5176\u4e0d\u65ad\u4e0a\u5347\u7684\u6210\u672c\u5a01\u80c1\u7740\u53ef\u6269\u5c55\u6027\u548c\u53ef\u53ca\u6027\u3002", "method": "\u5bf9GAIA\u57fa\u51c6\u8fdb\u884c\u4e86\u5b9e\u8bc1\u5206\u6790\uff0c\u8bc4\u4f30\u4e86LLM\u4e3b\u5e72\u9009\u62e9\u3001\u667a\u80fd\u4f53\u6846\u67b6\u8bbe\u8ba1\u548c\u6d4b\u8bd5\u65f6\u7f29\u653e\u7b56\u7565\u7684\u5f71\u54cd\uff0c\u4f7f\u7528cost-of-pass\u6307\u6807\u91cf\u5316\u4e86\u6548\u7387-\u6027\u80fd\u6743\u8861\u3002", "result": "Efficient Agents\u6846\u67b6\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5bf9\u73b0\u4ee3\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6548\u7387-\u6709\u6548\u6027\u6743\u8861\u8fdb\u884c\u4e86\u9996\u6b21\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEfficient Agents\u7684\u65b0\u578b\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5728\u4fdd\u630196.7%\u7684OWL\u6846\u67b6\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5c06\u8fd0\u8425\u6210\u672c\u964d\u4f4e\u4e8628.4%\u3002"}}
{"id": "2508.02697", "categories": ["cs.AI", "cs.CE", "03B35 (Primary) 03A99, 03B10, 03B25, 68V15, 03C07 (Secondary)", "I.2.3; I.2.4; F.4.1; F.2.2; H.3.3"], "pdf": "https://arxiv.org/pdf/2508.02697", "abs": "https://arxiv.org/abs/2508.02697", "authors": ["Mikhail Soutchanski", "Yongmei Liu"], "title": "Planning with Dynamically Changing Domains", "comment": "A revised version of the paper accepted to the 1st International\n  Workshop on Trends in Knowledge Representation and Reasoning organized as a\n  IJCAI 2025 workshop that takes place in August 2025 in Montreal, Canada. See\n  the details at https://tkr2025.krportal.org/programme.html", "summary": "In classical planning and conformant planning, it is assumed that there are\nfinitely many named objects given in advance, and only they can participate in\nactions and in fluents. This is the Domain Closure Assumption (DCA). However,\nthere are practical planning problems where the set of objects changes\ndynamically as actions are performed; e.g., new objects can be created, old\nobjects can be destroyed. We formulate the planning problem in first-order\nlogic, assume an initial theory is a finite consistent set of fluent literals,\ndiscuss when this guarantees that in every situation there are only finitely\nmany possible actions, impose a finite integer bound on the length of the plan,\nand propose to organize search over sequences of actions that are grounded at\nplanning time. We show the soundness and completeness of our approach. It can\nbe used to solve the bounded planning problems without DCA that belong to the\nintersection of sequential generalized planning (without sensing actions) and\nconformant planning, restricted to the case without the disjunction over fluent\nliterals. We discuss a proof-of-the-concept implementation of our planner.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u65e0\u9700\u9886\u57df\u95ed\u5305\u5047\u8bbe\uff0c\u5e76\u5728\u6709\u9650\u5bf9\u8c61\u96c6\u7684\u9650\u5236\u4e0b\uff0c\u89e3\u51b3\u4e86\u987a\u5e8f\u5e7f\u4e49\u89c4\u5212\u548c\u4e00\u81f4\u6027\u89c4\u5212\u7684\u4ea4\u96c6\u95ee\u9898\u3002", "motivation": "\u7ecf\u5178\u89c4\u5212\u548c\u4e00\u81f4\u6027\u89c4\u5212\u5047\u8bbe\u5b58\u5728\u9884\u5148\u7ed9\u5b9a\u7684\u6709\u9650\u591a\u4e2a\u547d\u540d\u5bf9\u8c61\uff0c\u4f46\u5b9e\u9645\u89c4\u5212\u95ee\u9898\u4e2d\u5bf9\u8c61\u7684\u96c6\u5408\u4f1a\u52a8\u6001\u53d8\u5316\u3002", "method": "\u8be5\u65b9\u6cd5\u57fa\u4e8e\u4e00\u9636\u903b\u8f91\uff0c\u5047\u8bbe\u521d\u59cb\u7406\u8bba\u662f\u4e00\u7ec4\u6709\u9650\u7684\u4e00\u81f4\u6027\u6d41\u7545\u6587\u5b57\uff0c\u5e76\u5728\u89c4\u5212\u65f6\u5bf9\u52a8\u4f5c\u8fdb\u884c\u63a5\u5730\u5904\u7406\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700DCA\u5373\u53ef\u89e3\u51b3\u6709\u754c\u89c4\u5212\u95ee\u9898\u7684\u5b8c\u6574\u4e14\u6b63\u786e\u7684\u65b9\u6cd5\uff0c\u5e76\u5b9e\u73b0\u4e86\u6982\u5ff5\u9a8c\u8bc1\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6ca1\u6709\u9886\u57df\u95ed\u5305\u5047\u8bbe(DCA)\u7684\u60c5\u51b5\u4e0b\u89e3\u51b3\u6709\u754c\u89c4\u5212\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u987a\u5e8f\u5e7f\u4e49\u89c4\u5212\u548c\u4e00\u81f4\u6027\u89c4\u5212\u7684\u4ea4\u96c6\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6b63\u786e\u6027\u548c\u5b8c\u6574\u6027\u3002"}}
{"id": "2508.02734", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2508.02734", "abs": "https://arxiv.org/abs/2508.02734", "authors": ["Weiyu Luo", "Chenfeng Xiong"], "title": "Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model", "comment": "20 pages, 5 figures", "summary": "Location-Based Service (LBS) data provides critical insights into human\nmobility, yet its sparsity often yields incomplete trip and activity sequences,\nmaking accurate inferences about trips and activities difficult. We raise a\nresearch problem: Can we use activity sequences derived from high-quality LBS\ndata to recover incomplete activity sequences at the individual level? This\nstudy proposes a new solution, the Variable Selection Network-fused Insertion\nTransformer (VSNIT), integrating the Insertion Transformer's flexible sequence\nconstruction with the Variable Selection Network's dynamic covariate handling\ncapability, to recover missing segments in incomplete activity sequences while\npreserving existing data. The findings show that VSNIT inserts more diverse,\nrealistic activity patterns, more closely matching real-world variability, and\nrestores disrupted activity transitions more effectively aligning with the\ntarget. It also performs significantly better than the baseline model across\nall metrics. These results highlight VSNIT's superior accuracy and diversity in\nactivity sequence recovery tasks, demonstrating its potential to enhance LBS\ndata utility for mobility analysis. This approach offers a promising framework\nfor future location-based research and applications.", "AI": {"tldr": "VSNIT\u6709\u6548\u6062\u590d\u4e0d\u5b8c\u6574LBS\u6d3b\u52a8\u5e8f\u5217\uff0c\u63d0\u5347\u6570\u636e\u5229\u7528\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4f4d\u7f6e\u7684\u670d\u52a1\uff08LBS\uff09\u6570\u636e\u7a00\u758f\uff0c\u5bfc\u81f4\u6d3b\u52a8\u5e8f\u5217\u4e0d\u5b8c\u6574\uff0c\u96be\u4ee5\u51c6\u786e\u63a8\u65ad\u51fa\u884c\u548c\u6d3b\u52a8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff1aVariable Selection Network-fused Insertion Transformer (VSNIT)\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u63d2\u5165Transformer\u7684\u7075\u6d3b\u5e8f\u5217\u6784\u5efa\u548c\u53d8\u91cf\u9009\u62e9\u7f51\u7edc\u7684\u52a8\u6001\u534f\u53d8\u91cf\u5904\u7406\u80fd\u529b\u3002", "result": "VSNIT\u80fd\u591f\u63d2\u5165\u66f4\u591a\u6837\u3001\u66f4\u771f\u5b9e\u7684\u6d3b\u52a8\u6a21\u5f0f\uff0c\u66f4\u6709\u6548\u5730\u6062\u590d\u4e2d\u65ad\u7684\u6d3b\u52a8\u8f6c\u6362\uff0c\u5e76\u5728\u6240\u6709\u6307\u6807\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "Variable Selection Network-fused Insertion Transformer (VSNIT) \u80fd\u591f\u66f4\u51c6\u786e\u3001\u66f4\u5168\u9762\u5730\u6062\u590d\u4e0d\u5b8c\u6574\u6d3b\u52a8\u5e8f\u5217\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4e3a\u57fa\u4e8e\u4f4d\u7f6e\u7684\u670d\u52a1\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.02744", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02744", "abs": "https://arxiv.org/abs/2508.02744", "authors": ["Peiran Wang", "Yaoning Yu", "Ke Chen", "Xianyang Zhan", "Haohan Wang"], "title": "Large Language Model-based Data Science Agent: A Survey", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has driven novel\napplications across diverse domains, with LLM-based agents emerging as a\ncrucial area of exploration. This survey presents a comprehensive analysis of\nLLM-based agents designed for data science tasks, summarizing insights from\nrecent studies. From the agent perspective, we discuss the key design\nprinciples, covering agent roles, execution, knowledge, and reflection methods.\nFrom the data science perspective, we identify key processes for LLM-based\nagents, including data preprocessing, model development, evaluation,\nvisualization, etc. Our work offers two key contributions: (1) a comprehensive\nreview of recent developments in applying LLMbased agents to data science\ntasks; (2) a dual-perspective framework that connects general agent design\nprinciples with the practical workflows in data science.", "AI": {"tldr": "Survey paper reviewing LLM-based agents for data science, offering a framework bridging agent design and data science workflows.", "motivation": "Rapid advancement of LLMs and the emergence of LLM-based agents in diverse domains, particularly data science.", "method": "Review and analysis of recent studies on LLM-based agents in data science.", "result": "Provides a comprehensive review and a dual-perspective framework for understanding and designing LLM-based agents for data science tasks.", "conclusion": "This survey comprehensively analyzes LLM-based agents for data science tasks, offering a dual-perspective framework connecting general agent design with data science workflows."}}
{"id": "2508.02789", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02789", "abs": "https://arxiv.org/abs/2508.02789", "authors": ["Newman Cheng", "Gordon Broadbent", "William Chappell"], "title": "Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science", "comment": null, "summary": "The capacity for artificial intelligence (AI) to formulate, evolve, and test\naltered thought patterns under dynamic conditions indicates advanced cognition\nthat is crucial for scientific discovery. The existing AI development landscape\nfalls into two categories: 1) frameworks over non-reasoning models that\nnatively incorporate opinions on how humans think, and 2) reasoning models that\nabstract precise control of the reasoning intuition away from end users. While\npowerful, for scientists to maximize utility of AI in scientific discovery,\nthey not only require accuracy and transparency in reasoning, but also\nsteerability. Hence, we introduce an alternative approach that enables deep and\nprecise control over the reasoning process called: a cognitive loop via in-situ\noptimization (CLIO). CLIO enables large language models (LLMs) to\nself-formulate ways of approaching a problem, adapt behavior when\nself-confidence is low, and ultimately provide scientists with a final belief\nor answer. Through CLIO's open design, scientists can observe uncertainty\nlevels, understand how final belief states are formulated using graph\nstructures, and interject corrections. Without any further post-training,\nOpenAI's GPT-4.1 with CLIO yields an accuracy of 22.37\\% in text-based biology\nand medicine questions on Humanity's Last Exam (HLE). This yields a 13.82\\% net\nor 161.64\\% relative increase when compared to the base GPT-4.1 model and\nsurpasses OpenAI's o3 performance in high and low reasoning effort modes. We\nfurther discovered that oscillations within internal uncertainty measures are\nkey in determining the accuracy of CLIO's results, revealing how its open\ndesign and internal mechanisms can provide insight and control into scientific\ndecision-making processes.", "AI": {"tldr": "CLIO enhances LLMs' reasoning capabilities, boosting accuracy and providing scientists with unprecedented control and transparency in scientific discovery.", "motivation": "Existing AI frameworks lack steerability, hindering their utility in scientific discovery.  CLIO addresses this by providing scientists with deep control and insight into the reasoning process.", "method": "Introduces CLIO (cognitive loop via in-situ optimization), allowing LLMs to self-formulate problem-solving approaches, adapt based on self-confidence, and provide final beliefs with transparency.", "result": "GPT-4.1 with CLIO achieves 22.37% accuracy on HLE, a 13.82% net increase over the base model, exceeding OpenAI's o3 performance. Oscillations in internal uncertainty measures correlate with accuracy.", "conclusion": "CLIO, a novel approach enabling deep and precise control over the reasoning process in LLMs, significantly improves accuracy in text-based biology and medicine questions, surpassing existing models."}}
{"id": "2508.02841", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.02841", "abs": "https://arxiv.org/abs/2508.02841", "authors": ["Ziruo Yi", "Jinyu Liu", "Ting Xiao", "Mark V. Albert"], "title": "A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering", "comment": null, "summary": "Radiology visual question answering (RVQA) provides precise answers to\nquestions about chest X-ray images, alleviating radiologists' workload. While\nrecent methods based on multimodal large language models (MLLMs) and\nretrieval-augmented generation (RAG) have shown promising progress in RVQA,\nthey still face challenges in factual accuracy, hallucinations, and cross-modal\nmisalignment. We introduce a multi-agent system (MAS) designed to support\ncomplex reasoning in RVQA, with specialized agents for context understanding,\nmultimodal reasoning, and answer validation. We evaluate our system on a\nchallenging RVQA set curated via model disagreement filtering, comprising\nconsistently hard cases across multiple MLLMs. Extensive experiments\ndemonstrate the superiority and effectiveness of our system over strong MLLM\nbaselines, with a case study illustrating its reliability and interpretability.\nThis work highlights the potential of multi-agent approaches to support\nexplainable and trustworthy clinical AI applications that require complex\nreasoning.", "AI": {"tldr": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u5347\u4e86\u533b\u5b66\u5f71\u50cf\u95ee\u7b54\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eMLLM\u548cRAG\u7684RVQA\u65b9\u6cd5\u5b58\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u5e7b\u89c9\u548c\u8de8\u6a21\u6001\u9519\u4f4d\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u7cfb\u7edf(MAS)\uff0c\u5305\u542b\u4e0a\u4e0b\u6587\u7406\u89e3\u3001\u591a\u6a21\u6001\u63a8\u7406\u548c\u7b54\u6848\u9a8c\u8bc1\u4e09\u4e2a\u4e13\u7528\u667a\u80fd\u4f53\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u7cfb\u7edf\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5177\u6709\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728RVQA\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u57fa\u7ebf\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5c55\u73b0\u4e86\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u5728\u590d\u6742\u4e34\u5e8aAI\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.02900", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02900", "abs": "https://arxiv.org/abs/2508.02900", "authors": ["Michael Katz", "Harsha Kokel", "Sarath Sreedharan"], "title": "Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game", "comment": null, "summary": "There is a broad consensus that the inability to form long-term plans is one\nof the key limitations of current foundational models and agents. However, the\nexisting planning benchmarks remain woefully inadequate to truly measure their\nplanning capabilities. Most existing benchmarks either focus on loosely defined\ntasks like travel planning or end up leveraging existing domains and problems\nfrom international planning competitions. While the former tasks are hard to\nformalize and verify, the latter were specifically designed to test and\nchallenge the weaknesses of existing automated planners. To address these\nshortcomings, we propose a procedure for creating a planning benchmark centered\naround the game called Countdown, where a player is expected to form a target\nnumber from a list of input numbers through arithmetic operations. We discuss\nhow this problem meets many of the desiderata associated with an ideal\nbenchmark for planning capabilities evaluation. Specifically, the domain allows\nfor an intuitive, natural language description for each problem instance, it is\ncomputationally challenging (NP-complete), and the instance space is rich\nenough that we do not have to worry about memorization. We perform an extensive\ntheoretical analysis, establishing the computational complexity result and\ndemonstrate the advantage of our instance generation procedure over public\nbenchmarks. We evaluate a variety of existing LLM-assisted planning methods on\ninstances generated using our procedure. Our results show that, unlike other\ndomains like 24 Game (a special case of Countdown), our proposed dynamic\nbenchmark remains extremely challenging for existing LLM-based approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u201cCountdown\u201d\u6e38\u620f\u7684\u66f4\u5177\u6311\u6218\u6027\u7684\u89c4\u5212\u57fa\u51c6\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u89c4\u5212\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u89c4\u5212\u57fa\u51c6\u4e0d\u8db3\u4ee5\u8861\u91cf\u5f53\u524d\u57fa\u7840\u6a21\u578b\u548c\u667a\u80fd\u4f53\u7684\u89c4\u5212\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u201cCountdown\u201d\u6e38\u620f\u7684\u89c4\u5212\u57fa\u51c6\uff0c\u5e76\u5bf9\u73b0\u6709LLM\u8f85\u52a9\u89c4\u5212\u65b9\u6cd5\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\uff0c\u66f4\u5177\u6311\u6218\u6027\u7684\u89c4\u5212\u57fa\u51c6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u201cCountdown\u201d\u6e38\u620f\u7684\u65b0\u578b\u89c4\u5212\u80fd\u529b\u8bc4\u4f30\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u514b\u670d\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u4e0d\u8db3\uff0c\u4f8b\u5982\u4efb\u52a1\u5b9a\u4e49\u6a21\u7cca\u6216\u9488\u5bf9\u7279\u5b9a\u7b97\u6cd5\u5f31\u70b9\u8bbe\u8ba1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u57fa\u51c6\u5bf9\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u89c4\u5212\u65b9\u6cd5\u5177\u6709\u5f88\u5f3a\u7684\u6311\u6218\u6027\u3002"}}
{"id": "2508.02913", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02913", "abs": "https://arxiv.org/abs/2508.02913", "authors": ["Carolina Minami Oguchi", "Leo Wei", "Koyo Kobayashi", "Hsin-Tai Wu", "Dipak Ghosal"], "title": "Enhancing Japanese Large Language Models with Reasoning Vectors", "comment": null, "summary": "Post-training methods have improved the performance and enhanced the\nreasoning capability for mainstream large language models (LLMs), but the same\nis challenging for Japanese LLMs to achieve due to the amount of resources\nrequired. Inspired by task vectors that extract the change of weights before\nand after training, specifically for a certain task, we obtain reasoning\nvectors from reasoning LLMs and apply them to Japanese LLMs to boost their\nperformance. While the resources available present a challenge to improve\nJapanese LLMs, we present a simple and effective way to obtain high improvement\nand hope to inspire for other languages.", "AI": {"tldr": "\u5229\u7528\u63a8\u7406\u5411\u91cf\u63d0\u5347\u65e5\u8bedLLM\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u63d0\u5347\u65e5\u8bedLLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u4e3a\u8d44\u6e90\u6709\u9650\u3002", "method": "\u4ece\u63a8\u7406LLM\u4e2d\u63d0\u53d6\u63a8\u7406\u5411\u91cf\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u5230\u65e5\u8bedLLM\u3002", "result": "\u8be5\u65b9\u6cd5\u7b80\u5355\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u65e5\u8bedLLM\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u63a8\u7406\u5411\u91cf\u4ece\u63a8\u7406LLM\u5e94\u7528\u5230\u65e5\u8bedLLM\uff0c\u4ece\u800c\u63d0\u9ad8\u65e5\u8bedLLM\u7684\u6027\u80fd\uff0c\u4e3a\u5176\u4ed6\u8bed\u8a00\u7684\u6539\u8fdb\u63d0\u4f9b\u4e86\u542f\u53d1\u3002"}}
{"id": "2508.02921", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.02921", "abs": "https://arxiv.org/abs/2508.02921", "authors": ["Shane Caldwell", "Max Harley", "Michael Kouremetis", "Vincent Abruzzo", "Will Pearce"], "title": "PentestJudge: Judging Agent Behavior Against Operational Requirements", "comment": "18 pages, 5 figures, 3 tables", "summary": "We introduce PentestJudge, a system for evaluating the operations of\npenetration testing agents. PentestJudge is a large language model\n(LLM)-as-judge with access to tools that allow it to consume arbitrary\ntrajectories of agent states and tool call history to determine whether a\nsecurity agent's actions meet certain operating criteria that would be\nimpractical to evaluate programmatically. We develop rubrics that use a tree\nstructure to hierarchically collapse the penetration testing task for a\nparticular environment into smaller, simpler, and more manageable sub-tasks and\ncriteria until each leaf node represents simple yes-or-no criteria for\nPentestJudge to evaluate. Task nodes are broken down into different categories\nrelated to operational objectives, operational security, and tradecraft.\nLLM-as-judge scores are compared to human domain experts as a ground-truth\nreference, allowing us to compare their relative performance with standard\nbinary classification metrics, such as F1 scores. We evaluate several frontier\nand open-source models acting as judge agents, with the best model reaching an\nF1 score of 0.83. We find models that are better at tool-use perform more\nclosely to human experts. By stratifying the F1 scores by requirement type, we\nfind even models with similar overall scores struggle with different types of\nquestions, suggesting certain models may be better judges of particular\noperating criteria. We find that weaker and cheaper models can judge the\ntrajectories of pentests performed by stronger and more expensive models,\nsuggesting verification may be easier than generation for the penetration\ntesting task. We share this methodology to facilitate future research in\nunderstanding the ability of judges to holistically and scalably evaluate the\nprocess quality of AI-based information security agents so that they may be\nconfidently used in sensitive production environments.", "AI": {"tldr": "\u4f7f\u7528LLM\u8bc4\u4f30\u6e17\u900f\u6d4b\u8bd5\u4ee3\u7406\uff0cF1\u5f97\u52060.83\uff0c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u9a8c\u8bc1\u6bd4\u751f\u6210\u66f4\u5bb9\u6613\u3002", "motivation": "\u8bc4\u4f30AI\u5b89\u5168\u4ee3\u7406\u7684\u8fc7\u7a0b\u8d28\u91cf\uff0c\u4ee5\u4fbf\u5728\u654f\u611f\u7684\u751f\u4ea7\u73af\u5883\u4e2d\u5b89\u5168\u53ef\u9760\u5730\u4f7f\u7528\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u4f5c\u4e3a\u8bc4\u5224\u8005\uff0c\u7ed3\u5408\u5de5\u5177\u8bbf\u95ee\u4ee3\u7406\u72b6\u6001\u548c\u5de5\u5177\u8c03\u7528\u5386\u53f2\uff0c\u57fa\u4e8e\u6811\u72b6\u7ed3\u6784\u7684\u8bc4\u4f30\u6807\u51c6\u5bf9\u6e17\u900f\u6d4b\u8bd5\u4efb\u52a1\u8fdb\u884c\u5206\u89e3\uff0c\u6700\u7ec8\u8bc4\u4f30\u7b80\u5355\u7684\u662f/\u5426\u6807\u51c6\u3002", "result": "\u6700\u4f73\u6a21\u578b\u8fbe\u52300.83\u7684F1\u5206\u6570\uff0c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u8868\u73b0\u66f4\u4f73\uff0c\u4f46\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u8bc4\u4f30\u6807\u51c6\u4e0a\u8868\u73b0\u5dee\u5f02\u8f83\u5927\u3002\u8f83\u5f31\u7684\u6a21\u578b\u53ef\u4ee5\u8bc4\u4f30\u8f83\u5f3a\u6a21\u578b\u7684\u6e17\u900f\u6d4b\u8bd5\u8f68\u8ff9\u3002", "conclusion": "PentestJudge\u7cfb\u7edf\u53ef\u4ee5\u6709\u6548\u8bc4\u4f30\u6e17\u900f\u6d4b\u8bd5\u4ee3\u7406\u7684\u64cd\u4f5c\uff0c\u5176F1\u5206\u6570\u8fbe\u52300.83\uff0c\u5e76\u4e14\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u66f4\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\u7684\u5224\u65ad\u3002"}}
{"id": "2508.02936", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02936", "abs": "https://arxiv.org/abs/2508.02936", "authors": ["Songkun Yan", "Zhi Li", "Siyu Zhu", "Yixin Wen", "Mofan Zhang", "Mengye Chen", "Jie Cao", "Yang Hong"], "title": "AQUAH: Automatic Quantification and Unified Agent in Hydrology", "comment": "8 pages, 5 figures, 2025 ICCV SEA workshop paper", "summary": "We introduce AQUAH, the first end-to-end language-based agent designed\nspecifically for hydrologic modeling. Starting from a simple natural-language\nprompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to\n2022'), AQUAH autonomously retrieves the required terrain, forcing, and gauge\ndata; configures a hydrologic model; runs the simulation; and generates a\nself-contained PDF report. The workflow is driven by vision-enabled large\nlanguage models, which interpret maps and rasters on the fly and steer key\ndecisions such as outlet selection, parameter initialization, and uncertainty\ncommentary. Initial experiments across a range of U.S. basins show that AQUAH\ncan complete cold-start simulations and produce analyst-ready documentation\nwithout manual intervention. The results are judged by hydrologists as clear,\ntransparent, and physically plausible. While further calibration and validation\nare still needed for operational deployment, these early outcomes highlight the\npromise of LLM-centered, vision-grounded agents to streamline complex\nenvironmental modeling and lower the barrier between Earth observation data,\nphysics-based tools, and decision makers.", "AI": {"tldr": "LLM-powered agent automates hydrologic modeling from natural language, showing promise but needing further validation.", "motivation": "To streamline complex environmental modeling and improve accessibility of Earth observation data.", "method": "Uses vision-enabled LLMs to interpret data, configure models, run simulations, and generate reports.", "result": "Successfully performs cold-start simulations and generates analyst-ready documentation without manual intervention. Results deemed clear, transparent, and physically plausible by hydrologists.", "conclusion": "AQUAH, a novel language-based agent, automates hydrologic modeling from natural language prompts, producing self-contained reports.  Initial tests show promising results, though further validation is needed."}}
{"id": "2508.02951", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02951", "abs": "https://arxiv.org/abs/2508.02951", "authors": ["Mahtab Bigverdi", "Wisdom Ikezogwo", "Kevin Zhang", "Hyewon Jeong", "Mingyu Lu", "Sungjae Cho", "Linda Shapiro", "Ranjay Krishna"], "title": "MedBLINK: Probing Basic Perception in Multimodal Language Models for Medicine", "comment": null, "summary": "Multimodal language models (MLMs) show promise for clinical decision support\nand diagnostic reasoning, raising the prospect of end-to-end automated medical\nimage interpretation. However, clinicians are highly selective in adopting AI\ntools; a model that makes errors on seemingly simple perception tasks such as\ndetermining image orientation or identifying whether a CT scan is\ncontrast-enhance are unlikely to be adopted for clinical tasks. We introduce\nMedblink, a benchmark designed to probe these models for such perceptual\nabilities. Medblink spans eight clinically meaningful tasks across multiple\nimaging modalities and anatomical regions, totaling 1,429 multiple-choice\nquestions over 1,605 images. We evaluate 19 state-of-the-art MLMs, including\ngeneral purpose (GPT4o, Claude 3.5 Sonnet) and domain specific (Med Flamingo,\nLLaVA Med, RadFM) models. While human annotators achieve 96.4% accuracy, the\nbest-performing model reaches only 65%. These results show that current MLMs\nfrequently fail at routine perceptual checks, suggesting the need to strengthen\ntheir visual grounding to support clinical adoption. Data is available on our\nproject page.", "AI": {"tldr": "Medblink\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u5f53\u524d\u7684\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u5f71\u50cf\u611f\u77e5\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u5176\u89c6\u89c9\u7406\u89e3\u80fd\u529b\u624d\u80fd\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u53d1\u6325\u4f5c\u7528\u3002", "motivation": "\u63a2\u7a76\u5f53\u524d\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u5f71\u50cf\u611f\u77e5\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4ee5\u4fc3\u8fdb\u5176\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u6784\u5efaMedblink\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b8\u4e2a\u4e34\u5e8a\u76f8\u5173\u7684\u4efb\u52a1\uff0c\u6db5\u76d6\u591a\u79cd\u5f71\u50cf\u6a21\u5f0f\u548c\u89e3\u5256\u533a\u57df\uff0c\u5171\u67091429\u4e2a\u591a\u9879\u9009\u62e9\u9898\uff0c\u57fa\u4e8e1605\u5f20\u56fe\u50cf\u3002\u5bf919\u4e2a\u6700\u5148\u8fdb\u7684MLM\u6a21\u578b(\u5305\u62ec\u901a\u7528\u6a21\u578b\u548c\u7279\u5b9a\u9886\u57df\u6a21\u578b)\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u76ee\u524d\u7684MLM\u6a21\u578b\u7ecf\u5e38\u5728\u5e38\u89c4\u7684\u611f\u77e5\u68c0\u67e5\u4e2d\u5931\u8d25\uff0c\u8fd9\u8868\u660e\u9700\u8981\u52a0\u5f3a\u5176\u89c6\u89c9\u57fa\u7840\u4ee5\u652f\u6301\u4e34\u5e8a\u91c7\u7528\u3002", "conclusion": "\u5f53\u524d\u7684\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b(MLM)\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u548c\u8bca\u65ad\u63a8\u7406\u65b9\u9762\u663e\u793a\u51fa\u524d\u666f\uff0c\u4f46\u5176\u5728\u4e00\u4e9b\u7b80\u5355\u7684\u611f\u77e5\u4efb\u52a1\u4e0a(\u4f8b\u5982\u786e\u5b9a\u56fe\u50cf\u65b9\u5411\u6216\u8bc6\u522bCT\u626b\u63cf\u662f\u5426\u589e\u5f3a\u5bf9\u6bd4\u5ea6)\u7684\u9519\u8bef\u7387\u8f83\u9ad8\uff0c\u963b\u788d\u4e86\u5176\u4e34\u5e8a\u5e94\u7528\u3002Medblink\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e8619\u4e2a\u6700\u5148\u8fdb\u7684MLM\u6a21\u578b\u5728\u8fd9\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\u51c6\u786e\u7387\u4e5f\u53ea\u670965%\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b96.4%\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2508.02959", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02959", "abs": "https://arxiv.org/abs/2508.02959", "authors": ["Chia-Tung Ho", "Jing Gong", "Xufeng Yao", "Yunsheng Bai", "Abhishek B Akkur", "Haoxing Ren"], "title": "Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow", "comment": "18 pages, 12 figures, under review for AAAI2026", "summary": "Large language models (LLMs) excel at solving complex tasks by executing\nagentic workflows composed of detailed instructions and structured operations.\nYet, building general-purpose agents by manually embedding foundation models\ninto agentic systems such as Chain-of-Thought, Self-Reflection, and ReACT\nthrough text interfaces limits scalability and efficiency. Recently, many\nresearchers have sought to automate the generation and optimization of these\nworkflows through code-based representations. However, existing methods often\nrely on labeled datasets to train and optimize workflows, making them\nineffective and inflexible for solving real-world, dynamic problems where\nlabeled data is unavailable. To address this challenge, we introduce Polymath,\na self-optimizing agent with dynamic hierarchical workflow that leverages the\nflexibility of task flow graphs and the expressiveness of code-represented\nworkflows to solve a wide range of real-world, dynamic problems. The proposed\noptimization methodology integrates multi-grid-inspired graph optimization with\na self-reflection-guided evolutionary algorithm to refine workflows without\nlabeled data. Experimental results on six benchmark datasets across coding,\nmath, and multi-turn QA tasks show that Polymath achieves 8.1% average\nimprovement over state-of-the-art baselines.", "AI": {"tldr": "Polymath \u662f\u4e00\u79cd\u65e0\u9700\u6807\u8bb0\u6570\u636e\u5373\u53ef\u81ea\u6211\u4f18\u5316\u7684\u667a\u80fd\u4f53\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6807\u8bb0\u6570\u636e\u96c6\u6765\u8bad\u7ec3\u548c\u4f18\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u5728\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4e2d\u7f3a\u4e4f\u6807\u8bb0\u6570\u636e\u7684\u52a8\u6001\u95ee\u9898\u65f6\u6548\u7387\u4f4e\u4e0b\u4e14\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002", "method": "Polymath \u96c6\u6210\u4e86\u591a\u7f51\u683c\u542f\u53d1\u7684\u56fe\u4f18\u5316\u548c\u81ea\u6211\u53cd\u601d\u5f15\u5bfc\u7684\u8fdb\u5316\u7b97\u6cd5\uff0c\u65e0\u9700\u6807\u8bb0\u6570\u636e\u5373\u53ef\u4f18\u5316\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u5728\u7f16\u7801\u3001\u6570\u5b66\u548c\u591a\u8f6e QA \u4efb\u52a1\u7684\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cPolymath \u7684\u5e73\u5747\u6027\u80fd\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u63d0\u9ad8\u4e86 8.1%\u3002", "conclusion": "Polymath\uff0c\u4e00\u4e2a\u5177\u6709\u52a8\u6001\u5c42\u6b21\u5de5\u4f5c\u6d41\u7a0b\u7684\u81ea\u6211\u4f18\u5316\u4ee3\u7406\uff0c\u901a\u8fc7\u7ed3\u5408\u4efb\u52a1\u6d41\u7a0b\u56fe\u7684\u7075\u6d3b\u6027\u548c\u4ee3\u7801\u8868\u793a\u5de5\u4f5c\u6d41\u7a0b\u7684\u8868\u73b0\u529b\uff0c\u89e3\u51b3\u4e86\u5e7f\u6cdb\u7684\u73b0\u5b9e\u4e16\u754c\u52a8\u6001\u95ee\u9898\u3002\u5b83\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e73\u5747\u6027\u80fd\u63d0\u9ad8\u4e86 8.1%\u3002"}}
{"id": "2508.02961", "categories": ["cs.AI", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.02961", "abs": "https://arxiv.org/abs/2508.02961", "authors": ["Boshi Huang", "Fabio Nonato de Paula"], "title": "Defend LLMs Through Self-Consciousness", "comment": "Presented at KDD Workshop on Ethical Artificial Intelligence: Methods\n  and Applications (EAI) 2025", "summary": "This paper introduces a novel self-consciousness defense mechanism for Large\nLanguage Models (LLMs) to combat prompt injection attacks. Unlike traditional\napproaches that rely on external classifiers, our method leverages the LLM's\ninherent reasoning capabilities to perform self-protection. We propose a\nframework that incorporates Meta-Cognitive and Arbitration Modules, enabling\nLLMs to evaluate and regulate their own outputs autonomously. Our approach is\nevaluated on seven state-of-the-art LLMs using two datasets: AdvBench and\nPrompt-Injection-Mixed-Techniques-2024. Experiment results demonstrate\nsignificant improvements in defense success rates across models and datasets,\nwith some achieving perfect and near-perfect defense in Enhanced Mode. We also\nanalyze the trade-off between defense success rate improvement and\ncomputational overhead. This self-consciousness method offers a lightweight,\ncost-effective solution for enhancing LLM ethics, particularly beneficial for\nGenAI use cases across various platforms.", "AI": {"tldr": "\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u7ecf\u6d4e\u9ad8\u6548\u7684\u81ea\u6211\u610f\u8bc6\u9632\u5fa1\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u4e3a\u4e86\u5bf9\u6297\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u63d0\u5347LLM\u7684\u5b89\u5168\u6027\u4e0e\u4f26\u7406\u9053\u5fb7\u3002", "method": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u5143\u8ba4\u77e5\u548c\u4ef2\u88c1\u6a21\u5757\uff0c\u4f7fLLM\u80fd\u591f\u81ea\u4e3b\u8bc4\u4f30\u548c\u89c4\u8303\u81ea\u8eab\u7684\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5404\u79cd\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u9632\u5fa1\u6210\u529f\u7387\uff0c\u67d0\u4e9b\u6a21\u578b\u5728\u589e\u5f3a\u6a21\u5f0f\u4e0b\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u6216\u63a5\u8fd1\u5b8c\u7f8e\u7684\u9632\u5fa1\uff0c\u5e76\u5728\u9632\u5fa1\u6210\u529f\u7387\u63d0\u5347\u548c\u8ba1\u7b97\u5f00\u9500\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u6211\u610f\u8bc6\u9632\u5fa1\u673a\u5236\uff0c\u7528\u4e8e\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5bf9\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\uff0c\u8be5\u673a\u5236\u5229\u7528LLM\u81ea\u8eab\u7684\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u81ea\u6211\u4fdd\u62a4\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002"}}
{"id": "2508.02979", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02979", "abs": "https://arxiv.org/abs/2508.02979", "authors": ["Peng Ding", "Rick Stevens"], "title": "Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling", "comment": "arXiv admin note: substantial text overlap with arXiv:2507.10593", "summary": "The proliferation of tool-augmented Large Language Models (LLMs) has created\na fragmented ecosystem where developers must navigate multiple protocols,\nmanual schema definitions, and complex execution workflows. We address this\nchallenge by proposing a unified approach to tool integration that abstracts\nprotocol differences while optimizing execution performance. Our solution\ndemonstrates how protocol-agnostic design principles can significantly reduce\ndevelopment overhead through automated schema generation, dual-mode concurrent\nexecution, and seamless multi-source tool management. Experimental results show\n60-80% code reduction across integration scenarios, performance improvements up\nto 3.1x through optimized concurrency, and full compatibility with existing\nfunction calling standards. This work contributes both theoretical insights\ninto tool integration architecture and practical solutions for real-world LLM\napplication development.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7edf\u4e00\u65b9\u6cd5\uff0c\u7b80\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u5177\u96c6\u6210\uff0c\u51cf\u5c11\u4ee3\u7801\uff0c\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5de5\u5177\u589e\u5f3a\u578b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6001\u7cfb\u7edf\u6bd4\u8f83\u5206\u6563\uff0c\u5f00\u53d1\u4eba\u5458\u9700\u8981\u5904\u7406\u591a\u79cd\u534f\u8bae\u3001\u624b\u52a8\u6a21\u5f0f\u5b9a\u4e49\u548c\u590d\u6742\u7684\u6267\u884c\u5de5\u4f5c\u6d41\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5de5\u5177\u96c6\u6210\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u62bd\u8c61\u534f\u8bae\u5dee\u5f02\uff0c\u4f18\u5316\u6267\u884c\u6027\u80fd\uff0c\u5e76\u652f\u6301\u81ea\u52a8\u5316\u6a21\u5f0f\u751f\u6210\u3001\u53cc\u6a21\u5e76\u53d1\u6267\u884c\u548c\u65e0\u7f1d\u591a\u6e90\u5de5\u5177\u7ba1\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u51cf\u5c1160-80%\u7684\u4ee3\u7801\uff0c\u5c06\u6027\u80fd\u63d0\u9ad83.1\u500d\uff0c\u5e76\u5b8c\u5168\u517c\u5bb9\u73b0\u6709\u7684\u51fd\u6570\u8c03\u7528\u6807\u51c6\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5de5\u5177\u96c6\u6210\u67b6\u6784\u63d0\u4f9b\u4e86\u7406\u8bba\u89c1\u89e3\u548c\u5b9e\u9645\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u7b80\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e94\u7528\u5f00\u53d1\u3002"}}
{"id": "2508.02994", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02994", "abs": "https://arxiv.org/abs/2508.02994", "authors": ["Fangyi Yu"], "title": "When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs", "comment": null, "summary": "As large language models (LLMs) grow in capability and autonomy, evaluating\ntheir outputs-especially in open-ended and complex tasks-has become a critical\nbottleneck. A new paradigm is emerging: using AI agents as the evaluators\nthemselves. This \"agent-as-a-judge\" approach leverages the reasoning and\nperspective-taking abilities of LLMs to assess the quality and safety of other\nmodels, promising calable and nuanced alternatives to human evaluation. In this\nreview, we define the agent-as-a-judge concept, trace its evolution from\nsingle-model judges to dynamic multi-agent debate frameworks, and critically\nexamine their strengths and shortcomings. We compare these approaches across\nreliability, cost, and human alignment, and survey real-world deployments in\ndomains such as medicine, law, finance, and education. Finally, we highlight\npressing challenges-including bias, robustness, and meta evaluation-and outline\nfuture research directions. By bringing together these strands, our review\ndemonstrates how agent-based judging can complement (but not replace) human\noversight, marking a step toward trustworthy, scalable evaluation for\nnext-generation LLMs.", "AI": {"tldr": "AI agent\u53ef\u7528\u4e8e\u8bc4\u4f30LLM\u8f93\u51fa\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u89e3\u51b3\u504f\u5dee\u548c\u9c81\u68d2\u6027\u7b49\u95ee\u9898\uff0c\u4ee5\u5b9e\u73b0\u53ef\u4fe1\u8d56\u548c\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u3002", "motivation": "\u968f\u7740LLM\u80fd\u529b\u7684\u63d0\u5347\uff0c\u5bf9\u8f93\u51fa\u7ed3\u679c\u7684\u8bc4\u4f30\u6210\u4e3a\u74f6\u9888\uff0cagent-as-a-judge\u65b9\u6cd5\u5229\u7528AI agent\u8bc4\u4f30\u5176\u4ed6\u6a21\u578b\u7684\u8d28\u91cf\u548c\u5b89\u5168\u6027\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u548c\u7ec6\u81f4\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u56de\u987e\u5206\u6790\u4e86agent-as-a-judge\u65b9\u6cd5\u7684\u6f14\u53d8\uff0c\u4ece\u5355\u6a21\u578b\u5230\u591aAgent\u8fa9\u8bba\u6846\u67b6\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u533b\u5b66\u3001\u6cd5\u5f8b\u3001\u91d1\u878d\u548c\u6559\u80b2\u7b49\u9886\u57df\u6709\u5b9e\u9645\u5e94\u7528\uff0c\u4f46\u4ecd\u9762\u4e34\u504f\u5dee\u3001\u9c81\u68d2\u6027\u548c\u5143\u8bc4\u4f30\u7b49\u6311\u6218\u3002", "conclusion": "Agent-as-a-judge\u65b9\u6cd5\u53ef\u4ee5\u8f85\u52a9\u4eba\u5de5\u8bc4\u4f30\uff0c\u4f46\u4e0d\u80fd\u5b8c\u5168\u53d6\u4ee3\u4eba\u5de5\uff1b\u8be5\u65b9\u6cd5\u5728\u53ef\u9760\u6027\u3001\u6210\u672c\u548c\u4e0e\u4eba\u7c7b\u4e00\u81f4\u6027\u65b9\u9762\u5404\u6709\u4f18\u52a3\uff0c\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u504f\u5dee\u3001\u9c81\u68d2\u6027\u548c\u5143\u8bc4\u4f30\u7b49\u95ee\u9898\u3002"}}
{"id": "2508.02999", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.02999", "abs": "https://arxiv.org/abs/2508.02999", "authors": ["Xinjie Zhao", "Moritz Blum", "Fan Gao", "Yingjian Chen", "Boming Yang", "Luis Marquez-Carpintero", "M\u00f3nica Pina-Navarro", "Yanran Fu", "So Morikawa", "Yusuke Iwasawa", "Yutaka Matsuo", "Chanjun Park", "Irene Li"], "title": "AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots", "comment": "CIKM 2025, Demo Track", "summary": "AGENTiGraph is a user-friendly, agent-driven system that enables intuitive\ninteraction and management of domain-specific data through the manipulation of\nknowledge graphs in natural language. It gives non-technical users a complete,\nvisual solution to incrementally build and refine their knowledge bases,\nallowing multi-round dialogues and dynamic updates without specialized query\nlanguages. The flexible design of AGENTiGraph, including intent classification,\ntask planning, and automatic knowledge integration, ensures seamless reasoning\nbetween diverse tasks. Evaluated on a 3,500-query benchmark within an\neducational scenario, the system outperforms strong zero-shot baselines\n(achieving 95.12% classification accuracy, 90.45% execution success),\nindicating potential scalability to compliance-critical or multi-step queries\nin legal and medical domains, e.g., incorporating new statutes or research on\nthe fly. Our open-source demo offers a powerful new paradigm for multi-turn\nenterprise knowledge management that bridges LLMs and structured graphs.", "AI": {"tldr": "AGENTiGraph\u662f\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u7684\u77e5\u8bc6\u56fe\u8c31\u7ba1\u7406\u7cfb\u7edf\uff0c\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u975e\u6280\u672f\u7528\u6237\u80fd\u591f\u76f4\u89c2\u5730\u6784\u5efa\u548c\u5b8c\u5584\u77e5\u8bc6\u5e93\uff0cAGENTiGraph\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u53ef\u89c6\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5141\u8bb8\u591a\u8f6e\u5bf9\u8bdd\u548c\u52a8\u6001\u66f4\u65b0\uff0c\u65e0\u9700\u4e13\u95e8\u7684\u67e5\u8be2\u8bed\u8a00\u3002", "method": "AGENTiGraph\u662f\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u7684\u3001\u4ee3\u7406\u9a71\u52a8\u7684\u7cfb\u7edf\uff0c\u5141\u8bb8\u7528\u6237\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u64cd\u4f5c\u77e5\u8bc6\u56fe\u6765\u4ea4\u4e92\u548c\u7ba1\u7406\u7279\u5b9a\u9886\u57df\u7684\u6570\u636e\u3002\u5b83\u5305\u62ec\u610f\u56fe\u5206\u7c7b\u3001\u4efb\u52a1\u89c4\u5212\u548c\u81ea\u52a8\u77e5\u8bc6\u6574\u5408\u7b49\u529f\u80fd\u3002", "result": "\u5728\u6559\u80b2\u573a\u666f\u4e0b\u76843500\u4e2a\u67e5\u8be2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAGENTiGraph\u7684\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u523095.12%\uff0c\u6267\u884c\u6210\u529f\u7387\u8fbe\u523090.45%\uff0c\u4f18\u4e8e\u5f3a\u96f6\u6837\u672c\u57fa\u7ebf\u3002", "conclusion": "AGENTiGraph\u7cfb\u7edf\u5728\u6559\u80b2\u573a\u666f\u4e0b\u76843500\u4e2a\u67e5\u8be2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u523095.12%\uff0c\u6267\u884c\u6210\u529f\u7387\u8fbe\u523090.45%\uff0c\u4f18\u4e8e\u5f3a\u96f6\u6837\u672c\u57fa\u7ebf\uff0c\u663e\u793a\u51fa\u5176\u5728\u6cd5\u5f8b\u548c\u533b\u7597\u7b49\u9886\u57df\u5904\u7406\u5408\u89c4\u6027\u5173\u952e\u6216\u591a\u6b65\u9aa4\u67e5\u8be2\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.03018", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.03018", "abs": "https://arxiv.org/abs/2508.03018", "authors": ["Yutong Wang", "Pengliang Ji", "Kaixin Li", "Baolong Bi", "Tao Feng", "Guillaume Sartoretti"], "title": "Beyond Policy Optimization: A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning", "comment": null, "summary": "Large Language Reasoning Models have demonstrated remarkable success on\nstatic tasks, yet their application to multi-round agentic planning in\ninteractive environments faces two fundamental challenges. First, the\nintractable credit assignment problem renders conventional reinforcement\nlearning ineffective in sparse-reward settings. Second, the computational\noverhead of verbose, step-by-step reasoning histories is prohibitive. To\naddress these challenges, we propose BPO, a three-stage framework\n(bootstrapping, extrapolation, and refinement) that establishes a\nself-improving data flywheel to develop robust reasoning models for\nlong-horizon, sparse-reward environments. Our framework first bootstraps\nefficient reasoning using the proposed planning quaternions with long-short\nchain-of-thought fusion. It then extrapolates to out-of-distribution tasks\nthrough complexity-stratified curriculum learning. Finally, the model\niteratively refines itself by learning exclusively on experiences selected via\nreward-gated rejection sampling. Experiments on ALFWorld, ScienceWorld, and\nWebShop demonstrate that our approach achieves state-of-the-art with\nsignificant token efficiency, providing a new recipe for reasoning models in\nagentic planning.", "AI": {"tldr": "BPO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7406\u89c4\u5212\u4e2d\u9762\u4e34\u7684\u4fe1\u7528\u5206\u914d\u548c\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u63a8\u7406\u6a21\u578b\u96be\u4ee5\u5e94\u7528\u4e8e\u4ea4\u4e92\u73af\u5883\u4e2d\u7684\u591a\u8f6e\u4ee3\u7406\u89c4\u5212\uff0c\u56e0\u4e3a\u5b58\u5728\u68d8\u624b\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\u548c\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u9636\u6bb5\u6846\u67b6BPO (bootstrapping, extrapolation, and refinement)\uff0c\u7ed3\u5408\u89c4\u5212\u56db\u5143\u6570\u548c\u957f\u77ed\u94fe\u5f0f\u601d\u7ef4\u878d\u5408\uff0c\u901a\u8fc7\u590d\u6742\u5ea6\u5206\u5c42\u8bfe\u7a0b\u5b66\u4e60\u548c\u5956\u52b1\u95e8\u63a7\u62d2\u7edd\u91c7\u6837\u8fed\u4ee3\u6539\u8fdb\u6a21\u578b\u3002", "result": "\u5728ALFWorld\uff0cScienceWorld\u548cWebShop\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5e76\u5177\u6709\u663e\u8457\u7684\u6807\u8bb0\u6548\u7387\u3002", "conclusion": "BPO\u6846\u67b6\u5728ALFWorld\uff0cScienceWorld\u548cWebShop\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5e76\u5177\u6709\u663e\u8457\u7684\u6807\u8bb0\u6548\u7387\uff0c\u4e3a\u4ee3\u7406\u89c4\u5212\u4e2d\u7684\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.03030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03030", "abs": "https://arxiv.org/abs/2508.03030", "authors": ["Siyuan Li", "Yifan Yu", "Yanchen Deng", "Zhihao Zhang", "Mengjing Chen", "Fangzhou Zhu", "Tao Zhong", "Jianye Hao", "Peng Liu", "Bo An"], "title": "Collab-Solver: Collaborative Solving Policy Learning for Mixed-Integer Linear Programming", "comment": null, "summary": "Mixed-integer linear programming (MILP) has been a fundamental problem in\ncombinatorial optimization. Previous works have designed a plethora of\nhard-coded heuristics to accomplish challenging MILP solving with domain\nknowledge. Driven by the high capability of neural networks, recent research is\ndevoted to replacing manually designed heuristics with learned policies.\nAlthough learning-based MILP methods have shown great promise, existing\nworksindependentlytreatthepolicylearningineachmoduleofMILPsolvers without\nconsidering their interdependence, severely hurting the solving speed and\nquality. To address this issue, we propose a novel multi-agent-based policy\nlearning framework for MILP (Collab-Solver), which can collaboratively optimize\nthe policies for multiple modules. Specifically, we formulate the collaboration\nof cut selection and branching in MILP solving as a Stackelberg game. Under\nthis formulation, we develop a two-phase learning paradigm to stabilize the\ncollaborative policy learning, where the first phase achieves the\ndata-communicated policy pretraining and the second phase further orchestrates\nthe policy learning for various modules. The jointly learned policy\nsignificantly improves the solving performance on both synthetic and\nlarge-scale real-world MILP datasets. Moreover, the policies learned by\nCollab-Solver have also demonstrated excellent generalization abilities across\ndifferent instance sets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aCollab-Solver\u7684\u591a\u667a\u80fd\u4f53\u534f\u540c\u7b56\u7565\u5b66\u4e60\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347MILP\u6c42\u89e3\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5b66\u4e60\u7684MILP\u65b9\u6cd5\u72ec\u7acb\u5904\u7406\u5404\u6a21\u5757\u7684\u7b56\u7565\u5b66\u4e60\uff0c\u5ffd\u7565\u6a21\u5757\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\uff0c\u5f71\u54cd\u6c42\u89e3\u901f\u5ea6\u548c\u8d28\u91cf\u3002", "method": "\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7b56\u7565\u5b66\u4e60\u7684Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u4e24\u9636\u6bb5\u5b66\u4e60\u8303\u5f0f\uff08\u6570\u636e\u901a\u4fe1\u7b56\u7565\u9884\u8bad\u7ec3\u548c\u591a\u6a21\u5757\u7b56\u7565\u5b66\u4e60\uff09\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u5927\u578bMILP\u6570\u636e\u96c6\u4e0a\uff0c\u534f\u540c\u5b66\u4e60\u7684\u7b56\u7565\u663e\u8457\u63d0\u9ad8\u4e86\u6c42\u89e3\u6027\u80fd\uff0c\u5e76\u5c55\u73b0\u51fa\u4f18\u5f02\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Collab-Solver\u6846\u67b6\u901a\u8fc7\u5c06\u5272\u9009\u62e9\u548c\u5206\u652f\u7b56\u7565\u5b66\u4e60\u5236\u5b9a\u4e3aStackelberg\u535a\u5f08\uff0c\u5e76\u91c7\u7528\u4e24\u9636\u6bb5\u5b66\u4e60\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86MILP\u6c42\u89e3\u5668\u591a\u4e2a\u6a21\u5757\u7b56\u7565\u7684\u534f\u540c\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89e3\u51b3\u901f\u5ea6\u548c\u8d28\u91cf\uff0c\u5e76\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
