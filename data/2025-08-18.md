<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Grounding Rule-Based Argumentation Using Datalog](https://arxiv.org/abs/2508.10976)
*Martin Diller,Sarah Alice Gaggl,Philipp Hanisch,Giuseppina Monterosso,Fritz Rauschenbach*

Main category: cs.AI

TL;DR: 提出一种改进的ASPIC+一阶规则推理的接地方法，通过Datalog引擎提高效率并保证正确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数基于规则的论证推理方法仅支持命题规则，而对一阶规则的推理需要预先进行接地，这可能导致输入理论规模呈指数级增长。

Method: 将一阶ASPIC+实例转换为Datalog程序，并查询Datalog引擎以获得用于对规则和反例进行接地的基本替换。此外，还提出了特定于ASPIC+形式的简化方法，以避免对推理过程没有影响的规则进行接地。

Result: 对原型实现进行了实证评估，以展示其可扩展性。

Conclusion: 提出了一种智能接地程序，该程序在保持推理过程正确性的同时，保持接地规模的可管理性。

Abstract: ASPIC+ is one of the main general frameworks for rule-based argumentation for
AI. Although first-order rules are commonly used in ASPIC+ examples, most
existing approaches to reason over rule-based argumentation only support
propositional rules. To enable reasoning over first-order instances, a
preliminary grounding step is required. As groundings can lead to an
exponential increase in the size of the input theories, intelligent procedures
are needed. However, there is a lack of dedicated solutions for ASPIC+.
Therefore, we propose an intelligent grounding procedure that keeps the size of
the grounding manageable while preserving the correctness of the reasoning
process. To this end, we translate the first-order ASPIC+ instance into a
Datalog program and query a Datalog engine to obtain ground substitutions to
perform the grounding of rules and contraries. Additionally, we propose
simplifications specific to the ASPIC+ formalism to avoid grounding of rules
that have no influence on the reasoning process. Finally, we performed an
empirical evaluation of a prototypical implementation to show scalability.

</details>


### [2] [From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching](https://arxiv.org/abs/2508.11070)
*Zahra Khotanlou,Kate Larson,Amir-Hossein Karimi*

Main category: cs.AI

TL;DR: 该论文提出一种新的多主体算法追溯框架，通过带容量的加权二部匹配和三层优化，在最大化社会福利的同时，保证个体行动的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有的算法追溯研究主要集中在单一寻求者和单一模型的场景，忽略了现实世界中多个个体相互作用和竞争有限资源的本质。

Method: 该论文提出一个三层优化框架：(1) 基本带容量匹配；(2) 最优容量再分配以最小化福利差距；(3) 成本感知优化，在福利最大化和容量调整成本之间取得平衡。

Result: 该框架能够实现多对多算法追溯，以最小的系统设置修改实现接近最优的福利。

Conclusion: 该论文提出了一种多主体算法追溯框架，用于解决现实世界中多个寻求者和提供者之间相互作用的算法追溯问题，该框架将这种多对多交互建模为一个带容量的加权二部匹配问题，并通过三层优化框架实现接近最优的社会福利，同时最大限度地减少系统设置的修改。

Abstract: Decision makers are increasingly relying on machine learning in sensitive
situations. In such settings, algorithmic recourse aims to provide individuals
with actionable and minimally costly steps to reverse unfavorable AI-driven
decisions. While existing research predominantly focuses on single-individual
(i.e., seeker) and single-model (i.e., provider) scenarios, real-world
applications often involve multiple interacting stakeholders. Optimizing
outcomes for seekers under an individual welfare approach overlooks the
inherently multi-agent nature of real-world systems, where individuals interact
and compete for limited resources. To address this, we introduce a novel
framework for multi-agent algorithmic recourse that accounts for multiple
recourse seekers and recourse providers. We model this many-to-many interaction
as a capacitated weighted bipartite matching problem, where matches are guided
by both recourse cost and provider capacity. Edge weights, reflecting recourse
costs, are optimized for social welfare while quantifying the welfare gap
between individual welfare and this collectively feasible outcome. We propose a
three-layer optimization framework: (1) basic capacitated matching, (2) optimal
capacity redistribution to minimize the welfare gap, and (3) cost-aware
optimization balancing welfare maximization with capacity adjustment costs.
Experimental validation on synthetic and real-world datasets demonstrates that
our framework enables the many-to-many algorithmic recourse to achieve
near-optimal welfare with minimum modification in system settings. This work
extends algorithmic recourse from individual recommendations to system-level
design, providing a tractable path toward higher social welfare while
maintaining individual actionability.

</details>


### [3] [Learn to optimize for automatic proton PBS treatment planning for H&N cancers](https://arxiv.org/abs/2508.11085)
*Qingqing Wang,Liqiang Xiao,Chang Chang*

Main category: cs.AI

TL;DR: 数据驱动逆优化器结合PPO自动治疗计划框架，高效生成高质量质子治疗计划，显著提高效率和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的质子治疗计划需要大量的人工干预和计算，该研究旨在通过数据驱动的方法自动化和优化这一过程。

Method: 该研究采用基于Transformer的L2O方法作为逆优化器，并结合PPO算法进行自动参数调整，利用长文本处理技术解决现有L2O方法的可扩展性问题。

Result: 与L-BFGSB相比，该研究提出的L2O逆优化器将有效性提高了22.97%，效率提高了36.41%。在与基于PPO的虚拟规划器结合使用时，该框架生成的计划平均耗时2.55小时，并且在器官危及结构保护和靶区覆盖率方面优于或与人工生成的计划相当。

Conclusion: 该研究提出了一种数据驱动逆优化器并将其集成到基于PPO的自动治疗计划框架中，以在临床可接受的计划时间内自动生成高质量的质子治疗计划，在效率和有效性方面均优于现有方法，生成的计划与人工计划相比，具有更好或相当的器官危及结构保护和更好的靶区覆盖率。

Abstract: Proton PBS treatment planning for H&N cancers involves numerous conflicting
objectives, requiring significant effort from human planners to balance and
satisfy multiple clinical goals during planning. To achieve this,
experience-demanding objective parameter adjustment and computationally
expensive inverse optimization are performed iteratively. Extensive efforts
have been made to automatically adjust objective parameters, but the most
time-consuming component, i.e., inverse optimization, still relies heavily on
theory-driven approaches. We propose a data-driven inverse optimizer and
integrate it into a PPO-based automatic treatment planning framework to
automatically generate high-quality plans within a clinical acceptable planning
time. The inverse optimizer is a L2O method that predicts update steps by
learning from the task-specific data distribution. For the first time, we
integrate techniques designed for long-context processing, originally developed
for LLMs, into a Transformer-based L2O framework to address the scalability
issue of existing L2O methods. The PPO framework functions as an outer-loop
virtual planner, autonomously adjusting objective parameters through a policy
network, and the dose predictor is used to initialize objective parameters. The
inner-loop L2O inverse optimizer computes machine-deliverable MU values based
on objectives refined by the PPO policy network. 97 patients are collected in
this study, and compared with L-BFGSB, our L2O-based inverse optimizer improves
the effectiveness and efficiency by 22.97% and 36.41%, respectively. In
conjunction with the PPO-based learned virtual planner, plans generated by our
framework within an average of 2.55 hours show improved or comparable OAR
sparing with superior target coverage for patients with different prescription
dose levels, number of target volumes, beam angles, etc., compared with
human-generated plans.

</details>


### [4] [On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation](https://arxiv.org/abs/2508.11182)
*Matti Berthold,Lydia Blümel,Anna Rapberger*

Main category: cs.AI

TL;DR: 本文研究了基于假设的论证中强和弱可容许性，并扩展了相应的语义到一般非扁平框架，证明了中心模块化特性，并讨论了解决其不足的方法。


<details>
  <summary>Details</summary>
Motivation: 标准可容许性概念的局限性，以及对强和弱可容许性的研究不足。

Method: 使用抽象双极集论证框架(BSAFs)作为形式化手段，研究了强和弱可容许性，并扩展了弱可容许性在扁平ABA片段中的研究到非扁平情况。

Result: 证明了在经典、强和弱可容许性下，中心模块化特性得以保持。强和弱可容许语义在非扁平ABA中也存在一些不足，并讨论了解决这些不足的方法。

Conclusion: 本文扩展了基于假设的论证(ABA)中可容许性概念的研究，研究了强和弱可容许性两种重要的替代方案，并引入了相应的首选、完整和接地语义，用于一般的非扁平ABA。

Abstract: In this work, we broaden the investigation of admissibility notions in the
context of assumption-based argumentation (ABA). More specifically, we study
two prominent alternatives to the standard notion of admissibility from
abstract argumentation, namely strong and weak admissibility, and introduce the
respective preferred, complete and grounded semantics for general (sometimes
called non-flat) ABA. To do so, we use abstract bipolar set-based argumentation
frameworks (BSAFs) as formal playground since they concisely capture the
relations between assumptions and are expressive enough to represent general
non-flat ABA frameworks, as recently shown. While weak admissibility has been
recently investigated for a restricted fragment of ABA in which assumptions
cannot be derived (flat ABA), strong admissibility has not been investigated
for ABA so far. We introduce strong admissibility for ABA and investigate
desirable properties. We furthermore extend the recent investigations of weak
admissibility in the flat ABA fragment to the non-flat case. We show that the
central modularization property is maintained under classical, strong, and weak
admissibility. We also show that strong and weakly admissible semantics in
non-flat ABA share some of the shortcomings of standard admissible semantics
and discuss ways to address these.

</details>


### [5] [Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information](https://arxiv.org/abs/2508.11252)
*Youcheng Huang,Bowen Qin,Chen Huang,Duanyu Feng,Xi Yang,Wenqiang Lei*

Main category: cs.AI

TL;DR: 大型推理模型难以处理信息不完整的问题，需要改进以增强其主动获取信息的能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法忽略了智能体主动索要信息的能力，本文旨在弥补这一差距。

Method: 构建了一个包含两种不完整问题类型的新数据集，系统性地评估了LRM在主动索要信息方面的能力，并揭示了LRM的过度思考和幻觉行为。

Result: LRM难以主动索要信息，存在过度思考和幻觉问题，监督微调在学习此能力方面也存在挑战。

Conclusion: 大型推理模型(LRM)在解决数学问题方面表现出色，但现有基准测试仅限于定义明确的问题，这存在缺陷。真正的智能体不仅要解决问题，还要在信息不足时主动索要信息。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable problem-solving
abilities in mathematics, as evaluated by existing benchmarks exclusively on
well-defined problems. However, such evaluation setup constitutes a critical
gap, since a genuine intelligent agent should not only solve problems (as a
math quiz solver), but also be able~to ask for information when the problems
lack sufficient information, enabling proactivity in responding users'
requests. To bridge such gap, we proposes a new dataset consisting of two types
of incomplete problems with diverse contexts. Based on the dataset, our
systematical evaluation of LRMs reveals their inability in proactively asking
for information. In addition, we uncover the behaviors related to overthinking
and hallucination of LRMs, and highlight the potential and challenges of
supervised fine-tuning in learning such ability. We hope to provide new
insights in developing LRMs with genuine intelligence, rather than just solving
problems.

</details>


### [6] [SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding](https://arxiv.org/abs/2508.11347)
*Yifei Li,Lingling Zhang,Hang Yan,Tianzhe Zhao,Zihan Ma,Muye Huang,Jun Liu*

Main category: cs.AI

TL;DR: SAGE是一个新的规模感知的CKGE框架，它通过自适应嵌入维度和动态蒸馏机制，有效地处理了动态知识图的更新，并在基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的CKGE方法往往未能考虑更新的不同规模，并且缺乏对整个更新过程的系统评估。

Method: 提出了一种规模感知的渐进式演化框架SAGE，该框架首先根据更新规模确定嵌入维度并相应地扩展嵌入空间，然后采用动态蒸馏机制来平衡已学习知识的保存和新事实的结合。

Result: SAGE在七个基准测试上取得了最先进的结果，并在每个快照上都取得了最佳性能，优于使用固定嵌入维度的现有方法。

Conclusion: SAGE框架在七个基准测试中持续优于现有基线，在MRR、H@1和H@10方面分别提高了1.38%、1.25%和1.6%，并证明了自适应嵌入维度在CKGE中的重要性。

Abstract: Traditional knowledge graph (KG) embedding methods aim to represent entities
and relations in a low-dimensional space, primarily focusing on static graphs.
However, real-world KGs are dynamically evolving with the constant addition of
entities, relations and facts. To address such dynamic nature of KGs, several
continual knowledge graph embedding (CKGE) methods have been developed to
efficiently update KG embeddings to accommodate new facts while maintaining
learned knowledge. As KGs grow at different rates and scales in real-world
scenarios, existing CKGE methods often fail to consider the varying scales of
updates and lack systematic evaluation throughout the entire update process. In
this paper, we propose SAGE, a scale-aware gradual evolution framework for
CKGE. Specifically, SAGE firstly determine the embedding dimensions based on
the update scales and expand the embedding space accordingly. The Dynamic
Distillation mechanism is further employed to balance the preservation of
learned knowledge and the incorporation of new facts. We conduct extensive
experiments on seven benchmarks, and the results show that SAGE consistently
outperforms existing baselines, with a notable improvement of 1.38% in MRR,
1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with
methods using fixed embedding dimensions show that SAGE achieves optimal
performance on every snapshot, demonstrating the importance of adaptive
embedding dimensions in CKGE. The codes of SAGE are publicly available at:
https://github.com/lyfxjtu/Dynamic-Embedding.

</details>


### [7] [CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks](https://arxiv.org/abs/2508.11360)
*Songqin Nong,Jingxuan Xu,Sheng Zhou,Jianfeng Chen,Xiaoxuan Tang,Tao Jiang,Wenhao Xu*

Main category: cs.AI

TL;DR: CRAFT-GUI框架通过课程学习和改进的奖励函数，显著提升了强化学习智能体在GUI环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在GUI任务中存在两个局限性：忽略任务难度差异和奖励信号粗糙。

Method: CRAFT-GUI框架，基于Group Relative Policy Optimization (GRPO)的课程学习框架，结合简单的规则信号和模型评估的奖励函数。

Result: 在Android Control公开基准测试中提高了5.6%，在内部在线基准测试中提高了10.3%。

Conclusion: CRAFT-GUI框架通过结合课程学习和基于GRPO的策略优化，显著提高了智能体在GUI环境中执行任务的效率，并在公开基准测试和内部基准测试中均取得了优于现有技术的成果。

Abstract: As autonomous agents become adept at understanding and interacting with
graphical user interface (GUI) environments, a new era of automated task
execution is emerging. Recent studies have demonstrated that Reinforcement
Learning (RL) can effectively enhance agents' performance in dynamic
interactive GUI environments. However, these methods face two key limitations:
(1) they overlook the significant variation in difficulty across different GUI
tasks by treating the entire training data as a uniform set, which hampers the
agent's ability to adapt its learning process; and (2) most approaches collapse
task-specific nuances into a single, coarse reward, leaving the agent with a
uniform signal that yields inefficient policy updates. To address these
limitations, we propose CRAFT-GUI, a curriculum learning framework based on
Group Relative Policy Optimization (GRPO) that explicitly accounts for the
varying difficulty across trajectories. To enable more fine-grained policy
optimization, we design a reward function that combines simple rule-based
signals with model-judged evaluation, providing richer and more nuanced
feedback during training. Experimental results demonstrate that our method
achieves significant improvements over previous state-of-the-art approaches,
outperforming them by 5.6% on public benchmarks Android Control and 10.3% on
our internal online benchmarks, respectively. These findings empirically
validate the effectiveness of integrating reinforcement learning with
curriculum learning in GUI interaction tasks.

</details>


### [8] [AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager](https://arxiv.org/abs/2508.11416)
*Xuhua Zhao,Yuxuan Xie,Caihua Chen,Yuxiang Sun*

Main category: cs.AI

TL;DR: 研究发现LLM代理在库存决策中存在与人类相似的偏差，并提出通过认知反思和信息共享等策略来缓解这些偏差。


<details>
  <summary>Details</summary>
Motivation: LLM 代理在不确定环境下的库存决策能力以及决策偏差（例如框架效应）等问题仍未得到充分探索。

Method: 构建了一个名为 AIM-Bench 的基准，用于评估 LLM 代理在不确定供应链管理场景中的决策行为。通过一系列库存补充实验，评估了不同LLM的决策偏差。

Result: 不同LLM表现出不同程度的决策偏差，类似于人类。认知反思和信息共享可以减轻中心效应和牛鞭效应。

Conclusion: 该论文介绍了 AIM-Bench，一个用于评估大型语言模型 (LLM) 代理在不确定供应链管理场景中决策行为的基准。结果表明，不同的 LLM 通常表现出不同程度的决策偏差，类似于人类。此外，研究了减轻中心效应和牛鞭效应的策略，例如认知反思和信息共享的实施。

Abstract: Recent advances in mathematical reasoning and the long-term planning
capabilities of large language models (LLMs) have precipitated the development
of agents, which are being increasingly leveraged in business operations
processes. Decision models to optimize inventory levels are one of the core
elements of operations management. However, the capabilities of the LLM agent
in making inventory decisions in uncertain contexts, as well as the
decision-making biases (e.g. framing effect, etc.) of the agent, remain largely
unexplored. This prompts concerns regarding the capacity of LLM agents to
effectively address real-world problems, as well as the potential implications
of biases that may be present. To address this gap, we introduce AIM-Bench, a
novel benchmark designed to assess the decision-making behaviour of LLM agents
in uncertain supply chain management scenarios through a diverse series of
inventory replenishment experiments. Our results reveal that different LLMs
typically exhibit varying degrees of decision bias that are similar to those
observed in human beings. In addition, we explored strategies to mitigate the
pull-to-centre effect and the bullwhip effect, namely cognitive reflection and
implementation of information sharing. These findings underscore the need for
careful consideration of the potential biases in deploying LLMs in Inventory
decision-making scenarios. We hope that these insights will pave the way for
mitigating human decision bias and developing human-centred decision support
systems for supply chains.

</details>


### [9] [Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps](https://arxiv.org/abs/2508.11452)
*Kangyu Wang,Hongliang He,Lin Liu,Ruiqi Liang,Zhenzhong Lan,Jianguo Li*

Main category: cs.AI

TL;DR: Inclusion Arena是一个基于真实用户反馈的LLM和MLLM模型排名平台，排名更可靠，更能反映实际应用效果。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试依赖静态数据集或众包，难以反映真实世界应用中的性能。

Method: 该平台整合了成对模型比较到自然用户交互中，采用改进的Bradley-Terry模型，并结合Placement Matches和Proximity Sampling两种创新机制对模型进行排名。

Result: Inclusion Arena平台提供可靠稳定的模型排名，数据传递性高，有效降低了恶意操纵的风险，加速了LLM和MLLM的实际应用开发。

Conclusion: Inclusion Arena平台通过收集来自AI应用的真实用户反馈，对LLM和MLLM模型进行排名，解决了现有基准测试依赖静态数据集或众包的问题，该平台采用改进的Bradley-Terry模型，并结合Placement Matches和Proximity Sampling两种创新机制，确保排名可靠稳定，并能有效防止恶意操纵。

Abstract: Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)
have ushered in a new era of AI capabilities, demonstrating near-human-level
performance across diverse scenarios. While numerous benchmarks (e.g., MMLU)
and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the
development of LLMs and MLLMs, most rely on static datasets or crowdsourced
general-domain prompts, often falling short of reflecting performance in
real-world applications. To bridge this critical gap, we present Inclusion
Arena, a live leaderboard that ranks models based on human feedback collected
directly from AI-powered applications. Our platform integrates pairwise model
comparisons into natural user interactions, ensuring evaluations reflect
practical usage scenarios. For robust model ranking, we employ the
Bradley-Terry model augmented with two key innovations: (1) Placement Matches,
a cold-start mechanism to quickly estimate initial ratings for newly integrated
models, and (2) Proximity Sampling, an intelligent comparison strategy that
prioritizes battles between models of similar capabilities to maximize
information gain and enhance rating stability. Extensive empirical analyses and
simulations demonstrate that Inclusion Arena yields reliable and stable
rankings, exhibits higher data transitivity compared to general crowdsourced
datasets, and significantly mitigates the risk of malicious manipulation. By
fostering an open alliance between foundation models and real-world
applications, Inclusion Arena aims to accelerate the development of LLMs and
MLLMs truly optimized for practical, user-centric deployments. The platform is
publicly accessible at https://doraemon.alipay.com/model-ranking.

</details>


### [10] [Landmark-Assisted Monte Carlo Planning](https://arxiv.org/abs/2508.11493)
*David H. Chan,Mark Roberts,Dana S. Nau*

Main category: cs.AI

TL;DR: Probabilistic landmarks improve UCT performance in online probabilistic planning, but optimal balance between greedy and long-term goals is problem-specific.


<details>
  <summary>Details</summary>
Motivation: Landmarks have contributed to major advancements in classical planning, but seldom used in stochastic domains.

Method: Formalized probabilistic landmarks and adapted the UCT algorithm to leverage them as subgoals to decompose MDPs.

Result: Well-chosen landmarks can significantly improve the performance of UCT in online probabilistic planning.  The best balance of greedy versus long-term goal achievement is problem-dependent.

Conclusion: Probabilistic landmarks can significantly improve the performance of UCT in online probabilistic planning, but the optimal balance between greedy landmark achievement and final goal achievement is problem-dependent.

Abstract: Landmarks$\unicode{x2013}$conditions that must be satisfied at some point in
every solution plan$\unicode{x2013}$have contributed to major advancements in
classical planning, but they have seldom been used in stochastic domains. We
formalize probabilistic landmarks and adapt the UCT algorithm to leverage them
as subgoals to decompose MDPs; core to the adaptation is balancing between
greedy landmark achievement and final goal achievement. Our results in
benchmark domains show that well-chosen landmarks can significantly improve the
performance of UCT in online probabilistic planning, while the best balance of
greedy versus long-term goal achievement is problem-dependent. The results
suggest that landmarks can provide helpful guidance for anytime algorithms
solving MDPs.

</details>


### [11] [Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models](https://arxiv.org/abs/2508.11524)
*Wenkai Yu,Jianhang Tang,Yang Zhang,Shanjiang Tang,Kebing Jin,Hankz Hankui Zhuo*

Main category: cs.AI

TL;DR: 利用大型语言模型结合问题分解和领域特定知识，有效解决了大规模规划问题。


<details>
  <summary>Details</summary>
Motivation: 解决大规模规划问题中的状态空间爆炸问题，现有方法忽略了将大型语言模型与领域特定知识相结合。

Method: 提出了一种结合问题分解的，由大型语言模型辅助的规划器，包含LLM4Inspire和LLM4Predict两种利用LLM的范式。

Result: 实验证明该方法有效缩减了搜索空间，提高了解决大规模规划问题的效率，其中LLM4Predict（利用领域特定知识）的效果优于LLM4Inspire（利用通用知识）。

Conclusion: 本文提出了一种新颖的，结合了问题分解的，由大型语言模型辅助的规划器，该规划器将大型规划问题分解成多个简单的子任务，并利用LLM4Inspire和LLM4Predict两种范式辅助问题分解，实验证明该方法有效缩减了搜索空间，提高了解决大规模规划问题的效率，其中LLM4Predict（利用领域特定知识）的效果优于LLM4Inspire（利用通用知识）。

Abstract: Addressing large-scale planning problems has become one of the central
challenges in the planning community, deriving from the state-space explosion
caused by growing objects and actions. Recently, researchers have explored the
effectiveness of leveraging Large Language Models (LLMs) to generate helpful
actions and states to prune the search space. However, prior works have largely
overlooked integrating LLMs with domain-specific knowledge to ensure valid
plans. In this paper, we propose a novel LLM-assisted planner integrated with
problem decomposition, which first decomposes large planning problems into
multiple simpler sub-tasks. Then we explore two novel paradigms to utilize
LLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where
LLM4Inspire provides heuristic guidance according to general knowledge and
LLM4Predict employs domain-specific knowledge to infer intermediate conditions.
We empirically validate the effectiveness of our planner across multiple
domains, demonstrating the ability of search space partition when solving
large-scale planning problems. The experimental results show that LLMs
effectively locate feasible solutions when pruning the search space, where
infusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds
particular promise compared with LLM4Inspire, which offers general knowledge
within LLMs.

</details>
