{"id": "2507.22951", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22951", "abs": "https://arxiv.org/abs/2507.22951", "authors": ["Alessandro Lonardi", "Samy Badreddine", "Tarek R. Besold", "Pablo Sanchez Martin"], "title": "Unifying Post-hoc Explanations of Knowledge Graph Completions", "comment": null, "summary": "Post-hoc explainability for Knowledge Graph Completion (KGC) lacks\nformalization and consistent evaluations, hindering reproducibility and\ncross-study comparisons. This paper argues for a unified approach to post-hoc\nexplainability in KGC. First, we propose a general framework to characterize\npost-hoc explanations via multi-objective optimization, balancing their\neffectiveness and conciseness. This unifies existing post-hoc explainability\nalgorithms in KGC and the explanations they produce. Next, we suggest and\nempirically support improved evaluation protocols using popular metrics like\nMean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of\ninterpretability as the ability of explanations to address queries meaningful\nto end-users. By unifying methods and refining evaluation standards, this work\naims to make research in KGC explainability more reproducible and impactful.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u6539\u8fdb\u8bc4\u4f30\u534f\u8bae\uff0c\u63d0\u5347 KGC \u53ef\u89e3\u91ca\u6027\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u548c\u5f71\u54cd\u529b\u3002", "motivation": "KGC \u7684\u4e8b\u540e\u53ef\u89e3\u91ca\u6027\u7f3a\u4e4f\u5f62\u5f0f\u5316\u548c\u4e00\u81f4\u7684\u8bc4\u4f30\uff0c\u963b\u788d\u4e86\u53ef\u91cd\u590d\u6027\u548c\u8de8\u7814\u7a76\u6bd4\u8f83\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\u6765\u63cf\u8ff0 KGC \u4e2d\u7684\u4e8b\u540e\u89e3\u91ca\uff0c\u5e73\u8861\u4e86\u5176\u6709\u6548\u6027\u548c\u7b80\u6d01\u6027\uff1b\u5e76\u5efa\u8bae\u5e76\u5b9e\u8bc1\u652f\u6301\u4f7f\u7528\u5e73\u5747\u5012\u6570\u6392\u540d\u548c Hits@$k$ \u7b49\u5e38\u7528\u6307\u6807\u6539\u8fdb\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u7edf\u4e00\u4e86\u73b0\u6709\u7684 KGC \u4e8b\u540e\u53ef\u89e3\u91ca\u6027\u7b97\u6cd5\u53ca\u5176\u4ea7\u751f\u7684\u89e3\u91ca\uff1b\u6539\u8fdb\u8bc4\u4f30\u534f\u8bae\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u65e8\u5728\u901a\u8fc7\u7edf\u4e00\u65b9\u6cd5\u548c\u6539\u8fdb\u8bc4\u4f30\u6807\u51c6\uff0c\u4f7f\u77e5\u8bc6\u56fe\u8c31\u8865\u5168 (KGC) \u53ef\u89e3\u91ca\u6027\u7814\u7a76\u66f4\u5177\u53ef\u91cd\u590d\u6027\u548c\u5f71\u54cd\u529b\u3002"}}
{"id": "2507.23018", "categories": ["cs.AI", "cs.CE", "cs.DC", "cs.LG", "I.2.6"], "pdf": "https://arxiv.org/pdf/2507.23018", "abs": "https://arxiv.org/abs/2507.23018", "authors": ["Wesley Brewer", "Patrick Widener", "Valentine Anantharaj", "Feiyi Wang", "Tom Beck", "Arjun Shankar", "Sarp Oral"], "title": "Data Readiness for Scientific AI at Scale", "comment": "10 pages, 1 figure, 2 tables", "summary": "This paper examines how Data Readiness for AI (DRAI) principles apply to\nleadership-scale scientific datasets used to train foundation models. We\nanalyze archetypal workflows across four representative domains - climate,\nnuclear fusion, bio/health, and materials - to identify common preprocessing\npatterns and domain-specific constraints. We introduce a two-dimensional\nreadiness framework composed of Data Readiness Levels (raw to AI-ready) and\nData Processing Stages (ingest to shard), both tailored to high performance\ncomputing (HPC) environments. This framework outlines key challenges in\ntransforming scientific data for scalable AI training, emphasizing\ntransformer-based generative models. Together, these dimensions form a\nconceptual maturity matrix that characterizes scientific data readiness and\nguides infrastructure development toward standardized, cross-domain support for\nscalable and reproducible AI for science.", "AI": {"tldr": "\u7814\u7a76\u5982\u4f55\u5c06\u6570\u636e\u51c6\u5907\u5c31\u7eea\u5ea6\u539f\u5219\u5e94\u7528\u4e8e\u79d1\u5b66\u6570\u636e\u96c6\u4ee5\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\uff0c\u63d0\u51fa\u4e00\u4e2a\u4e8c\u7ef4\u6846\u67b6\u8bc4\u4f30\u79d1\u5b66\u6570\u636e\u51c6\u5907\u60c5\u51b5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5c06\u79d1\u5b66\u6570\u636e\u8f6c\u5316\u4e3a\u53ef\u6269\u5c55AI\u8bad\u7ec3\u7684\u5173\u952e\u6311\u6218\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u8f6c\u6362\u5668\u7684\u751f\u6210\u6a21\u578b\u3002", "method": "\u5206\u6790\u4e86\u56db\u4e2a\u4ee3\u8868\u6027\u9886\u57df\uff08\u6c14\u5019\u3001\u6838\u805a\u53d8\u3001\u751f\u7269/\u5065\u5eb7\u548c\u6750\u6599\uff09\u7684\u5178\u578b\u5de5\u4f5c\u6d41\u7a0b\uff0c\u786e\u5b9a\u4e86\u5e38\u89c1\u7684\u9884\u5904\u7406\u6a21\u5f0f\u548c\u7279\u5b9a\u9886\u57df\u7684\u7ea6\u675f\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7531\u6570\u636e\u51c6\u5907\u5c31\u7eea\u7ea7\u522b\u548c\u6570\u636e\u5904\u7406\u9636\u6bb5\u7ec4\u6210\u7684\u4e8c\u7ef4\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e8c\u7ef4\u51c6\u5907\u5c31\u7eea\u6846\u67b6\uff0c\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u79d1\u5b66\u6570\u636e\u51c6\u5907\u60c5\u51b5\u8fdb\u884c\u4e86\u8868\u5f81\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u6570\u636e\u51c6\u5907\u5c31\u7eea\u5ea6 (DRAI) \u539f\u5219\u5982\u4f55\u5e94\u7528\u4e8e\u7528\u4e8e\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u7684\u9886\u5bfc\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u4e8c\u7ef4\u6846\u67b6\u6765\u8868\u5f81\u79d1\u5b66\u6570\u636e\u7684\u51c6\u5907\u5c31\u7eea\u72b6\u6001\uff0c\u6307\u5bfc\u57fa\u7840\u8bbe\u65bd\u5f00\u53d1\uff0c\u4ece\u800c\u4e3a\u79d1\u5b66\u7684AI\u63d0\u4f9b\u6807\u51c6\u5316\u3001\u8de8\u9886\u57df\u7684\u652f\u6491\u3002"}}
{"id": "2507.23067", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23067", "abs": "https://arxiv.org/abs/2507.23067", "authors": ["Zhenyu Pan", "Yutong Zhang", "Jianshu Zhang", "Haoran Lu", "Haozheng Luo", "Yuwei Han", "Philip S. Yu", "Manling Li", "Han Liu"], "title": "FairReason: Balancing Reasoning and Social Bias in MLLMs", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) already achieve state-of-the-art\nresults across a wide range of tasks and modalities. To push their reasoning\nability further, recent studies explore advanced prompting schemes and\npost-training fine-tuning. Although these techniques improve logical accuracy,\nthey frequently leave the models' outputs burdened with pronounced social\nbiases. Clarifying how reasoning gains interact with bias mitigation-and\nwhether the two objectives inherently trade off-therefore remains an open and\npressing research problem. Our study begins by benchmarking three\nbias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation\n(KD), and rule-based reinforcement learning (RL)-under identical conditions,\nestablishing their baseline strengths and weaknesses. Building on these\nresults, we vary the proportion of debias-focused and reasoning-centric samples\nwithin each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps\nreveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement\nlearning cuts stereotype scores by 10% while retaining 88% of the model's\noriginal reasoning accuracy, offering concrete guidance for balancing fairness\nand capability in MLLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u7279\u5b9a\u6bd4\u4f8b\u7684\u6570\u636e\u80fd\u591f\u6709\u6548\u5e73\u8861MLLM\u7684\u63a8\u7406\u80fd\u529b\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709\u7684MLLM\u867d\u7136\u5728\u591a\u79cd\u4efb\u52a1\u548c\u6a21\u6001\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u4f46\u5728\u63a8\u7406\u80fd\u529b\u548c\u793e\u4f1a\u504f\u89c1\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u5bf9\u4e09\u79cd\u504f\u89c1\u7f13\u89e3\u7b56\u7565\uff08\u76d1\u7763\u5fae\u8c03\u3001\u77e5\u8bc6\u84b8\u998f\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60\uff09\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u901a\u8fc7\u6539\u53d8\u4e0d\u540c\u7c7b\u578b\u6837\u672c\u7684\u6bd4\u4f8b\u6765\u7814\u7a76\u63a8\u7406\u80fd\u529b\u548c\u504f\u89c1\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u57281:4\u7684\u6837\u672c\u6bd4\u4f8b\u4e0b\uff0c\u5c06\u523b\u677f\u5370\u8c61\u5f97\u5206\u964d\u4f4e\u4e8610%\uff0c\u540c\u65f6\u4fdd\u7559\u4e8688%\u7684\u539f\u59cb\u63a8\u7406\u51c6\u786e\u7387\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8c03\u67e5\u4e86\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b (MLLM) \u4e2d\u63a8\u7406\u80fd\u529b\u63d0\u5347\u4e0e\u504f\u89c1\u7f13\u89e3\u4e4b\u95f4\u7684\u6743\u8861\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u4ee51:4\u7684\u6bd4\u4f8b\u6df7\u5408\u53bb\u504f\u89c1\u548c\u63a8\u7406\u6837\u672c\uff0c\u53ef\u4ee5\u5728\u51cf\u5c11\u523b\u677f\u5370\u8c61\u5f97\u5206\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u8f83\u9ad8\u7684\u63a8\u7406\u51c6\u786e\u7387\u3002"}}
{"id": "2507.23091", "categories": ["cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.23091", "abs": "https://arxiv.org/abs/2507.23091", "authors": ["David Noever", "Forrest McKee"], "title": "Moravec's Paradox: Towards an Auditory Turing Test", "comment": null, "summary": "This research work demonstrates that current AI systems fail catastrophically\non auditory tasks that humans perform effortlessly. Drawing inspiration from\nMoravec's paradox (i.e., tasks simple for humans often prove difficult for\nmachines, and vice versa), we introduce an auditory Turing test comprising 917\nchallenges across seven categories: overlapping speech, speech in noise,\ntemporal distortion, spatial audio, coffee-shop noise, phone distortion, and\nperceptual illusions. Our evaluation of state-of-the-art audio models including\nGPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate\nexceeding 93%, with even the best-performing model achieving only 6.9% accuracy\non tasks that humans solved at 7.5 times higher success (52%). These results\nexpose focusing failures in how AI systems process complex auditory scenes,\nparticularly in selective attention, noise robustness, and contextual\nadaptation. Our benchmark not only quantifies the human-machine auditory gap\nbut also provides insights into why these failures occur, suggesting that\ncurrent architectures lack fundamental mechanisms for human-like auditory scene\nanalysis. The traditional design of audio CAPTCHAs highlights common filters\nthat humans evolved but machines fail to select in multimodal language models.\nThis work establishes a diagnostic framework for measuring progress toward\nhuman-level machine listening and highlights the need for novel approaches\nintegrating selective attention, physics-based audio understanding, and\ncontext-aware perception into multimodal AI systems.", "AI": {"tldr": "AI\u542c\u89c9\u80fd\u529b\u8fdc\u843d\u540e\u4e8e\u4eba\u7c7b\uff0c\u9700\u6539\u8fdb\u9009\u62e9\u6027\u6ce8\u610f\u3001\u57fa\u4e8e\u7269\u7406\u7684\u97f3\u9891\u7406\u89e3\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7b49\u673a\u5236\u3002", "motivation": "\u83ab\u62c9\u7ef4\u514b\u6096\u8bba\u542f\u53d1\uff0c\u65e8\u5728\u91cf\u5316\u4eba\u7c7b\u548c\u673a\u5668\u5728\u542c\u89c9\u80fd\u529b\u4e0a\u7684\u5dee\u8ddd\uff0c\u5e76\u627e\u51faAI\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u542c\u89c9\u573a\u666f\u65f6\u5b58\u5728\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b917\u4e2a\u6311\u6218\u7684\u542c\u89c9\u56fe\u7075\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u5305\u62ecGPT-4\u548cWhisper\u5728\u5185\u7684\u591a\u4e2a\u6700\u5148\u8fdb\u7684\u97f3\u9891\u6a21\u578b\u3002", "result": "AI\u6a21\u578b\u5728\u542c\u89c9\u4efb\u52a1\u4e0a\u7684\u5931\u8d25\u7387\u8d85\u8fc793%\uff0c\u5373\u4f7f\u662f\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\u51c6\u786e\u7387\u4e5f\u53ea\u67096.9%\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u768452%\u3002\u7ed3\u679c\u63ed\u793a\u4e86AI\u7cfb\u7edf\u5728\u9009\u62e9\u6027\u6ce8\u610f\u3001\u566a\u58f0\u9c81\u68d2\u6027\u548c\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "conclusion": "\u5f53\u524dAI\u7cfb\u7edf\u5728\u4eba\u7c7b\u8f7b\u677e\u5b8c\u6210\u7684\u542c\u89c9\u4efb\u52a1\u4e0a\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u8be5\u7814\u7a76\u901a\u8fc7\u4e00\u4e2a\u5305\u542b\u4e03\u4e2a\u7c7b\u522b\u7684\u542c\u89c9\u56fe\u7075\u6d4b\u8bd5\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684\u97f3\u9891\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793aAI\u6a21\u578b\u7684\u5931\u8d25\u7387\u8d85\u8fc793%\uff0c\u4e0e\u4eba\u7c7b\u8868\u73b0\u5b58\u5728\u5de8\u5927\u5dee\u8ddd\u3002"}}
{"id": "2507.23163", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.23163", "abs": "https://arxiv.org/abs/2507.23163", "authors": ["Deniz Gorur", "Antonio Rago", "Francesca Toni"], "title": "Argumentatively Coherent Judgmental Forecasting", "comment": "17 pages, 18 figures, ECAI 2025", "summary": "Judgmental forecasting employs human opinions to make predictions about\nfuture events, rather than exclusively historical data as in quantitative\nforecasting. When these opinions form an argumentative structure around\nforecasts, it is useful to study the properties of the forecasts from an\nargumentative perspective. In this paper, we advocate and formally define a\nproperty of argumentative coherence, which, in essence, requires that a\nforecaster's reasoning is coherent with their forecast. We then conduct three\nevaluations with our notion of coherence. First, we assess the impact of\nenforcing coherence on human forecasters as well as on Large Language Model\n(LLM)-based forecasters, given that they have recently shown to be competitive\nwith human forecasters. In both cases, we show that filtering out incoherent\npredictions improves forecasting accuracy consistently, supporting the\npractical value of coherence in both human and LLM-based forecasting. Then, via\ncrowd-sourced user experiments, we show that, despite its apparent\nintuitiveness and usefulness, users do not generally align with this coherence\nproperty. This points to the need to integrate, within argumentation-based\njudgmental forecasting, mechanisms to filter out incoherent opinions before\nobtaining group forecasting predictions.", "AI": {"tldr": "\u9884\u6d4b\u4e00\u81f4\u6027\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u7528\u6237\u4e0d\u8ba4\u540c\uff0c\u9700\u6539\u8fdb\u8fc7\u6ee4\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u8bba\u8bc1\u7ed3\u6784\u4e2d\u9884\u6d4b\u7684\u4e00\u81f4\u6027\uff0c\u4ee5\u63d0\u9ad8\u5224\u65ad\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u8bc4\u4f30\u5f3a\u5236\u4e00\u81f4\u6027\u5bf9\u4eba\u7c7b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u4f17\u5305\u7528\u6237\u5b9e\u9a8c\u8bc4\u4f30\u7528\u6237\u5bf9\u4e00\u81f4\u6027\u7684\u8ba4\u540c\u7a0b\u5ea6\u3002", "result": "\u5f3a\u5236\u4e00\u81f4\u6027\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u7528\u6237\u5e76\u4e0d\u603b\u662f\u8ba4\u540c\u8fd9\u79cd\u4e00\u81f4\u6027\uff0c\u8fd9\u8868\u660e\u9700\u8981\u5728\u57fa\u4e8e\u8bba\u8bc1\u7684\u5224\u65ad\u9884\u6d4b\u4e2d\u52a0\u5165\u8fc7\u6ee4\u4e0d\u4e00\u81f4\u610f\u89c1\u7684\u673a\u5236\u3002", "conclusion": "\u5f3a\u5236\u9884\u6d4b\u4e00\u81f4\u6027\u53ef\u4ee5\u63d0\u9ad8\u4eba\u7c7b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u7528\u6237\u901a\u5e38\u5e76\u4e0d\u8ba4\u540c\u8fd9\u79cd\u4e00\u81f4\u6027\u3002"}}
{"id": "2507.23191", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23191", "abs": "https://arxiv.org/abs/2507.23191", "authors": ["Meghyn Bienvenu", "Diego Figueira", "Pierre Lafourcade"], "title": "Tractable Responsibility Measures for Ontology-Mediated Query Answering", "comment": "Long version of a paper to appear at KR 2025, which contains further\n  proof details in the appendix", "summary": "Recent work on quantitative approaches to explaining query answers employs\nresponsibility measures to assign scores to facts in order to quantify their\nrespective contributions to obtaining a given answer. In this paper, we study\nthe complexity of computing such responsibility scores in the setting of\nontology-mediated query answering, focusing on a very recently introduced\nfamily of Shapley-value-based responsibility measures defined in terms of\nweighted sums of minimal supports (WSMS). By exploiting results from the\ndatabase setting, we can show that such measures enjoy polynomial data\ncomplexity for classes of ontology-mediated queries that are\nfirst-order-rewritable, whereas the problem becomes \"shP\"-hard when the\nontology language can encode reachability queries (via axioms like $\\exists R.\nA \\sqsubseteq A$). To better understand the tractability frontier, we next\nexplore the combined complexity of WSMS computation. We prove that\nintractability applies already to atomic queries if the ontology language\nsupports conjunction, as well as to unions of `well-behaved' conjunctive\nqueries, even in the absence of an ontology. By contrast, our study yields\npositive results for common DL-Lite dialects: by means of careful analysis, we\nidentify classes of structurally restricted conjunctive queries (which\nintuitively disallow undesirable interactions between query atoms) that admit\ntractable WSMS computation.", "AI": {"tldr": "\u672c\u4f53\u4ecb\u5bfc\u67e5\u8be2\u5e94\u7b54\u4e2d\u8ba1\u7b97\u8d23\u4efb\u5206\u6570\u7684\u590d\u6742\u6027\u7814\u7a76\uff0c\u7ed3\u679c\u8868\u660e\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u662f\u591a\u9879\u5f0f\u590d\u6742\u5ea6\uff0c\u800c\u5728\u53e6\u4e00\u4e9b\u60c5\u51b5\u4e0b\u662f\u96be\u5904\u7406\u7684\u3002", "motivation": "\u91cf\u5316\u89e3\u91ca\u67e5\u8be2\u7b54\u6848\u7684\u5b9a\u91cf\u65b9\u6cd5\uff0c\u5229\u7528\u8d23\u4efb\u5ea6\u91cf\u4e3a\u4e8b\u5b9e\u5206\u914d\u5206\u6570\u4ee5\u91cf\u5316\u5b83\u4eec\u5bf9\u83b7\u5f97\u7ed9\u5b9a\u7b54\u6848\u7684\u8d21\u732e\u3002", "method": "\u5229\u7528\u6570\u636e\u5e93\u8bbe\u7f6e\u7684\u7ed3\u679c\uff0c\u5206\u6790\u4e86\u52a0\u6743\u6700\u5c0f\u652f\u6301\u8ba1\u7b97\u7684\u7ec4\u5408\u590d\u6742\u5ea6\uff0c\u8bc1\u660e\u4e86\u5728\u672c\u4f53\u8bed\u8a00\u652f\u6301\u5408\u53d6\u7684\u60c5\u51b5\u4e0b\uff0c\u5373\u4f7f\u5bf9\u4e8e\u539f\u5b50\u67e5\u8be2\uff0c\u8ba1\u7b97\u4e5f\u662f\u96be\u5904\u7406\u7684\u3002", "result": "\u786e\u5b9a\u4e86\u5177\u6709\u6613\u5904\u7406WSMS\u8ba1\u7b97\u7684\u7ed3\u6784\u53d7\u9650\u67e5\u8be2\u7c7b\uff0c\u5e76\u6307\u51fa\u4e86\u672c\u4f53\u8bed\u8a00\u652f\u6301\u5408\u53d6\u65f6\u8ba1\u7b97\u7684\u96be\u5904\u7406\u6027\u3002", "conclusion": "\u7814\u7a76\u4e86\u5728\u672c\u4f53\u4ecb\u5bfc\u67e5\u8be2\u5e94\u7b54\u73af\u5883\u4e0b\u8ba1\u7b97\u8d23\u4efb\u5206\u6570\u7684\u590d\u6742\u6027\uff0c\u53d1\u73b0\u57fa\u4e8e\u52a0\u6743\u6700\u5c0f\u652f\u6301\u7684Shapley\u503c\u8d23\u4efb\u5ea6\u91cf\u5728\u67d0\u4e9b\u672c\u4f53\u4ecb\u5bfc\u67e5\u8be2\u7c7b\u4e0a\u5177\u6709\u591a\u9879\u5f0f\u6570\u636e\u590d\u6742\u5ea6\uff0c\u800c\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\u5219\u4e3a'shP'-hard\u3002"}}
{"id": "2507.23197", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23197", "abs": "https://arxiv.org/abs/2507.23197", "authors": ["Yuke Liao", "Blaise Genest", "Kuldeep Meel", "Shaan Aryaman"], "title": "Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification", "comment": null, "summary": "To handle complex instances, we revisit a divide-and-conquer approach to\nbreak down the complexity: instead of few complex BaB calls, we rely on many\nsmall {\\em partial} MILP calls. The crucial step is to select very few but very\nimportant ReLUs to treat using (costly) binary variables. The previous attempts\nwere suboptimal in that respect. To select these important ReLU variables, we\npropose a novel {\\em solution-aware} ReLU scoring ({\\sf SAS}), as well as adapt\nthe BaB-SR and BaB-FSB branching functions as {\\em global} ReLU scoring ({\\sf\nGS}) functions. We compare them theoretically as well as experimentally, and\n{\\sf SAS} is more efficient at selecting a set of variables to open using\nbinary variables. Compared with previous attempts, SAS reduces the number of\nbinary variables by around 6 times, while maintaining the same level of\naccuracy. Implemented in {\\em Hybrid MILP}, calling first $\\alpha,\\beta$-CROWN\nwith a short time-out to solve easier instances, and then partial MILP,\nproduces a very accurate yet efficient verifier, reducing by up to $40\\%$ the\nnumber of undecided instances to low levels ($8-15\\%$), while keeping a\nreasonable runtime ($46s-417s$ on average per instance), even for fairly large\nCNNs with 2 million parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u7684\u57fa\u4e8e\u5206\u6cbb\u548c\u6df7\u5408MILP\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u6548\u7387\u5e76\u4fdd\u6301\u9ad8\u51c6\u786e\u7387", "motivation": "\u5904\u7406\u590d\u6742\u5b9e\u4f8b\u7684\u9a8c\u8bc1\u95ee\u9898\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u7387\u3002", "method": "\u91c7\u7528\u5206\u6cbb\u7b56\u7565\uff0c\u7ed3\u5408\u89e3\u51b3\u65b9\u6848\u611f\u77e5ReLU\u8bc4\u5206\uff08SAS\uff09\u4ee5\u53ca\u6539\u8fdb\u7684BaB-SR\u548cBaB-FSB\u5206\u652f\u51fd\u6570\uff0c\u4f7f\u7528\u6df7\u5408MILP\u65b9\u6cd5\uff0c\u5148\u8c03\u7528\u03b1,\u03b2-CROWN\u8fdb\u884c\u5feb\u901f\u6c42\u89e3\uff0c\u518d\u8fdb\u884c\u5c40\u90e8MILP\u6c42\u89e3\u3002", "result": "\u5c06\u4e8c\u5143\u53d8\u91cf\u6570\u91cf\u51cf\u5c11\u7ea66\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7cbe\u5ea6\uff1b\u5c06\u672a\u786e\u5b9a\u5b9e\u4f8b\u7684\u6570\u91cf\u51cf\u5c11\u9ad8\u8fbe40%\uff0c\u964d\u4f4e\u81f38-15%\uff1b\u5e73\u5747\u8fd0\u884c\u65f6\u95f4\u4e3a46-417\u79d2\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u611f\u77e5ReLU\u8bc4\u5206\uff08SAS\uff09\u65b9\u6cd5\uff0c\u5e76\u6539\u8fdb\u4e86BaB-SR\u548cBaB-FSB\u5206\u652f\u51fd\u6570\uff0c\u5c06\u5176\u4f5c\u4e3a\u5168\u5c40ReLU\u8bc4\u5206\uff08GS\uff09\u51fd\u6570\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u4e8c\u5143\u53d8\u91cf\u6570\u91cf\uff0c\u63d0\u9ad8\u4e86\u9a8c\u8bc1\u6548\u7387\u3002\u7ed3\u5408\u6df7\u5408MILP\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u672a\u786e\u5b9a\u5b9e\u4f8b\u7684\u6570\u91cf\uff0c\u5e76\u5728\u5408\u7406\u7684\u8fd0\u884c\u65f6\u95f4\u5185\u4fdd\u6301\u8f83\u9ad8\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2507.23276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23276", "abs": "https://arxiv.org/abs/2507.23276", "authors": ["Qiujie Xie", "Yixuan Weng", "Minjun Zhu", "Fuchen Shen", "Shulin Huang", "Zhen Lin", "Jiahui Zhou", "Zilan Mao", "Zijie Yang", "Linyi Yang", "Jian Wu", "Yue Zhang"], "title": "How Far Are AI Scientists from Changing the World?", "comment": null, "summary": "The emergence of large language models (LLMs) is propelling automated\nscientific discovery to the next level, with LLM-based Artificial Intelligence\n(AI) Scientist systems now taking the lead in scientific research. Several\ninfluential works have already appeared in the field of AI Scientist systems,\nwith AI-generated research papers having been accepted at the ICLR 2025\nworkshop, suggesting that a human-level AI Scientist capable of uncovering\nphenomena previously unknown to humans, may soon become a reality. In this\nsurvey, we focus on the central question: How far are AI scientists from\nchanging the world and reshaping the scientific research paradigm? To answer\nthis question, we provide a prospect-driven review that comprehensively\nanalyzes the current achievements of AI Scientist systems, identifying key\nbottlenecks and the critical components required for the emergence of a\nscientific agent capable of producing ground-breaking discoveries that solve\ngrand challenges. We hope this survey will contribute to a clearer\nunderstanding of limitations of current AI Scientist systems, showing where we\nare, what is missing, and what the ultimate goals for scientific AI should be.", "AI": {"tldr": "\u7efc\u8ff0\u4e86AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u73b0\u72b6\u3001\u6311\u6218\u548c\u672a\u6765\uff0c\u65e8\u5728\u4fc3\u8fdb\u5bf9\u79d1\u5b66AI\u7684\u66f4\u6e05\u6670\u7406\u89e3\u3002", "motivation": "\u63a2\u7a76AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u8ddd\u79bb\u6539\u53d8\u4e16\u754c\u548c\u91cd\u5851\u79d1\u5b66\u7814\u7a76\u8303\u5f0f\u8fd8\u6709\u591a\u8fdc\u3002", "method": "\u5bf9\u73b0\u6709AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u7efc\u8ff0\u5206\u6790\uff0c\u5305\u62ec\u5176\u6210\u5c31\u3001\u74f6\u9888\u548c\u5173\u952e\u7ec4\u4ef6\u3002", "result": "\u8bc6\u522b\u4e86AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u5f53\u524d\u7684\u5c40\u9650\u6027\uff0c\u6307\u51fa\u4e86\u672a\u6765\u53d1\u5c55\u65b9\u5411\u548c\u6700\u7ec8\u76ee\u6807\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u5206\u6790\u4e86AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u5f53\u524d\u6210\u5c31\u3001\u5173\u952e\u74f6\u9888\u548c\u5b9e\u73b0\u7a81\u7834\u6027\u53d1\u73b0\u6240\u9700\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u65e8\u5728\u5bf9AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u8fdb\u884c\u66f4\u6e05\u6670\u7684\u7406\u89e3\uff0c\u5e76\u5c55\u671b\u5176\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2507.23330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23330", "abs": "https://arxiv.org/abs/2507.23330", "authors": ["Tosin Adewumi", "Lama Alkhaled", "Florent Imbert", "Hui Han", "Nudrat Habib", "Karl L\u00f6wenmark"], "title": "AI Must not be Fully Autonomous", "comment": "11 pages, 1 figure", "summary": "Autonomous Artificial Intelligence (AI) has many benefits. It also has many\nrisks. In this work, we identify the 3 levels of autonomous AI. We are of the\nposition that AI must not be fully autonomous because of the many risks,\nespecially as artificial superintelligence (ASI) is speculated to be just\ndecades away. Fully autonomous AI, which can develop its own objectives, is at\nlevel 3 and without responsible human oversight. However, responsible human\noversight is crucial for mitigating the risks. To ague for our position, we\ndiscuss theories of autonomy, AI and agents. Then, we offer 12 distinct\narguments and 6 counterarguments with rebuttals to the counterarguments. We\nalso present 15 pieces of recent evidence of AI misaligned values and other\nrisks in the appendix.", "AI": {"tldr": "Fully autonomous AI is too risky; responsible human oversight is crucial.", "motivation": "To argue against fully autonomous AI by highlighting its risks and the importance of responsible human oversight.", "method": "Identifies three levels of autonomous AI, discusses theories of autonomy, AI, and agents, presents 12 arguments for and 6 counterarguments (with rebuttals) against fully autonomous AI, and provides 15 pieces of evidence of AI risks.", "result": "The paper argues convincingly against fully autonomous AI, providing a structured analysis with supporting evidence.", "conclusion": "Fully autonomous AI is risky and should not be pursued due to the potential for misaligned values and other risks, especially with the advent of ASI."}}
{"id": "2507.23336", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23336", "abs": "https://arxiv.org/abs/2507.23336", "authors": ["Ram Mohan Rao Kadiyala", "Siddhant Gupta", "Jebish Purbey", "Giulio Martini", "Suman Debnath", "Hamza Farooq"], "title": "DSBC : Data Science task Benchmarking with Context engineering", "comment": "32 pages", "summary": "Recent advances in large language models (LLMs) have significantly impacted\ndata science workflows, giving rise to specialized data science agents designed\nto automate analytical tasks. Despite rapid adoption, systematic benchmarks\nevaluating the efficacy and limitations of these agents remain scarce. In this\npaper, we introduce a comprehensive benchmark specifically crafted to reflect\nreal-world user interactions with data science agents by observing usage of our\ncommercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,\nGemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with\ncontext engineering, multi-step with context engineering, and with SmolAgent.\nOur benchmark assesses performance across a diverse set of eight data science\ntask categories, additionally exploring the sensitivity of models to common\nprompting issues, such as data leakage and slightly ambiguous instructions. We\nfurther investigate the influence of temperature parameters on overall and\ntask-specific outcomes for each model and approach. Our findings reveal\ndistinct performance disparities among the evaluated models and methodologies,\nhighlighting critical factors that affect practical deployment. The benchmark\ndataset and evaluation framework introduced herein aim to provide a foundation\nfor future research of more robust and effective data science agents.", "AI": {"tldr": "\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u4e0d\u540cLLM\u548c\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u663e\u8457\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u7528\u6237\u4ea4\u4e92\uff0c\u6784\u5efa\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u5f25\u8865\u8fd9\u4e00\u4e0d\u8db3\u3002", "method": "\u5bf9\u4e09\u79cdLLM\u5728\u4e09\u79cd\u65b9\u6cd5\uff08zero-shot with context engineering, multi-step with context engineering, and with SmolAgent\uff09\u4e0b\uff0c\u9488\u5bf9\u516b\u4e2a\u6570\u636e\u79d1\u5b66\u4efb\u52a1\u7c7b\u522b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u5206\u6790\u4e86prompting issues\uff08\u5982\u6570\u636e\u6cc4\u9732\u548c\u6a21\u68f1\u4e24\u53ef\u7684\u6307\u4ee4\uff09\u4ee5\u53catemperature\u53c2\u6570\u7684\u5f71\u54cd\u3002", "result": "\u4e0d\u540c\u6a21\u578b\u548c\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u663e\u8457\uff0c\u7a81\u51fa\u4e86\u5f71\u54cd\u5b9e\u9645\u90e8\u7f72\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u6709\u6548\u6027\u548c\u5c40\u9650\u6027\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5bf9\u4e09\u79cdLLM\uff08Claude-4.0-Sonnet\uff0cGemini-2.5-Flash\u548cOpenAI-o4-Mini\uff09\u5728\u4e0d\u540c\u65b9\u6cd5\u4e0b\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u63ed\u793a\u4e86\u6a21\u578b\u548c\u65b9\u6cd5\u4e4b\u95f4\u660e\u663e\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4e3a\u672a\u6765\u6784\u5efa\u66f4\u5f3a\u5927\u6709\u6548\u7684\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.23377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23377", "abs": "https://arxiv.org/abs/2507.23377", "authors": ["Zhuo Li", "Xianghuai Deng", "Chiwei Feng", "Hanmeng Li", "Shenjie Wang", "Haichao Zhang", "Teng Jia", "Conlin Chen", "Louis Linchun Wu", "Jia Wang"], "title": "LLM4Rail: An LLM-Augmented Railway Service Consulting Platform", "comment": null, "summary": "Large language models (LLMs) have significantly reshaped different walks of\nbusiness. To meet the increasing demands for individualized railway service, we\ndevelop LLM4Rail - a novel LLM-augmented railway service consulting platform.\nEmpowered by LLM, LLM4Rail can provide custom modules for ticketing, railway\nfood & drink recommendations, weather information, and chitchat. In LLM4Rail,\nwe propose the iterative \"Question-Thought-Action-Observation (QTAO)\" prompting\nframework. It meticulously integrates verbal reasoning with task-oriented\nactions, that is, reasoning to guide action selection, to effectively retrieve\nexternal observations relevant to railway operation and service to generate\naccurate responses. To provide personalized onboard dining services, we first\nconstruct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible\ntakeout dataset tailored for railway services. CRFD-25 covers a wide range of\nsignature dishes categorized by cities, cuisines, age groups, and spiciness\nlevels. We further introduce an LLM-based zero-shot conversational recommender\nfor railway catering. To address the unconstrained nature of open\nrecommendations, the feature similarity-based post-processing step is\nintroduced to ensure all the recommended items are aligned with CRFD-25\ndataset.", "AI": {"tldr": "LLM4Rail\u5e73\u53f0\u5229\u7528LLM\u63d0\u4f9b\u4e2a\u6027\u5316\u94c1\u8def\u670d\u52a1\uff0c\u5305\u542b\u8ba2\u7968\u3001\u9910\u996e\u63a8\u8350\u7b49\u529f\u80fd\uff0c\u5e76\u4f7f\u7528QTAO\u63d0\u793a\u6846\u67b6\u548cCRFD-25\u6570\u636e\u96c6\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u3002", "motivation": "\u6ee1\u8db3\u65e5\u76ca\u589e\u957f\u7684\u4e2a\u6027\u5316\u94c1\u8def\u670d\u52a1\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86LLM\u589e\u5f3a\u7684\u94c1\u8def\u670d\u52a1\u54a8\u8be2\u5e73\u53f0LLM4Rail\uff0c\u63d0\u51faQTAO\u63d0\u793a\u6846\u67b6\uff0c\u6784\u5efaCRFD-25\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u57fa\u4e8eLLM\u7684\u96f6\u6837\u672c\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u3002", "result": "\u5f00\u53d1\u4e86LLM4Rail\u5e73\u53f0\uff0c\u63d0\u4f9b\u4e86\u5b9a\u5236\u5316\u94c1\u8def\u670d\u52a1\u6a21\u5757\uff0c\u5e76\u6709\u6548\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u4e2a\u6027\u5316\u7a0b\u5ea6\u3002", "conclusion": "LLM4Rail\u5e73\u53f0\u5229\u7528LLM\u63d0\u4f9b\u5b9a\u5236\u5316\u94c1\u8def\u670d\u52a1\u6a21\u5757\uff0c\u5e76\u63d0\u51fa\u8fed\u4ee3\u5f0fQTAO\u63d0\u793a\u6846\u67b6\uff0c\u6709\u6548\u6574\u5408\u8a00\u8bed\u63a8\u7406\u548c\u9762\u5411\u4efb\u52a1\u7684\u52a8\u4f5c\uff0c\u751f\u6210\u51c6\u786e\u7684\u56de\u590d\u3002\u4e3a\u63d0\u4f9b\u4e2a\u6027\u5316\u9910\u996e\u670d\u52a1\uff0c\u6784\u5efa\u4e86CRFD-25\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u57fa\u4e8eLLM\u7684\u96f6\u6837\u672c\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff0c\u7ed3\u5408\u7279\u5f81\u76f8\u4f3c\u6027\u540e\u5904\u7406\u6b65\u9aa4\uff0c\u786e\u4fdd\u63a8\u8350\u7ed3\u679c\u4e0e\u6570\u636e\u96c6\u4e00\u81f4\u3002"}}
{"id": "2507.23429", "categories": ["cs.AI", "cs.DB", "cs.ET", "cs.HC", "cs.MA", "68T50, 68P20", "I.2.7; H.2.5; H.2.8; H.5.m"], "pdf": "https://arxiv.org/pdf/2507.23429", "abs": "https://arxiv.org/abs/2507.23429", "authors": ["Jorge Ruiz G\u00f3mez", "Lidia Andr\u00e9s Susinos", "Jorge Alamo Oliv\u00e9", "Sonia Rey Osorno", "Manuel Luis Gonzalez Hern\u00e1ndez"], "title": "Chatting with your ERP: A Recipe", "comment": "11 pages, includes 3 tables summarizing schema and model performance.\n  Submitted on July 31, 2025. Targets integration of LLM agents with ERP\n  systems using open-weight models and Ollama deployment", "summary": "This paper presents the design, implementation, and evaluation behind a Large\nLanguage Model (LLM) agent that chats with an industrial production-grade ERP\nsystem. The agent is capable of interpreting natural language queries and\ntranslating them into executable SQL statements, leveraging open-weight LLMs. A\nnovel dual-agent architecture combining reasoning and critique stages was\nproposed to improve query generation reliability.", "AI": {"tldr": "LLM\u4ee3\u7406\u901a\u8fc7\u53cc\u4ee3\u7406\u67b6\u6784\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3a\u53ef\u6267\u884cSQL\u8bed\u53e5\uff0c\u4ee5\u63d0\u9ad8\u4e0eERP\u7cfb\u7edf\u7684\u4ea4\u4e92\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u4e0e\u5de5\u4e1a\u751f\u4ea7\u7ea7ERP\u7cfb\u7edf\u7684\u4ea4\u4e92\u6548\u7387\u548c\u4fbf\u6377\u6027\u3002", "method": "\u8be5\u4ee3\u7406\u80fd\u591f\u89e3\u91ca\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684SQL\u8bed\u53e5\uff0c\u5229\u7528\u5f00\u653e\u6743\u91cd\u7684LLM\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53cc\u4ee3\u7406\u67b6\u6784\uff0c\u7ed3\u5408\u63a8\u7406\u548c\u6279\u5224\u9636\u6bb5\uff0c\u4ee5\u63d0\u9ad8\u67e5\u8be2\u751f\u6210\u7684\u53ef\u9760\u6027\u3002", "result": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u80fd\u591f\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3a\u53ef\u6267\u884cSQL\u8bed\u53e5\u7684LLM\u4ee3\u7406\uff0c\u5e76\u901a\u8fc7\u53cc\u4ee3\u7406\u67b6\u6784\u63d0\u9ad8\u4e86\u67e5\u8be2\u751f\u6210\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u4ee3\u7406\u7684\u8bbe\u8ba1\u3001\u5b9e\u73b0\u548c\u8bc4\u4f30\uff0c\u8be5\u4ee3\u7406\u4e0e\u5de5\u4e1a\u751f\u4ea7\u7ea7ERP\u7cfb\u7edf\u8fdb\u884c\u4ea4\u4e92\u3002"}}
{"id": "2507.23440", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23440", "abs": "https://arxiv.org/abs/2507.23440", "authors": ["Mingzhe Li", "Xin Lu", "Yanyan Zhao"], "title": "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation", "comment": "Accepted by Findings of ACL 2025", "summary": "Large language models (LLMs) with instruction following capabilities have\ndemonstrated impressive problem-solving abilities. While synthesizing\ninstructional data from unsupervised text has become a common approach for\ntraining such models, conventional methods rely heavily on human effort for\ndata annotation. Although existing automated synthesis paradigms have\nalleviated this constraint, they still exhibit significant limitations in\nensuring adequate diversity and difficulty of synthesized instructions. To\naddress these challenges, we propose Self-Foveate, an innovative LLM-driven\nmethod for instruction synthesis. This approach introduces a\n\"Micro-Scatter-Macro\" multi-level foveation methodology that effectively guides\nthe LLM to deeply excavate fine-grained information embedded in unsupervised\ntext, thereby enhancing both the diversity and difficulty of synthesized\ninstructions. Comprehensive experiments across multiple unsupervised corpora\nand diverse model architectures validate the effectiveness and superiority of\nour proposed method. We publicly release our data and codes:\nhttps://github.com/Mubuky/Self-Foveate", "AI": {"tldr": "Self-Foveate \u4f7f\u7528\u591a\u5c42\u6b21\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86 LLM \u6307\u4ee4\u5408\u6210\u7684\u591a\u6837\u6027\u548c\u96be\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u6307\u4ee4\u5408\u6210\u65b9\u6cd5\u5728\u6307\u4ee4\u7684\u591a\u6837\u6027\u548c\u96be\u5ea6\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5408\u6210\u9ad8\u8d28\u91cf\u7684\u6307\u4ee4\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a \"Micro-Scatter-Macro\" \u7684\u591a\u5c42\u6b21\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u4e8e\u6307\u5bfc LLM \u6df1\u5165\u6316\u6398\u975e\u76d1\u7763\u6587\u672c\u4e2d\u7684\u7ec6\u7c92\u5ea6\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e Self-Foveate \u65b9\u6cd5\u5728\u591a\u4e2a\u975e\u76d1\u7763\u8bed\u6599\u5e93\u548c\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e0a\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u4ee3\u7801\u548c\u6570\u636e\u5df2\u516c\u5f00\u53d1\u5e03\u3002", "conclusion": "Self-Foveate \u662f\u4e00\u79cd\u521b\u65b0\u7684 LLM \u9a71\u52a8\u6307\u4ee4\u5408\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5c42\u6b21\u7684\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u63d0\u9ad8\u4e86\u5408\u6210\u6307\u4ee4\u7684\u591a\u6837\u6027\u548c\u96be\u5ea6\u3002"}}
{"id": "2507.23488", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23488", "abs": "https://arxiv.org/abs/2507.23488", "authors": ["Kacper Kadziolka", "Saber Salehkaleybar"], "title": "Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery", "comment": null, "summary": "Causal inference remains a fundamental challenge for large language models.\nRecent advances in internal reasoning with large language models have sparked\ninterest in whether state-of-the-art reasoning models can robustly perform\ncausal discovery-a task where conventional models often suffer from severe\noverfitting and near-random performance under data perturbations. We study\ncausal discovery on the Corr2Cause benchmark using the emergent OpenAI's\no-series and DeepSeek-R model families and find that these reasoning-first\narchitectures achieve significantly greater native gains than prior approaches.\nTo capitalize on these strengths, we introduce a modular in-context pipeline\ninspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding\nnearly three-fold improvements over conventional baselines. We further probe\nthe pipeline's impact by analyzing reasoning chain length, complexity, and\nconducting qualitative and quantitative comparisons between conventional and\nreasoning models. Our findings suggest that while advanced reasoning models\nrepresent a substantial leap forward, carefully structured in-context\nframeworks are essential to maximize their capabilities and offer a\ngeneralizable blueprint for causal discovery across diverse domains.", "AI": {"tldr": "\u5148\u8fdb\u63a8\u7406\u6a21\u578b\u7ed3\u5408\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4e0a\u4e0b\u6587\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56e0\u679c\u53d1\u73b0\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u56e0\u679c\u63a8\u7406\u7684\u6839\u672c\u6027\u6311\u6218\uff0c\u4ee5\u53ca\u73b0\u6709\u6a21\u578b\u5728\u56e0\u679c\u53d1\u73b0\u4efb\u52a1\u4e2d\u5bb9\u6613\u8fc7\u62df\u5408\u548c\u6027\u80fd\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528Corr2Cause\u57fa\u51c6\uff0c\u7814\u7a76\u4e86OpenAI\u7684o\u7cfb\u5217\u548cDeepSeek-R\u6a21\u578b\u5bb6\u65cf\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684\u4e0a\u4e0b\u6587\u7ba1\u9053\u3002", "result": "\u63a8\u7406\u4f18\u5148\u67b6\u6784\u6bd4\u4ee5\u5f80\u65b9\u6cd5\u53d6\u5f97\u4e86\u66f4\u5927\u7684\u8fdb\u6b65\uff0c\u6a21\u5757\u5316\u4e0a\u4e0b\u6587\u7ba1\u9053\u4f7f\u6027\u80fd\u63d0\u5347\u8fd1\u4e09\u500d\u3002", "conclusion": "\u5148\u8fdb\u63a8\u7406\u6a21\u578b\u5728\u56e0\u679c\u53d1\u73b0\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u9700\u8981\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4e0a\u4e0b\u6587\u6846\u67b6\u6765\u6700\u5927\u5316\u5176\u80fd\u529b\u3002"}}
{"id": "2507.23497", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23497", "abs": "https://arxiv.org/abs/2507.23497", "authors": ["David A Kelly", "Hana Chockler"], "title": "Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification", "comment": "13 pages, 13 figures, appendix included", "summary": "Existing algorithms for explaining the outputs of image classifiers are based\non a variety of approaches and produce explanations that lack formal rigor. On\nthe other hand, logic-based explanations are formally and rigorously defined\nbut their computability relies on strict assumptions about the model that do\nnot hold on image classifiers.\n  In this paper, we show that causal explanations, in addition to being\nformally and rigorously defined, enjoy the same formal properties as\nlogic-based ones, while still lending themselves to black-box algorithms and\nbeing a natural fit for image classifiers. We prove formal properties of causal\nexplanations and introduce contrastive causal explanations for image\nclassifiers. Moreover, we augment the definition of explanation with confidence\nawareness and introduce complete causal explanations: explanations that are\nclassified with exactly the same confidence as the original image.\n  We implement our definitions, and our experimental results demonstrate that\ndifferent models have different patterns of sufficiency, contrastiveness, and\ncompleteness. Our algorithms are efficiently computable, taking on average 6s\nper image on a ResNet50 model to compute all types of explanations, and are\ntotally black-box, needing no knowledge of the model, no access to model\ninternals, no access to gradient, nor requiring any properties, such as\nmonotonicity, of the model.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u56fe\u50cf\u5206\u7c7b\u5668\u89e3\u91ca\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5f62\u5f0f\u4e0a\u4e25\u683c\u3001\u53ef\u8ba1\u7b97\uff0c\u5e76\u4e14\u662f\u5b8c\u5168\u9ed1\u76d2\u7684\uff0c\u5e73\u5747\u6bcf\u5f20\u56fe\u7247\u89e3\u91ca\u65f6\u95f4\u4e3a6\u79d2\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u50cf\u5206\u7c7b\u5668\u89e3\u91ca\u7b97\u6cd5\u7f3a\u4e4f\u5f62\u5f0f\u4e0a\u7684\u4e25\u683c\u6027\uff0c\u800c\u903b\u8f91\u89e3\u91ca\u65b9\u6cd5\u7684\u8ba1\u7b97\u4f9d\u8d56\u4e8e\u5bf9\u6a21\u578b\u7684\u4e25\u683c\u5047\u8bbe\uff0c\u8fd9\u5728\u56fe\u50cf\u5206\u7c7b\u5668\u4e2d\u5e76\u4e0d\u6210\u7acb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u56fe\u50cf\u5206\u7c7b\u5668\u89e3\u91ca\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u5f62\u5f0f\u4e0a\u7684\u4e25\u683c\u6027\u548c\u53ef\u8ba1\u7b97\u6027\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u4e86\u89e3\u6a21\u578b\u5185\u90e8\u7ec6\u8282\u3002", "result": "\u5b9e\u73b0\u4e86\u56e0\u679c\u89e3\u91ca\u7684\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e0d\u540c\u6a21\u578b\u5177\u6709\u4e0d\u540c\u7684\u5145\u5206\u6027\u3001\u5bf9\u6bd4\u6027\u548c\u5b8c\u6574\u6027\u6a21\u5f0f\u3002\u7b97\u6cd5\u5e73\u5747\u6bcf\u5f20\u56fe\u7247\u8ba1\u7b97\u6240\u6709\u7c7b\u578b\u7684\u89e3\u91ca\u9700\u89816\u79d2\uff0c\u5e76\u4e14\u662f\u5b8c\u5168\u9ed1\u76d2\u7684\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u56e0\u679c\u89e3\u91ca\u5728\u5f62\u5f0f\u4e0a\u4e0e\u903b\u8f91\u89e3\u91ca\u4e00\u6837\u4e25\u683c\uff0c\u540c\u65f6\u9002\u7528\u4e8e\u9ed1\u76d2\u7b97\u6cd5\u548c\u56fe\u50cf\u5206\u7c7b\u5668\uff0c\u5e76\u5f15\u5165\u4e86\u5bf9\u6bd4\u56e0\u679c\u89e3\u91ca\u548c\u5b8c\u6574\u56e0\u679c\u89e3\u91ca\u7684\u6982\u5ff5\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u4e0d\u540c\u6a21\u578b\u5177\u6709\u4e0d\u540c\u7684\u5145\u5206\u6027\u3001\u5bf9\u6bd4\u6027\u548c\u5b8c\u6574\u6027\u6a21\u5f0f\u3002"}}
{"id": "2507.23554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23554", "abs": "https://arxiv.org/abs/2507.23554", "authors": ["Ruoyu Wang", "Junda Wu", "Yu Xia", "Tong Yu", "Ryan A. Rossi", "Julian McAuley", "Lina Yao"], "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "comment": null, "summary": "Large language model-based agents, empowered by in-context learning (ICL),\nhave demonstrated strong capabilities in complex reasoning and tool-use tasks.\nHowever, existing works have shown that the effectiveness of ICL is highly\nsensitive to the choice of demonstrations, with suboptimal examples often\nleading to unstable or degraded performance. While prior work has explored\nexample selection, including in some agentic or multi-step settings, existing\napproaches typically rely on heuristics or task-specific designs and lack a\ngeneral, theoretically grounded criterion for what constitutes an effective\ndemonstration across reasoning steps. Therefore, it is non-trivial to develop a\nprincipled, general-purpose method for selecting demonstrations that\nconsistently benefit agent performance. In this paper, we address this\nchallenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a\ntheoretically grounded ICL framework for agentic tasks that selects the most\nrelevant demonstrations at each step of reasoning. Our approach decomposes\ndemonstration knowledge into transferable and non-transferable components\nthrough a causal lens, showing how the latter can introduce spurious\ndependencies that impair generalization. We further propose a stepwise\nselection criterion with a formal guarantee of improved agent performance.\nImportantly, DICE is a general, framework-agnostic solution that can be\nintegrated as a plug-in module into existing agentic frameworks without any\nadditional training cost. Extensive experiments across diverse domains\ndemonstrate our method's effectiveness and generality, highlighting the\nimportance of principled, context-aware demo selection for robust and efficient\nLLM agents.", "AI": {"tldr": "DICE\u6846\u67b6\u901a\u8fc7\u56e0\u679c\u5206\u89e3\u6f14\u793a\u77e5\u8bc6\uff0c\u9009\u62e9\u6700\u76f8\u5173\u7684\u793a\u4f8b\uff0c\u4ece\u800c\u63d0\u9ad8LLM\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eICL\u7684LLM\u667a\u80fd\u4f53\u5bf9\u6f14\u793a\u9009\u62e9\u9ad8\u5ea6\u654f\u611f\uff0c\u6b21\u4f18\u793a\u4f8b\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0d\u7a33\u5b9a\u6216\u4e0b\u964d\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u7279\u5b9a\u4efb\u52a1\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u666e\u904d\u9002\u7528\u7684\u6709\u6548\u6f14\u793a\u6807\u51c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDICE\u7684\u52a8\u6001\u4e0a\u4e0b\u6587\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u5c06\u6f14\u793a\u77e5\u8bc6\u5206\u89e3\u4e3a\u53ef\u8f6c\u79fb\u548c\u4e0d\u53ef\u8f6c\u79fb\u90e8\u5206\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u9010\u6b65\u9009\u62e9\u6807\u51c6\uff0c\u5177\u6709\u63d0\u5347\u667a\u80fd\u4f53\u6027\u80fd\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86DICE\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\uff0c\u5f3a\u8c03\u4e86\u5728\u9c81\u68d2\u548c\u9ad8\u6548\u7684LLM\u667a\u80fd\u4f53\u4e2d\uff0c\u57fa\u4e8e\u539f\u5219\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6f14\u793a\u9009\u62e9\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86DICE\uff0c\u4e00\u4e2a\u7406\u8bba\u4e0a\u6709\u6839\u636e\u7684\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684ICL\u6846\u67b6\uff0c\u7528\u4e8e\u9009\u62e9\u6700\u76f8\u5173\u7684\u6f14\u793a\uff0c\u4ece\u800c\u63d0\u9ad8LLM\u667a\u80fd\u4f53\u7684\u6027\u80fd\u3002DICE\u80fd\u591f\u5206\u89e3\u6f14\u793a\u77e5\u8bc6\uff0c\u8bc6\u522b\u5e76\u53bb\u9664\u6709\u5bb3\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u4fdd\u8bc1\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6210\u672c\u3002"}}
