<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 基于LLM的预测性维护系统，结合轴承振动分析和多智能体生成，提供精准的故障检测和可执行的维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械的维护需要及时干预，以防止灾难性故障并优化运营效率。传统的异常检测方法不足以提供可操作的维护建议，因此需要一种更智能的预测性维护系统。

Method: 该系统将轴承振动数据序列化为自然语言，利用LLM进行异常检测和故障类型分类；同时，利用多智能体组件处理维护手册，进行语义搜索和网络搜索，获取全面的程序化知识和最新的维护实践，最终生成结构化维护建议。

Result: 实验结果表明，该系统能够有效地进行异常检测，并提供与上下文相关的维护指导，成功地弥合了状态监测和可操作维护规划之间的差距。

Conclusion: 该论文提出了一种基于大型语言模型 (LLM) 的预测性维护智能系统，该系统结合轴承振动频率分析和多智能体生成，能够对故障进行精准检测和分类，并提供包含具体行动、检查清单、纠正措施、零件需求和时间规范的结构化维护建议。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [2] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow 自动生成地理空间任务代理工作流，提高效率并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有方法侧重于推理分解，而忽略了 API 选择，GeoFlow 通过提供详细的工具调用目标来提高代理的成功率和效率。

Method: GeoFlow 方法通过为每个代理提供详细的工具调用目标来指导地理空间 API 的运行时调用。

Result: GeoFlow 将代理成功率提高了 6.8%，并将主要 LLM 家族的令牌使用量减少了多达四倍。

Conclusion: GeoFlow 是一种自动生成地理空间任务代理工作流的方法，它通过为每个代理提供详细的工具调用目标来指导地理空间 API 的运行时调用，从而提高了代理的成功率并减少了令牌的使用。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [3] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 利用对抗性棋盘游戏评估大型语言模型的性能，发现LLM适应性强但技能不稳定。


<details>
  <summary>Details</summary>
Motivation: 现有问答式基准测试方法依赖于数据，该论文旨在通过对抗性棋盘游戏评估LLM的综合性能，克服数据依赖性限制。

Method: 该论文提出了一种新的基准测试框架，利用5种棋盘游戏和20个LLM驱动的玩家进行循环赛评估，并使用Elo评分系统和PLG对LLM进行评估，同时还捕捉游戏过程中的积极情绪得分（PSS）。

Result: 实验结果表明LLM在高压力对抗环境下比人类更适应，但其技能存在不稳定性。

Conclusion: 该论文提出了一种基于对抗性棋盘游戏评估大型语言模型（LLM）性能的框架，该框架使用Elo评分系统和性能循环图（PLG）对LLM的技术能力和心理适应性进行量化评估。实验结果表明，LLM在高压对抗环境中表现出比人类更好的适应性，但也暴露出其技能的不稳定性。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [4] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 客户端小型语言模型方法在AWebGIS中实现最高精度，并解决了服务器端处理的隐私和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有AWebGIS方案依赖云端LLM，存在隐私和可扩展性问题，因此研究旨在探索无需持续网络访问的替代方案。

Method: 比较了三种方法：基于云端LLM的在线方法、基于经典机器学习的离线方法和基于微调SLM的客户端离线方法。

Result: 基于微调小型语言模型（T5-small）的客户端方法准确率最高，精确匹配准确率为0.93，Levenshtein相似度为0.99，ROUGE-1和ROUGE-L评分为0.98。

Conclusion: 研究比较了三种实现AWebGIS的方法，基于微调小型语言模型的客户端方法在准确率、Levenshtein相似度和ROUGE评分上均取得最佳效果，并有效降低了后端服务器负载。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [5] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 强化学习提高了LLM在理想条件下的推理能力，但在非理想条件下效果不佳，暴露出先进推理能力的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽略了LLM在现实非理想场景下的推理性能，本文识别并评估了三种具有实际意义的非理想场景：摘要推理、细粒度噪声抑制和上下文过滤。

Method: 使用强化学习(RL)微调三个LLM和一个最先进的大型视觉语言模型(LVLM)，并在八个公共数据集上测试其性能。

Result: RL微调提高了理想场景下的基线推理能力，但在所有三种非理想场景下的性能都显著下降。

Conclusion: 大型语言模型(LLM)的推理能力经常被夸大，现有方法难以解决其在非理想场景下的推理缺陷。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [6] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: Self-evolving AI agent HealthFlow surpasses existing methods in complex health data analysis, showcasing the potential of autonomous AI for scientific discovery.


<details>
  <summary>Details</summary>
Motivation: Address the limitation of static, predefined strategies in AI agents for healthcare research, enabling agents to become better strategic planners.

Method: Introduce a novel meta-level evolution mechanism for self-evolving AI agents and a new benchmark, EHRFlowBench, for evaluating agents' performance in complex health data analysis tasks.

Result: HealthFlow significantly outperforms state-of-the-art agent frameworks.

Conclusion: HealthFlow, a self-evolving AI agent, significantly outperforms state-of-the-art agent frameworks in complex health data analysis tasks, demonstrating the efficacy of self-evolving AI for scientific discovery.

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [7] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 利用博弈论框架和Loop Self-Play算法改进分子对接，提高预测精度约10%。


<details>
  <summary>Details</summary>
Motivation: 现有多任务学习模型在配体对接方面性能不如蛋白质口袋对接，原因在于配体和蛋白质的结构复杂性不同。

Method: 提出了一种基于博弈论的Loop Self-Play算法，该算法通过两个玩家（配体和蛋白质）的迭代训练和相互适应来优化分子对接预测。

Result: 在公共基准数据集上，LoopPlay算法在预测准确结合模式方面比现有技术提高了约10%。

Conclusion: 提出了一种新颖的博弈论框架Docking Game和Loop Self-Play算法，显著提高了分子对接预测精度，比现有技术提升约10%。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [8] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: LLM为城市空间数据整合提供了一种灵活高效的方案，但需要进一步研究以改进其空间推理能力和适应多种数据格式。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则的方法和机器学习方法在处理城市空间数据整合问题时存在局限性，LLM提供了一种有前景的替代方案。

Method: 研究分析了LLM的空间推理能力，并采用了一种迭代改进的方法来修正错误，提高准确性。

Result: LLM在整合空间数据方面表现出较好的性能，尤其是在提供相关特征后。迭代改进方法有效提高了准确性。

Conclusion: 大型语言模型(LLM)在整合大型、异构和嘈杂的城市空间数据集方面显示出潜力，尤其是在结合相关特征后，其性能显著提高。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [9] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: CogniWeb:  高效的网络代理，结合快速直觉和深思熟虑的推理，在WebArena上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前的自主网络代理方法难以有效整合离线模仿学习和在线探索，本文受双过程认知理论启发，提出一种将两者有效结合的框架。

Method: 结合离线模仿学习和在线探索，采用模块化agent架构，根据任务复杂度自适应切换快速直觉处理和深思熟虑的推理。

Result: CogniWeb在WebArena上的成功率为43.96%，token使用效率提升75%。

Conclusion: CogniWeb, 受双过程认知理论启发，结合离线学习和在线探索，在WebArena上取得了具有竞争力的性能(43.96%的成功率)和更高的效率(token使用减少75%)。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [10] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: 提出MedMKEB基准测试，评估医疗多模态大型语言模型的知识编辑能力，并揭示了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗多模态大型语言模型难以有效更新过时或不正确的信息，缺乏系统性的基准测试来评估多模态医学知识编辑。

Method: 构建了一个高质量的医学视觉问答数据集，并精心构建了编辑任务，包括反事实校正、语义泛化、知识迁移和对抗鲁棒性，并结合了人类专家的验证。

Result: 实验证明了现有基于知识的编辑方法在医学领域的局限性，突出了开发专门的编辑策略的必要性。MedMKEB将成为促进开发值得信赖和高效的医疗知识编辑算法的标准基准。

Conclusion: MedMKEB，一个用于评估医疗多模态大型语言模型知识编辑可靠性、通用性、局部性、可移植性和鲁棒性的综合基准测试，被提出以促进可信和高效的医疗知识编辑算法的开发。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [11] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize:轻量级、通用、高效的模拟电路门尺寸调整框架，显著提升设计效率。


<details>
  <summary>Details</summary>
Motivation: 模拟电路设计耗时且依赖经验，现有AI方法普遍存在模型过大、缺乏跨工艺节点可移植性等问题。

Method: EasySize利用性能指标的可达性(EOA)动态构建特定任务的损失函数，结合全局差分进化(DE)和局部粒子群优化(PSO)算法进行高效启发式搜索。

Result: EasySize在5个运算放大器(Op-Amp)电路网表上的180nm、45nm和22nm工艺节点均取得了优异性能，并在86.67%的任务中超越了AutoCkt，同时减少了96.67%以上的仿真资源。

Conclusion: EasySize，一个基于微调Qwen3-8B模型的轻量级门尺寸调整框架，在跨不同工艺节点、设计规范和电路拓扑结构的通用适用性方面表现出色，显著减少了对人工专业知识和计算资源的依赖，从而加快并简化了模拟电路设计流程。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [12] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: Socratic AI tutors improve critical thinking in students; orchestrated multi-agent systems offer a scalable and cost-effective approach to hybrid learning in higher education.


<details>
  <summary>Details</summary>
Motivation: To evaluate the impact of a Socratic AI tutor on student learning and to explore the potential of orchestrated multi-agent systems (MAS) for enhancing pedagogical practices in higher education, addressing concerns about generative AI de-skilling.

Method: Controlled experiment comparing a Socratic AI tutor with an uninstructed AI chatbot, involving 65 pre-service teacher students in Germany.  The study also utilizes a cost-effectiveness analysis and proposes an adapted offer-and-use model for human-AI interaction.

Result: Students using the Socratic AI tutor showed significantly greater support for critical, independent, and reflective thinking. The study demonstrates the feasibility and potential benefits of orchestrated MAS in education, highlighting scalability and cost-effectiveness.

Conclusion: This study provides empirical evidence and a conceptual roadmap for hybrid learning ecosystems using human-AI co-agency and pedagogical alignment, showing that a Socratic AI tutor significantly enhances critical thinking in students compared to an uninstructed AI chatbot.  It proposes orchestrated multi-agent systems (MAS) for diverse learning trajectories and discusses the system-level implications for higher education.

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [13] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 使用异构图神经网络修复流程挖掘中事件日志的缺失属性，效果好于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的流程挖掘事件日志修复方法要么需要过程模型，要么依赖于机器学习/深度学习模型，而本文提出了一种基于异构图神经网络的模型，该模型能够处理更自然、更复杂的序列表示，从而提高修复精度。

Method: 开发了一种异构图神经网络模型，用于修复包含不完整事件的轨迹中缺失的属性。该模型与现有技术（基于自动编码器的模型）进行了比较。

Result: 该方法在两个合成日志和四个真实事件日志上进行了评估，结果表明该方法在重建所有不同事件属性方面具有非常好的性能，优于现有模型，特别是在处理多种类型的缺失值时。

Conclusion: 本文提出了一种基于异构图神经网络模型的方法来修复流程挖掘中事件日志中缺失的信息，并在合成日志和真实事件日志上进行了评估，结果表明该方法在重建所有不同事件属性方面具有良好的性能。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [14] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon系统有效提升了知识密集型VQA的推理能力，在多模态、多轮和多跳推理场景下表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法通常只检索文本或图像，限制了其处理需要多跳推理或最新事实知识的复杂查询。

Method: 提出了一种查询感知的动态RAG系统QA-Dragon，该系统包含领域路由器和搜索路由器，支持多模态、多轮和多跳推理。

Result: 在Meta CRAG-MM挑战赛中，QA-Dragon在单源、多源和多轮任务上分别比基线提高了5.06%、6.35%和5.03%，显著提高了答案准确性和知识重叠得分。

Conclusion: QA-Dragon，一个查询感知的动态RAG系统，通过结合文本和图像搜索代理，显著提高了知识密集型VQA任务的推理性能，在Meta CRAG-MM挑战赛中取得了优异成绩，超越基线模型5%以上。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [15] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 用RDF图数据库和LLM构建框架，提升大型维护组织沟通效率，解决信息过载和响应慢的问题。


<details>
  <summary>Details</summary>
Motivation: 大型维护组织中，识别领域专家和跨复杂实体关系的沟通管理存在挑战，传统方法难以有效解决信息过载和响应时间长的问题。

Method: 结合RDF图数据库和LLMs处理自然语言查询，实现精准的受众定位，并通过规划-协调架构提供透明的推理过程。

Result: 该方案使沟通负责人能够制定直观的查询，结合设备、制造商、维护工程师和设施等概念，提供可解释的结果，提高沟通效率。

Conclusion: 提出了一种结合RDF图数据库和LLM的新框架，用于提高大型维护组织内部的沟通效率，解决了传统方法的信息过载和响应时间长的问题。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [16] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 该论文提出一种混合神经符号推理架构，结合决策树和大型语言模型，在多个基准测试中取得了显著的性能提升，并具有良好的可解释性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法中符号和神经模块松散耦合的问题，该论文提出了一种将符号推理和神经网络推理紧密结合的混合架构。

Method: 该系统整合了决策树和随机森林作为可调用预言机，嵌入到统一的推理系统中，结合大型语言模型进行推理。

Result: 该系统在ProofWriter、GSM8k和ARC等基准测试中均取得了显著的性能提升，分别提高了逻辑蕴含一致性、多步数学问题准确性和抽象准确性。

Conclusion: 该论文提出了一种混合架构，结合了基于决策树的符号推理和大型语言模型的生成能力，在协调的多智能体框架内实现了强大的推理能力，并在基准测试中取得了显著的性能提升。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>
