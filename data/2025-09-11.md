<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Learning-Based Planning for Improving Science Return of Earth Observation Satellites](https://arxiv.org/abs/2509.07997)
*Abigail Breitfeld,Alberto Candela,Juan Delfa,Akseli Kangaslahti,Itai Zilberstein,Steve Chien,David Wettergreen*

Main category: cs.AI

TL;DR: 利用强化学习和模仿学习改进卫星动态目标选择，提高数据收集效率，结果表明学习方法优于现有启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有卫星数据收集方法受限于轨道、传感器视野和资源，需要优化数据收集策略。

Method: 基于动态规划的强化学习和模仿学习方法，并与现有启发式方法对比。

Result: 模仿学习比最佳启发式方法平均提高10.0%，强化学习平均提高13.7%，且两种学习方法训练数据需求较少。

Conclusion: 学习方法有效提高了卫星动态目标选择的效率和科学信息的收集量。

Abstract: Earth observing satellites are powerful tools for collecting scientific
information about our planet, however they have limitations: they cannot easily
deviate from their orbital trajectories, their sensors have a limited field of
view, and pointing and operating these sensors can take a large amount of the
spacecraft's resources. It is important for these satellites to optimize the
data they collect and include only the most important or informative
measurements. Dynamic targeting is an emerging concept in which satellite
resources and data from a lookahead instrument are used to intelligently
reconfigure and point a primary instrument. Simulation studies have shown that
dynamic targeting increases the amount of scientific information gathered
versus conventional sampling strategies. In this work, we present two different
learning-based approaches to dynamic targeting, using reinforcement and
imitation learning, respectively. These learning methods build on a dynamic
programming solution to plan a sequence of sampling locations. We evaluate our
approaches against existing heuristic methods for dynamic targeting, showing
the benefits of using learning for this application. Imitation learning
performs on average 10.0\% better than the best heuristic method, while
reinforcement learning performs on average 13.7\% better. We also show that
both learning methods can be trained effectively with relatively small amounts
of data.

</details>


### [2] [EnvX: Agentize Everything with Agentic AI](https://arxiv.org/abs/2509.08088)
*Linyao Chen,Zimian Peng,Yingxuan Yang,Yikun Wang,Wenzheng Tom Tang,Hiroki H. Kobayashi,Weinan Zhang*

Main category: cs.AI

TL;DR: EnvX框架利用Agentic AI将GitHub仓库转化为智能代理，实现自然语言交互和代理间协作，提高了软件复用效率。


<details>
  <summary>Details</summary>
Motivation: 现有软件复用方式效率低，EnvX旨在通过将代码库转化为智能代理来解决这个问题。

Method: 三阶段过程：环境初始化、人类对齐的代理自动化和代理间协作协议。结合大型语言模型和结构化工具集成，自动化理解、初始化和运行代码库功能。

Result: 在GitTaskBench基准测试中，EnvX的执行完成率为74.07%，任务通过率为51.85%，优于现有框架。案例研究还证明了EnvX支持多代码库协作。

Conclusion: EnvX将代码库从被动的代码资源转变为智能交互式代理，促进了开源生态系统中的协作。

Abstract: The widespread availability of open-source repositories has led to a vast
collection of reusable software components, yet their utilization remains
manual, error-prone, and disconnected. Developers must navigate documentation,
understand APIs, and write integration code, creating significant barriers to
efficient software reuse. To address this, we present EnvX, a framework that
leverages Agentic AI to agentize GitHub repositories, transforming them into
intelligent, autonomous agents capable of natural language interaction and
inter-agent collaboration. Unlike existing approaches that treat repositories
as static code resources, EnvX reimagines them as active agents through a
three-phase process: (1) TODO-guided environment initialization, which sets up
the necessary dependencies, data, and validation datasets; (2) human-aligned
agentic automation, allowing repository-specific agents to autonomously perform
real-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple
agents to collaborate. By combining large language model capabilities with
structured tool integration, EnvX automates not just code generation, but the
entire process of understanding, initializing, and operationalizing repository
functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18
repositories across domains such as image processing, speech recognition,
document analysis, and video manipulation. Our results show that EnvX achieves
a 74.07% execution completion rate and 51.85% task pass rate, outperforming
existing frameworks. Case studies further demonstrate EnvX's ability to enable
multi-repository collaboration via the A2A protocol. This work marks a shift
from treating repositories as passive code resources to intelligent,
interactive agents, fostering greater accessibility and collaboration within
the open-source ecosystem.

</details>


### [3] [Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI](https://arxiv.org/abs/2509.08151)
*Botao Zhu,Jeslyn Wang,Dusit Niyato,Xianbin Wang*

Main category: cs.AI

TL;DR: 针对复杂计算任务的协同设备信任评估，提出一种基于大型AI模型的教师-学生代理架构的特定任务信任语义蒸馏(2TSD)模型，以减少评估时间、设备资源消耗并提高选择准确性。


<details>
  <summary>Details</summary>
Motivation: 现有协同设备信任评估方法存在数据交换频繁、推理复杂、动态变化等问题，导致开销大、评估效果差。

Method: 提出基于大型AI模型驱动的教师-学生代理架构的2TSD模型。教师代理收集多维信任数据，提取特定任务信任语义，进行任务-协作者匹配分析；学生代理接收教师代理的信任语义，快速准确地选择协作者。

Result: 实验结果表明，2TSD模型能减少协作者评估时间，降低设备资源消耗，提高协作者选择准确性。

Conclusion: 2TSD模型有效解决了复杂计算任务中协同设备信任评估的挑战，为提高协同计算效率提供了新的途径。

Abstract: Accurate trustworthiness evaluation of potential collaborating devices is
essential for the effective execution of complex computing tasks. This
evaluation process involves collecting diverse trust-related data from
potential collaborators, including historical performance and available
resources, for collaborator selection. However, when each task owner
independently assesses all collaborators' trustworthiness, frequent data
exchange, complex reasoning, and dynamic situation changes can result in
significant overhead and deteriorated trust evaluation. To overcome these
challenges, we propose a task-specific trust semantics distillation (2TSD)
model based on a large AI model (LAM)-driven teacher-student agent
architecture. The teacher agent is deployed on a server with powerful
computational capabilities and an augmented memory module dedicated to
multidimensional trust-related data collection, task-specific trust semantics
extraction, and task-collaborator matching analysis. Upon receiving
task-specific requests from device-side student agents, the teacher agent
transfers the trust semantics of potential collaborators to the student agents,
enabling rapid and accurate collaborator selection. Experimental results
demonstrate that the proposed 2TSD model can reduce collaborator evaluation
time, decrease device resource consumption, and improve the accuracy of
collaborator selection.

</details>


### [4] [Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following](https://arxiv.org/abs/2509.08222)
*Minjong Yoo,Jinwoo Jang,Wei-jin Park,Honguk Woo*

Main category: cs.AI

TL;DR: ExRAP框架增强LLM在动态环境中执行持续指令的能力，通过环境探索和上下文记忆提升任务规划。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理动态环境下的持续指令跟随任务。

Method: 提出ExRAP框架，结合信息探索和时间一致性细化方案，高效探索环境，构建环境上下文记忆，并进行基于记忆的任务规划。

Result: 在VirtualHome，ALFRED和CARLA上的实验表明，ExRAP在目标成功率和执行效率方面优于其他LLM基准任务规划方法。

Conclusion: ExRAP框架有效提升了LLM在动态非平稳环境中执行持续指令跟随任务的能力。

Abstract: This study presents an Exploratory Retrieval-Augmented Planning (ExRAP)
framework, designed to tackle continual instruction following tasks of embodied
agents in dynamic, non-stationary environments. The framework enhances Large
Language Models' (LLMs) embodied reasoning capabilities by efficiently
exploring the physical environment and establishing the environmental context
memory, thereby effectively grounding the task planning process in time-varying
environment contexts. In ExRAP, given multiple continual instruction following
tasks, each instruction is decomposed into queries on the environmental context
memory and task executions conditioned on the query results. To efficiently
handle these multiple tasks that are performed continuously and simultaneously,
we implement an exploration-integrated task planning scheme by incorporating
the {information-based exploration} into the LLM-based planning process.
Combined with memory-augmented query evaluation, this integrated scheme not
only allows for a better balance between the validity of the environmental
context memory and the load of environment exploration, but also improves
overall task performance. Furthermore, we devise a {temporal consistency
refinement} scheme for query evaluation to address the inherent decay of
knowledge in the memory. Through experiments with VirtualHome, ALFRED, and
CARLA, our approach demonstrates robustness against a variety of embodied
instruction following scenarios involving different instruction scales and
types, and non-stationarity degrees, and it consistently outperforms other
state-of-the-art LLM-based task planning approaches in terms of both goal
success rate and execution efficiency.

</details>


### [5] [Real-world Music Plagiarism Detection With Music Segment Transcription System](https://arxiv.org/abs/2509.08282)
*Seonghyeon Go*

Main category: cs.AI

TL;DR: 本文提出一种结合多种音乐信息检索(MIR)技术的音乐剽窃检测系统，并公开了一个用于音乐相似性研究的相似音乐对(SMP)数据集。


<details>
  <summary>Details</summary>
Motivation: 随着MIR技术的进步，音乐创作和分发更加多元化，对音乐知识产权保护的需求日益增长。

Method: 开发了一个音乐片段转录系统，提取音频记录中具有音乐意义的片段，并基于多种音乐特征计算相似度分数。

Result: 实验表明该方法在音乐剽窃检测方面具有良好效果，可应用于实际场景。

Conclusion: 该系统和数据集为音乐剽窃检测和音乐相似性研究提供了有益工具。

Abstract: As a result of continuous advances in Music Information Retrieval (MIR)
technology, generating and distributing music has become more diverse and
accessible. In this context, interest in music intellectual property protection
is increasing to safeguard individual music copyrights. In this work, we
propose a system for detecting music plagiarism by combining various MIR
technologies. We developed a music segment transcription system that extracts
musically meaningful segments from audio recordings to detect plagiarism across
different musical formats. With this system, we compute similarity scores based
on multiple musical features that can be evaluated through comprehensive
musical analysis. Our approach demonstrated promising results in music
plagiarism detection experiments, and the proposed method can be applied to
real-world music scenarios. We also collected a Similar Music Pair (SMP)
dataset for musical similarity research using real-world cases. The dataset are
publicly available.

</details>


### [6] [Leveraging AI Agents for Autonomous Networks: A Reference Architecture and Empirical Studies](https://arxiv.org/abs/2509.08312)
*Binghan Wu,Shoufeng Wang,Yunxin Liu,Ya-Qin Zhang,Joseph Sifakis,Ye Ouyang*

Main category: cs.AI

TL;DR: 该论文实现了Joseph Sifakis的AN Agent参考架构，并在5G NR网络中实现了亚10毫秒的实时控制，提高了吞吐量并降低了误码率。


<details>
  <summary>Details</summary>
Motivation: 推动自主网络向4级演进，实现自配置、自修复和自优化的网络。

Method: 在无线接入网链路自适应代理中实现Joseph Sifakis的AN Agent参考架构，使用混合知识表示驱动主动-被动运行时。

Result: 在5G NR sub-6 GHz网络中实现了亚10毫秒的实时控制，下行吞吐量比传统算法提高6%，误码率降低67%。

Conclusion: 该架构克服了传统自主性障碍，为下一代目标推动了关键的4级自主能力。

Abstract: The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a
strategic inflection point in telecommunications, where networks must transcend
reactive automation to achieve genuine cognitive capabilities--fulfilling TM
Forum's vision of self-configuring, self-healing, and self-optimizing systems
that deliver zero-wait, zero-touch, and zero-fault services. This work bridges
the gap between architectural theory and operational reality by implementing
Joseph Sifakis's AN Agent reference architecture in a functional cognitive
system, deploying coordinated proactive-reactive runtimes driven by hybrid
knowledge representation. Through an empirical case study of a Radio Access
Network (RAN) Link Adaptation (LA) Agent, we validate this framework's
transformative potential: demonstrating sub-10 ms real-time control in 5G NR
sub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link
Adaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for
ultra-reliable services through dynamic Modulation and Coding Scheme (MCS)
optimization. These improvements confirm the architecture's viability in
overcoming traditional autonomy barriers and advancing critical L4-enabling
capabilities toward next-generation objectives.

</details>


### [7] [Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives](https://arxiv.org/abs/2509.08380)
*Prathamesh Vasudeo Naik,Naresh Kumar Dintakurthi,Zhanghao Hu,Yue Wang,Robby Qiu*

Main category: cs.AI

TL;DR: 利用AI智能体框架Co-Investigator AI提高可疑活动报告(SAR)生成效率和准确性，解决传统方法的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有SAR生成流程成本高、效率低，而LLM存在事实幻觉等问题，难以应用于合规领域。

Method: 构建包含规划、犯罪类型检测、外部情报收集和合规验证等专用智能体的代理框架，并集成动态内存管理、AI隐私保护层和实时验证智能体。

Result: 在多种复杂的金融犯罪场景中，Co-Investigator AI能够简化SAR起草流程，使报告更符合监管预期，并提高合规团队的工作效率。

Conclusion: Co-Investigator AI标志着合规报告新时代的开始，实现了AI在监管流程中的转型应用，为可扩展、可靠和透明的SAR生成铺平了道路。

Abstract: Generating regulatorily compliant Suspicious Activity Report (SAR) remains a
high-cost, low-scalability bottleneck in Anti-Money Laundering (AML) workflows.
While large language models (LLMs) offer promising fluency, they suffer from
factual hallucination, limited crime typology alignment, and poor
explainability -- posing unacceptable risks in compliance-critical domains.
This paper introduces Co-Investigator AI, an agentic framework optimized to
produce Suspicious Activity Reports (SARs) significantly faster and with
greater accuracy than traditional methods. Drawing inspiration from recent
advances in autonomous agent architectures, such as the AI Co-Scientist, our
approach integrates specialized agents for planning, crime type detection,
external intelligence gathering, and compliance validation. The system features
dynamic memory management, an AI-Privacy Guard layer for sensitive data
handling, and a real-time validation agent employing the Agent-as-a-Judge
paradigm to ensure continuous narrative quality assurance. Human investigators
remain firmly in the loop, empowered to review and refine drafts in a
collaborative workflow that blends AI efficiency with domain expertise. We
demonstrate the versatility of Co-Investigator AI across a range of complex
financial crime scenarios, highlighting its ability to streamline SAR drafting,
align narratives with regulatory expectations, and enable compliance teams to
focus on higher-order analytical work. This approach marks the beginning of a
new era in compliance reporting -- bringing the transformative benefits of AI
agents to the core of regulatory processes and paving the way for scalable,
reliable, and transparent SAR generation.

</details>


### [8] [TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making](https://arxiv.org/abs/2509.08500)
*Kechen Jiao,Zhirui Fang,Jiahao Liu,Bei Li,Qifan Wang,Xinyu Liu,Junhao Ruan,Zhongjian Qiao,Yifan Zhu,Yaxin Xu,Jingang Wang,Xiu Li*

Main category: cs.AI

TL;DR: 本文提出了一种基于思想的偏好优化方法（TCPO）来改进具身AI中视觉语言模型的决策能力，该方法通过逐步的偏好优化和动作策略一致性约束提高了样本效率，减少了模型退化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态环境中存在响应迟缓和幻觉问题，且样本效率低，一致性差。

Method: 提出思想中心偏好优化（TCPO）方法，将稀疏奖励转换为更丰富的样本对，并结合动作策略一致性约束（APC）提高模型输出的一致性。

Result: 在ALFWorld环境中，TCPO取得了26.67%的平均成功率，比RL4VLM提高了6%，验证了该方法在减轻微调后模型退化的有效性。

Conclusion: 基于偏好学习和思维链过程可以有效增强具身智能体中视觉语言模型的决策能力。

Abstract: Using effective generalization capabilities of vision language models (VLMs)
in context-specific dynamic tasks for embodied artificial intelligence remains
a significant challenge. Although supervised fine-tuned models can better align
with the real physical world, they still exhibit sluggish responses and
hallucination issues in dynamically changing environments, necessitating
further alignment. Existing post-SFT methods, reliant on reinforcement learning
and chain-of-thought (CoT) approaches, are constrained by sparse rewards and
action-only optimization, resulting in low sample efficiency, poor consistency,
and model degradation. To address these issues, this paper proposes
Thought-Centric Preference Optimization (TCPO) for effective embodied
decision-making. Specifically, TCPO introduces a stepwise preference-based
optimization approach, transforming sparse reward signals into richer step
sample pairs. It emphasizes the alignment of the model's intermediate reasoning
process, mitigating the problem of model degradation. Moreover, by
incorporating Action Policy Consistency Constraint (APC), it further imposes
consistency constraints on the model output. Experiments in the ALFWorld
environment demonstrate an average success rate of 26.67%, achieving a 6%
improvement over RL4VLM and validating the effectiveness of our approach in
mitigating model degradation after fine-tuning. These results highlight the
potential of integrating preference-based learning techniques with CoT
processes to enhance the decision-making capabilities of vision-language models
in embodied agents.

</details>


### [9] [No-Knowledge Alarms for Misaligned LLMs-as-Judges](https://arxiv.org/abs/2509.08593)
*Andrés Corrada-Emmanuel*

Main category: cs.AI

TL;DR: 论文探究了使用LLM评估其他LLM复杂决策时出现的无限监控链问题，提出利用逻辑一致性来减轻评估不确定性，通过线性规划方法检测LLM评委的错位情况，实现无误报的异常检测。


<details>
  <summary>Details</summary>
Motivation: 解决LLM评估中缺乏客观标准和信任问题。

Method: 利用LLM评委之间对其他LLM评估结果的意见一致性和差异性，构建线性规划模型。

Result: 开发出一种无误报的异常检测机制，能够检测出LLM评委群体中至少一个成员违反用户指定的评分能力要求。

Conclusion: 该方法有效缓解了LLM评估中的不确定性，为LLM的可靠性评估提供了新的思路。

Abstract: If we use LLMs as judges to evaluate the complex decisions of other LLMs, who
or what monitors the judges? Infinite monitoring chains are inevitable whenever
we do not know the ground truth of the decisions by experts and we do not want
to trust them. One way to ameliorate our evaluation uncertainty is to exploit
the use of logical consistency between disagreeing experts. By observing how
LLM judges agree and disagree while grading other LLMs, we can compute the only
possible evaluations of their grading ability. For example, if two LLM judges
disagree on which tasks a third one completed correctly, they cannot both be
100\% correct in their judgments. This logic can be formalized as a Linear
Programming problem in the space of integer response counts for any finite
test. We use it here to develop no-knowledge alarms for misaligned LLM judges.
The alarms can detect, with no false positives, that at least one member or
more of an ensemble of judges are violating a user specified grading ability
requirement.

</details>


### [10] [Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference](https://arxiv.org/abs/2509.08682)
*Guoqing Ma,Jia Zhu,Hanghui Guo,Weijie Shi,Jiawei Shen,Jingjiang Liu,Yidan Liang*

Main category: cs.AI

TL;DR: 本文提出一种基于多粒度因果推理的故障归因框架，以提高多智能体系统(MAS)的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有MAS故障诊断工具准确率低，本文旨在解决MAS故障归因难题。

Method: 提出一种性能因果反演原则结合Shapley值进行智能体级别责任分配，以及一种新颖的因果发现算法CDC-MAS，用于识别关键故障步骤。

Result: 在Who\&When和TRAIL基准测试中，步骤级准确率高达36.2%，整体任务成功率提高了22.4%。

Conclusion: 该框架为调试复杂的智能体交互提供了有效解决方案，促进了更可靠和可解释的MAS发展。

Abstract: Multi-agent systems (MAS) are critical for automating complex tasks, yet
their practical deployment is severely hampered by the challenge of failure
attribution. Current diagnostic tools, which rely on statistical correlations,
are fundamentally inadequate; on challenging benchmarks like Who\&When,
state-of-the-art methods achieve less than 15\% accuracy in locating the
root-cause step of a failure. To address this critical gap, we introduce the
first failure attribution framework for MAS grounded in multi-granularity
causal inference. Our approach makes two key technical contributions: (1) a
performance causal inversion principle, which correctly models performance
dependencies by reversing the data flow in execution logs, combined with
Shapley values to accurately assign agent-level blame; (2) a novel causal
discovery algorithm, CDC-MAS, that robustly identifies critical failure steps
by tackling the non-stationary nature of MAS interaction data. The framework's
attribution results directly fuel an automated optimization loop, generating
targeted suggestions whose efficacy is validated via counterfactual
simulations. Evaluations on the Who\&When and TRAIL benchmarks demonstrate a
significant leap in performance. Our method achieves up to 36.2\% step-level
accuracy. Crucially, the generated optimizations boost overall task success
rates by an average of 22.4\%. This work provides a principled and effective
solution for debugging complex agent interactions, paving the way for more
reliable and interpretable multi-agent systems.

</details>


### [11] [One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases](https://arxiv.org/abs/2509.08705)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 该论文提出了一种基于双过程理论的思维理论框架，结合快速直觉的图卷积网络和慢速、情境相关的元学习系统，实现了对人类认知偏差的模拟。


<details>
  <summary>Details</summary>
Motivation: 构建一个能模拟人类认知过程，特别是双过程理论中直觉与理性思维动态平衡的模型。

Method: 构建了一个结合图卷积网络（GCN）和元学习技术的双过程模型，通过学习上下文门机制动态平衡直觉和审慎推理。

Result: 模型在经典的错误信念任务中取得了良好的效果，并成功复制了锚定效应、认知负荷疲劳、框架效应和启动效应等认知偏差。

Conclusion: 该研究成果弥合了人工智能与认知理论之间的差距，为开发具有细致入微、类似人类的社会认知和自适应决策能力的AI系统铺平了道路。

Abstract: We introduce a novel Theory of Mind (ToM) framework inspired by dual-process
theories from cognitive science, integrating a fast, habitual graph-based
reasoning system (System 1), implemented via graph convolutional networks
(GCNs), and a slower, context-sensitive meta-adaptive learning system (System
2), driven by meta-learning techniques. Our model dynamically balances
intuitive and deliberative reasoning through a learned context gate mechanism.
We validate our architecture on canonical false-belief tasks and systematically
explore its capacity to replicate hallmark cognitive biases associated with
dual-process theory, including anchoring, cognitive-load fatigue, framing
effects, and priming effects. Experimental results demonstrate that our
dual-process approach closely mirrors human adaptive behavior, achieves robust
generalization to unseen contexts, and elucidates cognitive mechanisms
underlying reasoning biases. This work bridges artificial intelligence and
cognitive theory, paving the way for AI systems exhibiting nuanced, human-like
social cognition and adaptive decision-making capabilities.

</details>


### [12] [The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems](https://arxiv.org/abs/2509.08713)
*Ziming Luo,Atoosa Kasirzadeh,Nihar B. Shah*

Main category: cs.AI

TL;DR: AI科学家系统可能存在四个潜在缺陷：基准选择不当、数据泄漏、指标滥用和事后选择偏差。


<details>
  <summary>Details</summary>
Motivation: 评估AI科学家系统的内部流程，以确保其研究成果的完整性、可靠性和可信度。

Method: 设计对照实验，隔离每个潜在缺陷，并评估两个开源AI科学家系统。

Result: 发现多个严重程度不同的缺陷，并证明访问完整的自动化工作流程的跟踪日志和代码能够更有效地检测这些缺陷。

Conclusion: 建议期刊和会议要求提交AI生成研究的跟踪日志和代码，以确保透明度、问责制和可重复性。

Abstract: AI scientist systems, capable of autonomously executing the full research
workflow from hypothesis generation and experimentation to paper writing, hold
significant potential for accelerating scientific discovery. However, the
internal workflow of these systems have not been closely examined. This lack of
scrutiny poses a risk of introducing flaws that could undermine the integrity,
reliability, and trustworthiness of their research outputs. In this paper, we
identify four potential failure modes in contemporary AI scientist systems:
inappropriate benchmark selection, data leakage, metric misuse, and post-hoc
selection bias. To examine these risks, we design controlled experiments that
isolate each failure mode while addressing challenges unique to evaluating AI
scientist systems. Our assessment of two prominent open-source AI scientist
systems reveals the presence of several failures, across a spectrum of
severity, which can be easily overlooked in practice. Finally, we demonstrate
that access to trace logs and code from the full automated workflow enables far
more effective detection of such failures than examining the final paper alone.
We thus recommend journals and conferences evaluating AI-generated research to
mandate submission of these artifacts alongside the paper to ensure
transparency, accountability, and reproducibility.

</details>


### [13] [Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making](https://arxiv.org/abs/2509.08785)
*Anup Tuladhar,Araz Minhas,Adam Kirton,Eli Kinney-Lang*

Main category: cs.AI

TL;DR: 该平台结合强化学习和语言模型推理，探索叙事元素如何影响AI决策。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统决策和叙事推理能力通常分开研究，本平台尝试将两者结合。

Method: 使用双系统架构，强化学习策略提供行动建议，语言模型基于叙事框架处理建议并指导决策，在可配置的网格世界环境中实现。

Result: 初步实验结果为研究叙事框架如何影响基于奖励的决策提供了基础。

Conclusion: 该平台为研究优化学习和符号推理在AI系统中的相互作用提供了基础。

Abstract: We present a preliminary experimental platform that explores how narrative
elements might shape AI decision-making by combining reinforcement learning
(RL) with language model reasoning. While AI systems can now both make
decisions and engage in narrative reasoning, these capabilities have mostly
been studied separately. Our platform attempts to bridge this gap using a
dual-system architecture to examine how narrative frameworks could influence
reward-based learning. The system comprises a reinforcement learning policy
that suggests actions based on past experience, and a language model that
processes these suggestions through different narrative frameworks to guide
decisions. This setup enables initial experimentation with narrative elements
while maintaining consistent environment and reward structures. We implement
this architecture in a configurable gridworld environment, where agents receive
both policy suggestions and information about their surroundings. The
platform's modular design facilitates controlled testing of environmental
complexity, narrative parameters, and the interaction between reinforcement
learning and narrative-based decisions. Our logging system captures basic
decision metrics, from RL policy values to language model reasoning to action
selection patterns. While preliminary, this implementation provides a
foundation for studying how different narrative frameworks might affect
reward-based decisions and exploring potential interactions between
optimization-based learning and symbolic reasoning in AI systems.

</details>
