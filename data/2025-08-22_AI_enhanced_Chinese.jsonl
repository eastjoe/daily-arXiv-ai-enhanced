{"id": "2508.14923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14923", "abs": "https://arxiv.org/abs/2508.14923", "authors": ["Andrew Kiruluta"], "title": "A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone", "comment": null, "summary": "We propose a fully spectral, neuro\\-symbolic reasoning architecture that\nleverages Graph Signal Processing (GSP) as the primary computational backbone\nfor integrating symbolic logic and neural inference. Unlike conventional\nreasoning models that treat spectral graph methods as peripheral components,\nour approach formulates the entire reasoning pipeline in the graph spectral\ndomain. Logical entities and relationships are encoded as graph signals,\nprocessed via learnable spectral filters that control multi-scale information\npropagation, and mapped into symbolic predicates for rule-based inference. We\npresent a complete mathematical framework for spectral reasoning, including\ngraph Fourier transforms, band-selective attention, and spectral rule\ngrounding. Experiments on benchmark reasoning datasets (ProofWriter,\nEntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in\nlogical consistency, interpretability, and computational efficiency over\nstate\\-of\\-the\\-art neuro\\-symbolic models. Our results suggest that GSP\nprovides a mathematically grounded and computationally efficient substrate for\nrobust and interpretable reasoning systems.", "AI": {"tldr": "\u5229\u7528\u56fe\u8c31\u57df\u8fdb\u884c\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\uff0c\u63d0\u9ad8\u4e86\u903b\u8f91\u4e00\u81f4\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u901a\u5e38\u5c06\u8c31\u56fe\u65b9\u6cd5\u4f5c\u4e3a\u8f85\u52a9\u7ec4\u4ef6\uff0c\u8be5\u8bba\u6587\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u5b8c\u5168\u5728\u56fe\u8c31\u57df\u4e2d\u8fdb\u884c\u63a8\u7406\u7684\u6a21\u578b\u3002", "method": "\u8be5\u67b6\u6784\u5c06\u903b\u8f91\u5b9e\u4f53\u548c\u5173\u7cfb\u7f16\u7801\u4e3a\u56fe\u4fe1\u53f7\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u8c31\u6ee4\u6ce2\u5668\u5904\u7406\uff0c\u6620\u5c04\u5230\u7b26\u53f7\u8c13\u8bcd\u8fdb\u884c\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u3002", "result": "\u5728ProofWriter\u3001EntailmentBank\u3001bAbI\u3001CLUTRR\u548cARC-Challenge\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u6a21\u578b\u5728\u903b\u8f91\u4e00\u81f4\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u57fa\u4e8e\u8c31\u7684\u3001\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u67b6\u6784\uff0c\u5229\u7528\u56fe\u4fe1\u53f7\u5904\u7406 (GSP) \u4f5c\u4e3a\u4e3b\u8981\u8ba1\u7b97\u6846\u67b6\uff0c\u6574\u5408\u7b26\u53f7\u903b\u8f91\u548c\u795e\u7ecf\u63a8\u7406\uff0c\u5e76\u5728\u57fa\u51c6\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u7684\u7ed3\u679c\u3002"}}
{"id": "2508.15013", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2508.15013", "abs": "https://arxiv.org/abs/2508.15013", "authors": ["Nadav Amir", "Stas Tiomkin", "Angela Langdon"], "title": "Goals and the Structure of Experience", "comment": null, "summary": "Purposeful behavior is a hallmark of natural and artificial intelligence. Its\nacquisition is often believed to rely on world models, comprising both\ndescriptive (what is) and prescriptive (what is desirable) aspects that\nidentify and evaluate state of affairs in the world, respectively. Canonical\ncomputational accounts of purposeful behavior, such as reinforcement learning,\nposit distinct components of a world model comprising a state representation\n(descriptive aspect) and a reward function (prescriptive aspect). However, an\nalternative possibility, which has not yet been computationally formulated, is\nthat these two aspects instead co-emerge interdependently from an agent's goal.\nHere, we describe a computational framework of goal-directed state\nrepresentation in cognitive agents, in which the descriptive and prescriptive\naspects of a world model co-emerge from agent-environment interaction\nsequences, or experiences. Drawing on Buddhist epistemology, we introduce a\nconstruct of goal-directed, or telic, states, defined as classes of\ngoal-equivalent experience distributions. Telic states provide a parsimonious\naccount of goal-directed learning in terms of the statistical divergence\nbetween behavioral policies and desirable experience features. We review\nempirical and theoretical literature supporting this novel perspective and\ndiscuss its potential to provide a unified account of behavioral,\nphenomenological and neural dimensions of purposeful behaviors across diverse\nsubstrates.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u89e3\u91ca\u8ba4\u77e5\u4e3b\u4f53\u4e2d\u76ee\u7684\u6027\u884c\u4e3a\u7684\u63cf\u8ff0\u6027\u548c\u89c4\u5b9a\u6027\u65b9\u9762\u5982\u4f55\u4ece\u76ee\u6807\u4e2d\u5171\u540c\u6d8c\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u8ba1\u7b97\u6a21\u578b\u5c06\u4e16\u754c\u6a21\u578b\u7684\u63cf\u8ff0\u6027\u548c\u89c4\u5b9a\u6027\u65b9\u9762\u89c6\u4e3a\u4e0d\u540c\u7684\u7ec4\u4ef6\uff0c\u800c\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u80fd\u6027\uff1a\u8fd9\u4e24\u4e2a\u65b9\u9762\u53ef\u80fd\u4ece\u4e3b\u4f53\u7684\u76ee\u6807\u4e2d\u5171\u540c\u6d8c\u73b0\u3002", "method": "\u8be5\u6846\u67b6\u501f\u9274\u4f5b\u6559\u8ba4\u8bc6\u8bba\uff0c\u5f15\u5165\u76ee\u6807\u5bfc\u5411\u72b6\u6001\uff08telic states\uff09\u7684\u6982\u5ff5\uff0c\u5c06\u76ee\u6807\u5b9a\u4e49\u4e3a\u76ee\u6807\u7b49\u6548\u7ecf\u9a8c\u5206\u5e03\u7684\u7c7b\u522b\uff0c\u5e76\u7528\u884c\u4e3a\u7b56\u7565\u548c\u7406\u60f3\u7ecf\u9a8c\u7279\u5f81\u4e4b\u95f4\u7684\u7edf\u8ba1\u5dee\u5f02\u6765\u89e3\u91ca\u76ee\u6807\u5bfc\u5411\u5b66\u4e60\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u76ee\u7684\u6027\u884c\u4e3a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u89c6\u89d2\uff0c\u5e76\u80fd\u89e3\u91ca\u5176\u884c\u4e3a\u3001\u73b0\u8c61\u548c\u795e\u7ecf\u7ef4\u5ea6\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76ee\u6807\u5bfc\u5411\u72b6\u6001\u8868\u5f81\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u91ca\u8ba4\u77e5\u4e3b\u4f53\u4e2d\u7684\u76ee\u7684\u6027\u884c\u4e3a\uff0c\u5176\u4e2d\u4e16\u754c\u6a21\u578b\u7684\u63cf\u8ff0\u6027\u548c\u89c4\u5b9a\u6027\u65b9\u9762\u4ece\u4e3b\u4f53\u4e0e\u73af\u5883\u7684\u4ea4\u4e92\u4e2d\u5171\u540c\u6d8c\u73b0\u3002"}}
{"id": "2508.15030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15030", "abs": "https://arxiv.org/abs/2508.15030", "authors": ["Ashmi Banerjee", "Fitri Nur Aisyah", "Adithi Satish", "Wolfgang W\u00f6rndl", "Yashar Deldjoo"], "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism", "comment": null, "summary": "We propose Collab-REC, a multi-agent framework designed to counteract\npopularity bias and enhance diversity in tourism recommendations. In our\nsetting, three LLM-based agents -- Personalization, Popularity, and\nSustainability generate city suggestions from complementary perspectives. A\nnon-LLM moderator then merges and refines these proposals via multi-round\nnegotiation, ensuring each agent's viewpoint is incorporated while penalizing\nspurious or repeated responses. Experiments on European city queries show that\nCollab-REC improves diversity and overall relevance compared to a single-agent\nbaseline, surfacing lesser-visited locales that often remain overlooked. This\nbalanced, context-aware approach addresses over-tourism and better aligns with\nconstraints provided by the user, highlighting the promise of multi-stakeholder\ncollaboration in LLM-driven recommender systems.", "AI": {"tldr": "\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63a8\u8350\u6846\u67b6Collab-REC\u6709\u6548\u63d0\u5347\u65c5\u6e38\u63a8\u8350\u7684\u591a\u6837\u6027\u548c\u76f8\u5173\u6027\uff0c\u7f13\u89e3\u8fc7\u5ea6\u65c5\u6e38\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u65c5\u6e38\u63a8\u8350\u4e2d\u6d41\u884c\u5ea6\u504f\u5dee\u548c\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u63a8\u8350\u6846\u67b6Collab-REC\uff0c\u8be5\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\uff08\u4e2a\u6027\u5316\u3001\u6d41\u884c\u5ea6\u548c\u53ef\u6301\u7eed\u6027\uff09\u548c\u4e00\u4e2a\u975eLLM\u534f\u8c03\u8005\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u76f8\u6bd4\uff0cCollab-REC\u63d0\u9ad8\u4e86\u591a\u6837\u6027\u548c\u6574\u4f53\u76f8\u5173\u6027\uff0c\u63a8\u8350\u4e86\u66f4\u591a\u9c9c\u4e3a\u4eba\u77e5\u7684\u65c5\u6e38\u5730\u70b9\u3002", "conclusion": "Collab-REC\u6846\u67b6\u63d0\u9ad8\u4e86\u65c5\u6e38\u63a8\u8350\u7684\u591a\u6837\u6027\u548c\u76f8\u5173\u6027\uff0c\u89e3\u51b3\u4e86\u8fc7\u5ea6\u65c5\u6e38\u95ee\u9898\uff0c\u5e76\u66f4\u597d\u5730\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u3002"}}
{"id": "2508.15047", "categories": ["cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2508.15047", "abs": "https://arxiv.org/abs/2508.15047", "authors": ["Yibo Liu", "Liam Shatzel", "Brandon Haworth", "Teseo Schneider"], "title": "Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions", "comment": null, "summary": "Animating and simulating crowds using an agent-based approach is a\nwell-established area where every agent in the crowd is individually controlled\nsuch that global human-like behaviour emerges. We observe that human navigation\nand movement in crowds are often influenced by complex social and environmental\ninteractions, driven mainly by language and dialogue. However, most existing\nwork does not consider these dimensions and leads to animations where\nagent-agent and agent-environment interactions are largely limited to steering\nand fixed higher-level goal extrapolation.\n  We propose a novel method that exploits large language models (LLMs) to\ncontrol agents' movement. Our method has two main components: a dialogue system\nand language-driven navigation. We periodically query agent-centric LLMs\nconditioned on character personalities, roles, desires, and relationships to\ncontrol the generation of inter-agent dialogue when necessitated by the spatial\nand social relationships with neighbouring agents. We then use the conversation\nand each agent's personality, emotional state, vision, and physical state to\ncontrol the navigation and steering of each agent. Our model thus enables\nagents to make motion decisions based on both their perceptual inputs and the\nongoing dialogue.\n  We validate our method in two complex scenarios that exemplify the interplay\nbetween social interactions, steering, and crowding. In these scenarios, we\nobserve that grouping and ungrouping of agents automatically occur.\nAdditionally, our experiments show that our method serves as an\ninformation-passing mechanism within the crowd. As a result, our framework\nproduces more realistic crowd simulations, with emergent group behaviours\narising naturally from any environmental setting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u66f4\u903c\u771f\u7684\u7fa4\u4f53\u6a21\u62df\uff0c\u901a\u8fc7\u5bf9\u8bdd\u7cfb\u7edf\u548c\u8bed\u8a00\u9a71\u52a8\u7684\u5bfc\u822a\uff0c\u4f7f\u4ee3\u7406\u7684\u8fd0\u52a8\u51b3\u7b56\u57fa\u4e8e\u611f\u77e5\u8f93\u5165\u548c\u5bf9\u8bdd\uff0c\u4ece\u800c\u81ea\u7136\u4ea7\u751f\u7fa4\u4f53\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u7fa4\u4f53\u52a8\u753b\u548c\u6a21\u62df\u65b9\u6cd5\u5ffd\u7565\u4e86\u8bed\u8a00\u548c\u5bf9\u8bdd\u7b49\u590d\u6742\u793e\u4f1a\u548c\u73af\u5883\u4e92\u52a8\u5bf9\u4eba\u7c7b\u5bfc\u822a\u548c\u8fd0\u52a8\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u4ee3\u7406\u95f4\u7684\u4e92\u52a8\u4ec5\u9650\u4e8e\u8f6c\u5411\u548c\u56fa\u5b9a\u9ad8\u5c42\u76ee\u6807\u63a8\u65ad\u3002\u8be5\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u5229\u7528LLM\u6a21\u62df\u8fd9\u4e9b\u4e92\u52a8\uff0c\u4ece\u800c\u751f\u6210\u66f4\u903c\u771f\u7684\u7fa4\u4f53\u6a21\u62df\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u7ec4\u4ef6\uff1a\u5bf9\u8bdd\u7cfb\u7edf\u548c\u8bed\u8a00\u9a71\u52a8\u7684\u5bfc\u822a\u3002\u5468\u671f\u6027\u5730\u67e5\u8be2\u4ee5\u89d2\u8272\u4e2a\u6027\u3001\u89d2\u8272\u3001\u613f\u671b\u548c\u5173\u7cfb\u4e3a\u6761\u4ef6\u7684\u4ee5\u4ee3\u7406\u4e3a\u4e2d\u5fc3\u7684LLM\uff0c\u4ee5\u63a7\u5236\u5728\u7a7a\u95f4\u548c\u793e\u4f1a\u5173\u7cfb\u9700\u8981\u65f6\u4ea7\u751f\u7684\u4ee3\u7406\u95f4\u5bf9\u8bdd\u3002\u7136\u540e\uff0c\u5229\u7528\u5bf9\u8bdd\u548c\u6bcf\u4e2a\u4ee3\u7406\u7684\u4e2a\u6027\u3001\u60c5\u7eea\u72b6\u6001\u3001\u89c6\u91ce\u548c\u7269\u7406\u72b6\u6001\u6765\u63a7\u5236\u6bcf\u4e2a\u4ee3\u7406\u7684\u5bfc\u822a\u548c\u8f6c\u5411\u3002", "result": "\u5728\u4e24\u4e2a\u590d\u6742\u7684\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u7ed3\u679c\u8868\u660e\u4ee3\u7406\u7684\u805a\u96c6\u548c\u5206\u6563\u4f1a\u81ea\u52a8\u53d1\u751f\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u53ef\u4ee5\u4f5c\u4e3a\u7fa4\u4f53\u5185\u7684\u4fe1\u606f\u4f20\u9012\u673a\u5236\uff0c\u4ea7\u751f\u66f4\u771f\u5b9e\u7684\u7fa4\u4f53\u6a21\u62df\uff0c\u7fa4\u4f53\u884c\u4e3a\u81ea\u7136\u4ea7\u751f\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a7\u5236\u7fa4\u4f53\u4e2d\u4e2a\u4f53\u4ee3\u7406\u8fd0\u52a8\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5bf9\u8bdd\u7cfb\u7edf\u548c\u8bed\u8a00\u9a71\u52a8\u7684\u5bfc\u822a\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u57fa\u4e8e\u611f\u77e5\u8f93\u5165\u548c\u6301\u7eed\u5bf9\u8bdd\u505a\u51fa\u8fd0\u52a8\u51b3\u7b56\uff0c\u4ece\u800c\u751f\u6210\u66f4\u903c\u771f\u7684\u7fa4\u4f53\u6a21\u62df\uff0c\u5e76\u81ea\u7136\u4ea7\u751f\u7fa4\u4f53\u884c\u4e3a\u3002"}}
{"id": "2508.15050", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15050", "abs": "https://arxiv.org/abs/2508.15050", "authors": ["Romain Lacombe", "Kerrie Wu", "Eddie Dilworth"], "title": "Don't Think Twice! Over-Reasoning Impairs Confidence Calibration", "comment": "Published at ICML 2025 Workshop on Reliable and Responsible\n  Foundation Models", "summary": "Large Language Models deployed as question answering tools require robust\ncalibration to avoid overconfidence. We systematically evaluate how reasoning\ncapabilities and budget affect confidence assessment accuracy, using the\nClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary\nhealth. Our key finding challenges the \"test-time scaling\" paradigm: while\nrecent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,\nincreasing reasoning budgets consistently impairs rather than improves\ncalibration. Extended reasoning leads to systematic overconfidence that worsens\nwith longer thinking budgets, producing diminishing and negative returns beyond\nmodest computational investments. Conversely, search-augmented generation\ndramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving\nrelevant evidence. Our results suggest that information access, rather than\nreasoning depth or inference budget, may be the critical bottleneck for\nimproved confidence calibration of knowledge-intensive tasks.", "AI": {"tldr": "\u589e\u52a0\u63a8\u7406\u9884\u7b97\u53cd\u800c\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u7cbe\u5ea6\uff1b\u641c\u7d22\u589e\u5f3a\u751f\u6210\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u95ee\u7b54\u5de5\u5177\u9700\u8981\u5f3a\u5927\u7684\u6821\u51c6\u4ee5\u907f\u514d\u8fc7\u5ea6\u81ea\u4fe1\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u63a8\u7406\u80fd\u529b\u548c\u9884\u7b97\u5982\u4f55\u5f71\u54cd\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff0c\u4f7f\u7528ClimateX\u6570\u636e\u96c6\uff0c\u5e76\u6269\u5c55\u5230\u4eba\u7c7b\u548c\u5730\u7403\u5065\u5eb7\u3002", "result": "\u589e\u52a0\u63a8\u7406\u9884\u7b97\u4f1a\u964d\u4f4e\u6821\u51c6\u7cbe\u5ea6\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u3002\u641c\u7d22\u589e\u5f3a\u751f\u6210\u663e\u8457\u4f18\u4e8e\u7eaf\u63a8\u7406\uff0c\u51c6\u786e\u7387\u8fbe\u523089.3%\u3002\u4fe1\u606f\u83b7\u53d6\u800c\u975e\u63a8\u7406\u6df1\u5ea6\u6216\u63a8\u7406\u9884\u7b97\u53ef\u80fd\u662f\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u6539\u8fdb\u7f6e\u4fe1\u5ea6\u6821\u51c6\u7684\u5173\u952e\u74f6\u9888\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u95ee\u7b54\u5de5\u5177\u9700\u8981\u5f3a\u5927\u7684\u6821\u51c6\u4ee5\u907f\u514d\u8fc7\u5ea6\u81ea\u4fe1\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u589e\u52a0\u63a8\u7406\u9884\u7b97\u4f1a\u964d\u4f4e\u6821\u51c6\u7cbe\u5ea6\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u3002\u800c\u641c\u7d22\u589e\u5f3a\u751f\u6210\u5219\u663e\u8457\u4f18\u4e8e\u7eaf\u63a8\u7406\uff0c\u51c6\u786e\u7387\u8fbe\u523089.3%\u3002"}}
{"id": "2508.15053", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15053", "abs": "https://arxiv.org/abs/2508.15053", "authors": ["Itai Zilberstein", "Alberto Candela", "Steve Chien", "David Rijlaarsdam", "Tom Hendrix", "Leonie Buckley", "Aubrey Dunne"], "title": "Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning", "comment": "International Symposium on Artificial Intelligence, Robotics and\n  Automation in Space, November 2024", "summary": "In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is\ndemonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).\nCS-6 is a satellite with a visible and near infrared range hyperspectral\ninstrument and neural network acceleration hardware. Performing data analysis\nat the edge (e.g. onboard) can enable new Earth science measurements and\nresponses. We will demonstrate data analysis and inference onboard CS-6 for\nnumerous applications using deep learning and spectral analysis algorithms.", "AI": {"tldr": "CS-6\u536b\u661f\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u548c\u5149\u8c31\u5206\u6790\u7b97\u6cd5\u8fdb\u884c\u661f\u8f7d\u6570\u636e\u5206\u6790\uff0c\u5b9e\u73b0\u65b0\u7684\u5730\u7403\u79d1\u5b66\u6d4b\u91cf\u548c\u54cd\u5e94\u3002", "motivation": "\u661f\u8f7d\u6570\u636e\u5206\u6790\u53ef\u4ee5\u5b9e\u73b0\u65b0\u7684\u5730\u7403\u79d1\u5b66\u6d4b\u91cf\u548c\u54cd\u5e94\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u548c\u5149\u8c31\u5206\u6790\u7b97\u6cd5\u8fdb\u884c\u661f\u8f7d\u6570\u636e\u5206\u6790\u548c\u63a8\u7406\u3002", "result": "\u6f14\u793a\u4e86CS-6\u4e0a\u9488\u5bf9\u591a\u79cd\u5e94\u7528\u7684\u661f\u8f7d\u6570\u636e\u5206\u6790\u548c\u63a8\u7406\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86CogniSAT-6/HAMMER (CS-6)\u536b\u661f\u4e0a\u8fdb\u884c\u6570\u636e\u5206\u6790\u7684\u6f14\u793a\uff0c\u8be5\u536b\u661f\u642d\u8f7d\u4e86\u9ad8\u5149\u8c31\u4eea\u5668\u548c\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u786c\u4ef6\u3002"}}
{"id": "2508.15068", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15068", "abs": "https://arxiv.org/abs/2508.15068", "authors": ["Shuang Ao", "Gopal Rumchurn"], "title": "S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner", "comment": "9 pages, 2 figures", "summary": "Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning\n(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based\nagents. However, these adaptations can unintentionally compromise safety\nalignment, leading to unsafe or unstable behaviors, particularly in agent\nplanning tasks. Existing safety-aware adaptation methods often require access\nto both base and instruction-tuned model checkpoints, which are frequently\nunavailable in practice, limiting their applicability. We propose S3LoRA (Safe\nSpectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and\nmodel-independent framework that mitigates safety risks in LoRA-adapted models\nby inspecting only the fine-tuned weight updates. We first introduce\nMagnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes\nthe structural properties of LoRA updates while preserving global magnitude\ninformation. We then design the Spectral Sharpness Index (SSI), a\nsharpness-aware metric to detect layers with highly concentrated and\npotentially unsafe updates. These layers are pruned post-hoc to reduce risk\nwithout sacrificing task performance. Extensive experiments and ablation\nstudies across agent planning and language generation tasks show that S3LoRA\nconsistently improves safety metrics while maintaining or improving utility\nmetrics and significantly reducing inference cost. These results establish\nS3LoRA as a practical and scalable solution for safely deploying LLM-based\nagents in real-world, resource-constrained, and safety-critical environments.", "AI": {"tldr": "S3LoRA \u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u6570\u636e\u65e0\u5173\u3001\u6a21\u578b\u65e0\u5173\u7684\u5b89\u5168\u6846\u67b6\uff0c\u7528\u4e8e\u51cf\u8f7b LoRA \u81ea\u9002\u5e94\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u98ce\u9669\uff0c\u65e0\u9700\u8bbf\u95ee\u57fa\u7840\u6a21\u578b\u68c0\u67e5\u70b9\u3002", "motivation": "\u73b0\u6709\u7684\u5b89\u5168\u611f\u77e5\u81ea\u9002\u5e94\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u8bbf\u95ee\u57fa\u7840\u6a21\u578b\u548c\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u68c0\u67e5\u70b9\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u5f80\u5f80\u4e0d\u53ef\u7528\uff0c\u9650\u5236\u4e86\u5176\u9002\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u65e0\u6570\u636e\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6 S3LoRA\uff0c\u8be5\u6846\u67b6\u4f7f\u7528 Magnitude-Aware Spherically Normalized SVD (MAS-SVD) \u548c Spectral Sharpness Index (SSI) \u6765\u68c0\u6d4b\u548c\u526a\u679d\u9ad8\u98ce\u9669\u5c42\u3002", "result": "\u5927\u91cf\u7684\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0cS3LoRA \u5728\u4ee3\u7406\u89c4\u5212\u548c\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u4e2d\u59cb\u7ec8\u63d0\u9ad8\u5b89\u5168\u6307\u6807\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u6548\u7528\u6307\u6807\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "conclusion": "S3LoRA \u6846\u67b6\u901a\u8fc7\u68c0\u67e5\u5fae\u8c03\u6743\u91cd\u66f4\u65b0\uff0c\u65e0\u9700\u8bbf\u95ee\u57fa\u7840\u6a21\u578b\u548c\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u68c0\u67e5\u70b9\uff0c\u5373\u53ef\u51cf\u8f7b LoRA \u81ea\u9002\u5e94\u6a21\u578b\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u6548\u7528\u6307\u6807\u7684\u540c\u65f6\uff0c\u6301\u7eed\u63d0\u9ad8\u5b89\u5168\u6307\u6807\u5e76\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002"}}
{"id": "2508.15118", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15118", "abs": "https://arxiv.org/abs/2508.15118", "authors": ["Jennifer Leigh", "Dimitrios Letsios", "Alessandro Mella", "Lucio Machetti", "Francesca Toni"], "title": "Argumentation for Explainable Workforce Optimisation (with Appendix)", "comment": "Accepted to PAIS 2025", "summary": "Workforce management is a complex problem optimising the makespan and travel\ndistance required for a team of operators to complete a set of jobs, using a\nset of instruments. A crucial challenge in workforce management is\naccommodating changes at execution time so that explanations are provided to\nall stakeholders involved. Here, we show that, by understanding workforce\nmanagement as abstract argumentation in an industrial application, we can\naccommodate change and obtain faithful explanations. We show, with a user\nstudy, that our tool and explanations lead to faster and more accurate problem\nsolving than conventional solutions by hand.", "AI": {"tldr": "\u4f7f\u7528\u62bd\u8c61\u8bba\u8bc1\u65b9\u6cd5\u6539\u8fdb\u52b3\u52a8\u529b\u7ba1\u7406\uff0c\u5b9e\u73b0\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u7684\u95ee\u9898\u89e3\u51b3\u3002", "motivation": "\u89e3\u51b3\u52b3\u52a8\u529b\u7ba1\u7406\u4e2d\u9002\u5e94\u6267\u884c\u65f6\u53d8\u5316\u5e76\u63d0\u4f9b\u89e3\u91ca\u7684\u6311\u6218\u3002", "method": "\u5c06\u52b3\u52a8\u529b\u7ba1\u7406\u95ee\u9898\u5efa\u6a21\u4e3a\u62bd\u8c61\u8bba\u8bc1\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u76f8\u5e94\u7684\u5de5\u5177\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8be5\u5de5\u5177\u548c\u89e3\u91ca\u6bd4\u4f20\u7edf\u624b\u5de5\u89e3\u51b3\u65b9\u6848\u80fd\u591f\u66f4\u5feb\u66f4\u51c6\u786e\u5730\u89e3\u51b3\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5c06\u52b3\u52a8\u529b\u7ba1\u7406\u7406\u89e3\u4e3a\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u62bd\u8c61\u8bba\u8bc1\uff0c\u80fd\u591f\u9002\u5e94\u53d8\u5316\u5e76\u83b7\u5f97\u53ef\u9760\u7684\u89e3\u91ca\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8be5\u5de5\u5177\u548c\u89e3\u91ca\u6bd4\u4f20\u7edf\u624b\u5de5\u89e3\u51b3\u65b9\u6848\u80fd\u591f\u66f4\u5feb\u66f4\u51c6\u786e\u5730\u89e3\u51b3\u95ee\u9898\u3002"}}
{"id": "2508.15119", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15119", "abs": "https://arxiv.org/abs/2508.15119", "authors": ["Rachel Ma", "Jingyi Qu", "Andreea Bobu", "Dylan Hadfield-Menell"], "title": "Open-Universe Assistance Games", "comment": "7 pages + 2 pages references + 7 pages appendix", "summary": "Embodied AI agents must infer and act in an interpretable way on diverse\nhuman goals and preferences that are not predefined. To formalize this setting,\nwe introduce Open-Universe Assistance Games (OU-AGs), a framework where the\nagent must reason over an unbounded and evolving space of possible goals. In\nthis context, we introduce GOOD (GOals from Open-ended Dialogue), a\ndata-efficient, online method that extracts goals in the form of natural\nlanguage during an interaction with a human, and infers a distribution over\nnatural language goals. GOOD prompts an LLM to simulate users with different\ncomplex intents, using its responses to perform probabilistic inference over\ncandidate goals. This approach enables rich goal representations and\nuncertainty estimation without requiring large offline datasets. We evaluate\nGOOD in a text-based grocery shopping domain and in a text-operated simulated\nhousehold robotics environment (AI2Thor), using synthetic user profiles. Our\nmethod outperforms a baseline without explicit goal tracking, as confirmed by\nboth LLM-based and human evaluations.", "AI": {"tldr": "\u63d0\u51faGOOD\u65b9\u6cd5\uff0c\u5229\u7528LLM\u9ad8\u6548\u5730\u4ece\u5f00\u653e\u5bf9\u8bdd\u4e2d\u63d0\u53d6\u7528\u6237\u76ee\u6807\uff0c\u5e76\u5728\u6a21\u62df\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u5177\u8eabAI\u4ee3\u7406\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7406\u89e3\u548c\u6267\u884c\u4eba\u7c7b\u672a\u9884\u5b9a\u4e49\u76ee\u6807\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGOOD\u7684\u6570\u636e\u9ad8\u6548\u5728\u7ebf\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528LLM\u6a21\u62df\u4e0d\u540c\u590d\u6742\u610f\u56fe\u7684\u7528\u6237\uff0c\u901a\u8fc7\u5176\u53cd\u9988\u5bf9\u5019\u9009\u76ee\u6807\u8fdb\u884c\u6982\u7387\u63a8\u7406\uff0c\u4ece\u800c\u63d0\u53d6\u81ea\u7136\u8bed\u8a00\u5f62\u5f0f\u7684\u76ee\u6807\u3002", "result": "GOOD\u65b9\u6cd5\u5728\u6587\u672c\u8d2d\u7269\u548cAI2Thor\u6a21\u62df\u73af\u5883\u4e2d\u4f18\u4e8e\u65e0\u663e\u5f0f\u76ee\u6807\u8ffd\u8e2a\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GOOD\u65b9\u6cd5\u5728\u6587\u672c\u8d2d\u7269\u548cAI2Thor\u6a21\u62df\u73af\u5883\u4e2d\u4f18\u4e8e\u65e0\u663e\u5f0f\u76ee\u6807\u8ffd\u8e2a\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7531LLM\u548c\u4eba\u5de5\u8bc4\u4f30\u8bc1\u5b9e\u3002"}}
{"id": "2508.15126", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15126", "abs": "https://arxiv.org/abs/2508.15126", "authors": ["Pengsong Zhang", "Xiang Hu", "Guowei Huang", "Yang Qi", "Heng Zhang", "Xiuxu Li", "Jiaxing Song", "Jiabin Luo", "Yijiang Li", "Shuo Yin", "Chengxiao Dai", "Eric Hanchen Jiang", "Xiaoyan Zhou", "Zhenfei Yin", "Boqin Yuan", "Jing Dong", "Guinan Su", "Guanren Qiao", "Haiming Tang", "Anghong Du", "Lili Pan", "Zhenzhong Lan", "Xinyu Liu"], "title": "aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists", "comment": "Preprint under review. Code is available at\n  https://github.com/aixiv-org. Website is available at\n  https://forms.gle/DxQgCtXFsJ4paMtn8", "summary": "Recent advances in large language models (LLMs) have enabled AI agents to\nautonomously generate scientific proposals, conduct experiments, author papers,\nand perform peer reviews. Yet this flood of AI-generated research content\ncollides with a fragmented and largely closed publication ecosystem.\nTraditional journals and conferences rely on human peer review, making them\ndifficult to scale and often reluctant to accept AI-generated research content;\nexisting preprint servers (e.g. arXiv) lack rigorous quality-control\nmechanisms. Consequently, a significant amount of high-quality AI-generated\nresearch lacks appropriate venues for dissemination, hindering its potential to\nadvance scientific progress. To address these challenges, we introduce aiXiv, a\nnext-generation open-access platform for human and AI scientists. Its\nmulti-agent architecture allows research proposals and papers to be submitted,\nreviewed, and iteratively refined by both human and AI scientists. It also\nprovides API and MCP interfaces that enable seamless integration of\nheterogeneous human and AI scientists, creating a scalable and extensible\necosystem for autonomous scientific discovery. Through extensive experiments,\nwe demonstrate that aiXiv is a reliable and robust platform that significantly\nenhances the quality of AI-generated research proposals and papers after\niterative revising and reviewing on aiXiv. Our work lays the groundwork for a\nnext-generation open-access ecosystem for AI scientists, accelerating the\npublication and dissemination of high-quality AI-generated research content.\nCode is available at https://github.com/aixiv-org. Website is available at\nhttps://forms.gle/DxQgCtXFsJ4paMtn8.", "AI": {"tldr": "aiXiv\u5e73\u53f0\u65e8\u5728\u89e3\u51b3AI\u751f\u6210\u7814\u7a76\u5185\u5bb9\u53d1\u8868\u96be\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u548cAPI/MCP\u63a5\u53e3\uff0c\u5b9e\u73b0\u4eba\u7c7b\u548cAI\u79d1\u5b66\u5bb6\u7684\u534f\u540c\uff0c\u63d0\u9ad8AI\u7814\u7a76\u6210\u679c\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u51fa\u7248\u751f\u6001\u7cfb\u7edf\u96be\u4ee5\u5e94\u5bf9AI\u751f\u6210\u7684\u6d77\u91cf\u7814\u7a76\u5185\u5bb9\uff0c\u4f20\u7edf\u7684\u671f\u520a\u548c\u4f1a\u8bae\u4f9d\u8d56\u4eba\u5de5\u540c\u884c\u8bc4\u5ba1\uff0c\u96be\u4ee5\u6269\u5c55\uff0c\u5e76\u4e14\u5e38\u5e38\u4e0d\u613f\u63a5\u53d7AI\u751f\u6210\u7684\u7814\u7a76\u5185\u5bb9\uff1b\u73b0\u6709\u7684\u9884\u5370\u672c\u670d\u52a1\u5668\u7f3a\u4e4f\u4e25\u683c\u7684\u8d28\u91cf\u63a7\u5236\u673a\u5236\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aaiXiv\u7684\u5f00\u653e\u83b7\u53d6\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5141\u8bb8\u4eba\u7c7b\u548cAI\u79d1\u5b66\u5bb6\u63d0\u4ea4\u3001\u8bc4\u5ba1\u548c\u8fed\u4ee3\u6539\u8fdb\u7814\u7a76\u63d0\u6848\u548c\u8bba\u6587\uff0c\u5e76\u63d0\u4f9bAPI\u548cMCP\u63a5\u53e3\u4ee5\u5b9e\u73b0\u5f02\u6784\u4eba\u7c7b\u548cAI\u79d1\u5b66\u5bb6\u7684\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0caiXiv\u662f\u4e00\u4e2a\u53ef\u9760\u4e14\u5f3a\u5927\u7684\u5e73\u53f0\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8AI\u751f\u6210\u7814\u7a76\u63d0\u6848\u548c\u8bba\u6587\u7684\u8d28\u91cf\u3002", "conclusion": "aiXiv\u5e73\u53f0\u80fd\u591f\u663e\u8457\u63d0\u9ad8AI\u751f\u6210\u7814\u7a76\u63d0\u6848\u548c\u8bba\u6587\u7684\u8d28\u91cf\uff0c\u4e3aAI\u79d1\u5b66\u5bb6\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u4e00\u4ee3\u5f00\u653e\u83b7\u53d6\u751f\u6001\u7cfb\u7edf\uff0c\u52a0\u901f\u9ad8\u8d28\u91cfAI\u751f\u6210\u7814\u7a76\u5185\u5bb9\u7684\u53d1\u8868\u548c\u4f20\u64ad\u3002"}}
{"id": "2508.15144", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15144", "abs": "https://arxiv.org/abs/2508.15144", "authors": ["Jiabo Ye", "Xi Zhang", "Haiyang Xu", "Haowei Liu", "Junyang Wang", "Zhaoqing Zhu", "Ziwei Zheng", "Feiyu Gao", "Junjie Cao", "Zhengxi Lu", "Jitong Liao", "Qi Zheng", "Fei Huang", "Jingren Zhou", "Ming Yan"], "title": "Mobile-Agent-v3: Foundamental Agents for GUI Automation", "comment": null, "summary": "This paper introduces GUI-Owl, a foundational GUI agent model that achieves\nstate-of-the-art performance among open-source end-to-end models on ten GUI\nbenchmarks across desktop and mobile environments, covering grounding, question\nanswering, planning, decision-making, and procedural knowledge. GUI-Owl-7B\nachieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose\nMobile-Agent-v3, a general-purpose GUI agent framework that further improves\nperformance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new\nstate-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates\nthree key innovations: (1) Large-scale Environment Infrastructure: a\ncloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,\nenabling our Self-Evolving GUI Trajectory Production framework. This generates\nhigh-quality interaction data via automated query generation and correctness\nvalidation, leveraging GUI-Owl to refine trajectories iteratively, forming a\nself-improving loop. It supports diverse data pipelines and reduces manual\nannotation. (2) Diverse Foundational Agent Capabilities: by integrating UI\ngrounding, planning, action semantics, and reasoning patterns, GUI-Owl supports\nend-to-end decision-making and can act as a modular component in multi-agent\nsystems. (3) Scalable Environment RL: we develop a scalable reinforcement\nlearning framework with fully asynchronous training for real-world alignment.\nWe also introduce Trajectory-aware Relative Policy Optimization (TRPO) for\nonline RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are\nopen-sourced at https://github.com/X-PLUG/MobileAgent.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e24\u4e2a\u5f00\u6e90GUI\u4ee3\u7406\u6a21\u578bGUI-Owl\u548cMobile-Agent-v3\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5f00\u6e90\u7aef\u5230\u7aefGUI\u4ee3\u7406\u6a21\u578b\u6027\u80fd\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u9ad8\u6548\u3001\u66f4\u901a\u7528\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86GUI-Owl\u57fa\u7840GUI\u4ee3\u7406\u6a21\u578b\uff0c\u5e76\u6784\u5efa\u4e86Mobile-Agent-v3\u901a\u7528\u6846\u67b6\uff0c\u5305\u542b\u5927\u89c4\u6a21\u73af\u5883\u57fa\u7840\u8bbe\u65bd\u3001\u591a\u6837\u5316\u57fa\u7840\u4ee3\u7406\u80fd\u529b\u548c\u53ef\u6269\u5c55\u73af\u5883\u5f3a\u5316\u5b66\u4e60\u7b49\u521b\u65b0\u3002", "result": "GUI-Owl-7B \u5728AndroidWorld \u548c OSWorld \u4e0a\u5206\u522b\u53d6\u5f97\u4e8666.4 \u548c 29.4 \u7684\u6210\u7ee9\uff1bMobile-Agent-v3 \u5219\u5206\u522b\u53d6\u5f97\u4e8673.3 \u548c 37.7 \u7684\u6210\u7ee9\uff0c\u5237\u65b0\u4e86\u5f00\u6e90GUI\u4ee3\u7406\u6846\u67b6\u7684\u6700\u65b0\u6280\u672f\u6c34\u5e73\u3002", "conclusion": "GUI-Owl \u548c Mobile-Agent-v3 \u4e24\u4e2a\u6a21\u578b\u5728\u591a\u4e2aGUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5f00\u6e90\u53d1\u5e03\u3002"}}
{"id": "2508.15180", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.15180", "abs": "https://arxiv.org/abs/2508.15180", "authors": ["Kai Xiong", "Yanwei Huang", "Rongjunchen Zhang", "Kun Chen", "Haipang Wu"], "title": "PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data", "comment": null, "summary": "High-quality mathematical and logical datasets with verifiable answers are\nessential for strengthening the reasoning capabilities of large language models\n(LLMs). While recent data augmentation techniques have facilitated the creation\nof large-scale benchmarks, existing LLM-generated datasets often suffer from\nlimited reliability, diversity, and scalability. To address these challenges,\nwe introduce PuzzleClone, a formal framework for synthesizing verifiable data\nat scale using Satisfiability Modulo Theories (SMT). Our approach features\nthree key innovations: (1) encoding seed puzzles into structured logical\nspecifications, (2) generating scalable variants through systematic variable\nand constraint randomization, and (3) ensuring validity via a reproduction\nmechanism. Applying PuzzleClone, we construct a curated benchmark comprising\nover 83K diverse and programmatically validated puzzles. The generated puzzles\nspan a wide spectrum of difficulty and formats, posing significant challenges\nto current state-of-the-art models. We conduct post training (SFT and RL) on\nPuzzleClone datasets. Experimental results show that training on PuzzleClone\nyields substantial improvements not only on PuzzleClone testset but also on\nlogic and mathematical benchmarks. Post training raises PuzzleClone average\nfrom 14.4 to 56.2 and delivers consistent improvements across 7 logic and\nmathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from\n52.5 to 65.0). Our code and data are available at\nhttps://github.com/puzzleclone.", "AI": {"tldr": "\u4f7f\u7528SMT\u6280\u672f\u751f\u6210\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u5b66\u903b\u8f91\u6570\u636e\u96c6PuzzleClone\uff0c\u6709\u6548\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709LLM\u751f\u6210\u7684\u6570\u636e\u96c6\u53ef\u9760\u6027\u3001\u591a\u6837\u6027\u548c\u53ef\u6269\u5c55\u6027\u6709\u9650\uff0c\u9700\u8981\u66f4\u9ad8\u8d28\u91cf\u3001\u53ef\u9a8c\u8bc1\u7684\u6570\u636e\u96c6\u6765\u589e\u5f3aLLM\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5229\u7528SMT\u6280\u672f\uff0c\u5c06\u79cd\u5b50\u8c1c\u9898\u7f16\u7801\u6210\u7ed3\u6784\u5316\u903b\u8f91\u89c4\u8303\uff0c\u901a\u8fc7\u7cfb\u7edf\u5730\u968f\u673a\u5316\u53d8\u91cf\u548c\u7ea6\u675f\u6765\u751f\u6210\u53ef\u6269\u5c55\u7684\u53d8\u4f53\uff0c\u5e76\u901a\u8fc7\u590d\u5236\u673a\u5236\u786e\u4fdd\u6709\u6548\u6027\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8d85\u8fc783,000\u4e2a\u591a\u6837\u5316\u4e14\u7ecf\u8fc7\u7f16\u7a0b\u9a8c\u8bc1\u7684\u8c1c\u9898\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u5728\u5fae\u8c03\u540e\uff0c\u5728PuzzleClone\u6d4b\u8bd5\u96c6\u548c7\u4e2a\u903b\u8f91\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff08\u4f8b\u5982\uff0cPuzzleClone\u5e73\u5747\u5206\u6570\u4ece14.4\u63d0\u5347\u523056.2\uff0cAMC2023\u4ece52.5\u63d0\u5347\u523065.0\uff09\u3002", "conclusion": "PuzzleClone\u6846\u67b6\u901a\u8fc7SMT\u6280\u672f\u5927\u89c4\u6a21\u5408\u6210\u53ef\u9a8c\u8bc1\u7684\u6570\u5b66\u903b\u8f91\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2508.15192", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15192", "abs": "https://arxiv.org/abs/2508.15192", "authors": ["Wenjie Lin", "Jin Wei-Kocsis"], "title": "LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support", "comment": null, "summary": "While large language models (LLMs) have shown promise in healthcare, their\napplication for rare medical conditions is still hindered by scarce and\nunreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing\nexcessive sweating beyond physiological needs, is one such rare disorder,\naffecting 2-3% of the population and significantly impacting both physical\ncomfort and psychosocial well-being. To date, no work has tailored LLMs to\nadvance the diagnosis or care of hyperhidrosis. To address this gap, we present\nLLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and\nempathetic hyperhidrosis support. The system follows a three-stage pipeline. In\nthe data augmentation stage, a frontier LLM generates medically plausible\nsynthetic vignettes from curated open-source data to create a diverse and\nbalanced question-answer dataset. In the fine-tuning stage, an open-source\nfoundation model is fine-tuned on the dataset to provide diagnosis,\npersonalized treatment recommendations, and empathetic psychological support.\nIn the inference and expert evaluation stage, clinical and psychological\nspecialists assess accuracy, appropriateness, and empathy, with validated\nresponses iteratively enriching the dataset. Experiments show that LLM4Sweat\noutperforms baselines and delivers the first open-source LLM framework for\nhyperhidrosis, offering a generalizable approach for other rare diseases with\nsimilar data and trustworthiness challenges.", "AI": {"tldr": "\u9488\u5bf9\u591a\u6c57\u75c7\u5f00\u53d1\u7684\u5f00\u6e90LLM\u6846\u67b6LLM4Sweat\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u4e13\u5bb6\u8bc4\u4f30\uff0c\u63d0\u4f9b\u8bca\u65ad\u3001\u6cbb\u7597\u5efa\u8bae\u548c\u5fc3\u7406\u652f\u6301\u3002", "motivation": "\u89e3\u51b3\u7f55\u89c1\u75c5\uff08\u591a\u6c57\u75c7\uff09\u6570\u636e\u7a00\u7f3a\u5bfc\u81f4LLM\u96be\u4ee5\u5e94\u7528\u7684\u95ee\u9898\u3002", "method": "\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a\u6570\u636e\u589e\u5f3a\u3001\u5fae\u8c03\u548c\u63a8\u7406\u4e0e\u4e13\u5bb6\u8bc4\u4f30\u3002\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u533b\u5b66\u4e0a\u5408\u7406\u7684\u5408\u6210\u6570\u636e\uff0c\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u4ee5\u63d0\u4f9b\u8bca\u65ad\u3001\u4e2a\u6027\u5316\u6cbb\u7597\u5efa\u8bae\u548c\u5fc3\u7406\u652f\u6301\uff0c\u5e76\u7531\u4e34\u5e8a\u548c\u5fc3\u7406\u4e13\u5bb6\u8bc4\u4f30\u51c6\u786e\u6027\u3001\u9002\u5f53\u6027\u548c\u540c\u7406\u5fc3\u3002", "result": "\u6784\u5efa\u4e86LLM4Sweat\u6846\u67b6\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u5176\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "LLM4Sweat\uff0c\u4e00\u4e2a\u5f00\u6e90\u7684\u9488\u5bf9\u591a\u6c57\u75c7\u7684LLM\u6846\u67b6\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u7f55\u89c1\u75be\u75c5\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.15204", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15204", "abs": "https://arxiv.org/abs/2508.15204", "authors": ["Raj Jain", "Marc Wetter"], "title": "R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling", "comment": null, "summary": "Effective scheduling under tight resource, timing, and operational\nconstraints underpins large-scale planning across sectors such as capital\nprojects, manufacturing, logistics, and IT fleet transitions. However, the\nreliability of large language models (LLMs) when reasoning under\nhigh-constraint regimes is insufficiently characterized. To address this gap,\nwe present R-ConstraintBench, a scalable framework that evaluates models on\nResource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete\nfeasibility class, while difficulty increases via linear growth in constraints.\nR-ConstraintBench incrementally increases non-redundant precedence constraints\nin Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal\nwindows, and disjunctive constraints. As an illustrative example, we\ninstantiate the benchmark in a data center migration setting and evaluate\nmultiple LLMs using feasibility and error analysis, identifying degradation\nthresholds and constraint types most associated with failure. Empirically,\nstrong models are near-ceiling on precedence-only DAGs, but feasibility\nperformance collapses when downtime, temporal windows, and disjunctive\nconstraints interact, implicating constraint interaction, not graph depth, as\nthe principal bottleneck. Performance on clean synthetic ramps also does not\nguarantee transfer to domain-grounded scenarios, underscoring limited\ngeneralization.", "AI": {"tldr": "R-ConstraintBench\u6846\u67b6\u8bc4\u4f30\u4e86LLM\u5728\u8d44\u6e90\u53d7\u9650\u9879\u76ee\u8c03\u5ea6\u95ee\u9898\u4e0a\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u7ea6\u675f\u4ea4\u4e92\u662f\u6027\u80fd\u74f6\u9888\uff0c\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u7ea6\u675f\u73af\u5883\u4e0b\u7684\u53ef\u9760\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "method": "\u63d0\u51faR-ConstraintBench\u6846\u67b6\uff0c\u901a\u8fc7\u9010\u6b65\u589e\u52a0\u5148\u5e8f\u7ea6\u675f\u3001\u505c\u673a\u65f6\u95f4\u3001\u65f6\u95f4\u7a97\u548c\u4e92\u65a5\u7ea6\u675f\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u9879\u76ee\u8c03\u5ea6\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u4ec5\u5305\u542b\u5148\u5e8f\u7ea6\u675f\u7684DAG\u4e0a\uff0c\u5f3a\u6a21\u578b\u7684\u6027\u80fd\u63a5\u8fd1\u4e0a\u9650\uff0c\u4f46\u5728\u5f15\u5165\u505c\u673a\u65f6\u95f4\u3001\u65f6\u95f4\u7a97\u548c\u4e92\u65a5\u7ea6\u675f\u540e\uff0c\u53ef\u884c\u6027\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff1b\u7ea6\u675f\u6761\u4ef6\u7684\u4ea4\u4e92\u4f5c\u7528\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u7ea6\u675f\u73af\u5883\u4e0b\u7684\u53ef\u9760\u6027\u4e0d\u8db3\uff0cR-ConstraintBench\u6846\u67b6\u901a\u8fc7\u9010\u6b65\u589e\u52a0\u7ea6\u675f\u6761\u4ef6\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u9879\u76ee\u8c03\u5ea6\u95ee\u9898\u4e0a\u7684\u6027\u80fd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u7ea6\u675f\u6761\u4ef6\u7684\u4ea4\u4e92\u4f5c\u7528\u800c\u975e\u56fe\u7684\u6df1\u5ea6\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u4e14\u5728\u5e72\u51c0\u7684\u5408\u6210\u73af\u5883\u4e2d\u7684\u826f\u597d\u6027\u80fd\u4e0d\u80fd\u4fdd\u8bc1\u8fc1\u79fb\u5230\u5b9e\u9645\u573a\u666f\u3002"}}
{"id": "2508.15222", "categories": ["cs.AI", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.15222", "abs": "https://arxiv.org/abs/2508.15222", "authors": ["Hantao Zhang", "Jingyang Liu", "Ed Li"], "title": "See it. Say it. Sorted: Agentic System for Compositional Diagram Generation", "comment": null, "summary": "We study sketch-to-diagram generation: converting rough hand sketches into\nprecise, compositional diagrams. Diffusion models excel at photorealism but\nstruggle with the spatial precision, alignment, and symbolic structure required\nfor flowcharts. We introduce See it. Say it. Sorted., a training-free agentic\nsystem that couples a Vision-Language Model (VLM) with Large Language Models\n(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system\nruns an iterative loop in which a Critic VLM proposes a small set of\nqualitative, relational edits; multiple candidate LLMs synthesize SVG updates\nwith diverse strategies (conservative->aggressive, alternative, focused); and a\nJudge VLM selects the best candidate, ensuring stable improvement. This design\nprioritizes qualitative reasoning over brittle numerical estimates, preserves\nglobal constraints (e.g., alignment, connectivity), and naturally supports\nhuman-in-the-loop corrections. On 10 sketches derived from flowcharts in\npublished papers, our method more faithfully reconstructs layout and structure\nthan two frontier closed-source image generation LLMs (GPT-5 and\nGemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)\nwithout inserting unwanted text. Because outputs are programmatic SVGs, the\napproach is readily extensible to presentation tools (e.g., PowerPoint) via\nAPIs and can be specialized with improved prompts and task-specific tools. The\ncodebase is open-sourced at\nhttps://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.", "AI": {"tldr": "\u65e0\u9700\u8bad\u7ec3\u7684\u4ee3\u7406\u7cfb\u7edfSee it. Say it. Sorted.\u5229\u7528VLM\u548cLLM\u5c06\u8349\u56fe\u8f6c\u6362\u4e3a\u7cbe\u786e\u7684SVG\u56fe\u8868\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u6a21\u578b\u96be\u4ee5\u80dc\u4efb\u9700\u8981\u7a7a\u95f4\u7cbe\u5ea6\u3001\u5bf9\u9f50\u548c\u7b26\u53f7\u7ed3\u6784\u7684\u56fe\u8868\u751f\u6210\u4efb\u52a1\u3002", "method": "\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u8fed\u4ee3\u5730\u8fdb\u884c\u7f16\u8f91\uff0cCritic VLM\u63d0\u51fa\u4fee\u6539\u5efa\u8bae\uff0c\u591a\u4e2aLLM\u751f\u6210SVG\u66f4\u65b0\uff0cJudge VLM\u9009\u62e9\u6700\u4f73\u65b9\u6848\u3002", "result": "\u572810\u4e2a\u8349\u56fe\u4e0a\uff0cSee it. Say it. Sorted.\u6bd4GPT-5\u548cGemini-2.5-Pro\u66f4\u51c6\u786e\u5730\u91cd\u5efa\u4e86\u5e03\u5c40\u548c\u7ed3\u6784\uff0c\u80fd\u591f\u51c6\u786e\u5730\u7ec4\u5408\u57fa\u672c\u56fe\u5f62\uff0c\u5e76\u4e14\u8f93\u51fa\u4e3a\u53ef\u7f16\u8f91\u7684SVG\u7a0b\u5e8f\uff0c\u6613\u4e8e\u6269\u5c55\u5230\u6f14\u793a\u5de5\u5177\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u4ee3\u7406\u7cfb\u7edfSee it. Say it. Sorted.\uff0c\u7528\u4e8e\u5c06\u8349\u56fe\u8f6c\u6362\u4e3a\u7cbe\u786e\u7684\u56fe\u8868\uff0c\u8be5\u7cfb\u7edf\u7ed3\u5408\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u751f\u6210\u53ef\u7f16\u8f91\u7684SVG\u7a0b\u5e8f\uff0c\u5e76\u4f18\u4e8eGPT-5\u548cGemini-2.5-Pro\u7b49\u95ed\u6e90\u6a21\u578b\u3002"}}
{"id": "2508.15240", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15240", "abs": "https://arxiv.org/abs/2508.15240", "authors": ["Sabab Aosaf", "Muhammad Ali Nayeem", "Afsana Haque", "M Sohel Rahmana"], "title": "Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas", "comment": null, "summary": "Urban land-use allocation represents a complex multi-objective optimization\nproblem critical for sustainable urban development policy. This paper presents\nnovel computational intelligence approaches for optimizing land-use allocation\nin mixed-use areas, addressing inherent trade-offs between land-use\ncompatibility and economic objectives. We develop multiple optimization\nalgorithms, including custom variants integrating differential evolution with\nmulti-objective genetic algorithms. Key contributions include: (1) CR+DES\nalgorithm leveraging scaled difference vectors for enhanced exploration, (2)\nsystematic constraint relaxation strategy improving solution quality while\nmaintaining feasibility, and (3) statistical validation using Kruskal-Wallis\ntests with compact letter displays. Applied to a real-world case study with\n1,290 plots, CR+DES achieves 3.16\\% improvement in land-use compatibility\ncompared to state-of-the-art methods, while MSBX+MO excels in price\noptimization with 3.3\\% improvement. Statistical analysis confirms algorithms\nincorporating difference vectors significantly outperform traditional\napproaches across multiple metrics. The constraint relaxation technique enables\nbroader solution space exploration while maintaining practical constraints.\nThese findings provide urban planners and policymakers with evidence-based\ncomputational tools for balancing competing objectives in land-use allocation,\nsupporting more effective urban development policies in rapidly urbanizing\nregions.", "AI": {"tldr": "\u6539\u8fdb\u7684\u8ba1\u7b97\u667a\u80fd\u7b97\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u57ce\u5e02\u571f\u5730\u4f7f\u7528\u5206\u914d\u7684\u4f18\u5316\u6548\u679c\uff0c\u4e3a\u57ce\u5e02\u89c4\u5212\u63d0\u4f9b\u6570\u636e\u652f\u6301\u3002", "motivation": "\u89e3\u51b3\u57ce\u5e02\u571f\u5730\u4f7f\u7528\u5206\u914d\u7684\u590d\u6742\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u5e73\u8861\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u548c\u7ecf\u6d4e\u76ee\u6807\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u63d0\u51fa\u5e76\u6539\u8fdb\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5(CR+DES)\u548c\u591a\u76ee\u6807\u9057\u4f20\u7b97\u6cd5(MSBX+MO)\uff0c\u7ed3\u5408\u7ea6\u675f\u677e\u5f1b\u7b56\u7565\u548c\u7edf\u8ba1\u68c0\u9a8c\u3002", "result": "CR+DES\u7b97\u6cd5\u5728\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u65b9\u9762\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e863.16%\uff0cMSBX+MO\u7b97\u6cd5\u5728\u4ef7\u683c\u4f18\u5316\u65b9\u9762\u63d0\u9ad8\u4e863.3%\u3002\u7edf\u8ba1\u5206\u6790\u8bc1\u5b9e\uff0c\u5f15\u5165\u5dee\u5206\u5411\u91cf\u7684\u7b97\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u6539\u8fdb\u7684\u5dee\u5206\u8fdb\u5316\u548c\u591a\u76ee\u6807\u9057\u4f20\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u6df7\u5408\u7528\u9014\u533a\u57df\u7684\u571f\u5730\u4f7f\u7528\u5206\u914d\uff0c\u5e76\u5728\u5b9e\u9645\u6848\u4f8b\u4e2d\u53d6\u5f97\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u7684\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u548c\u4ef7\u683c\u4f18\u5316\u6548\u679c\u3002"}}
