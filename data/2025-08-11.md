<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization](https://arxiv.org/abs/2508.05731)
*Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu*

Main category: cs.AI

TL;DR: 针对多模态大型语言模型在GUI自主代理中的语义对齐问题，提出AEPO框架，显著提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法难以有效解决多模态大型语言模型在图形用户界面自主代理中的语义对齐问题，探索效率低下限制了模型学习复杂的语义关联。

Method: 提出了一种新的策略优化框架AEPO，该框架采用多答案生成策略以增强探索，并使用基于效率原理的适应性探索奖励函数引导探索。

Result: AEPO训练的模型InfiGUI-G1-3B和InfiGUI-G1-7B在多个GUI grounding基准测试中取得了最先进的结果，相较于RLVR基线，相对提升高达9.0%。

Conclusion: AEPO，一个新的策略优化框架，通过多答案生成策略和基于效率原理的适应性探索奖励函数，显著提高了多模态大型语言模型在图形用户界面自主代理中的语义对齐能力，并在多个基准测试中取得了最先进的结果。

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has propelled the
development of autonomous agents that operate on Graphical User Interfaces
(GUIs) using pure visual input. A fundamental challenge is robustly grounding
natural language instructions. This requires a precise spatial alignment, which
accurately locates the coordinates of each element, and, more critically, a
correct semantic alignment, which matches the instructions to the functionally
appropriate UI element. Although Reinforcement Learning with Verifiable Rewards
(RLVR) has proven to be effective at improving spatial alignment for these
MLLMs, we find that inefficient exploration bottlenecks semantic alignment,
which prevent models from learning difficult semantic associations. To address
this exploration problem, we present Adaptive Exploration Policy Optimization
(AEPO), a new policy optimization framework. AEPO employs a multi-answer
generation strategy to enforce broader exploration, which is then guided by a
theoretically grounded Adaptive Exploration Reward (AER) function derived from
first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B
and InfiGUI-G1-7B, establish new state-of-the-art results across multiple
challenging GUI grounding benchmarks, achieving significant relative
improvements of up to 9.0% against the naive RLVR baseline on benchmarks
designed to test generalization and semantic understanding. Resources are
available at https://github.com/InfiXAI/InfiGUI-G1.

</details>


### [2] [A Framework for Inherently Safer AGI through Language-Mediated Active Inference](https://arxiv.org/abs/2508.05766)
*Bo Wen*

Main category: cs.AI

TL;DR: 提出一种结合主动推理和LLM开发安全AGI的新框架，通过在系统核心设计中集成安全保证来克服传统方法的局限性，并提出在ARC基准上进行验证的实验。


<details>
  <summary>Details</summary>
Motivation: 传统人工智能安全方法（事后解释性和奖励工程）存在局限性，需要一种从系统核心设计中保证安全的方法。

Method: 结合主动推理原则和大型语言模型，构建多Agent系统，通过分层马尔可夫毯传递偏好和安全约束。

Result: 提出了一种基于自然语言表示和操作信念，具有透明信念表示和分层价值对齐的架构，并包含具体的安全机制（例如，信念和偏好的明确分离、资源感知的自由能最小化和模块化Agent结构）。

Conclusion: 提出了一种结合主动推理和大型语言模型开发安全人工智能的新框架，该框架通过将安全保证集成到系统核心设计中来解决传统方法的局限性。

Abstract: This paper proposes a novel framework for developing safe Artificial General
Intelligence (AGI) by combining Active Inference principles with Large Language
Models (LLMs). We argue that traditional approaches to AI safety, focused on
post-hoc interpretability and reward engineering, have fundamental limitations.
We present an architecture where safety guarantees are integrated into the
system's core design through transparent belief representations and
hierarchical value alignment. Our framework leverages natural language as a
medium for representing and manipulating beliefs, enabling direct human
oversight while maintaining computational tractability. The architecture
implements a multi-agent system where agents self-organize according to Active
Inference principles, with preferences and safety constraints flowing through
hierarchical Markov blankets. We outline specific mechanisms for ensuring
safety, including: (1) explicit separation of beliefs and preferences in
natural language, (2) bounded rationality through resource-aware free energy
minimization, and (3) compositional safety through modular agent structures.
The paper concludes with a research agenda centered on the Abstraction and
Reasoning Corpus (ARC) benchmark, proposing experiments to validate our
framework's safety properties. Our approach offers a path toward AGI
development that is inherently safer, rather than retrofitted with safety
measures.

</details>


### [3] [Whither symbols in the era of advanced neural networks?](https://arxiv.org/abs/2508.05776)
*Thomas L. Griffiths,Brenden M. Lake,R. Thomas McCoy,Ellie Pavlick,Taylor W. Webb*

Main category: cs.AI

TL;DR: 神经网络与人类思维的相似性，挑战了符号系统是人类思维基础的观点


<details>
  <summary>Details</summary>
Motivation: 挑战将人类思维视为符号系统的传统观点

Method: 对比分析人类认知能力和现代神经网络的能力

Result: 现代神经网络展现出与人类思维类似的组合思想、产生新颖性和快速学习的能力，这削弱了人类认知基于符号系统的论点。

Conclusion: 现代神经网络与人类认知过程的相似性挑战了人类思维基于符号系统的观点，但符号系统依然在刻画人类思维解决的抽象问题中扮演重要角色。

Abstract: Some of the strongest evidence that human minds should be thought about in
terms of symbolic systems has been the way they combine ideas, produce novelty,
and learn quickly. We argue that modern neural networks -- and the artificial
intelligence systems built upon them -- exhibit similar abilities. This
undermines the argument that the cognitive processes and representations used
by human minds are symbolic, although the fact that these neural networks are
typically trained on data generated by symbolic systems illustrates that such
systems play an important role in characterizing the abstract problems that
human minds have to solve. This argument leads us to offer a new agenda for
research on the symbolic basis of human thought.

</details>


### [4] [Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making](https://arxiv.org/abs/2508.05792)
*Kausik Lakkaraju,Siva Likitha Valluru,Biplav Srivastava*

Main category: cs.AI

TL;DR: H-XAI框架通过结合因果评级和事后解释，以回答利益相关者在个体决策层面和整体模型层面的特定问题，从而改进现有XAI方法。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法主要服务于开发者，关注模型输出的合理性，而非支持不同的利益相关者需求。

Method: 整合因果评级方法与传统XAI方法，支持交互式多方法解释过程。

Result: H-XAI框架能够支持利益相关者提出系列问题、检验假设，并将模型行为与自动构建的随机和偏差基线进行比较，结合实例级和全局解释，适应每个利益相关者的目标。

Conclusion: Holistic-XAI (H-XAI)框架整合因果评级方法和传统XAI方法，支持交互式多方法解释过程，以满足不同利益相关者的需求，弥补现有XAI方法的不足。

Abstract: Current eXplainable AI (XAI) methods largely serve developers, often focusing
on justifying model outputs rather than supporting diverse stakeholder needs. A
recent shift toward Evaluative AI reframes explanation as a tool for hypothesis
testing, but still focuses primarily on operational organizations. We introduce
Holistic-XAI (H-XAI), a unified framework that integrates causal rating methods
with traditional XAI methods to support explanation as an interactive,
multi-method process. H-XAI allows stakeholders to ask a series of questions,
test hypotheses, and compare model behavior against automatically constructed
random and biased baselines. It combines instance-level and global
explanations, adapting to each stakeholder's goals, whether understanding
individual decisions, assessing group-level bias, or evaluating robustness
under perturbations. We demonstrate the generality of our approach through two
case studies spanning six scenarios: binary credit risk classification and
financial time-series forecasting. H-XAI fills critical gaps left by existing
XAI methods by combining causal ratings and post-hoc explanations to answer
stakeholder-specific questions at both the individual decision level and the
overall model level.

</details>


### [5] [Safety of Embodied Navigation: A Survey](https://arxiv.org/abs/2508.05855)
*Zixia Wang,Jia Hu,Ronghui Mu*

Main category: cs.AI

TL;DR: 综述了具身导航安全性的挑战、缓解技术和评估方法，并指出了未来研究方向


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLM)的不断发展和影响力日益增强，具身AI的发展也随之加快，尤其是在导航场景中。然而，将具身导航集成到关键应用中会带来重大的安全问题。

Method: 对现有安全挑战、缓解技术以及评估有效性和鲁棒性的各种数据集和指标进行了综合考察。

Result: 对具身导航安全性的全面分析，指出了未来研究方向，以开发更安全可靠的具身导航系统。

Conclusion: 对具身导航安全性的全面分析，包括攻击策略、防御机制和评估方法，并探讨了未来研究方向，例如潜在的攻击方法、缓解策略、更可靠的评估技术和验证框架的实施。

Abstract: As large language models (LLMs) continue to advance and gain influence, the
development of embodied AI has accelerated, drawing significant attention,
particularly in navigation scenarios. Embodied navigation requires an agent to
perceive, interact with, and adapt to its environment while moving toward a
specified target in unfamiliar settings. However, the integration of embodied
navigation into critical applications raises substantial safety concerns. Given
their deployment in dynamic, real-world environments, ensuring the safety of
such systems is critical. This survey provides a comprehensive analysis of
safety in embodied navigation from multiple perspectives, encompassing attack
strategies, defense mechanisms, and evaluation methodologies. Beyond conducting
a comprehensive examination of existing safety challenges, mitigation
technologies, and various datasets and metrics that assess effectiveness and
robustness, we explore unresolved issues and future research directions in
embodied navigation safety. These include potential attack methods, mitigation
strategies, more reliable evaluation techniques, and the implementation of
verification frameworks. By addressing these critical gaps, this survey aims to
provide valuable insights that can guide future research toward the development
of safer and more reliable embodied navigation systems. Furthermore, the
findings of this study have broader implications for enhancing societal safety
and increasing industrial efficiency.

</details>


### [6] [Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning](https://arxiv.org/abs/2508.05888)
*Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber*

Main category: cs.AI

TL;DR: 基于知识图谱的工具检索框架提高了AI智能体在复杂用户查询中选择工具的准确性，尤其在多步骤任务中效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有的工具检索方法主要依赖于用户查询和工具描述之间的相似性，在处理多步骤用户请求时准确率有限。

Method: 提出了一种基于知识图谱的工具检索框架，利用1-hop ego工具图的集成来建模工具之间直接和间接的联系。

Result: 在合成数据集上，基于知识图谱的方法在Complete Recall指标上取得了91.85%的工具覆盖率，超过了其他基线方法。

Conclusion: 知识图谱(KG)方法在工具检索中优于传统的语义-词汇混合检索方法，尤其在多步骤任务中效果显著，实现了91.85%的工具覆盖率。

Abstract: Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.

</details>


### [7] [Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making](https://arxiv.org/abs/2508.05996)
*Kaitao Chen,Mianxin Liu,Daoming Zong,Chaoyue Ding,Shaohao Rui,Yankai Jiang,Mu Zhou,Xiaosong Wang*

Main category: cs.AI

TL;DR: MedOrch框架利用LLM中介多个VLM，提升医疗多模态决策性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注语言任务，将多Agent系统扩展到多模态场景具有挑战性，且VLM在指令遵循和自我反思方面能力不足。

Method: 提出了一种基于LLM中介代理的多Agent协作框架MedOrch，利用多个开源VLM，实现医疗多模态决策。

Result: 在五个医学视觉问答基准上验证了MedOrch的有效性，其协作性能优于任何单个Agent。

Conclusion: MedOrch框架通过LLM中介代理，实现多个VLM专家代理的协作，在医疗多模态决策中取得优于单个代理的性能，无需模型训练。

Abstract: Complex medical decision-making involves cooperative workflows operated by
different clinicians. Designing AI multi-agent systems can expedite and augment
human-level clinical decision-making. Existing multi-agent researches primarily
focus on language-only tasks, yet their extension to multimodal scenarios
remains challenging. A blind combination of diverse vision-language models
(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are
less capable in instruction following and importantly self-reflection, compared
to large language models (LLMs) of comparable sizes. This disparity largely
constrains VLMs' ability in cooperative workflows. In this study, we propose
MedOrch, a mediator-guided multi-agent collaboration framework for medical
multimodal decision-making. MedOrch employs an LLM-based mediator agent that
enables multiple VLM-based expert agents to exchange and reflect on their
outputs towards collaboration. We utilize multiple open-source general-purpose
and domain-specific VLMs instead of costly GPT-series models, revealing the
strength of heterogeneous models. We show that the collaboration within
distinct VLM-based agents can surpass the capabilities of any individual agent.
We validate our approach on five medical vision question answering benchmarks,
demonstrating superior collaboration performance without model training. Our
findings underscore the value of mediator-guided multi-agent collaboration in
advancing medical multimodal intelligence. Our code will be made publicly
available.

</details>


### [8] [Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning](https://arxiv.org/abs/2508.06042)
*Daechul Ahn,San Kim,Jonghyun Choi*

Main category: cs.AI

TL;DR: 分层多智能体框架HIMA通过结合专业模仿学习智能体和元级协调，提高了LLM在星际争霸II等复杂战略游戏中表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法难以应对星际争霸II等动态、长时序任务，因为需要管理资源限制并在部分可观察环境中适应不断变化的战场情况。

Method: 提出了一种分层多智能体框架HIMA，该框架使用元控制器战略规划器(SP)下的专业模仿学习智能体。每个专业智能体学习不同的策略（如空中支援或防御性策略），产生连贯的、结构化的多步动作序列。SP将这些方案协调成一个单一的、适应环境的计划。

Result: HIMA在战略清晰度、适应性和计算效率方面优于现有技术。

Conclusion: HIMA框架在策略清晰度、适应性和计算效率方面优于现有技术，证明将专业模仿模块与元级协调相结合可以开发出更强大、更通用的AI智能体。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive action
sequence prediction capabilities but often struggle with dynamic, long-horizon
tasks such as real-time strategic games. In a game such as StarCraftII (SC2),
agents need to manage resource constraints and adapt to evolving battlefield
situations in a partially observable environment. This often overwhelms
exisiting LLM-based approaches. To address these challenges, we propose a
hierarchical multi-agent framework that employs specialized imitation learning
agents under a meta-controller called Strategic Planner (SP). By expert
demonstrations, each specialized agent learns a distinctive strategy, such as
aerial support or defensive maneuvers, and produces coherent, structured
multistep action sequences. The SP then orchestrates these proposals into a
single, environmentally adaptive plan that ensures local decisions aligning
with long-term strategies. We call this HIMA (Hierarchical Imitation
Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that
encompasses all race match combinations in SC2. Our empirical results show that
HIMA outperforms state of the arts in strategic clarity, adaptability, and
computational efficiency, underscoring the potential of combining specialized
imitation modules with meta-level orchestration to develop more robust,
general-purpose AI agents.

</details>


### [9] [LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences](https://arxiv.org/abs/2508.06060)
*Sankarshan Damle,Boi Faltings*

Main category: cs.AI

TL;DR: 本论文提出一个基于参与式预算的框架，用于评估大型语言模型在资源分配任务中的推理能力，结果显示LLM具有潜力但提示设计很重要。


<details>
  <summary>Details</summary>
Motivation: 现有基准存在数据污染和静态性问题，难以评估LLM的推理能力，因此需要一个新的评估框架。

Method: 该框架利用参与式预算(PB)作为LLM资源分配的实际场景和自适应基准，并设计了三种提示策略：贪婪选择、直接优化和爬山式改进。

Result: 结果表明，提示设计至关重要，LLM在处理非结构化输入的机制设计方面具有潜力，能够从自然语言选民输入或元数据中推断结构化偏好。

Conclusion: 大型语言模型(LLM)在资源分配任务上的表现有待提高，该论文提出了一种基于参与式预算的双重框架，用于评估LLM的推理能力和进行资源分配。

Abstract: Large Language Models (LLMs) are increasingly expected to handle complex
decision-making tasks, yet their ability to perform structured resource
allocation remains underexplored. Evaluating their reasoning is also difficult
due to data contamination and the static nature of existing benchmarks. We
present a dual-purpose framework leveraging Participatory Budgeting (PB) both
as (i) a practical setting for LLM-based resource allocation and (ii) an
adaptive benchmark for evaluating their reasoning capabilities. We task LLMs
with selecting project subsets under feasibility (e.g., budget) constraints via
three prompting strategies: greedy selection, direct optimization, and a
hill-climbing-inspired refinement. We benchmark LLMs' allocations against a
utility-maximizing oracle. Interestingly, we also test whether LLMs can infer
structured preferences from natural-language voter input or metadata, without
explicit votes. By comparing allocations based on inferred preferences to those
from ground-truth votes, we evaluate LLMs' ability to extract preferences from
open-ended input. Our results underscore the role of prompt design and show
that LLMs hold promise for mechanism design with unstructured inputs.

</details>


### [10] [Don't Forget Imagination!](https://arxiv.org/abs/2508.06062)
*Evgenii E. Vityaev,Andrei Mantsivoda*

Main category: cs.AI

TL;DR: Cognitive imagination is key to advanced AI; semantic models offer a promising path to simulate it.


<details>
  <summary>Details</summary>
Motivation: Current AI systems underestimate the role of cognitive imagination, limiting their capabilities in reasoning and decision-making.  Humans use cognitive imagination for context retrieval and semantic verification during reasoning.

Method: Proposing semantic models as a tool to simulate cognitive imagination.

Result: Semantic models offer a potential breakthrough by ensuring consistency of imaginary contexts and enabling manipulation of the context as a holistic system.

Conclusion: Cognitive imagination is crucial for human thinking and AI advancement.  Semantic models, a new approach to mathematical models based on probabilistic causal relationships, are proposed to simulate cognitive imagination.

Abstract: Cognitive imagination is a type of imagination that plays a key role in human
thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to
mentally visualize coherent and holistic systems of concepts and causal links
that serve as semantic contexts for reasoning, decision making and prediction.
Our position is that the role of cognitive imagination is still greatly
underestimated, and this creates numerous problems and diminishes the current
capabilities of AI. For instance, when reasoning, humans rely on imaginary
contexts to retrieve background info. They also constantly return to the
context for semantic verification that their reasoning is still reasonable.
Thus, reasoning without imagination is blind. This paper is a call for greater
attention to cognitive imagination as the next promising breakthrough in
artificial intelligence. As an instrument for simulating cognitive imagination,
we propose semantic models -- a new approach to mathematical models that can
learn, like neural networks, and are based on probabilistic causal
relationships. Semantic models can simulate cognitive imagination because they
ensure the consistency of imaginary contexts and implement a glass-box approach
that allows the context to be manipulated as a holistic and coherent system of
interrelated facts glued together with causal relations.

</details>


### [11] [A Generic Complete Anytime Beam Search for Optimal Decision Tree](https://arxiv.org/abs/2508.06064)
*Harold Silvère Kiossou,Siegfried Nijssen,Pierre Schaus*

Main category: cs.AI

TL;DR: 提出一种新的精确和anytime决策树学习框架CA-DL8.5，实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有精确方法的anytime扩展（如LDS-DL8.5、Top-k-DL8.5和Blossom）缺乏系统的比较，难以评估其相对有效性。

Method: 提出了一种通用的、完整的、anytime的beam search算法CA-DL8.5，该算法扩展了DL8.5框架，并统一了一些现有的anytime策略。CA-DL8.5通过模块化设计，可以集成各种启发式算法和松弛机制。

Result: 实验证明，使用LDS的CA-DL8.5始终提供最佳的anytime性能，优于其他CA-DL8.5变体和Blossom算法。

Conclusion: CA-DL8.5算法在标准分类基准测试中始终提供最佳的 anytime 性能，优于其他CA-DL8.5变体和Blossom算法，同时保持完整性和最优性保证。

Abstract: Finding an optimal decision tree that minimizes classification error is known
to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic
programming guarantee optimality, they often suffer from poor anytime behavior
-- meaning they struggle to find high-quality decision trees quickly when the
search is stopped before completion -- due to unbalanced search space
exploration. To address this, several anytime extensions of exact methods have
been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not
been systematically compared, making it difficult to assess their relative
effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and
anytime beam search algorithm that extends the DL8.5 framework and unifies some
existing anytime strategies. In particular, CA-DL8.5 generalizes previous
approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various
heuristics and relaxation mechanisms through a modular design. The algorithm
reuses DL8.5's efficient branch-and-bound pruning and trie-based caching,
combined with a restart-based beam search that gradually relaxes pruning
criteria to improve solution quality over time. Our contributions are twofold:
(1) We introduce this new generic framework for exact and anytime decision tree
learning, enabling the incorporation of diverse heuristics and search
strategies; (2) We conduct a rigorous empirical comparison of several
instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k
heuristics -- using an anytime evaluation metric called the primal gap
integral. Experimental results on standard classification benchmarks show that
CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime
performance, outperforming both other CA-DL8.5 variants and the Blossom
algorithm while maintaining completeness and optimality guarantees.

</details>


### [12] [ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception](https://arxiv.org/abs/2508.06074)
*Siyi Lu,Run Liu,Dongsheng Yang,Lei He*

Main category: cs.AI

TL;DR: 一种新的基于深度强化学习的自动驾驶方法，结合鸟瞰图感知和端到端学习，在CARLA模拟器上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统模块化方法的误差传播和协调问题以及端到端学习方法的计算瓶颈问题。

Method: 该方法使用Mamba-BEV模型进行高效的时空特征提取，并结合ME³-BEV框架进行端到端深度强化学习，同时通过语义分割可视化高维特征以增强模型的可解释性。

Result: ME³-BEV模型在碰撞率和轨迹精度等多个指标上优于现有模型，为实时自动驾驶提供了一种有前景的解决方案。

Conclusion: 该论文提出了一种新的基于深度强化学习的自动驾驶方法，该方法集成了鸟瞰图（BEV）感知，提高了实时决策能力，并在CARLA模拟器上的实验结果表明其优于现有模型。

Abstract: Autonomous driving systems face significant challenges in perceiving complex
environments and making real-time decisions. Traditional modular approaches,
while offering interpretability, suffer from error propagation and coordination
issues, whereas end-to-end learning systems can simplify the design but face
computational bottlenecks. This paper presents a novel approach to autonomous
driving using deep reinforcement learning (DRL) that integrates bird's-eye view
(BEV) perception for enhanced real-time decision-making. We introduce the
\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction
network that combines BEV-based perception with the Mamba framework for
temporal feature modeling. This integration allows the system to encode vehicle
surroundings and road features in a unified coordinate system and accurately
model long-range dependencies. Building on this, we propose the
\texttt{ME$^3$-BEV} framework, which utilizes the \texttt{Mamba-BEV} model as a
feature input for end-to-end DRL, achieving superior performance in dynamic
urban driving scenarios. We further enhance the interpretability of the model
by visualizing high-dimensional features through semantic segmentation,
providing insight into the learned representations. Extensive experiments on
the CARLA simulator demonstrate that \texttt{ME$^3$-BEV} outperforms existing
models across multiple metrics, including collision rate and trajectory
accuracy, offering a promising solution for real-time autonomous driving.

</details>


### [13] [Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2](https://arxiv.org/abs/2508.06091)
*Stan P Hauke,Przemysław Andrzej Wałęga*

Main category: cs.AI

TL;DR: 解决了关于聚合-组合-读出GNN逻辑表达能力的开放性问题，证明其表达能力超过C2。


<details>
  <summary>Details</summary>
Motivation: 理解图神经网络 (GNN) 的表达能力，并将其与逻辑语言联系起来。

Method: 证明

Result: 证明了聚合-组合-读出 GNN 的逻辑表达能力严格超过 C2。

Conclusion: 证明了聚合-组合-读出 GNN 的逻辑表达能力严格超过 C2，解决了 Barceló 等人提出的开放性问题。该结果适用于无向图和有向图。

Abstract: In recent years, there has been growing interest in understanding the
expressive power of graph neural networks (GNNs) by relating them to logical
languages. This research has been been initialised by an influential result of
Barcel\'o et al. (2020), who showed that the graded modal logic (or a guarded
fragment of the logic C2), characterises the logical expressiveness of
aggregate-combine GNNs. As a ``challenging open problem'' they left the
question whether full C2 characterises the logical expressiveness of
aggregate-combine-readout GNNs. This question has remained unresolved despite
several attempts. In this paper, we solve the above open problem by proving
that the logical expressiveness of aggregate-combine-readout GNNs strictly
exceeds that of C2. This result holds over both undirected and directed graphs.
Beyond its implications for GNNs, our work also leads to purely logical
insights on the expressive power of infinitary logics.

</details>


### [14] [PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](https://arxiv.org/abs/2508.06110)
*Yiran Rex Ma*

Main category: cs.AI

TL;DR: PanelTR利用LLM模拟科学家进行结构化研究，在表格推理方面取得了显著成果，无需训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有的表格推理方法依赖于标注数据或复杂的数据增强，LLM的性能也逊色于简单的监督模型。

Method: 利用LLM agent scientists进行结构化科学研究，包括个体调查、自我审查和同行评审。

Result: PanelTR在四个基准测试中取得了优异的成绩，超越了普通LLM，与全监督模型性能相当，且无需训练数据。

Conclusion: PanelTR框架通过模拟科学家进行结构化研究，在四个基准测试中超越了普通LLM，与全监督模型不相上下，且无需训练数据。

Abstract: Table reasoning, including tabular QA and fact verification, often depends on
annotated data or complex data augmentation, limiting flexibility and
generalization. LLMs, despite their versatility, often underperform compared to
simple supervised models. To approach these issues, we introduce PanelTR, a
framework utilizing LLM agent scientists for robust table reasoning through a
structured scientific approach. PanelTR's workflow involves agent scientists
conducting individual investigations, engaging in self-review, and
participating in collaborative peer-review discussions. This process, driven by
five scientist personas, enables semantic-level transfer without relying on
data augmentation or parametric optimization. Experiments across four
benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully
supervised models, all while remaining independent of training data. Our
findings indicate that structured scientific methodology can effectively handle
complex tasks beyond table reasoning with flexible semantic understanding in a
zero-shot context.

</details>


### [15] [SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges](https://arxiv.org/abs/2508.06111)
*Dewi S. W. Gould,Bruno Mlodozeniec,Samuel F. Brown*

Main category: cs.AI

TL;DR: SKATE框架通过模型间的相互评估，实现了对大型语言模型能力和风险的客观、可扩展评估。


<details>
  <summary>Details</summary>
Motivation: 当前评估基础模型的方法需要大量的领域专业知识，难以随着模型的快速发展而扩展。

Method: 提出了一种名为SKATE的新型评估框架，该框架将评估视为一个游戏，模型既是出题者又是解题者。

Result: 实验结果表明：（1）较弱的模型能够可靠地区分和评估更强的模型；（2）基于LLM的系统能够进行自我偏好行为，生成与其自身能力相符的问题；（3）SKATE能够自动发现模型之间细微的能力差异。

Conclusion: SKATE框架通过让大型语言模型相互出题解题来评估其能力和风险，具有可扩展性、客观性和开放性等优点，实验结果表明该框架有效可行。

Abstract: Evaluating the capabilities and risks of foundation models is paramount, yet
current methods demand extensive domain expertise, hindering their scalability
as these models rapidly evolve. We introduce SKATE: a novel evaluation
framework in which large language models (LLMs) compete by generating and
solving verifiable tasks for one another. Our core insight is to treat
evaluation as a game: models act as both task-setters and solvers, incentivized
to create questions which highlight their own strengths while exposing others'
weaknesses. SKATE offers several key advantages, balancing scalability,
open-endedness, and objectivity. It is fully automated, data-free, and
scalable, requiring no human input or domain expertise. By using verifiable
tasks rather than LLM judges, scoring is objective. Unlike domain-limited
programmatically-generated benchmarks (e.g. chess-playing or spatial
reasoning), having LLMs creatively pose challenges enables open-ended and
scalable evaluation. As a proof of concept, we introduce LLM-set
code-output-prediction (COP) challenges as a verifiable and extensible
framework in which to test our approach. Using a TrueSkill-based ranking
system, we evaluate six frontier LLMs and find that: (1) weaker models can
reliably differentiate and score stronger ones, (2) LLM-based systems are
capable of self-preferencing behavior, generating questions that align with
their own capabilities, and (3) SKATE automatically surfaces fine-grained
capability differences between models. Our findings are an important step
towards general, scalable evaluation frameworks which can keep pace with LLM
progress.

</details>


### [16] [Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem](https://arxiv.org/abs/2508.06129)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux*

Main category: cs.AI

TL;DR: 利用机器学习和可解释AI分析VRP解的特征重要性，提出改进元启发式算法的指导机制。


<details>
  <summary>Details</summary>
Motivation: 传统元启发式算法依赖人工设计，而机器学习方法可以利用组合优化问题的结构特征设计更高效的算法，本研究旨在通过分析特征重要性来改进VRP的求解算法。

Method: 使用多种分类器模型进行灵敏度分析，结合可解释AI技术分析模型决策过程，并提出特征影响排序的统一框架。

Result: 发现某些特征始终是强预测指标，并提出一个对不同场景下特征影响进行排序的统一框架，为元启发式VRP算法的指导机制提供了基础。

Conclusion: 这项研究扩展了先前利用机器学习预测VRP解质量的研究，通过灵敏度分析和可解释AI，识别出一致有效的预测特征，并提出一个统一框架对不同场景下的特征影响进行排序，为改进元启发式VRP算法提供指导。

Abstract: The Vehicle Routing Problem (VRP) is a complex optimization problem with
numerous real-world applications, mostly solved using metaheuristic algorithms
due to its $\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely
on human-crafted designs developed through empirical studies. However, recent
research shows that machine learning methods can be used the structural
characteristics of solutions in combinatorial optimization, thereby aiding in
designing more efficient algorithms, particularly for solving VRP. Building on
this advancement, this study extends the previous research by conducting a
sensitivity analysis using multiple classifier models that are capable of
predicting the quality of VRP solutions. Hence, by leveraging explainable AI,
this research is able to extend the understanding of how these models make
decisions. Finally, our findings indicate that while feature importance varies,
certain features consistently emerge as strong predictors. Furthermore, we
propose a unified framework able of ranking feature impact across different
scenarios to illustrate this finding. These insights highlight the potential of
feature importance analysis as a foundation for developing a guidance mechanism
of metaheuristic algorithms for solving the VRP.

</details>
