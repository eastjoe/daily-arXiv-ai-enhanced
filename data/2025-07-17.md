<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Study on the Application of Artificial Intelligence in Ecological Design](https://arxiv.org/abs/2507.11595)
*Hengyue Zhao*

Main category: cs.AI

TL;DR: AI可促进人与自然和谐共生，在生态设计中具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 探究AI在生态设计中促进人与自然和谐共生的潜力。

Method: 案例研究和原型设计，结合强化学习和植物修复技术。

Result: AI扩展了创作方法，并重塑了生态设计的理论和实践，为可持续的、技术赋能的生态系统研究提供了路线图。

Conclusion: AI 可以促进人与自然从支配关系向互利共生的转变，并为生态设计的理论和实践提供了新的框架。

Abstract: This paper asks whether our relationship with nature can move from human
dominance to genuine interdependence, and whether artificial intelligence (AI)
can mediate that shift. We examine a new ecological-design paradigm in which AI
interacts with non-human life forms. Through case studies we show how artists
and designers apply AI for data analysis, image recognition, and ecological
restoration, producing results that differ from conventional media. We argue
that AI not only expands creative methods but also reframes the theory and
practice of ecological design. Building on the author's prototype for
AI-assisted water remediation, the study proposes design pathways that couple
reinforcement learning with plant-based phytoremediation. The findings
highlight AI's potential to link scientific insight, artistic practice, and
environmental stewardship, offering a roadmap for future research on
sustainable, technology-enabled ecosystems.

</details>


### [2] [General Modular Harness for LLM Agents in Multi-Turn Gaming Environments](https://arxiv.org/abs/2507.11633)
*Yuxuan Zhang,Haoyang Yu,Lanxiang Hu,Haojian Jin,Hao Zhang*

Main category: cs.AI

TL;DR: 模块化LLM智能体框架提升了游戏性能，记忆和感知在不同游戏中起关键作用。


<details>
  <summary>Details</summary>
Motivation: 为了构建能够处理各种多回合游戏环境的通用智能体。

Method: 该论文提出了一种模块化的LLM智能体框架，包含感知、记忆和推理组件。

Result: 实验结果表明该框架提高了游戏性能，并揭示了不同模块在不同游戏类型中的贡献模式差异。

Conclusion: 该论文介绍了一种模块化的LLM智能体设计，使其能够在无需特定领域工程的情况下处理各种多回合游戏环境。实验结果表明，该设计提高了游戏性能，并揭示了不同模块在不同游戏类型中的作用差异。

Abstract: We introduce a modular harness design for LLM agents that composes of
perception, memory, and reasoning components, enabling a single LLM or VLM
backbone to tackle a wide spectrum of multi turn gaming environments without
domain-specific engineering. Using classic and modern game suites as
low-barrier, high-diversity testbeds, our framework provides a unified workflow
for analyzing how each module affects performance across dynamic interactive
settings. Extensive experiments demonstrate that the harness lifts gameplay
performance consistently over un-harnessed baselines and reveals distinct
contribution patterns, for example, memory dominates in long-horizon puzzles
while perception is critical in vision noisy arcades. These findings highlight
the effectiveness of our modular harness design in advancing general-purpose
agent, given the familiarity and ubiquity of games in everyday human
experience.

</details>


### [3] [Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](https://arxiv.org/abs/2507.11662)
*Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira*

Main category: cs.AI

TL;DR: 利用MLLM自身采样机制改进其作为验证器的能力，有效降低了偏差，提升了准确性和效率


<details>
  <summary>Details</summary>
Motivation: 现有验证者难以扩展到没有明确成功标准的领域(例如计算机使用)，而MLLM因其世界知识、人类偏好一致性和推理能力而成为一种很有前景的解决方案。

Method: 提出了一种名为自基础验证(SGV)的轻量级方法，该方法利用大型多模态语言模型(MLLM)自身的采样机制，通过无条件和有条件生成来提高MLLM知识和推理的有效性。

Result: SGV方法提高了MLLM验证器的准确性和故障检测率，并在多个基准测试中取得了最先进的结果，超过了之前的最好结果48%。

Conclusion: 大型多模态语言模型(MLLM)作为验证者在评估智能体轨迹方面存在偏差，该偏差会导致对错误行为的合理化。为了解决这个问题，研究人员提出了自基础验证(SGV)方法，该方法利用MLLM自身的采样机制，通过无条件和有条件生成来提高MLLM知识和推理的有效性。SGV方法在准确性和故障检测率方面取得了高达20个点的增益，并在OSWorld、robomimic和VisualWebArena等基准测试中取得了最先进的结果。

Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key
for AI progress in domains like math and board games. However, extending these
gains to domains without clear-cut success criteria (e.g.,computer use) remains
a challenge: while humans can recognize suitable outcomes, translating this
intuition into scalable rules is non-trivial. Multimodal Large Language
Models(MLLMs) emerge as a promising solution, given their world knowledge,
human-preference alignment, and reasoning skills. We evaluate MLLMs as
verifiers of agent trajectories across web navigation, computer use, and
robotic manipulation, and identify a critical limitation: agreement bias, a
strong tendency for MLLMs to favor information in their context window, often
generating chains of thought to rationalize flawed behavior. This bias is
pervasive across models, resilient to test-time scaling, and can impact several
methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs
despite MLLMs showing strong, human-aligned priors on desired behavior. To
address this, we propose Self-Grounded Verification (SGV), a lightweight method
that enables more effective use of MLLMs' knowledge and reasoning by harnessing
their own sampling mechanisms via unconditional and conditional generation. SGV
operates in two steps: first, the MLLM is elicited to retrieve broad priors
about task completion, independent of the data under evaluation. Then,
conditioned on self-generated priors, it reasons over and evaluates a candidate
trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in
accuracy and failure detection rates, and can perform real-time supervision of
heterogeneous agents, boosting task completion of a GUI specialist in OSWorld,
a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting
a new state of the art on the benchmark, surpassing the previous best by 48%.

</details>


### [4] [ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making](https://arxiv.org/abs/2507.11733)
*Srikanth Vemula*

Main category: cs.AI

TL;DR: ClarifAI通过结合案例推理和本体论，提高了AI的可解释性，使其能够应用于关键决策过程。


<details>
  <summary>Details</summary>
Motivation: 满足AI应用中不同利益相关者对解释的需求。

Method: 结合案例推理(CBR)和本体论方法。

Result: 阐述了ClarifAI的理论基础、设计原则和架构，并强调其在不同行业中的应用潜力。

Conclusion: ClarifAI增强了人工智能在决策中的透明度和可解释性。

Abstract: This Study introduces Clarity and Reasoning Interface for Artificial
Intelligence(ClarifAI), a novel approach designed to augment the transparency
and interpretability of artificial intelligence (AI) in the realm of improved
decision making. Leveraging the Case-Based Reasoning (CBR) methodology and
integrating an ontology-driven approach, ClarifAI aims to meet the intricate
explanatory demands of various stakeholders involved in AI-powered
applications. The paper elaborates on ClarifAI's theoretical foundations,
combining CBR and ontologies to furnish exhaustive explanation mechanisms. It
further elaborates on the design principles and architectural blueprint,
highlighting ClarifAI's potential to enhance AI interpretability across
different sectors and its applicability in high-stake environments. This
research delineates the significant role of ClariAI in advancing the
interpretability of AI systems, paving the way for its deployment in critical
decision-making processes.

</details>


### [5] [Auto-Formulating Dynamic Programming Problems with Large Language Models](https://arxiv.org/abs/2507.11737)
*Chenyu Zhou,Jingyuan Yang,Linwei Xin,Yitian Chen,Ziyan He,Dongdong Ge*

Main category: cs.AI

TL;DR: 针对动态规划问题数据稀缺的挑战，提出了一种新的7B参数模型DPLM和数据增强方法DualReflect，在基准测试中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统的动态规划建模需要专家知识，LLM有潜力自动化此过程，但DP问题的随机性和数据稀缺性带来挑战。

Method: 提出了一种名为DPLM的7B参数专用模型，并设计了DualReflect数据生成管线，该管线结合正向和反向生成策略。

Result: DPLM模型在DP-Bench基准测试中取得了与现有SOTA LLM相当甚至更好的性能，验证了DualReflect数据生成管线的有效性，并揭示了正向和反向生成策略在不同数据规模下的权衡。

Conclusion: DPLM模型在DP问题上取得了与现有SOTA LLM相当甚至更好的性能，尤其在难题上表现突出。其关键在于DualReflect数据生成管线，该管线结合了正向和反向生成，有效解决了DP问题训练数据不足的问题。

Abstract: Dynamic programming (DP) is a fundamental method in operations research, but
formulating DP models has traditionally required expert knowledge of both the
problem context and DP techniques. Large Language Models (LLMs) offer the
potential to automate this process. However, DP problems pose unique challenges
due to their inherently stochastic transitions and the limited availability of
training data. These factors make it difficult to directly apply existing
LLM-based models or frameworks developed for other optimization problems, such
as linear or integer programming. We introduce DP-Bench, the first benchmark
covering a wide range of textbook-level DP problems to enable systematic
evaluation. We present Dynamic Programming Language Model (DPLM), a
7B-parameter specialized model that achieves performance comparable to
state-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on
hard problems. Central to DPLM's effectiveness is DualReflect, our novel
synthetic data generation pipeline, designed to scale up training data from a
limited set of initial examples. DualReflect combines forward generation for
diversity and backward generation for reliability. Our results reveal a key
insight: backward generation is favored in low-data regimes for its strong
correctness guarantees, while forward generation, though lacking such
guarantees, becomes increasingly valuable at scale for introducing diverse
formulations. This trade-off highlights the complementary strengths of both
approaches and the importance of combining them.

</details>


### [6] [Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11787)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.AI

TL;DR: 综述了使用群体智能算法进行基于语义相似度文档搜索的最新研究，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 群体智能算法在解决实际问题中越来越受欢迎，其在计算机优化问题中的有效性促使了该综述的产生。

Method: 文献综述

Result: 对基于语义相似度的文档搜索中群体智能算法的最新发展进行了综述。

Conclusion: 本文综述了使用群体智能算法进行基于语义相似度的文档搜索的最新进展，并推荐了未来的研究方向。

Abstract: Swarm Intelligence (SI) is gaining a lot of popularity in artificial
intelligence, where the natural behavior of animals and insects is observed and
translated into computer algorithms called swarm computing to solve real-world
problems. Due to their effectiveness, they are applied in solving various
computer optimization problems. This survey will review all the latest
developments in Searching for documents based on semantic similarity using
Swarm Intelligence algorithms and recommend future research directions.

</details>


### [7] [A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS](https://arxiv.org/abs/2507.11916)
*Ehsan Futuhi,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 利用CPU和GPU的并行性，改进深度优先搜索算法，提升求解Rubik's Cube和STP难题的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的GPU加速搜索算法较少，本文旨在利用GPU的并行计算能力来提高深度优先搜索算法的效率。

Method: 提出了一种新的成本边界深度优先搜索(CB-DFS)方法，该方法利用现代CPU和GPU的并行性，通过批量处理GPU计算来改进IDA*和Budgeted Tree Search算法。

Result: 实验证明该方法能够有效地批量处理GPU计算，并在Rubik's Cube和STP难题上取得了性能提升，并分析了相关因素对性能的影响。

Conclusion: 本文介绍了一种在深度优先搜索中批量处理GPU计算的方法，并将其应用于迭代深化A*算法和预算树搜索算法的改进版本，在Rubik's Cube和STP难题上进行了实验评估，结果表明GPU计算可以有效地批量处理，并分析了超参数、神经网络启发式大小和硬件资源对性能的影响。

Abstract: The rapid advancement of GPU technology has unlocked powerful parallel
processing capabilities, creating new opportunities to enhance classic search
algorithms. A recent successful application of GPUs is in compressing large
pattern database (PDB) heuristics using neural networks while preserving
heuristic admissibility. However, very few algorithms have been designed to
exploit GPUs during search. Several variants of A* exist that batch GPU
computations. In this paper we introduce a method for batching GPU computations
in depth first search. In particular, we describe a new cost-bounded
depth-first search (CB-DFS) method that leverages the combined parallelism of
modern CPUs and GPUs. This is used to create algorithms like \emph{Batch IDA*},
an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an
extensions of Budgeted Tree Search. Our approach builds on the general approach
used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality
guarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding
tile puzzle (STP), showing that GPU operations can be efficiently batched in
DFS. Additionally, we conduct extensive experiments to analyze the effects of
hyperparameters, neural network heuristic size, and hardware resources on
performance.

</details>


### [8] [Aime: Towards Fully-Autonomous Multi-Agent Framework](https://arxiv.org/abs/2507.11988)
*Yexuan Shi,Mingyu Wang,Yunxiang Cao,Hongjie Lai,Junjian Lan,Xin Han,Yu Wang,Jie Geng,Zhenan Li,Zihao Xia,Xiang Chen,Chen Li,Jian Xu,Wenbo Duan,Yuanshuo Zhu*

Main category: cs.AI

TL;DR: Aime是一个新的多智能体框架，通过动态规划、按需创建智能体和集中的进度管理，显著提高了多智能体系统的适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型的多智能体系统常受限于僵化的计划执行、静态的智能体能力和低效的通信，难以适应动态环境。

Method: Aime框架通过动态、反应式规划和执行来克服现有计划-执行框架的局限性，其核心创新包括动态规划器、Actor工厂和集中的进度管理模块。

Result: Aime框架在通用推理、软件工程和实时网页导航等基准测试中均取得了优异的成果，显著优于现有技术。

Conclusion: Aime框架在多项基准测试中持续优于最先进的专业智能体，展现出更强的适应性和任务成功率，为多智能体协作提供了更有效的基础。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are
emerging as a powerful paradigm for solving complex, multifaceted problems.
However, the potential of these systems is often constrained by the prevalent
plan-and-execute framework, which suffers from critical limitations: rigid plan
execution, static agent capabilities, and inefficient communication. These
weaknesses hinder their adaptability and robustness in dynamic environments.
This paper introduces Aime, a novel multi-agent framework designed to overcome
these challenges through dynamic, reactive planning and execution. Aime
replaces the conventional static workflow with a fluid and adaptive
architecture. Its core innovations include: (1) a Dynamic Planner that
continuously refines the overall strategy based on real-time execution
feedback; (2) an Actor Factory that implements Dynamic Actor instantiation,
assembling specialized agents on-demand with tailored tools and knowledge; and
(3) a centralized Progress Management Module that serves as a single source of
truth for coherent, system-wide state awareness. We empirically evaluated Aime
on a diverse suite of benchmarks spanning general reasoning (GAIA), software
engineering (SWE-bench Verified), and live web navigation (WebVoyager). The
results demonstrate that Aime consistently outperforms even highly specialized
state-of-the-art agents in their respective domains. Its superior adaptability
and task success rate establish Aime as a more resilient and effective
foundation for multi-agent collaboration.

</details>


### [9] [Understanding visual attention beehind bee-inspired UAV navigation](https://arxiv.org/abs/2507.11992)
*Pranav Rajbhandari,Abhi Veda,Matthew Garratt,Mandayam Srinivasan,Sridhar Ravi*

Main category: cs.AI

TL;DR: 强化学习智能体通过关注光流的不连续区域和高光流幅度区域，成功模仿蜜蜂在复杂环境中的导航行为，为无人机控制律设计提供新思路。


<details>
  <summary>Details</summary>
Motivation: 生物启发式设计常用于自主无人机导航，因为生物系统能够飞行和避障，即使感官和计算能力有限。蜜蜂主要利用光流（视觉场中物体的表观运动）的感觉输入来导航杂乱的环境。

Method: 使用强化学习训练智能体，仅使用光流作为感觉输入，在有障碍物的隧道中导航。

Result: 训练的智能体主要关注光流的不连续区域以及光流幅度大的区域。

Conclusion: 训练的智能体通过避免产生大的光流的障碍物，同时保持其在环境中的居中位置，从而在杂乱的隧道中导航，这类似于飞行昆虫的行为。这种模式在独立训练的智能体中持续存在，这表明这可能是为物理无人机开发简单的显式控制律的一个好策略。

Abstract: Bio-inspired design is often used in autonomous UAV navigation due to the
capacity of biological systems for flight and obstacle avoidance despite
limited sensory and computational capabilities. In particular, honeybees mainly
use the sensory input of optic flow, the apparent motion of objects in their
visual field, to navigate cluttered environments. In our work, we train a
Reinforcement Learning agent to navigate a tunnel with obstacles using only
optic flow as sensory input. We inspect the attention patterns of trained
agents to determine the regions of optic flow on which they primarily base
their motor decisions. We find that agents trained in this way pay most
attention to regions of discontinuity in optic flow, as well as regions with
large optic flow magnitude. The trained agents appear to navigate a cluttered
tunnel by avoiding the obstacles that produce large optic flow, while
maintaining a centered position in their environment, which resembles the
behavior seen in flying insects. This pattern persists across independently
trained agents, which suggests that this could be a good strategy for
developing a simple explicit control law for physical UAVs.

</details>


### [10] [Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs](https://arxiv.org/abs/2507.12110)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 提出一种新的拓扑增强型多智能体强化学习方法(TPE-MARL)，有效提高了混合交通中联网自动驾驶车辆的协同决策能力。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体强化学习中探索-利用困境，尤其是在面对联网自动驾驶车辆的复杂交通状态时，有效降低搜索空间。

Method: 构建游戏拓扑张量压缩高维交通状态信息，并结合QMIX算法，利用访问计数和智能体互信息建立拓扑增强型MARL框架。

Result: TPE-MARL在不同交通密度和CAV渗透率下的仿真实验中，成功平衡了探索和利用，提高了交通效率、安全性、决策平滑性和任务完成度。

Conclusion: 该论文提出了一种拓扑增强型多智能体强化学习方法(TPE-MARL)，用于优化混合交通中联网自动驾驶车辆的协同决策，并在交通效率、安全性和决策平滑性等方面表现出优越性能，其决策理性可与人类驾驶员相媲美甚至超越。

Abstract: The exploration-exploitation trade-off constitutes one of the fundamental
challenges in reinforcement learning (RL), which is exacerbated in multi-agent
reinforcement learning (MARL) due to the exponential growth of joint
state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)
method for optimizing cooperative decision-making of connected and autonomous
vehicles (CAVs) in mixed traffic. This work presents two primary contributions:
First, we construct a game topology tensor for dynamic traffic flow,
effectively compressing high-dimensional traffic state information and decrease
the search space for MARL algorithms. Second, building upon the designed game
topology tensor and using QMIX as the backbone RL algorithm, we establish a
topology-enhanced MARL framework incorporating visit counts and agent mutual
information. Extensive simulations across varying traffic densities and CAV
penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations
encompassing training dynamics, exploration patterns, macroscopic traffic
performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL
successfully balances exploration and exploitation. Consequently, it exhibits
superior performance in terms of traffic efficiency, safety, decision
smoothness, and task completion. Furthermore, the algorithm demonstrates
decision-making rationality comparable to or exceeding that of human drivers in
both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is
available at
\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.

</details>


### [11] [Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation](https://arxiv.org/abs/2507.12186)
*Edward Kim,Hanna Kurniawati*

Main category: cs.AI

TL;DR: 提出一种新颖的随时在线近似POMDP求解器，在大型动态环境问题中显著优于现有基准。


<details>
  <summary>Details</summary>
Motivation: 解决现有在线POMDP求解器在处理大规模动态环境问题时效率低下的问题。

Method: 该算法通过对有意义的未来历史进行深入采样，同时强制渐进策略更新来实现。

Result: 理论和实验证明，该算法的性能损失受采样近似误差平均值的限制，而不是最大值的限制，并且在处理大型动态环境问题（例如直升机紧急救援场景）时，显著优于现有的在线基准算法。

Conclusion: 本文提出了一种新颖的随时在线近似POMDP求解器——部分可观测参考策略规划(Partially Observable Reference Policy Programming)，该求解器能够对有意义的未来历史进行非常深入的采样，同时强制进行渐进的策略更新。

Abstract: This paper proposes Partially Observable Reference Policy Programming, a
novel anytime online approximate POMDP solver which samples meaningful future
histories very deeply while simultaneously forcing a gradual policy update. We
provide theoretical guarantees for the algorithm's underlying scheme which say
that the performance loss is bounded by the average of the sampling
approximation errors rather than the usual maximum, a crucial requirement given
the sampling sparsity of online planning. Empirical evaluations on two
large-scale problems with dynamically evolving environments -- including a
helicopter emergency scenario in the Corsica region requiring approximately 150
planning steps -- corroborate the theoretical results and indicate that our
solver considerably outperforms current online benchmarks.

</details>


### [12] [BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution](https://arxiv.org/abs/2507.12207)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: BuildEvo使用LLM自动设计可解释的建筑能源预测启发式算法，在基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 准确的建筑能源预测至关重要，但传统的启发式方法往往缺乏精度，而高级模型可能不透明，并且由于忽略物理原理而难以泛化。

Method: 使用大型语言模型(LLM)自动设计有效且可解释的能源预测启发式算法，在一个进化过程中，BuildEvo指导LLM通过系统地结合建筑特征和运行数据的物理见解来构建和增强启发式算法。

Result: BuildEvo在基准测试中取得了最先进的性能，具有更好的泛化能力和透明的预测逻辑。

Conclusion: BuildEvo框架在基准测试中取得了最先进的性能，提高了泛化能力和预测逻辑的透明度，推动了鲁棒、物理基础启发式算法的自动化设计，从而促进了复杂能源系统的可信赖模型。

Abstract: Accurate building energy forecasting is essential, yet traditional heuristics
often lack precision, while advanced models can be opaque and struggle with
generalization by neglecting physical principles. This paper introduces
BuildEvo, a novel framework that uses Large Language Models (LLMs) to
automatically design effective and interpretable energy prediction heuristics.
Within an evolutionary process, BuildEvo guides LLMs to construct and enhance
heuristics by systematically incorporating physical insights from building
characteristics and operational data (e.g., from the Building Data Genome
Project 2). Evaluations show BuildEvo achieves state-of-the-art performance on
benchmarks, offering improved generalization and transparent prediction logic.
This work advances the automated design of robust, physically grounded
heuristics, promoting trustworthy models for complex energy systems.

</details>


### [13] [Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning](https://arxiv.org/abs/2507.12215)
*Yuhao Chen,Shuochen Liu,Yuanjie Lyu,Chao Zhang,Jiayao Shi,Tong Xu*

Main category: cs.AI

TL;DR: 针对大型语言模型在空间策略推理上的不足，研究者提出Xiangqi-R1模型，在中国象棋任务上取得显著进展。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)在空间策略推理方面能力不足，中国象棋作为复杂游戏，可作为评估AGI的良好基准。

Method: 提出了一种针对中国象棋的训练框架Xiangqi-R1，该框架基于500万棋局数据，结合专家标注和引擎评估，采用多阶段训练方法：1)微调进行合法性预测；2)融入策略标注；3)使用基于组相对策略优化的强化学习算法。

Result: Xiangqi-R1模型在合法性预测和分析准确性上分别提高了18%和22%，显著优于通用LLM。

Conclusion: 该研究表明，大型语言模型(LLM)在需要空间策略推理的复杂游戏中表现不足，并提出了一种针对中国象棋的训练框架Xiangqi-R1，通过多阶段训练显著提高了模型在合法性预测和分析准确性方面的性能，为在空间复杂领域创建通用策略智能提供了有前景的途径。

Abstract: Game playing has long served as a fundamental benchmark for evaluating
Artificial General Intelligence (AGI). While Large Language Models (LLMs) have
demonstrated impressive capabilities in general reasoning, their effectiveness
in spatial strategic reasoning, which is critical for complex and fully
observable board games, remains insufficiently explored. In this work, we adopt
Chinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate
rules and spatial complexity. To advance LLMs' strategic competence in such
environments, we propose a training framework tailored to Xiangqi, built upon a
large-scale dataset of five million board-move pairs enhanced with expert
annotations and engine evaluations. Building on this foundation, we introduce
Xiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning
for legal move prediction to capture basic spatial rules, (2) incorporating
strategic annotations to improve decision-making, and (3) applying
reinforcement learning via Group Relative Policy Optimization (GRPO) with
multi-dimensional reward signals to enhance reasoning stability. Our
Experimental results indicate that, despite their size and power,
general-purpose LLMs struggle to achieve satisfactory performance in these
tasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an
18% rise in move legality and a 22% boost in analysis accuracy. Our results
point to a promising path for creating general strategic intelligence in
spatially complex areas.

</details>
