{"id": "2509.07997", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.07997", "abs": "https://arxiv.org/abs/2509.07997", "authors": ["Abigail Breitfeld", "Alberto Candela", "Juan Delfa", "Akseli Kangaslahti", "Itai Zilberstein", "Steve Chien", "David Wettergreen"], "title": "Learning-Based Planning for Improving Science Return of Earth Observation Satellites", "comment": "International Symposium on Artificial Intelligence, Robotics and\n  Automation in Space, November 2024", "summary": "Earth observing satellites are powerful tools for collecting scientific\ninformation about our planet, however they have limitations: they cannot easily\ndeviate from their orbital trajectories, their sensors have a limited field of\nview, and pointing and operating these sensors can take a large amount of the\nspacecraft's resources. It is important for these satellites to optimize the\ndata they collect and include only the most important or informative\nmeasurements. Dynamic targeting is an emerging concept in which satellite\nresources and data from a lookahead instrument are used to intelligently\nreconfigure and point a primary instrument. Simulation studies have shown that\ndynamic targeting increases the amount of scientific information gathered\nversus conventional sampling strategies. In this work, we present two different\nlearning-based approaches to dynamic targeting, using reinforcement and\nimitation learning, respectively. These learning methods build on a dynamic\nprogramming solution to plan a sequence of sampling locations. We evaluate our\napproaches against existing heuristic methods for dynamic targeting, showing\nthe benefits of using learning for this application. Imitation learning\nperforms on average 10.0\\% better than the best heuristic method, while\nreinforcement learning performs on average 13.7\\% better. We also show that\nboth learning methods can be trained effectively with relatively small amounts\nof data.", "AI": {"tldr": "\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u4eff\u5b66\u4e60\u6539\u8fdb\u536b\u661f\u52a8\u6001\u76ee\u6807\u9009\u62e9\uff0c\u63d0\u9ad8\u6570\u636e\u6536\u96c6\u6548\u7387\uff0c\u7ed3\u679c\u8868\u660e\u5b66\u4e60\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u536b\u661f\u6570\u636e\u6536\u96c6\u65b9\u6cd5\u53d7\u9650\u4e8e\u8f68\u9053\u3001\u4f20\u611f\u5668\u89c6\u91ce\u548c\u8d44\u6e90\uff0c\u9700\u8981\u4f18\u5316\u6570\u636e\u6536\u96c6\u7b56\u7565\u3002", "method": "\u57fa\u4e8e\u52a8\u6001\u89c4\u5212\u7684\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u4e0e\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u5bf9\u6bd4\u3002", "result": "\u6a21\u4eff\u5b66\u4e60\u6bd4\u6700\u4f73\u542f\u53d1\u5f0f\u65b9\u6cd5\u5e73\u5747\u63d0\u9ad810.0%\uff0c\u5f3a\u5316\u5b66\u4e60\u5e73\u5747\u63d0\u9ad813.7%\uff0c\u4e14\u4e24\u79cd\u5b66\u4e60\u65b9\u6cd5\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u8f83\u5c11\u3002", "conclusion": "\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u4e86\u536b\u661f\u52a8\u6001\u76ee\u6807\u9009\u62e9\u7684\u6548\u7387\u548c\u79d1\u5b66\u4fe1\u606f\u7684\u6536\u96c6\u91cf\u3002"}}
{"id": "2509.08088", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.08088", "abs": "https://arxiv.org/abs/2509.08088", "authors": ["Linyao Chen", "Zimian Peng", "Yingxuan Yang", "Yikun Wang", "Wenzheng Tom Tang", "Hiroki H. Kobayashi", "Weinan Zhang"], "title": "EnvX: Agentize Everything with Agentic AI", "comment": null, "summary": "The widespread availability of open-source repositories has led to a vast\ncollection of reusable software components, yet their utilization remains\nmanual, error-prone, and disconnected. Developers must navigate documentation,\nunderstand APIs, and write integration code, creating significant barriers to\nefficient software reuse. To address this, we present EnvX, a framework that\nleverages Agentic AI to agentize GitHub repositories, transforming them into\nintelligent, autonomous agents capable of natural language interaction and\ninter-agent collaboration. Unlike existing approaches that treat repositories\nas static code resources, EnvX reimagines them as active agents through a\nthree-phase process: (1) TODO-guided environment initialization, which sets up\nthe necessary dependencies, data, and validation datasets; (2) human-aligned\nagentic automation, allowing repository-specific agents to autonomously perform\nreal-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple\nagents to collaborate. By combining large language model capabilities with\nstructured tool integration, EnvX automates not just code generation, but the\nentire process of understanding, initializing, and operationalizing repository\nfunctionality. We evaluate EnvX on the GitTaskBench benchmark, using 18\nrepositories across domains such as image processing, speech recognition,\ndocument analysis, and video manipulation. Our results show that EnvX achieves\na 74.07% execution completion rate and 51.85% task pass rate, outperforming\nexisting frameworks. Case studies further demonstrate EnvX's ability to enable\nmulti-repository collaboration via the A2A protocol. This work marks a shift\nfrom treating repositories as passive code resources to intelligent,\ninteractive agents, fostering greater accessibility and collaboration within\nthe open-source ecosystem.", "AI": {"tldr": "EnvX\u6846\u67b6\u5229\u7528Agentic AI\u5c06GitHub\u4ed3\u5e93\u8f6c\u5316\u4e3a\u667a\u80fd\u4ee3\u7406\uff0c\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u548c\u4ee3\u7406\u95f4\u534f\u4f5c\uff0c\u63d0\u9ad8\u4e86\u8f6f\u4ef6\u590d\u7528\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u590d\u7528\u65b9\u5f0f\u6548\u7387\u4f4e\uff0cEnvX\u65e8\u5728\u901a\u8fc7\u5c06\u4ee3\u7801\u5e93\u8f6c\u5316\u4e3a\u667a\u80fd\u4ee3\u7406\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u4e09\u9636\u6bb5\u8fc7\u7a0b\uff1a\u73af\u5883\u521d\u59cb\u5316\u3001\u4eba\u7c7b\u5bf9\u9f50\u7684\u4ee3\u7406\u81ea\u52a8\u5316\u548c\u4ee3\u7406\u95f4\u534f\u4f5c\u534f\u8bae\u3002\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7ed3\u6784\u5316\u5de5\u5177\u96c6\u6210\uff0c\u81ea\u52a8\u5316\u7406\u89e3\u3001\u521d\u59cb\u5316\u548c\u8fd0\u884c\u4ee3\u7801\u5e93\u529f\u80fd\u3002", "result": "\u5728GitTaskBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEnvX\u7684\u6267\u884c\u5b8c\u6210\u7387\u4e3a74.07%\uff0c\u4efb\u52a1\u901a\u8fc7\u7387\u4e3a51.85%\uff0c\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002\u6848\u4f8b\u7814\u7a76\u8fd8\u8bc1\u660e\u4e86EnvX\u652f\u6301\u591a\u4ee3\u7801\u5e93\u534f\u4f5c\u3002", "conclusion": "EnvX\u5c06\u4ee3\u7801\u5e93\u4ece\u88ab\u52a8\u7684\u4ee3\u7801\u8d44\u6e90\u8f6c\u53d8\u4e3a\u667a\u80fd\u4ea4\u4e92\u5f0f\u4ee3\u7406\uff0c\u4fc3\u8fdb\u4e86\u5f00\u6e90\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u534f\u4f5c\u3002"}}
{"id": "2509.08151", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08151", "abs": "https://arxiv.org/abs/2509.08151", "authors": ["Botao Zhu", "Jeslyn Wang", "Dusit Niyato", "Xianbin Wang"], "title": "Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI", "comment": null, "summary": "Accurate trustworthiness evaluation of potential collaborating devices is\nessential for the effective execution of complex computing tasks. This\nevaluation process involves collecting diverse trust-related data from\npotential collaborators, including historical performance and available\nresources, for collaborator selection. However, when each task owner\nindependently assesses all collaborators' trustworthiness, frequent data\nexchange, complex reasoning, and dynamic situation changes can result in\nsignificant overhead and deteriorated trust evaluation. To overcome these\nchallenges, we propose a task-specific trust semantics distillation (2TSD)\nmodel based on a large AI model (LAM)-driven teacher-student agent\narchitecture. The teacher agent is deployed on a server with powerful\ncomputational capabilities and an augmented memory module dedicated to\nmultidimensional trust-related data collection, task-specific trust semantics\nextraction, and task-collaborator matching analysis. Upon receiving\ntask-specific requests from device-side student agents, the teacher agent\ntransfers the trust semantics of potential collaborators to the student agents,\nenabling rapid and accurate collaborator selection. Experimental results\ndemonstrate that the proposed 2TSD model can reduce collaborator evaluation\ntime, decrease device resource consumption, and improve the accuracy of\ncollaborator selection.", "AI": {"tldr": "\u9488\u5bf9\u590d\u6742\u8ba1\u7b97\u4efb\u52a1\u7684\u534f\u540c\u8bbe\u5907\u4fe1\u4efb\u8bc4\u4f30\uff0c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5927\u578bAI\u6a21\u578b\u7684\u6559\u5e08-\u5b66\u751f\u4ee3\u7406\u67b6\u6784\u7684\u7279\u5b9a\u4efb\u52a1\u4fe1\u4efb\u8bed\u4e49\u84b8\u998f(2TSD)\u6a21\u578b\uff0c\u4ee5\u51cf\u5c11\u8bc4\u4f30\u65f6\u95f4\u3001\u8bbe\u5907\u8d44\u6e90\u6d88\u8017\u5e76\u63d0\u9ad8\u9009\u62e9\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u534f\u540c\u8bbe\u5907\u4fe1\u4efb\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u6570\u636e\u4ea4\u6362\u9891\u7e41\u3001\u63a8\u7406\u590d\u6742\u3001\u52a8\u6001\u53d8\u5316\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u5f00\u9500\u5927\u3001\u8bc4\u4f30\u6548\u679c\u5dee\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5927\u578bAI\u6a21\u578b\u9a71\u52a8\u7684\u6559\u5e08-\u5b66\u751f\u4ee3\u7406\u67b6\u6784\u76842TSD\u6a21\u578b\u3002\u6559\u5e08\u4ee3\u7406\u6536\u96c6\u591a\u7ef4\u4fe1\u4efb\u6570\u636e\uff0c\u63d0\u53d6\u7279\u5b9a\u4efb\u52a1\u4fe1\u4efb\u8bed\u4e49\uff0c\u8fdb\u884c\u4efb\u52a1-\u534f\u4f5c\u8005\u5339\u914d\u5206\u6790\uff1b\u5b66\u751f\u4ee3\u7406\u63a5\u6536\u6559\u5e08\u4ee3\u7406\u7684\u4fe1\u4efb\u8bed\u4e49\uff0c\u5feb\u901f\u51c6\u786e\u5730\u9009\u62e9\u534f\u4f5c\u8005\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c2TSD\u6a21\u578b\u80fd\u51cf\u5c11\u534f\u4f5c\u8005\u8bc4\u4f30\u65f6\u95f4\uff0c\u964d\u4f4e\u8bbe\u5907\u8d44\u6e90\u6d88\u8017\uff0c\u63d0\u9ad8\u534f\u4f5c\u8005\u9009\u62e9\u51c6\u786e\u6027\u3002", "conclusion": "2TSD\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u8ba1\u7b97\u4efb\u52a1\u4e2d\u534f\u540c\u8bbe\u5907\u4fe1\u4efb\u8bc4\u4f30\u7684\u6311\u6218\uff0c\u4e3a\u63d0\u9ad8\u534f\u540c\u8ba1\u7b97\u6548\u7387\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2509.08222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08222", "abs": "https://arxiv.org/abs/2509.08222", "authors": ["Minjong Yoo", "Jinwoo Jang", "Wei-jin Park", "Honguk Woo"], "title": "Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following", "comment": "21 pages. NeurIPS 2024", "summary": "This study presents an Exploratory Retrieval-Augmented Planning (ExRAP)\nframework, designed to tackle continual instruction following tasks of embodied\nagents in dynamic, non-stationary environments. The framework enhances Large\nLanguage Models' (LLMs) embodied reasoning capabilities by efficiently\nexploring the physical environment and establishing the environmental context\nmemory, thereby effectively grounding the task planning process in time-varying\nenvironment contexts. In ExRAP, given multiple continual instruction following\ntasks, each instruction is decomposed into queries on the environmental context\nmemory and task executions conditioned on the query results. To efficiently\nhandle these multiple tasks that are performed continuously and simultaneously,\nwe implement an exploration-integrated task planning scheme by incorporating\nthe {information-based exploration} into the LLM-based planning process.\nCombined with memory-augmented query evaluation, this integrated scheme not\nonly allows for a better balance between the validity of the environmental\ncontext memory and the load of environment exploration, but also improves\noverall task performance. Furthermore, we devise a {temporal consistency\nrefinement} scheme for query evaluation to address the inherent decay of\nknowledge in the memory. Through experiments with VirtualHome, ALFRED, and\nCARLA, our approach demonstrates robustness against a variety of embodied\ninstruction following scenarios involving different instruction scales and\ntypes, and non-stationarity degrees, and it consistently outperforms other\nstate-of-the-art LLM-based task planning approaches in terms of both goal\nsuccess rate and execution efficiency.", "AI": {"tldr": "ExRAP\u6846\u67b6\u589e\u5f3aLLM\u5728\u52a8\u6001\u73af\u5883\u4e2d\u6267\u884c\u6301\u7eed\u6307\u4ee4\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u73af\u5883\u63a2\u7d22\u548c\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u63d0\u5347\u4efb\u52a1\u89c4\u5212\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u52a8\u6001\u73af\u5883\u4e0b\u7684\u6301\u7eed\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u3002", "method": "\u63d0\u51faExRAP\u6846\u67b6\uff0c\u7ed3\u5408\u4fe1\u606f\u63a2\u7d22\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u7ec6\u5316\u65b9\u6848\uff0c\u9ad8\u6548\u63a2\u7d22\u73af\u5883\uff0c\u6784\u5efa\u73af\u5883\u4e0a\u4e0b\u6587\u8bb0\u5fc6\uff0c\u5e76\u8fdb\u884c\u57fa\u4e8e\u8bb0\u5fc6\u7684\u4efb\u52a1\u89c4\u5212\u3002", "result": "\u5728VirtualHome\uff0cALFRED\u548cCARLA\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cExRAP\u5728\u76ee\u6807\u6210\u529f\u7387\u548c\u6267\u884c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6LLM\u57fa\u51c6\u4efb\u52a1\u89c4\u5212\u65b9\u6cd5\u3002", "conclusion": "ExRAP\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u52a8\u6001\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u6267\u884c\u6301\u7eed\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u7684\u80fd\u529b\u3002"}}
{"id": "2509.08282", "categories": ["cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.08282", "abs": "https://arxiv.org/abs/2509.08282", "authors": ["Seonghyeon Go"], "title": "Real-world Music Plagiarism Detection With Music Segment Transcription System", "comment": "Accepted in APSIPA 2025 but not published yet(will be published in 2\n  month..), Arxiv preprint ready for references in future-works", "summary": "As a result of continuous advances in Music Information Retrieval (MIR)\ntechnology, generating and distributing music has become more diverse and\naccessible. In this context, interest in music intellectual property protection\nis increasing to safeguard individual music copyrights. In this work, we\npropose a system for detecting music plagiarism by combining various MIR\ntechnologies. We developed a music segment transcription system that extracts\nmusically meaningful segments from audio recordings to detect plagiarism across\ndifferent musical formats. With this system, we compute similarity scores based\non multiple musical features that can be evaluated through comprehensive\nmusical analysis. Our approach demonstrated promising results in music\nplagiarism detection experiments, and the proposed method can be applied to\nreal-world music scenarios. We also collected a Similar Music Pair (SMP)\ndataset for musical similarity research using real-world cases. The dataset are\npublicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u591a\u79cd\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22(MIR)\u6280\u672f\u7684\u97f3\u4e50\u527d\u7a83\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5e76\u516c\u5f00\u4e86\u4e00\u4e2a\u7528\u4e8e\u97f3\u4e50\u76f8\u4f3c\u6027\u7814\u7a76\u7684\u76f8\u4f3c\u97f3\u4e50\u5bf9(SMP)\u6570\u636e\u96c6\u3002", "motivation": "\u968f\u7740MIR\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u97f3\u4e50\u521b\u4f5c\u548c\u5206\u53d1\u66f4\u52a0\u591a\u5143\u5316\uff0c\u5bf9\u97f3\u4e50\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u97f3\u4e50\u7247\u6bb5\u8f6c\u5f55\u7cfb\u7edf\uff0c\u63d0\u53d6\u97f3\u9891\u8bb0\u5f55\u4e2d\u5177\u6709\u97f3\u4e50\u610f\u4e49\u7684\u7247\u6bb5\uff0c\u5e76\u57fa\u4e8e\u591a\u79cd\u97f3\u4e50\u7279\u5f81\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u5206\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u97f3\u4e50\u527d\u7a83\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u826f\u597d\u6548\u679c\uff0c\u53ef\u5e94\u7528\u4e8e\u5b9e\u9645\u573a\u666f\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u548c\u6570\u636e\u96c6\u4e3a\u97f3\u4e50\u527d\u7a83\u68c0\u6d4b\u548c\u97f3\u4e50\u76f8\u4f3c\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u76ca\u5de5\u5177\u3002"}}
{"id": "2509.08312", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08312", "abs": "https://arxiv.org/abs/2509.08312", "authors": ["Binghan Wu", "Shoufeng Wang", "Yunxin Liu", "Ya-Qin Zhang", "Joseph Sifakis", "Ye Ouyang"], "title": "Leveraging AI Agents for Autonomous Networks: A Reference Architecture and Empirical Studies", "comment": "7 pages, 5 figures. This manuscript is a preprint", "summary": "The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a\nstrategic inflection point in telecommunications, where networks must transcend\nreactive automation to achieve genuine cognitive capabilities--fulfilling TM\nForum's vision of self-configuring, self-healing, and self-optimizing systems\nthat deliver zero-wait, zero-touch, and zero-fault services. This work bridges\nthe gap between architectural theory and operational reality by implementing\nJoseph Sifakis's AN Agent reference architecture in a functional cognitive\nsystem, deploying coordinated proactive-reactive runtimes driven by hybrid\nknowledge representation. Through an empirical case study of a Radio Access\nNetwork (RAN) Link Adaptation (LA) Agent, we validate this framework's\ntransformative potential: demonstrating sub-10 ms real-time control in 5G NR\nsub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link\nAdaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for\nultra-reliable services through dynamic Modulation and Coding Scheme (MCS)\noptimization. These improvements confirm the architecture's viability in\novercoming traditional autonomy barriers and advancing critical L4-enabling\ncapabilities toward next-generation objectives.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5b9e\u73b0\u4e86Joseph Sifakis\u7684AN Agent\u53c2\u8003\u67b6\u6784\uff0c\u5e76\u57285G NR\u7f51\u7edc\u4e2d\u5b9e\u73b0\u4e86\u4e9a10\u6beb\u79d2\u7684\u5b9e\u65f6\u63a7\u5236\uff0c\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u5e76\u964d\u4f4e\u4e86\u8bef\u7801\u7387\u3002", "motivation": "\u63a8\u52a8\u81ea\u4e3b\u7f51\u7edc\u54114\u7ea7\u6f14\u8fdb\uff0c\u5b9e\u73b0\u81ea\u914d\u7f6e\u3001\u81ea\u4fee\u590d\u548c\u81ea\u4f18\u5316\u7684\u7f51\u7edc\u3002", "method": "\u5728\u65e0\u7ebf\u63a5\u5165\u7f51\u94fe\u8def\u81ea\u9002\u5e94\u4ee3\u7406\u4e2d\u5b9e\u73b0Joseph Sifakis\u7684AN Agent\u53c2\u8003\u67b6\u6784\uff0c\u4f7f\u7528\u6df7\u5408\u77e5\u8bc6\u8868\u793a\u9a71\u52a8\u4e3b\u52a8-\u88ab\u52a8\u8fd0\u884c\u65f6\u3002", "result": "\u57285G NR sub-6 GHz\u7f51\u7edc\u4e2d\u5b9e\u73b0\u4e86\u4e9a10\u6beb\u79d2\u7684\u5b9e\u65f6\u63a7\u5236\uff0c\u4e0b\u884c\u541e\u5410\u91cf\u6bd4\u4f20\u7edf\u7b97\u6cd5\u63d0\u9ad86%\uff0c\u8bef\u7801\u7387\u964d\u4f4e67%\u3002", "conclusion": "\u8be5\u67b6\u6784\u514b\u670d\u4e86\u4f20\u7edf\u81ea\u4e3b\u6027\u969c\u788d\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u76ee\u6807\u63a8\u52a8\u4e86\u5173\u952e\u76844\u7ea7\u81ea\u4e3b\u80fd\u529b\u3002"}}
{"id": "2509.08380", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.08380", "abs": "https://arxiv.org/abs/2509.08380", "authors": ["Prathamesh Vasudeo Naik", "Naresh Kumar Dintakurthi", "Zhanghao Hu", "Yue Wang", "Robby Qiu"], "title": "Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives", "comment": null, "summary": "Generating regulatorily compliant Suspicious Activity Report (SAR) remains a\nhigh-cost, low-scalability bottleneck in Anti-Money Laundering (AML) workflows.\nWhile large language models (LLMs) offer promising fluency, they suffer from\nfactual hallucination, limited crime typology alignment, and poor\nexplainability -- posing unacceptable risks in compliance-critical domains.\nThis paper introduces Co-Investigator AI, an agentic framework optimized to\nproduce Suspicious Activity Reports (SARs) significantly faster and with\ngreater accuracy than traditional methods. Drawing inspiration from recent\nadvances in autonomous agent architectures, such as the AI Co-Scientist, our\napproach integrates specialized agents for planning, crime type detection,\nexternal intelligence gathering, and compliance validation. The system features\ndynamic memory management, an AI-Privacy Guard layer for sensitive data\nhandling, and a real-time validation agent employing the Agent-as-a-Judge\nparadigm to ensure continuous narrative quality assurance. Human investigators\nremain firmly in the loop, empowered to review and refine drafts in a\ncollaborative workflow that blends AI efficiency with domain expertise. We\ndemonstrate the versatility of Co-Investigator AI across a range of complex\nfinancial crime scenarios, highlighting its ability to streamline SAR drafting,\nalign narratives with regulatory expectations, and enable compliance teams to\nfocus on higher-order analytical work. This approach marks the beginning of a\nnew era in compliance reporting -- bringing the transformative benefits of AI\nagents to the core of regulatory processes and paving the way for scalable,\nreliable, and transparent SAR generation.", "AI": {"tldr": "\u5229\u7528AI\u667a\u80fd\u4f53\u6846\u67b6Co-Investigator AI\u63d0\u9ad8\u53ef\u7591\u6d3b\u52a8\u62a5\u544a(SAR)\u751f\u6210\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u7684\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u73b0\u6709SAR\u751f\u6210\u6d41\u7a0b\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\uff0c\u800cLLM\u5b58\u5728\u4e8b\u5b9e\u5e7b\u89c9\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u5408\u89c4\u9886\u57df\u3002", "method": "\u6784\u5efa\u5305\u542b\u89c4\u5212\u3001\u72af\u7f6a\u7c7b\u578b\u68c0\u6d4b\u3001\u5916\u90e8\u60c5\u62a5\u6536\u96c6\u548c\u5408\u89c4\u9a8c\u8bc1\u7b49\u4e13\u7528\u667a\u80fd\u4f53\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u5e76\u96c6\u6210\u52a8\u6001\u5185\u5b58\u7ba1\u7406\u3001AI\u9690\u79c1\u4fdd\u62a4\u5c42\u548c\u5b9e\u65f6\u9a8c\u8bc1\u667a\u80fd\u4f53\u3002", "result": "\u5728\u591a\u79cd\u590d\u6742\u7684\u91d1\u878d\u72af\u7f6a\u573a\u666f\u4e2d\uff0cCo-Investigator AI\u80fd\u591f\u7b80\u5316SAR\u8d77\u8349\u6d41\u7a0b\uff0c\u4f7f\u62a5\u544a\u66f4\u7b26\u5408\u76d1\u7ba1\u9884\u671f\uff0c\u5e76\u63d0\u9ad8\u5408\u89c4\u56e2\u961f\u7684\u5de5\u4f5c\u6548\u7387\u3002", "conclusion": "Co-Investigator AI\u6807\u5fd7\u7740\u5408\u89c4\u62a5\u544a\u65b0\u65f6\u4ee3\u7684\u5f00\u59cb\uff0c\u5b9e\u73b0\u4e86AI\u5728\u76d1\u7ba1\u6d41\u7a0b\u4e2d\u7684\u8f6c\u578b\u5e94\u7528\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u53ef\u9760\u548c\u900f\u660e\u7684SAR\u751f\u6210\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2509.08500", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08500", "abs": "https://arxiv.org/abs/2509.08500", "authors": ["Kechen Jiao", "Zhirui Fang", "Jiahao Liu", "Bei Li", "Qifan Wang", "Xinyu Liu", "Junhao Ruan", "Zhongjian Qiao", "Yifan Zhu", "Yaxin Xu", "Jingang Wang", "Xiu Li"], "title": "TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making", "comment": null, "summary": "Using effective generalization capabilities of vision language models (VLMs)\nin context-specific dynamic tasks for embodied artificial intelligence remains\na significant challenge. Although supervised fine-tuned models can better align\nwith the real physical world, they still exhibit sluggish responses and\nhallucination issues in dynamically changing environments, necessitating\nfurther alignment. Existing post-SFT methods, reliant on reinforcement learning\nand chain-of-thought (CoT) approaches, are constrained by sparse rewards and\naction-only optimization, resulting in low sample efficiency, poor consistency,\nand model degradation. To address these issues, this paper proposes\nThought-Centric Preference Optimization (TCPO) for effective embodied\ndecision-making. Specifically, TCPO introduces a stepwise preference-based\noptimization approach, transforming sparse reward signals into richer step\nsample pairs. It emphasizes the alignment of the model's intermediate reasoning\nprocess, mitigating the problem of model degradation. Moreover, by\nincorporating Action Policy Consistency Constraint (APC), it further imposes\nconsistency constraints on the model output. Experiments in the ALFWorld\nenvironment demonstrate an average success rate of 26.67%, achieving a 6%\nimprovement over RL4VLM and validating the effectiveness of our approach in\nmitigating model degradation after fine-tuning. These results highlight the\npotential of integrating preference-based learning techniques with CoT\nprocesses to enhance the decision-making capabilities of vision-language models\nin embodied agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u601d\u60f3\u7684\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff08TCPO\uff09\u6765\u6539\u8fdb\u5177\u8eabAI\u4e2d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u9010\u6b65\u7684\u504f\u597d\u4f18\u5316\u548c\u52a8\u4f5c\u7b56\u7565\u4e00\u81f4\u6027\u7ea6\u675f\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u6a21\u578b\u9000\u5316\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b58\u5728\u54cd\u5e94\u8fdf\u7f13\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u4e14\u6837\u672c\u6548\u7387\u4f4e\uff0c\u4e00\u81f4\u6027\u5dee\u3002", "method": "\u63d0\u51fa\u601d\u60f3\u4e2d\u5fc3\u504f\u597d\u4f18\u5316\uff08TCPO\uff09\u65b9\u6cd5\uff0c\u5c06\u7a00\u758f\u5956\u52b1\u8f6c\u6362\u4e3a\u66f4\u4e30\u5bcc\u7684\u6837\u672c\u5bf9\uff0c\u5e76\u7ed3\u5408\u52a8\u4f5c\u7b56\u7565\u4e00\u81f4\u6027\u7ea6\u675f\uff08APC\uff09\u63d0\u9ad8\u6a21\u578b\u8f93\u51fa\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728ALFWorld\u73af\u5883\u4e2d\uff0cTCPO\u53d6\u5f97\u4e8626.67%\u7684\u5e73\u5747\u6210\u529f\u7387\uff0c\u6bd4RL4VLM\u63d0\u9ad8\u4e866%\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u51cf\u8f7b\u5fae\u8c03\u540e\u6a21\u578b\u9000\u5316\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u504f\u597d\u5b66\u4e60\u548c\u601d\u7ef4\u94fe\u8fc7\u7a0b\u53ef\u4ee5\u6709\u6548\u589e\u5f3a\u5177\u8eab\u667a\u80fd\u4f53\u4e2d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u51b3\u7b56\u80fd\u529b\u3002"}}
{"id": "2509.08593", "categories": ["cs.AI", "stat.ML", "90C05, 68T27", "I.2.3; F.4.1"], "pdf": "https://arxiv.org/pdf/2509.08593", "abs": "https://arxiv.org/abs/2509.08593", "authors": ["Andr\u00e9s Corrada-Emmanuel"], "title": "No-Knowledge Alarms for Misaligned LLMs-as-Judges", "comment": "7 pages, 1 figure", "summary": "If we use LLMs as judges to evaluate the complex decisions of other LLMs, who\nor what monitors the judges? Infinite monitoring chains are inevitable whenever\nwe do not know the ground truth of the decisions by experts and we do not want\nto trust them. One way to ameliorate our evaluation uncertainty is to exploit\nthe use of logical consistency between disagreeing experts. By observing how\nLLM judges agree and disagree while grading other LLMs, we can compute the only\npossible evaluations of their grading ability. For example, if two LLM judges\ndisagree on which tasks a third one completed correctly, they cannot both be\n100\\% correct in their judgments. This logic can be formalized as a Linear\nProgramming problem in the space of integer response counts for any finite\ntest. We use it here to develop no-knowledge alarms for misaligned LLM judges.\nThe alarms can detect, with no false positives, that at least one member or\nmore of an ensemble of judges are violating a user specified grading ability\nrequirement.", "AI": {"tldr": "\u8bba\u6587\u63a2\u7a76\u4e86\u4f7f\u7528LLM\u8bc4\u4f30\u5176\u4ed6LLM\u590d\u6742\u51b3\u7b56\u65f6\u51fa\u73b0\u7684\u65e0\u9650\u76d1\u63a7\u94fe\u95ee\u9898\uff0c\u63d0\u51fa\u5229\u7528\u903b\u8f91\u4e00\u81f4\u6027\u6765\u51cf\u8f7b\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u7ebf\u6027\u89c4\u5212\u65b9\u6cd5\u68c0\u6d4bLLM\u8bc4\u59d4\u7684\u9519\u4f4d\u60c5\u51b5\uff0c\u5b9e\u73b0\u65e0\u8bef\u62a5\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "\u89e3\u51b3LLM\u8bc4\u4f30\u4e2d\u7f3a\u4e4f\u5ba2\u89c2\u6807\u51c6\u548c\u4fe1\u4efb\u95ee\u9898\u3002", "method": "\u5229\u7528LLM\u8bc4\u59d4\u4e4b\u95f4\u5bf9\u5176\u4ed6LLM\u8bc4\u4f30\u7ed3\u679c\u7684\u610f\u89c1\u4e00\u81f4\u6027\u548c\u5dee\u5f02\u6027\uff0c\u6784\u5efa\u7ebf\u6027\u89c4\u5212\u6a21\u578b\u3002", "result": "\u5f00\u53d1\u51fa\u4e00\u79cd\u65e0\u8bef\u62a5\u7684\u5f02\u5e38\u68c0\u6d4b\u673a\u5236\uff0c\u80fd\u591f\u68c0\u6d4b\u51faLLM\u8bc4\u59d4\u7fa4\u4f53\u4e2d\u81f3\u5c11\u4e00\u4e2a\u6210\u5458\u8fdd\u53cd\u7528\u6237\u6307\u5b9a\u7684\u8bc4\u5206\u80fd\u529b\u8981\u6c42\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86LLM\u8bc4\u4f30\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3aLLM\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2509.08682", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08682", "abs": "https://arxiv.org/abs/2509.08682", "authors": ["Guoqing Ma", "Jia Zhu", "Hanghui Guo", "Weijie Shi", "Jiawei Shen", "Jingjiang Liu", "Yidan Liang"], "title": "Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference", "comment": null, "summary": "Multi-agent systems (MAS) are critical for automating complex tasks, yet\ntheir practical deployment is severely hampered by the challenge of failure\nattribution. Current diagnostic tools, which rely on statistical correlations,\nare fundamentally inadequate; on challenging benchmarks like Who\\&When,\nstate-of-the-art methods achieve less than 15\\% accuracy in locating the\nroot-cause step of a failure. To address this critical gap, we introduce the\nfirst failure attribution framework for MAS grounded in multi-granularity\ncausal inference. Our approach makes two key technical contributions: (1) a\nperformance causal inversion principle, which correctly models performance\ndependencies by reversing the data flow in execution logs, combined with\nShapley values to accurately assign agent-level blame; (2) a novel causal\ndiscovery algorithm, CDC-MAS, that robustly identifies critical failure steps\nby tackling the non-stationary nature of MAS interaction data. The framework's\nattribution results directly fuel an automated optimization loop, generating\ntargeted suggestions whose efficacy is validated via counterfactual\nsimulations. Evaluations on the Who\\&When and TRAIL benchmarks demonstrate a\nsignificant leap in performance. Our method achieves up to 36.2\\% step-level\naccuracy. Crucially, the generated optimizations boost overall task success\nrates by an average of 22.4\\%. This work provides a principled and effective\nsolution for debugging complex agent interactions, paving the way for more\nreliable and interpretable multi-agent systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u7c92\u5ea6\u56e0\u679c\u63a8\u7406\u7684\u6545\u969c\u5f52\u56e0\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf(MAS)\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709MAS\u6545\u969c\u8bca\u65ad\u5de5\u5177\u51c6\u786e\u7387\u4f4e\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3MAS\u6545\u969c\u5f52\u56e0\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6027\u80fd\u56e0\u679c\u53cd\u6f14\u539f\u5219\u7ed3\u5408Shapley\u503c\u8fdb\u884c\u667a\u80fd\u4f53\u7ea7\u522b\u8d23\u4efb\u5206\u914d\uff0c\u4ee5\u53ca\u4e00\u79cd\u65b0\u9896\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5CDC-MAS\uff0c\u7528\u4e8e\u8bc6\u522b\u5173\u952e\u6545\u969c\u6b65\u9aa4\u3002", "result": "\u5728Who\\&When\u548cTRAIL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6b65\u9aa4\u7ea7\u51c6\u786e\u7387\u9ad8\u8fbe36.2%\uff0c\u6574\u4f53\u4efb\u52a1\u6210\u529f\u7387\u63d0\u9ad8\u4e8622.4%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8c03\u8bd5\u590d\u6742\u7684\u667a\u80fd\u4f53\u4ea4\u4e92\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4fc3\u8fdb\u4e86\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u7684MAS\u53d1\u5c55\u3002"}}
{"id": "2509.08705", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08705", "abs": "https://arxiv.org/abs/2509.08705", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases", "comment": "9 pages, 7 figures, 2 tables", "summary": "We introduce a novel Theory of Mind (ToM) framework inspired by dual-process\ntheories from cognitive science, integrating a fast, habitual graph-based\nreasoning system (System 1), implemented via graph convolutional networks\n(GCNs), and a slower, context-sensitive meta-adaptive learning system (System\n2), driven by meta-learning techniques. Our model dynamically balances\nintuitive and deliberative reasoning through a learned context gate mechanism.\nWe validate our architecture on canonical false-belief tasks and systematically\nexplore its capacity to replicate hallmark cognitive biases associated with\ndual-process theory, including anchoring, cognitive-load fatigue, framing\neffects, and priming effects. Experimental results demonstrate that our\ndual-process approach closely mirrors human adaptive behavior, achieves robust\ngeneralization to unseen contexts, and elucidates cognitive mechanisms\nunderlying reasoning biases. This work bridges artificial intelligence and\ncognitive theory, paving the way for AI systems exhibiting nuanced, human-like\nsocial cognition and adaptive decision-making capabilities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u8fc7\u7a0b\u7406\u8bba\u7684\u601d\u7ef4\u7406\u8bba\u6846\u67b6\uff0c\u7ed3\u5408\u5feb\u901f\u76f4\u89c9\u7684\u56fe\u5377\u79ef\u7f51\u7edc\u548c\u6162\u901f\u3001\u60c5\u5883\u76f8\u5173\u7684\u5143\u5b66\u4e60\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4eba\u7c7b\u8ba4\u77e5\u504f\u5dee\u7684\u6a21\u62df\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u80fd\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u7279\u522b\u662f\u53cc\u8fc7\u7a0b\u7406\u8bba\u4e2d\u76f4\u89c9\u4e0e\u7406\u6027\u601d\u7ef4\u52a8\u6001\u5e73\u8861\u7684\u6a21\u578b\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u7ed3\u5408\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u548c\u5143\u5b66\u4e60\u6280\u672f\u7684\u53cc\u8fc7\u7a0b\u6a21\u578b\uff0c\u901a\u8fc7\u5b66\u4e60\u4e0a\u4e0b\u6587\u95e8\u673a\u5236\u52a8\u6001\u5e73\u8861\u76f4\u89c9\u548c\u5ba1\u614e\u63a8\u7406\u3002", "result": "\u6a21\u578b\u5728\u7ecf\u5178\u7684\u9519\u8bef\u4fe1\u5ff5\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u826f\u597d\u7684\u6548\u679c\uff0c\u5e76\u6210\u529f\u590d\u5236\u4e86\u951a\u5b9a\u6548\u5e94\u3001\u8ba4\u77e5\u8d1f\u8377\u75b2\u52b3\u3001\u6846\u67b6\u6548\u5e94\u548c\u542f\u52a8\u6548\u5e94\u7b49\u8ba4\u77e5\u504f\u5dee\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u679c\u5f25\u5408\u4e86\u4eba\u5de5\u667a\u80fd\u4e0e\u8ba4\u77e5\u7406\u8bba\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5f00\u53d1\u5177\u6709\u7ec6\u81f4\u5165\u5fae\u3001\u7c7b\u4f3c\u4eba\u7c7b\u7684\u793e\u4f1a\u8ba4\u77e5\u548c\u81ea\u9002\u5e94\u51b3\u7b56\u80fd\u529b\u7684AI\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2509.08713", "categories": ["cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2509.08713", "abs": "https://arxiv.org/abs/2509.08713", "authors": ["Ziming Luo", "Atoosa Kasirzadeh", "Nihar B. Shah"], "title": "The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems", "comment": null, "summary": "AI scientist systems, capable of autonomously executing the full research\nworkflow from hypothesis generation and experimentation to paper writing, hold\nsignificant potential for accelerating scientific discovery. However, the\ninternal workflow of these systems have not been closely examined. This lack of\nscrutiny poses a risk of introducing flaws that could undermine the integrity,\nreliability, and trustworthiness of their research outputs. In this paper, we\nidentify four potential failure modes in contemporary AI scientist systems:\ninappropriate benchmark selection, data leakage, metric misuse, and post-hoc\nselection bias. To examine these risks, we design controlled experiments that\nisolate each failure mode while addressing challenges unique to evaluating AI\nscientist systems. Our assessment of two prominent open-source AI scientist\nsystems reveals the presence of several failures, across a spectrum of\nseverity, which can be easily overlooked in practice. Finally, we demonstrate\nthat access to trace logs and code from the full automated workflow enables far\nmore effective detection of such failures than examining the final paper alone.\nWe thus recommend journals and conferences evaluating AI-generated research to\nmandate submission of these artifacts alongside the paper to ensure\ntransparency, accountability, and reproducibility.", "AI": {"tldr": "AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u53ef\u80fd\u5b58\u5728\u56db\u4e2a\u6f5c\u5728\u7f3a\u9677\uff1a\u57fa\u51c6\u9009\u62e9\u4e0d\u5f53\u3001\u6570\u636e\u6cc4\u6f0f\u3001\u6307\u6807\u6ee5\u7528\u548c\u4e8b\u540e\u9009\u62e9\u504f\u5dee\u3002", "motivation": "\u8bc4\u4f30AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u5185\u90e8\u6d41\u7a0b\uff0c\u4ee5\u786e\u4fdd\u5176\u7814\u7a76\u6210\u679c\u7684\u5b8c\u6574\u6027\u3001\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u8bbe\u8ba1\u5bf9\u7167\u5b9e\u9a8c\uff0c\u9694\u79bb\u6bcf\u4e2a\u6f5c\u5728\u7f3a\u9677\uff0c\u5e76\u8bc4\u4f30\u4e24\u4e2a\u5f00\u6e90AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u3002", "result": "\u53d1\u73b0\u591a\u4e2a\u4e25\u91cd\u7a0b\u5ea6\u4e0d\u540c\u7684\u7f3a\u9677\uff0c\u5e76\u8bc1\u660e\u8bbf\u95ee\u5b8c\u6574\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\u7684\u8ddf\u8e2a\u65e5\u5fd7\u548c\u4ee3\u7801\u80fd\u591f\u66f4\u6709\u6548\u5730\u68c0\u6d4b\u8fd9\u4e9b\u7f3a\u9677\u3002", "conclusion": "\u5efa\u8bae\u671f\u520a\u548c\u4f1a\u8bae\u8981\u6c42\u63d0\u4ea4AI\u751f\u6210\u7814\u7a76\u7684\u8ddf\u8e2a\u65e5\u5fd7\u548c\u4ee3\u7801\uff0c\u4ee5\u786e\u4fdd\u900f\u660e\u5ea6\u3001\u95ee\u8d23\u5236\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2509.08785", "categories": ["cs.AI", "cs.MA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.08785", "abs": "https://arxiv.org/abs/2509.08785", "authors": ["Anup Tuladhar", "Araz Minhas", "Adam Kirton", "Eli Kinney-Lang"], "title": "Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making", "comment": "Extended Abstract for RLDM 2025", "summary": "We present a preliminary experimental platform that explores how narrative\nelements might shape AI decision-making by combining reinforcement learning\n(RL) with language model reasoning. While AI systems can now both make\ndecisions and engage in narrative reasoning, these capabilities have mostly\nbeen studied separately. Our platform attempts to bridge this gap using a\ndual-system architecture to examine how narrative frameworks could influence\nreward-based learning. The system comprises a reinforcement learning policy\nthat suggests actions based on past experience, and a language model that\nprocesses these suggestions through different narrative frameworks to guide\ndecisions. This setup enables initial experimentation with narrative elements\nwhile maintaining consistent environment and reward structures. We implement\nthis architecture in a configurable gridworld environment, where agents receive\nboth policy suggestions and information about their surroundings. The\nplatform's modular design facilitates controlled testing of environmental\ncomplexity, narrative parameters, and the interaction between reinforcement\nlearning and narrative-based decisions. Our logging system captures basic\ndecision metrics, from RL policy values to language model reasoning to action\nselection patterns. While preliminary, this implementation provides a\nfoundation for studying how different narrative frameworks might affect\nreward-based decisions and exploring potential interactions between\noptimization-based learning and symbolic reasoning in AI systems.", "AI": {"tldr": "\u8be5\u5e73\u53f0\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u63a2\u7d22\u53d9\u4e8b\u5143\u7d20\u5982\u4f55\u5f71\u54cdAI\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u51b3\u7b56\u548c\u53d9\u4e8b\u63a8\u7406\u80fd\u529b\u901a\u5e38\u5206\u5f00\u7814\u7a76\uff0c\u672c\u5e73\u53f0\u5c1d\u8bd5\u5c06\u4e24\u8005\u7ed3\u5408\u3002", "method": "\u4f7f\u7528\u53cc\u7cfb\u7edf\u67b6\u6784\uff0c\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u884c\u52a8\u5efa\u8bae\uff0c\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u53d9\u4e8b\u6846\u67b6\u5904\u7406\u5efa\u8bae\u5e76\u6307\u5bfc\u51b3\u7b56\uff0c\u5728\u53ef\u914d\u7f6e\u7684\u7f51\u683c\u4e16\u754c\u73af\u5883\u4e2d\u5b9e\u73b0\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\u4e3a\u7814\u7a76\u53d9\u4e8b\u6846\u67b6\u5982\u4f55\u5f71\u54cd\u57fa\u4e8e\u5956\u52b1\u7684\u51b3\u7b56\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u5e73\u53f0\u4e3a\u7814\u7a76\u4f18\u5316\u5b66\u4e60\u548c\u7b26\u53f7\u63a8\u7406\u5728AI\u7cfb\u7edf\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
