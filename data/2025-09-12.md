<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [An Interval Type-2 Version of Bayes Theorem Derived from Interval Probability Range Estimates Provided by Subject Matter Experts](https://arxiv.org/abs/2509.08834)
*John T. Rickard,William A. Dembski,James Rickards*

Main category: cs.AI

TL;DR: 本文提出了一种区间二型贝叶斯定理，用于处理专家提供的区间概率估计，并提供了一种将区间编码为区间二型模糊隶属函数的新算法。


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯方法假设输入值精确，与现实应用不符，本文扩展贝叶斯定理以处理区间概率估计。

Method: 开发区间二型贝叶斯定理和区间编码算法。

Result: 提出一种新的区间二型贝叶斯定理和区间编码算法，避免潜在的不一致性，并能灵活地编码专家提供的区间。

Conclusion: 本文提出的方法可以更有效地处理现实世界中不确定性较高的贝叶斯推理问题。

Abstract: Bayesian inference is widely used in many different fields to test hypotheses
against observations. In most such applications, an assumption is made of
precise input values to produce a precise output value. However, this is
unrealistic for real-world applications. Often the best available information
from subject matter experts (SMEs) in a given field is interval range estimates
of the input probabilities involved in Bayes Theorem. This paper provides two
key contributions to extend Bayes Theorem to an interval type-2 (IT2) version.
First, we develop an IT2 version of Bayes Theorem that uses a novel and
conservative method to avoid potential inconsistencies in the input IT2 MFs
that otherwise might produce invalid output results. We then describe a novel
and flexible algorithm for encoding SME-provided intervals into IT2 fuzzy
membership functions (MFs), which we can use to specify the input probabilities
in Bayes Theorem. Our algorithm generalizes and extends previous work on this
problem that primarily addressed the encoding of intervals into word MFs for
Computing with Words applications.

</details>


### [2] [Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs](https://arxiv.org/abs/2509.08847)
*Amna Hassan*

Main category: cs.AI

TL;DR: 该论文提出了一种新框架，利用自然语言处理和多模态大型语言模型将游戏设计文档自动转换为Unity游戏原型。


<details>
  <summary>Details</summary>
Motivation: 简化游戏开发流程，缩短设计到实现的周期。

Method: 利用微调的LLaMA-3模型解析游戏设计文档，提取结构化游戏规范，生成Unity兼容的C#代码。

Result: 生成的原型在编译成功率、对游戏设计文档的遵循程度、最佳实践采用和代码模块化等方面均表现出色，平均得分达到4.8/5.0。

Conclusion: 该系统有效地弥补了AI辅助游戏开发中的关键差距，证明大型语言模型在简化游戏开发流程中具有重要价值。

Abstract: This paper presents a novel framework for automated game template generation
by transforming Game Design Documents (GDDs) into functional Unity game
prototypes using Natural Language Processing (NLP) and multi-modal Large
Language Models (LLMs). We introduce an end-to-end system that parses GDDs,
extracts structured game specifications, and synthesizes Unity-compatible C#
code that implements the core mechanics, systems, and architecture defined in
the design documentation. Our approach combines a fine-tuned LLaMA-3 model
specialized for Unity code generation with a custom Unity integration package
that streamlines the implementation process. Evaluation results demonstrate
significant improvements over baseline models, with our fine-tuned model
achieving superior performance (4.8/5.0 average score) compared to
state-of-the-art LLMs across compilation success, GDD adherence, best practices
adoption, and code modularity metrics. The generated templates demonstrate high
adherence to GDD specifications across multiple game genres. Our system
effectively addresses critical gaps in AI-assisted game development,
positioning LLMs as valuable tools in streamlining the transition from game
design to implementation.

</details>


### [3] [Global Constraint LLM Agents for Text-to-Model Translation](https://arxiv.org/abs/2509.08970)
*Junyang Cai,Serdar Kadioglu,Bistra Dilkina*

Main category: cs.AI

TL;DR: 利用多个大型语言模型(LLM)代理，根据全局约束类型分解建模任务，提高将自然语言描述的优化或满足问题转换为MiniZinc模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 将自然语言描述的优化或满足问题转换为MiniZinc模型很困难，需要逻辑推理和约束编程专业知识。

Method: 采用基于多个LLM代理的分解方法，每个代理负责特定类型的全局约束的代码生成，最后整合到完整的MiniZinc模型中。

Result: 实验表明，该方法优于一次性提示和思维链提示等基线方法。

Conclusion: 提出了一种改进的框架，并规划了未来的研究方向。

Abstract: Natural language descriptions of optimization or satisfaction problems are
challenging to translate into correct MiniZinc models, as this process demands
both logical reasoning and constraint programming expertise. We introduce a
framework that addresses this challenge with an agentic approach: multiple
specialized large language model (LLM) agents decompose the modeling task by
global constraint type. Each agent is dedicated to detecting and generating
code for a specific class of global constraint, while a final assembler agent
integrates these constraint snippets into a complete MiniZinc model. By
dividing the problem into smaller, well-defined sub-tasks, each LLM handles a
simpler reasoning challenge, potentially reducing overall complexity. We
conduct initial experiments with several LLMs and show better performance
against baselines such as one-shot prompting and chain-of-thought prompting.
Finally, we outline a comprehensive roadmap for future work, highlighting
potential enhancements and directions for improvement.

</details>


### [4] [ForTIFAI: Fending Off Recursive Training Induced Failure for AI Models](https://arxiv.org/abs/2509.08972)
*Soheil Zibakhsh Shabgahi,Pedram Aghazadeh,Azalia Mirhosseini,Farinaz Koushanfar*

Main category: cs.AI

TL;DR: 本文提出了一种新的损失函数Truncated Cross Entropy (TCE) 来缓解生成式模型在合成数据训练中出现的模型崩溃问题，该方法通过降低模型对高置信度预测的权重来提高模型的保真度，实验结果表明TCE能有效延缓模型崩溃，并具有模型无关性和跨模态的特性。


<details>
  <summary>Details</summary>
Motivation: 随着合成数据生成速度的加快，模型崩溃问题日益突出，现有缓解策略有限。

Method: 提出了一种新的置信度感知损失函数TCE，并从理论和实证上验证了其有效性。

Result: TCE显著延缓了模型崩溃，将模型保真度区间延长了2.3倍以上，并具有模型无关性和跨模态的特性。

Conclusion: 损失函数的设计为解决生成式模型在合成数据时代面临的质量问题提供了一种简单而有效的方法。

Abstract: The increasing reliance on generative AI models has accelerated the
generation rate of synthetic data, with some projections suggesting that most
available new data for training could be machine-generated by 2030. This shift
to a mainly synthetic content presents a critical challenge: repeated training
in synthetic data leads to a phenomenon known as model collapse, where model
performance degrades over generations of training, eventually rendering the
models ineffective. Although prior studies have explored the causes and
detection of model collapse, existing mitigation strategies remain limited.
  In this paper, we identify model overconfidence in their self-generated data
as a key driver of collapse. Building on this observation, we propose a
confidence-aware loss function that downweights high-confidence predictions
during training. We introduce a novel loss function we call Truncated Cross
Entropy (TCE). We demonstrate that TCE significantly delays model collapse in
recursive training.
  We provide a model-agnostic framework that links the loss function design to
model collapse mitigation and validate our approach both theoretically and
empirically, showing that it can extend the model's fidelity interval before
collapse by more than 2.3x. Finally, we show that our method generalizes across
modalities. These findings suggest that the design of loss functions provides a
simple yet powerful tool for preserving the quality of generative models in the
era of increasing synthetic data.

</details>


### [5] [Uncertainty Awareness and Trust in Explainable AI- On Trust Calibration using Local and Global Explanations](https://arxiv.org/abs/2509.08989)
*Carina Newen,Daniel Bodemer,Sonja Glantz,Emmanuel Müller,Magdalena Wischnewski,Lenka Schnaubert*

Main category: cs.AI

TL;DR: 该论文研究了可解释AI中不确定性解释和全局解释的构建指南，并通过实验验证了一种算法在提升用户信任和满意度方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有XAI研究多关注局部解释，忽略全局解释和不确定性解释，该研究旨在弥补这一不足。

Method: 选择一种同时涵盖不确定性、鲁棒性和全局XAI概念的算法，并测试其校准信任的能力，评估其在用户满意度和可解释性方面的表现。

Result: 实验验证了所选算法在提升用户信任和满意度方面的有效性，尽管算法本身复杂。

Conclusion: 该研究为XAI的全局解释和不确定性解释提供了新的见解和指导，并强调了直观可视化在提升用户体验中的重要性。

Abstract: Explainable AI has become a common term in the literature, scrutinized by
computer scientists and statisticians and highlighted by psychological or
philosophical researchers. One major effort many researchers tackle is
constructing general guidelines for XAI schemes, which we derived from our
study. While some areas of XAI are well studied, we focus on uncertainty
explanations and consider global explanations, which are often left out. We
chose an algorithm that covers various concepts simultaneously, such as
uncertainty, robustness, and global XAI, and tested its ability to calibrate
trust. We then checked whether an algorithm that aims to provide more of an
intuitive visual understanding, despite being complicated to understand, can
provide higher user satisfaction and human interpretability.

</details>


### [6] [Instructional Prompt Optimization for Few-Shot LLM-Based Recommendations on Cold-Start Users](https://arxiv.org/abs/2509.09066)
*Haowei Yang,Yushang Zhao,Sitao Min,Bo Su,Chao Yao,Wei Xu*

Main category: cs.AI

TL;DR: 本文提出一种基于提示工程的冷启动用户推荐方法，通过优化指令提示，提高了基于LLM的推荐系统在低数据场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决冷启动用户问题，提高LLM推荐系统的有效性。

Method: 提出一种上下文相关的提示生成方法P(u, Ds) → R̂，结合LLM（BioGPT, LLaMA-2, GPT-4）进行实验，使用token级对齐和embedding空间正则化。

Result: 实验证明，优化的指令结构和示例注入显著提高了模型在低数据场景下的precision@k和NDCG分数，证明了及时组合的语法和功能性作用。

Conclusion: 基于提示的适配方法可以有效解决LLM推荐系统中的冷启动问题。

Abstract: The cold-start user issue further compromises the effectiveness of
recommender systems in limiting access to the historical behavioral
information. It is an effective pipeline to optimize instructional prompts on a
few-shot large language model (LLM) used in recommender tasks. We introduce a
context-conditioned prompt formulation method P(u,\ Ds)\ \rightarrow\
R\widehat, where u is a cold-start user profile, Ds is a curated support set,
and R\widehat is the predicted ranked list of items. Based on systematic
experimentation with transformer-based autoregressive LLMs (BioGPT, LLaMA-2,
GPT-4), we provide empirical evidence that optimal exemplar injection and
instruction structuring can significantly improve the precision@k and NDCG
scores of such models in low-data settings. The pipeline uses token-level
alignments and embedding space regularization with a greater semantic fidelity.
Our findings not only show that timely composition is not merely syntactic but
also functional as it is in direct control of attention scales and decoder
conduct through inference. This paper shows that prompt-based adaptation may be
considered one of the ways to address cold-start recommendation issues in
LLM-based pipelines.

</details>


### [7] [Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games](https://arxiv.org/abs/2509.09071)
*Crystal Qian,Kehang Zhu,John Horton,Benjamin S. Manning,Vivian Tsai,James Wexler,Nithum Thain*

Main category: cs.AI

TL;DR: 本文比较了人类、大型语言模型（LLM）和贝叶斯模型在动态谈判环境中的表现，发现尽管LLM和人类在总收益上相似，但在行为策略上存在显著差异：LLM更保守，人类更具策略性和风险偏好。


<details>
  <summary>Details</summary>
Motivation: 随着自主代理越来越多地承担协调任务，评估代理的性能和协商过程至关重要。

Method: 在动态谈判环境中，比较了人类、LLM（GPT-4o，Gemini 1.5 Pro）和贝叶斯模型的谈判行为和结果。

Result: 贝叶斯模型收益最高，但拒绝交易频繁；LLM和人类收益相似，但LLM更保守，人类更具策略性和风险偏好。

Conclusion: 性能一致性可能掩盖过程和匹配中的根本差异，这对于实际应用至关重要。

Abstract: Coordination tasks traditionally performed by humans are increasingly being
delegated to autonomous agents. As this pattern progresses, it becomes critical
to evaluate not only these agents' performance but also the processes through
which they negotiate in dynamic, multi-agent environments. Furthermore,
different agents exhibit distinct advantages: traditional statistical agents,
such as Bayesian models, may excel under well-specified conditions, whereas
large language models (LLMs) can generalize across contexts. In this work, we
compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in
a dynamic negotiation setting that enables direct, identical-condition
comparisons across populations, capturing both outcomes and behavioral
dynamics. Bayesian agents extract the highest surplus through aggressive
optimization, at the cost of frequent trade rejections. Humans and LLMs can
achieve similar overall surplus, but through distinct behaviors: LLMs favor
conservative, concessionary trades with few rejections, while humans employ
more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find
that performance parity -- a common benchmark in agent evaluation -- can
conceal fundamental differences in process and alignment, which are critical
for practical deployment in real-world coordination tasks.

</details>


### [8] [Anti-Money Laundering Machine Learning Pipelines; A Technical Analysis on Identifying High-risk Bank Clients with Supervised Learning](https://arxiv.org/abs/2509.09127)
*Khashayar Namdar,Pin-Chien Wang,Tushar Raju,Steven Zheng,Fiona Li,Safwat Tahmin Khan*

Main category: cs.AI

TL;DR: 该论文提出一种利用机器学习识别高风险银行客户的综合方法，在多伦多大学IMI竞赛中获得第二名，AUROC达到0.961。


<details>
  <summary>Details</summary>
Motivation: 金融机构需要反洗钱措施，机器学习具有高潜力。

Method: 构建16步的机器学习pipeline，包括数据预处理、特征工程（基于SQL）、模型训练和XAI模块。使用SQLite数据库存储数据。

Result: AUROC达到0.961，标准差0.005，在竞赛中获得第二名。

Conclusion: 该论文提出的pipeline有效且鲁棒，为反洗钱提供了新的方法。

Abstract: Anti-money laundering (AML) actions and measurements are among the priorities
of financial institutions, for which machine learning (ML) has shown to have a
high potential. In this paper, we propose a comprehensive and systematic
approach for developing ML pipelines to identify high-risk bank clients in a
dataset curated for Task 1 of the University of Toronto 2023-2024 Institute for
Management and Innovation (IMI) Big Data and Artificial Intelligence
Competition. The dataset included 195,789 customer IDs, and we employed a
16-step design and statistical analysis to ensure the final pipeline was
robust. We also framed the data in a SQLite database, developed SQL-based
feature engineering algorithms, connected our pre-trained model to the
database, and made it inference-ready, and provided explainable artificial
intelligence (XAI) modules to derive feature importance. Our pipeline achieved
a mean area under the receiver operating characteristic curve (AUROC) of 0.961
with a standard deviation (SD) of 0.005. The proposed pipeline achieved second
place in the competition.

</details>


### [9] [Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective](https://arxiv.org/abs/2509.09154)
*Bui Duc Manh,Soumyaratna Debnath,Zetong Zhang,Shriram Damodaran,Arvind Kumar,Yueyi Zhang,Lu Mi,Erik Cambria,Lin Wang*

Main category: cs.AI

TL;DR: 本文探究了赋能空间智能的计算框架，该框架受神经科学启发，并对现有方法和数据集进行了分析，指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前AI的空间推理能力有限，本文旨在弥合AI与人类空间智能之间的差距。

Method: 提出了一种基于神经科学原理的计算框架，包含六个核心模块：生物启发的多模态感知、多传感器整合、自我中心-客体中心转换、人工认知地图、空间记忆和空间推理。并基于该框架分析了现有方法和数据集。

Result: 构建了一个用于赋能空间推理的计算框架，分析了现有方法的不足，并提出了未来研究方向。

Conclusion: 本文提供了神经科学视角下的空间推理研究框架和路线图，有助于推动该领域发展。

Abstract: Recent advances in agentic AI have led to systems capable of autonomous task
execution and language-based reasoning, yet their spatial reasoning abilities
remain limited and underexplored, largely constrained to symbolic and
sequential processing. In contrast, human spatial intelligence, rooted in
integrated multisensory perception, spatial memory, and cognitive maps, enables
flexible, context-aware decision-making in unstructured environments.
Therefore, bridging this gap is critical for advancing Agentic Spatial
Intelligence toward better interaction with the physical 3D world. To this end,
we first start from scrutinizing the spatial neural models as studied in
computational neuroscience, and accordingly introduce a novel computational
framework grounded in neuroscience principles. This framework maps core
biological functions to six essential computation modules: bio-inspired
multimodal sensing, multi-sensory integration, egocentric-allocentric
conversion, an artificial cognitive map, spatial memory, and spatial reasoning.
Together, these modules form a perspective landscape for agentic spatial
reasoning capability across both virtual and physical environments. On top, we
conduct a framework-guided analysis of recent methods, evaluating their
relevance to each module and identifying critical gaps that hinder the
development of more neuroscience-grounded spatial reasoning modules. We further
examine emerging benchmarks and datasets and explore potential application
domains ranging from virtual to embodied systems, such as robotics. Finally, we
outline potential research directions, emphasizing the promising roadmap that
can generalize spatial reasoning across dynamic or unstructured environments.
We hope this work will benefit the research community with a
neuroscience-grounded perspective and a structured pathway. Our project page
can be found at Github.

</details>


### [10] [ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent Motion Forecasting](https://arxiv.org/abs/2509.09210)
*Xing Gao,Zherui Huang,Weiyao Lin,Xiao Sun*

Main category: cs.AI

TL;DR: 本文提出了一种名为ProgD的渐进式多尺度解码策略，用于提高多智能体运动预测的准确性，并在INTERACTION和Argoverse 2基准测试中取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了多智能体交互的动态演变特性。

Method: 使用动态异构图建模和渐进式多尺度解码策略对多智能体未来场景进行建模，以捕获其动态交互和不确定性。

Result: 在INTERACTION和Argoverse 2基准测试中排名第一。

Conclusion: ProgD有效地提高了多智能体运动预测的准确性，为自动驾驶的安全规划提供了重要支撑。

Abstract: Accurate motion prediction of surrounding agents is crucial for the safe
planning of autonomous vehicles. Recent advancements have extended prediction
techniques from individual agents to joint predictions of multiple interacting
agents, with various strategies to address complex interactions within future
motions of agents. However, these methods overlook the evolving nature of these
interactions. To address this limitation, we propose a novel progressive
multi-scale decoding strategy, termed ProgD, with the help of dynamic
heterogeneous graph-based scenario modeling. In particular, to explicitly and
comprehensively capture the evolving social interactions in future scenarios,
given their inherent uncertainty, we design a progressive modeling of scenarios
with dynamic heterogeneous graphs. With the unfolding of such dynamic
heterogeneous graphs, a factorized architecture is designed to process the
spatio-temporal dependencies within future scenarios and progressively
eliminate uncertainty in future motions of multiple agents. Furthermore, a
multi-scale decoding procedure is incorporated to improve on the future
scenario modeling and consistent prediction of agents' future motion. The
proposed ProgD achieves state-of-the-art performance on the INTERACTION
multi-agent prediction benchmark, ranking $1^{st}$, and the Argoverse 2
multi-world forecasting benchmark.

</details>


### [11] [Enabling Regulatory Multi-Agent Collaboration: Architecture, Challenges, and Solutions](https://arxiv.org/abs/2509.09215)
*Qinnan Hu,Yuntao Wang,Yuan Gao,Zhou Su,Linkang Du*

Main category: cs.AI

TL;DR: 该论文提出了一种基于区块链的分层架构，用于规范多智能体协作，以解决大型语言模型驱动自主智能体的治理和问责挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型驱动的自主智能体具有不可预测的行为和异构能力，带来治理和问责挑战。

Method: 提出了一种基于区块链的分层架构，包含智能体层、区块链数据层和监管应用层，并设计了三个关键模块：行为追踪与仲裁模块、动态声誉评估模块和恶意行为预测模块。

Result: 建立了大型智能体生态系统中值得信赖、有弹性和可扩展的监管机制的系统基础。

Conclusion: 讨论了区块链赋能的多智能体系统监管框架的未来研究方向。

Abstract: Large language models (LLMs)-empowered autonomous agents are transforming
both digital and physical environments by enabling adaptive, multi-agent
collaboration. While these agents offer significant opportunities across
domains such as finance, healthcare, and smart manufacturing, their
unpredictable behaviors and heterogeneous capabilities pose substantial
governance and accountability challenges. In this paper, we propose a
blockchain-enabled layered architecture for regulatory agent collaboration,
comprising an agent layer, a blockchain data layer, and a regulatory
application layer. Within this framework, we design three key modules: (i) an
agent behavior tracing and arbitration module for automated accountability,
(ii) a dynamic reputation evaluation module for trust assessment in
collaborative scenarios, and (iii) a malicious behavior forecasting module for
early detection of adversarial activities. Our approach establishes a
systematic foundation for trustworthy, resilient, and scalable regulatory
mechanisms in large-scale agent ecosystems. Finally, we discuss the future
research directions for blockchain-enabled regulatory frameworks in multi-agent
systems.

</details>


### [12] [Jupiter: Enhancing LLM Data Analysis Capabilities via Notebook and Inference-Time Value-Guided Search](https://arxiv.org/abs/2509.09245)
*Shuocheng Li,Yihao Liu,Silin Du,Wenxuan Zeng,Zhe Xu,Mengyu Zhou,Yeye He,Haoyu Dong,Shi Han,Dongmei Zhang*

Main category: cs.AI

TL;DR: 该论文提出NbQA数据集和Jupiter框架，用于提升大型语言模型在复杂数据分析任务中的多步推理和工具使用能力，实验结果显示其性能优于GPT-4等模型。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型难以胜任复杂数据分析任务中涉及多步推理和工具使用的挑战。

Method: 构建NbQA数据集（包含真实世界Jupyter notebooks中的数据分析任务及其解决方案），并提出Jupiter框架，该框架将数据分析建模为搜索问题，利用蒙特卡洛树搜索生成多种解决方案路径，最终结合价值模型和节点访问计数高效地生成可执行的多步计划。

Result: 在NbQA数据集和InfiAgent-DABench基准测试上，Qwen2.5-7B和14B-Instruct模型分别解决了77.82%和86.38%的任务，性能优于或匹敌GPT-4和其它先进的agent框架。模型在多步推理任务中展现出更好的泛化能力和工具使用推理能力。

Conclusion: NbQA数据集和Jupiter框架有效提升了大型语言模型在复杂数据分析任务中的性能，为未来研究提供了新的方向。

Abstract: Large language models (LLMs) have shown great promise in automating data
science workflows, but existing models still struggle with multi-step reasoning
and tool use, which limits their effectiveness on complex data analysis tasks.
To address this, we propose a scalable pipeline that extracts high-quality,
tool-based data analysis tasks and their executable multi-step solutions from
real-world Jupyter notebooks and associated data files. Using this pipeline, we
introduce NbQA, a large-scale dataset of standardized task-solution pairs that
reflect authentic tool-use patterns in practical data science scenarios. To
further enhance multi-step reasoning, we present Jupiter, a framework that
formulates data analysis as a search problem and applies Monte Carlo Tree
Search (MCTS) to generate diverse solution trajectories for value model
learning. During inference, Jupiter combines the value model and node visit
counts to efficiently collect executable multi-step plans with minimal search
steps. Experimental results show that Qwen2.5-7B and 14B-Instruct models on
NbQA solve 77.82% and 86.38% of tasks on InfiAgent-DABench,
respectively-matching or surpassing GPT-4o and advanced agent frameworks.
Further evaluations demonstrate improved generalization and stronger tool-use
reasoning across diverse multi-step reasoning tasks.

</details>


### [13] [Fusing Knowledge and Language: A Comparative Study of Knowledge Graph-Based Question Answering with LLMs](https://arxiv.org/abs/2509.09272)
*Vaibhav Chaudhary,Neha Soni,Narotam Singh,Amita Kapoor*

Main category: cs.AI

TL;DR: 本文比较了三种构建知识图谱并将其与大型语言模型集成用于问答的方法：spaCy、Stanford CoreNLP-OpenIE和GraphRAG，结果表明OpenIE覆盖范围最广，GraphRAG推理能力最强。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在处理复杂长文本时存在局限性，需要更深入的文本和上下文分析，知识图谱可以增强问答系统。

Method: 比较三种开源技术spaCy、Stanford CoreNLP-OpenIE和GraphRAG构建知识图谱，并将其与LLM集成用于问答，评估其有效性、可行性和适应性。

Result: OpenIE提供最全面的三元组覆盖，GraphRAG表现出优越的推理能力。

Conclusion: 讨论了每种方法的优缺点，并指出了改进基于知识图谱的问答的未来方向。

Abstract: Knowledge graphs, a powerful tool for structuring information through
relational triplets, have recently become the new front-runner in enhancing
question-answering systems. While traditional Retrieval Augmented Generation
(RAG) approaches are proficient in fact-based and local context-based
extraction from concise texts, they encounter limitations when addressing the
thematic and holistic understanding of complex, extensive texts, requiring a
deeper analysis of both text and context. This paper presents a comprehensive
technical comparative study of three different methodologies for constructing
knowledge graph triplets and integrating them with Large Language Models (LLMs)
for question answering: spaCy, Stanford CoreNLP-OpenIE, and GraphRAG, all
leveraging open source technologies. We evaluate the effectiveness,
feasibility, and adaptability of these methods by analyzing their capabilities,
state of development, and their impact on the performance of LLM-based question
answering. Experimental results indicate that while OpenIE provides the most
comprehensive coverage of triplets, GraphRAG demonstrates superior reasoning
abilities among the three. We conclude with a discussion on the strengths and
limitations of each method and provide insights into future directions for
improving knowledge graph-based question answering.

</details>


### [14] [Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning](https://arxiv.org/abs/2509.09284)
*Bingning Huang,Tu Nguyen,Matthieu Zimmer*

Main category: cs.AI

TL;DR: 本文探索了如何将蒙特卡洛树搜索(MCTS)生成的轨迹用于改进基于偏好的强化学习(RL)中的策略优化，特别关注群体相对策略优化(GRPO)算法。


<details>
  <summary>Details</summary>
Motivation: 受LLM中MCTS有效性的启发，尝试将其应用于基于偏好的强化学习策略优化。

Method: 提出了一种分阶段的GRPO训练范式，利用MCTS rollout生成中间轨迹，并进行树状结构的优势估计。

Result: 初步结果表明，这种方法可以稳定更新，更好地反映组合推理质量，但也面临优势饱和和奖励信号崩溃等挑战。

Conclusion: 文章提出了解决这些挑战的启发式和统计方法，并讨论了基于分阶段或树状奖励结构的学习的开放性挑战。

Abstract: Recent advances in reasoning with large language models (LLMs) have shown the
effectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality
intermediate trajectories, particularly in math and symbolic domains. Inspired
by this, we explore how MCTS-derived trajectories, traditionally used for
training value or reward models, can be repurposed to improve policy
optimization in preference-based reinforcement learning (RL). Specifically, we
focus on Group Relative Policy Optimization (GRPO), a recent algorithm that
enables preference-consistent policy learning without value networks. We
propose a staged GRPO training paradigm where completions are derived from
partially revealed MCTS rollouts, introducing a novel tree-structured setting
for advantage estimation. This leads to a rich class of prefix-conditioned
reward signals, which we analyze theoretically and empirically. Our initial
results indicate that while structured advantage estimation can stabilize
updates and better reflect compositional reasoning quality, challenges such as
advantage saturation and reward signal collapse remain. We propose heuristic
and statistical solutions to mitigate these issues and discuss open challenges
for learning under staged or tree-like reward structures.

</details>


### [15] [LightAgent: Production-level Open-source Agentic AI Framework](https://arxiv.org/abs/2509.09292)
*Weige Cai,Tong Zhu,Jinyi Niu,Ruiqi Hu,Lingyao Li,Tenglong Wang,Xiaowu Dai,Weining Shen,Liwen Zhang*

Main category: cs.AI

TL;DR: LightAgent是一个轻量级且功能强大的智能体框架，它有效解决了现有框架在灵活性和简单性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有框架在构建多智能体系统时，在灵活性和效率之间难以平衡。

Method: 提出LightAgent框架，集成了内存、工具和思维树等核心功能，并保持轻量级结构。

Result: LightAgent作为一个完全开源的解决方案，可以无缝集成到主流聊天平台，方便开发者构建自学习智能体。

Conclusion: LightAgent有效地提升了多智能体系统的构建效率和灵活性。

Abstract: With the rapid advancement of large language models (LLMs), Multi-agent
Systems (MAS) have achieved significant progress in various application
scenarios. However, substantial challenges remain in designing versatile,
robust, and efficient platforms for agent deployment. To address these
limitations, we propose \textbf{LightAgent}, a lightweight yet powerful agentic
framework, effectively resolving the trade-off between flexibility and
simplicity found in existing frameworks. LightAgent integrates core
functionalities such as Memory (mem0), Tools, and Tree of Thought (ToT), while
maintaining an extremely lightweight structure. As a fully open-source
solution, it seamlessly integrates with mainstream chat platforms, enabling
developers to easily build self-learning agents. We have released LightAgent at
\href{https://github.com/wxai-space/LightAgent}{https://github.com/wxai-space/LightAgent}

</details>


### [16] [Explaining Tournament Solutions with Minimal Supports](https://arxiv.org/abs/2509.09312)
*Clément Contet,Umberto Grandi,Jérôme Mengin*

Main category: cs.AI

TL;DR: 本文研究了在各种锦标赛规则下，解释候选人获胜原因的认证方法。


<details>
  <summary>Details</summary>
Motivation: 为锦标赛获胜者提供可解释的认证解释。

Method: 识别最小支持，即候选人在其中必胜的最小子锦标赛。

Result: 确定了各种常见锦标赛规则下最小支持的大小，并提出了多项式时间算法来计算它们（加权未覆盖集除外，该问题为NP完全问题）。

Conclusion: 最小支持可以用来产生简洁、可靠和直观的解释。

Abstract: Tournaments are widely used models to represent pairwise dominance between
candidates, alternatives, or teams. We study the problem of providing certified
explanations for why a candidate appears among the winners under various
tournament rules. To this end, we identify minimal supports, minimal
sub-tournaments in which the candidate is guaranteed to win regardless of how
the rest of the tournament is completed (that is, the candidate is a necessary
winner of the sub-tournament). This notion corresponds to an abductive
explanation for the question,"Why does the winner win the tournament", a
central concept in formal explainable AI. We focus on common tournament
solutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule,
the maximin rule, and the weighted uncovered set. For each rule we determine
the size of the smallest minimal supports, and we present polynomial-time
algorithms to compute them for all but the weighted uncovered set, for which
the problem is NP-complete. Finally, we show how minimal supports can serve to
produce compact, certified, and intuitive explanations.

</details>
