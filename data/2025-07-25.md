<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics](https://arxiv.org/abs/2507.17777)
*Theofanis Aravanis,Grigorios Chrimatopoulos,Mohammad Ferdows,Michalis Xenos,Efstratios Em Tzirtzilakis*

Main category: cs.AI

TL;DR: 符号回归结合答案集编程，成功对3D层流矩形管道中的速度和压力场进行建模，得到与解析解一致的简洁方程，展现了其在流体力学中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统机器学习方法的“黑盒”特性，并结合流体力学中对物理机制理解的需求，该研究尝试使用符号回归方法对三维层流进行建模。

Method: 采用PySR库进行符号回归，并结合答案集编程(ASP)进行知识表示，确保生成的符号表达式既统计准确又物理合理。

Result: 得到了与解析解完全一致的简洁、可解释的符号方程，验证了符号回归结合知识表示方法在流体力学建模中的有效性。

Conclusion: 该研究通过将符号回归(SR)与答案集编程(ASP)相结合，成功地对三维层流矩形管道中的速度和压力场进行了建模，得到了与解析解完全一致的简洁、可解释的符号方程，并验证了该方法在流体力学中的应用潜力。

Abstract: Unlike conventional Machine-Learning (ML) approaches, often criticized as
"black boxes", Symbolic Regression (SR) stands out as a powerful tool for
revealing interpretable mathematical relationships in complex physical systems,
requiring no a priori assumptions about models' structures. Motivated by the
recognition that, in fluid mechanics, an understanding of the underlying flow
physics is as crucial as accurate prediction, this study applies SR to model a
fundamental three-dimensional (3D) incompressible flow in a rectangular
channel, focusing on the (axial) velocity and pressure fields under laminar
conditions. By employing the PySR library, compact symbolic equations were
derived directly from numerical simulation data, revealing key characteristics
of the flow dynamics. These equations not only approximate the parabolic
velocity profile and pressure drop observed in the studied fluid flow, but also
perfectly coincide with analytical solutions from the literature. Furthermore,
we propose an innovative approach that integrates SR with the
knowledge-representation framework of Answer Set Programming (ASP), combining
the generative power of SR with the declarative reasoning strengths of ASP. The
proposed hybrid SR/ASP framework ensures that the SR-generated symbolic
expressions are not only statistically accurate, but also physically plausible,
adhering to domain-specific principles. Overall, the study highlights two key
contributions: SR's ability to simplify complex flow behaviours into concise,
interpretable equations, and the potential of knowledge-representation
approaches to improve the reliability and alignment of data-driven SR models
with domain principles. Insights from the examined 3D channel flow pave the way
for integrating such hybrid approaches into efficient frameworks, [...] where
explainable predictions and real-time data analysis are crucial.

</details>


### [2] [I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis](https://arxiv.org/abs/2507.17874)
*SaiBarath Sundar,Pranav Satheesan,Udayaadithya Avadhanam*

Main category: cs.AI

TL;DR: I2I-STRADA通过结构化认知工作流程改进数据分析代理设计。


<details>
  <summary>Details</summary>
Motivation: 现有系统忽略了分析思维背后的结构化推理过程，I2I-STRADA旨在将这一过程形式化。

Method: I2I-STRADA架构，模拟分析中反映认知步骤的模块化子任务。

Result: 在DABstep和DABench基准测试中，I2I-STRADA在规划一致性和洞察力方面优于现有系统。

Conclusion: I2I-STRADA，一个用于数据分析的结构化推理代理架构，通过模拟分析中反映认知步骤的模块化子任务来改进数据分析流程，并在DABstep和DABench基准测试中优于现有系统。

Abstract: Recent advances in agentic systems for data analysis have emphasized
automation of insight generation through multi-agent frameworks, and
orchestration layers. While these systems effectively manage tasks like query
translation, data transformation, and visualization, they often overlook the
structured reasoning process underlying analytical thinking. Reasoning large
language models (LLMs) used for multi-step problem solving are trained as
general-purpose problem solvers. As a result, their reasoning or thinking steps
do not adhere to fixed processes for specific tasks. Real-world data analysis
requires a consistent cognitive workflow: interpreting vague goals, grounding
them in contextual knowledge, constructing abstract plans, and adapting
execution based on intermediate outcomes. We introduce I2I-STRADA
(Information-to-Insight via Structured Reasoning Agent for Data Analysis), an
agentic architecture designed to formalize this reasoning process. I2I-STRADA
focuses on modeling how analysis unfolds via modular sub-tasks that reflect the
cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench
benchmarks show that I2I-STRADA outperforms prior systems in planning coherence
and insight alignment, highlighting the importance of structured cognitive
workflows in agent design for data analysis.

</details>


### [3] [SMARTAPS: Tool-augmented LLMs for Operations Management](https://arxiv.org/abs/2507.17927)
*Timothy Tin Long Yu,Mahdi Mostajabdaveh,Jabo Serge Byusa,Rindra Ramamonjison,Giuseppe Carenini,Kun Mao,Zirui Zhou,Yong Zhang*

Main category: cs.AI

TL;DR: SmartAPS是一个对话式APS系统，使用LLM降低了APS的使用成本和门槛。


<details>
  <summary>Details</summary>
Motivation: 许多客户由于APS持续的咨询成本而无法使用，SmartAPS旨在解决这个问题，使APS更易于访问。

Method: 构建了一个基于工具增强型大型语言模型的对话系统SmartAPS。

Result: SmartAPS为操作规划人员提供了一个直观的自然语言聊天界面，允许他们查询信息、执行反事实推理、接收建议和执行情景分析，从而更好地管理他们的操作。

Conclusion: 本文介绍了SmartAPS系统，一个基于工具增强型大型语言模型的对话系统，旨在提高供应链规划人员对高级计划系统（APS）的可及性。

Abstract: Large language models (LLMs) present intriguing opportunities to enhance user
interaction with traditional algorithms and tools in real-world applications.
An advanced planning system (APS) is a sophisticated software that leverages
optimization to help operations planners create, interpret, and modify an
operational plan. While highly beneficial, many customers are priced out of
using an APS due to the ongoing costs of consultants responsible for
customization and maintenance. To address the need for a more accessible APS
expressed by supply chain planners, we present SmartAPS, a conversational
system built on a tool-augmented LLM. Our system provides operations planners
with an intuitive natural language chat interface, allowing them to query
information, perform counterfactual reasoning, receive recommendations, and
execute scenario analysis to better manage their operation. A short video
demonstrating the system has been released: https://youtu.be/KtIrJjlDbyw

</details>


### [4] [Synthesis of timeline-based planning strategies avoiding determinization](https://arxiv.org/abs/2507.17988)
*Dario Della Monica,Angelo Montanari,Pietro Sala*

Main category: cs.AI

TL;DR: 找到了一种基于定性时间线的规划片段，其策略合成问题可以高效解决。


<details>
  <summary>Details</summary>
Motivation: 现有的基于定性时间线的规划模型的计划存在问题是 PSPACE-完全的，难以直接合成规划策略。

Method: 将基于定性时间线的规划问题规约到确定性有限自动机的非空问题。

Result: 确定了可以高效合成策略的基于定性时间线的规划片段，并找到了对应的 Allen 关系子集。

Conclusion: 本文确定了基于定性时间线的规划的一个片段，其计划存在问题可以直接映射到确定性有限自动机的非空问题，从而可以合成策略，并确定了适合这种确定性片段的 Allen 关系的最大子集。

Abstract: Qualitative timeline-based planning models domains as sets of independent,
but
  interacting, components whose behaviors over time, the timelines, are
governed
  by sets of qualitative temporal constraints (ordering relations), called
  synchronization rules.
  Its plan-existence problem has been shown to be PSPACE-complete; in
  particular, PSPACE-membership has been proved via reduction to the
  nonemptiness problem for nondeterministic finite automata.
  However, nondeterministic automata cannot be directly used to synthesize
  planning strategies as a costly determinization step is needed.
  In this paper, we identify a fragment of qualitative timeline-based planning
  whose plan-existence problem can be directly mapped into the nonemptiness
  problem of deterministic finite automata, which can then
  synthesize strategies.
  In addition, we identify a maximal subset of Allen's relations that fits into
  such a deterministic fragment.

</details>


### [5] [E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI](https://arxiv.org/abs/2507.18004)
*Yusen Peng,Shuhua Mao*

Main category: cs.AI

TL;DR: 该论文提出了一种新方法，通过利用AI模型的错误来提升其创造力，并取得了显著成效。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在探索如何使AI超越模仿，实现真正的创造力，并提出“创造潜力隐藏在失败中”的观点。

Method: 该论文使用LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2和Stable Diffusion等工具，构建了一个基于新颖性、意外性和相关性的复合奖励函数的五阶段生成式流程 (E.A.R.T.H.)，包含错误生成、放大、优化选择、转换和利用反馈五个阶段。

Result: 在优化阶段，创造力评分提高了52.5% (1.179至1.898, t = -5.56, p < 0.001)，最终输出达到2.010，提高了70.4%。改进后的标语更短(减少48.4%)，更新颖(提高40.7%)，相关性略有下降(下降4.0%)。跨模态测试显示标语与图像高度一致(CLIPScore: 0.249; BERTScore F1: 0.816)。人类评估结果显示，60%的输出得分≥4.0，隐喻性标语(平均4.09)优于字面标语(3.99)。

Conclusion: 该论文提出了一种名为E.A.R.T.H.的五阶段生成式流程，通过将模型生成的错误转化为创意资产来增强AI的创造力，最终结果表明，以错误为中心、反馈驱动的生成能够增强创造力，为自我进化、与人类协调的创意AI提供了一条可扩展的路径。

Abstract: How can AI move beyond imitation toward genuine creativity? This paper
proposes the E.A.R.T.H. framework, a five-stage generative pipeline that
transforms model-generated errors into creative assets through Error
generation, Amplification, Refine selection, Transform, and Harness feedback.
Drawing on cognitive science and generative modeling, we posit that "creative
potential hides in failure" and operationalize this via structured prompts,
semantic scoring, and human-in-the-loop evaluation. Implemented using
LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the
pipeline employs a composite reward function based on novelty, surprise, and
relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to
1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4%
improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a
4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment
(CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs
scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones
(3.99). Feedback highlights stylistic precision and emotional resonance. These
results demonstrate that error-centered, feedback-driven generation enhances
creativity, offering a scalable path toward self-evolving, human-aligned
creative AI.

</details>


### [6] [Does visualization help AI understand data?](https://arxiv.org/abs/2507.18022)
*Victoria R. Li,Johnathan Sun,Martin Wattenberg*

Main category: cs.AI

TL;DR: 图表可以帮助AI系统更好地分析数据，提高精度和准确性。


<details>
  <summary>Details</summary>
Motivation: 研究图表是否可以帮助AI系统分析数据。

Method: 对两个商业视觉语言模型GPT 4.1和Claude 3.5进行了一系列实验，比较了三种具有代表性的分析任务中，提供图表和不提供图表两种情况下模型对合成数据集的描述精度和准确性。

Result: 实验结果表明，当原始数据伴随着散点图时，两个系统对合成数据集的描述更加精确和准确，尤其是在数据集复杂度增加的情况下。与两个基线（提供空白图表和数据不匹配的图表）的比较表明，性能的提高是由于图表的内容。

Conclusion: AI系统，如人类一样，可以从数据可视化中受益。

Abstract: Charts and graphs help people analyze data, but can they also be useful to AI
systems? To investigate this question, we perform a series of experiments with
two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three
representative analysis tasks, the two systems describe synthetic datasets more
precisely and accurately when raw data is accompanied by a scatterplot,
especially as datasets grow in complexity. Comparison with two baselines --
providing a blank chart and a chart with mismatched data -- shows that the
improved performance is due to the content of the charts. Our results are
initial evidence that AI systems, like humans, can benefit from visualization.

</details>


### [7] [Multi-Agent Guided Policy Optimization](https://arxiv.org/abs/2507.18059)
*Yueheng Li,Guangming Xie,Zongqing Lu*

Main category: cs.AI

TL;DR: MAGPO框架改进集中式训练与分散式执行，具有理论保证且经实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 现有的集中式训练与分散式执行方法往往低效利用集中式训练或缺乏理论保证。

Method: 提出了一种新颖的MAGPO框架，整合集中式指导和分散式执行，利用自回归联合策略进行可扩展的协调探索，并将其与分散式策略明确对齐。

Result: MAGPO在6种不同环境的43个任务中持续优于强基线，达到甚至超过完全集中式方法的水平。

Conclusion: MAGPO框架在43个任务中持续优于强基线，并在可部署性、可扩展性和理论保证方面取得进展。

Abstract: Due to practical constraints such as partial observability and limited
communication, Centralized Training with Decentralized Execution (CTDE) has
become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning
(MARL). However, existing CTDE methods often underutilize centralized training
or lack theoretical guarantees. We propose Multi-Agent Guided Policy
Optimization (MAGPO), a novel framework that better leverages centralized
training by integrating centralized guidance with decentralized execution.
MAGPO uses an auto-regressive joint policy for scalable, coordinated
exploration and explicitly aligns it with decentralized policies to ensure
deployability under partial observability. We provide theoretical guarantees of
monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across
6 diverse environments. Results show that MAGPO consistently outperforms strong
CTDE baselines and matches or surpasses fully centralized approaches, offering
a principled and practical solution for decentralized multi-agent learning. Our
code and experimental data can be found in https://github.com/liyheng/MAGPO.

</details>


### [8] [AlphaGo Moment for Model Architecture Discovery](https://arxiv.org/abs/2507.18074)
*Yixiu Liu,Yang Nan,Weixian Xu,Xiangkun Hu,Lyumanshan Ye,Zhen Qin,Pengfei Liu*

Main category: cs.AI

TL;DR: AI系统ASI-Arch自主发现了106种最先进的AI架构，突破了人类认知能力的限制，实现了AI的自主创新。


<details>
  <summary>Details</summary>
Motivation: AI研究的进展受到人类认知能力的限制，ASI-Arch旨在通过让AI进行自主创新来解决这一瓶颈问题。

Method: ASI-Arch系统能够进行端到端的科学研究，自主提出新的架构概念，将其转换为可执行代码，并通过实验验证其性能。

Result: 发现了106种创新的、最先进的线性注意力架构，优于人类设计的基线，并建立了科学发现的第一个经验缩放定律。

Conclusion: ASI-Arch，一个用于AI研究的Artificial Superintelligence系统，在神经架构发现领域实现了突破，通过自主创新打破了人类认知能力的限制。它进行了1773次自主实验，发现了106种创新的线性注意力架构，优于人类设计的基线，并揭示了新的架构创新路径。研究还建立了科学发现的第一个经验缩放定律，证明了架构突破可以通过计算进行扩展。

Abstract: While AI systems demonstrate exponentially improving capabilities, the pace
of AI research itself remains linearly bounded by human cognitive capacity,
creating an increasingly severe development bottleneck. We present ASI-Arch,
the first demonstration of Artificial Superintelligence for AI research
(ASI4AI) in the critical domain of neural architecture discovery--a fully
autonomous system that shatters this fundamental constraint by enabling AI to
conduct its own architectural innovation. Moving beyond traditional Neural
Architecture Search (NAS), which is fundamentally limited to exploring
human-defined spaces, we introduce a paradigm shift from automated optimization
to automated innovation. ASI-Arch can conduct end-to-end scientific research in
the domain of architecture discovery, autonomously hypothesizing novel
architectural concepts, implementing them as executable code, training and
empirically validating their performance through rigorous experimentation and
past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000
GPU hours, culminating in the discovery of 106 innovative, state-of-the-art
(SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed
unexpected strategic insights invisible to human players, our AI-discovered
architectures demonstrate emergent design principles that systematically
surpass human-designed baselines and illuminate previously unknown pathways for
architectural innovation. Crucially, we establish the first empirical scaling
law for scientific discovery itself--demonstrating that architectural
breakthroughs can be scaled computationally, transforming research progress
from a human-limited to a computation-scalable process. We provide
comprehensive analysis of the emergent design patterns and autonomous research
capabilities that enabled these breakthroughs, establishing a blueprint for
self-accelerating AI systems.

</details>


### [9] [Agentic AI framework for End-to-End Medical Data Inference](https://arxiv.org/abs/2507.18115)
*Soorya Ram Shimgekar,Shayan Vassef,Abhay Goyal,Navin Kumar,Koustuv Saha*

Main category: cs.AI

TL;DR: Agentic AI automates the entire clinical data pipeline for ML, reducing costs and manual effort through modular agents.


<details>
  <summary>Details</summary>
Motivation: To address the high cost and labor intensity of deploying machine learning solutions in healthcare due to fragmented workflows, compatibility issues, and data privacy concerns.

Method: A system of modular, task-specific agents handles structured and unstructured data, automating feature selection, model selection, and preprocessing.

Result: The framework was evaluated on publicly available datasets from geriatrics, palliative care, and colonoscopy imaging, demonstrating automated data processing and model deployment.

Conclusion: This paper introduces an Agentic AI framework that automates the entire clinical data pipeline for machine learning in healthcare, reducing costs and manual effort.

Abstract: Building and deploying machine learning solutions in healthcare remains
expensive and labor-intensive due to fragmented preprocessing workflows, model
compatibility issues, and stringent data privacy constraints. In this work, we
introduce an Agentic AI framework that automates the entire clinical data
pipeline, from ingestion to inference, through a system of modular,
task-specific agents. These agents handle both structured and unstructured
data, enabling automatic feature selection, model selection, and preprocessing
recommendation without manual intervention. We evaluate the system on publicly
available datasets from geriatrics, palliative care, and colonoscopy imaging.
For example, in the case of structured data (anxiety data) and unstructured
data (colonoscopy polyps data), the pipeline begins with file-type detection by
the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring
privacy compliance, where we first identify the data type and then anonymize
it. The Feature Extraction Agent identifies features using an embedding-based
approach for tabular data, extracting all column names, and a multi-stage
MedGemma-based approach for image data, which infers modality and disease name.
These features guide the Model-Data Feature Matcher Agent in selecting the
best-fit model from a curated repository. The Preprocessing Recommender Agent
and Preprocessing Implementor Agent then apply tailored preprocessing based on
data type and model requirements. Finally, the ``Model Inference Agent" runs
the selected model on the uploaded data and generates interpretable outputs
using tools like SHAP, LIME, and DETR attention maps. By automating these
high-friction stages of the ML lifecycle, the proposed framework reduces the
need for repeated expert intervention, offering a scalable, cost-efficient
pathway for operationalizing AI in clinical environments.

</details>


### [10] [Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes](https://arxiv.org/abs/2507.18123)
*Sedigh Khademi,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila,Jim Black*

Main category: cs.AI

TL;DR: 利用NLP和主动学习技术，从急诊记录中快速识别疫苗安全问题，提高了疫苗上市后监测效率。


<details>
  <summary>Details</summary>
Motivation: 疫苗上市后监测系统的重要性日益增加，需要快速有效的方法来检测疫苗安全问题。急诊分诊记录包含关键的患者信息，可以为及时的疫苗安全信号监测做出重大贡献。

Method: 使用自然语言处理技术和主动学习方法，对急诊分诊记录进行分析，以检测潜在的疫苗安全问题。

Result: 创建了一个能够有效检测疫苗安全问题的分类器，提高了疫苗安全监测的效率和准确性。

Conclusion: 本研究结合主动学习、数据增强和评估技术，从急诊分诊记录中创建了一个用于增强疫苗安全监测的分类器。

Abstract: The rapid development of COVID-19 vaccines has showcased the global
communitys ability to combat infectious diseases. However, the need for
post-licensure surveillance systems has grown due to the limited window for
safety data collection in clinical trials and early widespread implementation.
This study aims to employ Natural Language Processing techniques and Active
Learning to rapidly develop a classifier that detects potential vaccine safety
issues from emergency department notes. ED triage notes, containing expert,
succinct vital patient information at the point of entry to health systems, can
significantly contribute to timely vaccine safety signal surveillance. While
keyword-based classification can be effective, it may yield false positives and
demand extensive keyword modifications. This is exacerbated by the infrequency
of vaccination-related ED presentations and their similarity to other reasons
for ED visits. NLP offers a more accurate and efficient alternative, albeit
requiring annotated data, which is often scarce in the medical field. Active
learning optimizes the annotation process and the quality of annotated data,
which can result in faster model implementation and improved model performance.
This work combines active learning, data augmentation, and active learning and
evaluation techniques to create a classifier that is used to enhance vaccine
safety surveillance from ED triage notes.

</details>


### [11] [Logical Characterizations of GNNs with Mean Aggregation](https://arxiv.org/abs/2507.18145)
*Moritz Schönherr,Carsten Lutz*

Main category: cs.AI

TL;DR: 不同GNNs聚合函数的表达能力差异与相应的模态逻辑有关，平均值GNNs的表达能力介于最大值和求和之间。


<details>
  <summary>Details</summary>
Motivation: 研究不同GNNs聚合函数的表达能力差异。

Method: 通过分析不同聚合函数(平均值、最大值、求和)的GNNs在非均匀和均匀设置下的表达能力，并将其与相应的模态逻辑进行比较。

Result: 在非均匀设置下，平均值GNNs的表达能力与比例模态逻辑相同，高于最大值GNNs，低于求和GNNs；在均匀设置下，在连续组合函数和阈值分类函数的假设下，平均值GNNs的表达能力与无交替模态逻辑相同，低于求和GNNs和最大值GNNs。

Conclusion: 本文研究了以平均值作为聚合函数的图神经网络（GNNs）的表达能力，并在非均匀和均匀两种设置下，分别将其表达能力与比例模态逻辑和无交替模态逻辑联系起来。

Abstract: We study the expressive power of graph neural networks (GNNs) with mean as
the aggregation function. In the non-uniform setting, we show that such GNNs
have exactly the same expressive power as ratio modal logic, which has modal
operators expressing that at least a certain ratio of the successors of a
vertex satisfies a specified property. The non-uniform expressive power of mean
GNNs is thus higher than that of GNNs with max aggregation, but lower than for
sum aggregation--the latter are characterized by modal logic and graded modal
logic, respectively. In the uniform setting, we show that the expressive power
relative to MSO is exactly that of alternation-free modal logic, under the
natural assumptions that combination functions are continuous and
classification functions are thresholds. This implies that, relative to MSO and
in the uniform setting, mean GNNs are strictly less expressive than sum GNNs
and max GNNs. When any of the assumptions is dropped, the expressive power
increases.

</details>


### [12] [Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory](https://arxiv.org/abs/2507.18178)
*Mutian Yang,Jiandong Gao,Ji Wu*

Main category: cs.AI

TL;DR: 研究提出框架，区分LLM的知识和推理，发现推理具有领域特异性，参数扩展利好两者，知识主要在低层网络，推理在高层网络。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLM）中知识和推理的贡献，以及它们之间的相互作用。

Method: 提出了一种认知归因框架，将LLM的认知过程分解为知识检索和推理调整两个阶段，并通过分析不同认知模式（快速思维和慢速思维）下的性能来量化知识和推理的贡献。

Result: 1. 推理调整具有领域特异性；2. 参数扩展提高了知识和推理能力，知识提升更显著；3. 知识主要位于网络较低层，推理位于较高层。

Conclusion: 该研究提出了一种认知归因框架，将大型语言模型（LLM）的认知过程分解为知识检索和推理调整两个阶段，并通过分析不同认知模式下的性能来量化知识和推理的贡献。研究结果表明：推理调整具有领域特异性；参数扩展提高了知识和推理能力，但知识提升更显著；知识主要位于网络较低层，推理位于较高层。该框架有助于从“解耦”视角理解LLM，并为现有研究提供新的见解。

Abstract: While large language models (LLMs) leverage both knowledge and reasoning
during inference, the capacity to distinguish between them plays a pivotal role
in model analysis, interpretability, and development. Inspired by dual-system
cognitive theory, we propose a cognition attribution framework to decouple the
contribution of knowledge and reasoning. In particular, the cognition of LLMs
is decomposed into two distinct yet complementary phases: knowledge retrieval
(Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs
are prompted to generate answers under two different cognitive modes, fast
thinking and slow thinking, respectively. The performance under different
cognitive modes is analyzed to quantify the contribution of knowledge and
reasoning. This architecture is employed to 15 LLMs across 3 datasets. Results
reveal: (1) reasoning adjustment is domain-specific, benefiting
reasoning-intensive domains (e.g., mathematics, physics, and chemistry) and
potentially imparing knowledge-intensive domains. (2) Parameter scaling
improves both knowledge and reasoning, with knowledge improvements being more
pronounced. Additionally, parameter scaling make LLMs reasoning significantly
more prudent, while moderately more intelligent. (3) Knowledge primarily
resides in lower network layers, while reasoning operates in higher layers. Our
framework not only helps understand LLMs from a "decoupling" perspective, but
also provides new insights into existing research, including scaling laws,
hierarchical knowledge editing, and limitations of small-model reasoning.

</details>


### [13] [Comparing Non-minimal Semantics for Disjunction in Answer Set Programming](https://arxiv.org/abs/2507.18198)
*Felicidad Aguado,Pedro Cabalar,Brais Muñiz,Gilberto Pérez,Concepción Vidal*

Main category: cs.AI

TL;DR: 四种非极小语义，三种等价，一种更弱。


<details>
  <summary>Details</summary>
Motivation: 比较Answer Set Programming中四种不同的非极小语义，探究其关系。

Method: 比较了四种不同的Answer Set Programming中非极小语义的解集，并证明了其中三种的等价性。

Result: 证明了三种非极小语义的等价性，并指出其与第四种非极小语义的关系。

Conclusion: 本文证明了Answer Set Programming中四种非极小语义的三种(Forks, Justified Models和DI语义的合理放松)实际上是相同的，构成了一种共同的方法。这种共同语义总是提供程序稳定模型的超集，并且严格强于第四种方法(Strongly Supported Models)。

Abstract: In this paper, we compare four different semantics for disjunction in Answer
Set Programming that, unlike stable models, do not adhere to the principle of
model minimality. Two of these approaches, Cabalar and Mu\~niz' \emph{Justified
Models} and Doherty and Szalas' \emph{Strongly Supported Models}, directly
provide an alternative non-minimal semantics for disjunction. The other two,
Aguado et al's \emph{Forks} and Shen and Eiter's \emph{Determining Inference}
(DI) semantics, actually introduce a new disjunction connective, but are
compared here as if they constituted new semantics for the standard disjunction
operator. We are able to prove that three of these approaches (Forks, Justified
Models and a reasonable relaxation of the DI semantics) actually coincide,
constituting a common single approach under different definitions. Moreover,
this common semantics always provides a superset of the stable models of a
program (in fact, modulo any context) and is strictly stronger than the fourth
approach (Strongly Supported Models), that actually treats disjunctions as in
classical logic.

</details>


### [14] [Foundations for Risk Assessment of AI in Protecting Fundamental Rights](https://arxiv.org/abs/2507.18290)
*Antonino Rotolo,Beatrice Ferrigno,Jose Miguel Angel Garcia Godinez,Claudio Novelli,Giovanni Sartor*

Main category: cs.AI

TL;DR: 提出一个结合定义性平衡和可推翻推理的AI风险评估框架，以应对欧盟AI法案中的法律合规和基本权利保护挑战。


<details>
  <summary>Details</summary>
Motivation: 解决欧盟人工智能法案背景下人工智能的法律合规和基本权利保护的复杂性。

Method: 整合定义性平衡和可推翻的推理方法，对人工智能部署场景进行分析，识别潜在的法律违规行为和对基本权利的多层影响。

Result: 提供了一个用于人工智能风险分析的逻辑解释的哲学基础，并强调了该方法对高风险人工智能系统和通用人工智能系统更广泛的适用性。

Conclusion: 提出了一种用于人工智能风险评估的概念框架，特别是在欧盟人工智能法案的背景下，该框架通过整合定义性平衡和可推翻的推理来解决法律合规和基本权利保护的复杂性。

Abstract: This chapter introduces a conceptual framework for qualitative risk
assessment of AI, particularly in the context of the EU AI Act. The framework
addresses the complexities of legal compliance and fundamental rights
protection by itegrating definitional balancing and defeasible reasoning.
Definitional balancing employs proportionality analysis to resolve conflicts
between competing rights, while defeasible reasoning accommodates the dynamic
nature of legal decision-making. Our approach stresses the need for an analysis
of AI deployment scenarios and for identifying potential legal violations and
multi-layered impacts on fundamental rights. On the basis of this analysis, we
provide philosophical foundations for a logical account of AI risk analysis. In
particular, we consider the basic building blocks for conceptually grasping the
interaction between AI deployment scenarios and fundamental rights,
incorporating in defeasible reasoning definitional balancing and arguments
about the contextual promotion or demotion of rights. This layered approach
allows for more operative models of assessment of both high-risk AI systems and
General Purpose AI (GPAI) systems, emphasizing the broader applicability of the
latter. Future work aims to develop a formal model and effective algorithms to
enhance AI risk assessment, bridging theoretical insights with practical
applications to support responsible AI governance.

</details>


### [15] [The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams](https://arxiv.org/abs/2507.18337)
*Peter Baumgartner,Lachlan McGinness*

Main category: cs.AI

TL;DR: 利用多种技术自动批改物理考试，并在1500份真实试卷上进行了测试。


<details>
  <summary>Details</summary>
Motivation: 自动批改物理考试，提高效率并保证客观性。

Method: 结合计算机代数系统、SMT求解器、项重写系统和大型语言模型对学生答案进行形式化、校正和自动推理，以评估答案正确性。

Result: 在2023年澳大利亚物理奥林匹克竞赛的1500份真实学生考试答案上进行了评估。

Conclusion: 本文提出了一种自动批改物理考试的方法，该方法结合了计算机代数系统、SMT求解器和项重写系统，并利用大型语言模型处理学生答案，最终在1500份真实考试答案上进行评估。

Abstract: We present our method for automatically marking Physics exams. The marking
problem consists in assessing typed student answers for correctness with
respect to a ground truth solution. This is a challenging problem that we seek
to tackle using a combination of a computer algebra system, an SMT solver and a
term rewriting system. A Large Language Model is used to interpret and remove
errors from student responses and rewrite these in a machine readable format.
Once formalized and language-aligned, the next step then consists in applying
automated reasoning techniques for assessing student solution correctness. We
consider two methods of automated theorem proving: off-the-shelf SMT solving
and term rewriting systems tailored for physics problems involving
trigonometric expressions. The development of the term rewrite system and
establishing termination and confluence properties was not trivial, and we
describe it in some detail in the paper. We evaluate our system on a rich pool
of over 1500 real-world student exam responses from the 2023 Australian Physics
Olympiad.

</details>


### [16] [Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios](https://arxiv.org/abs/2507.18368)
*Zhuang Qiang Bok,Watson Wei Khong Chua*

Main category: cs.AI

TL;DR: ConDiFi基准评估了LLM在金融领域的推理能力，发现模型间存在显著差异，一些模型更擅长生成可操作的金融见解。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理基准侧重于事实准确性和逐步逻辑，忽略了金融领域对创造性和在不确定性下生成合理未来结果的需求。

Method: 构建ConDiFi基准，包含发散性推理的宏观金融提示和收敛性推理的多跳对抗性选择题，并用其评估了14个领先模型。

Result: GPT-4o在新颖性和可操作性方面表现不佳，而DeepSeek-R1和Cohere Command R+等模型在生成可用于投资决策的实用见解方面表现出色。

Conclusion: ConDiFi 基准测试揭示了大型语言模型在金融任务中，尤其是在发散性和收敛性思维方面的显著差异，一些模型在生成可行投资建议方面表现突出，另一些则不然，为安全有效地将大型语言模型应用于金融领域提供了新的评估视角。

Abstract: Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step
logic. In finance, however, professionals must not only converge on optimal
decisions but also generate creative, plausible futures under uncertainty. We
introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent
thinking in LLMs for financial tasks.
  ConDiFi features 607 macro-financial prompts for divergent reasoning and 990
multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we
evaluated 14 leading models and uncovered striking differences. Despite high
fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models
like DeepSeek-R1 and Cohere Command R+ rank among the top for generating
actionable, insights suitable for investment decisions. ConDiFi provides a new
perspective to assess reasoning capabilities essential to safe and strategic
deployment of LLMs in finance.

</details>
