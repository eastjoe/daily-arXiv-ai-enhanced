<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Unified Crew Planning and Replanning Optimization in Multi-Line Metro Systems Considering Workforce Heterogeneity](https://arxiv.org/abs/2509.14251)
*Qihang Chen*

Main category: cs.AI

TL;DR: 该论文提出一种统一的优化框架，用于解决多线路地铁人员计划和重新计划问题，并通过实验证明其优于基准启发式算法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单线地铁，缺乏跨线协调和快速重新计划能力，该论文旨在解决这一问题。

Method: 提出了一种分层时空网络模型，并基于列生成和最短路径调整算法进行求解。

Result: 实验结果表明，该方法在成本降低和任务完成方面优于基准启发式算法，尤其在应对中断情况下的紧急任务时效率更高。

Conclusion: 跨线协调和全局优化对于多线路地铁系统运行至关重要，对智慧城市公共交通的有效和可靠运行具有重要意义。

Abstract: Metro crew planning is a key component of smart city development as it
directly impacts the operational efficiency and service reliability of public
transportation. With the rapid expansion of metro networks, effective
multi-line scheduling and emergency management have become essential for
large-scale seamless operations. However, current research focuses primarily on
individual metro lines,with insufficient attention on cross-line coordination
and rapid replanning during disruptions. Here, a unified optimization framework
is presented for multi-line metro crew planning and replanning with
heterogeneous workforce. Specifically, a hierarchical time-space network model
is proposed to represent the unified crew action space, and computationally
efficient constraints and formulations are derived for the crew's heterogeneous
qualifications and preferences. Solution algorithms based on column generation
and shortest path adjustment are further developed, utilizing the proposed
network model. Experiments with real data from Shanghai and Beijing Metro
demonstrate that the proposed methods outperform benchmark heuristics in both
cost reduction and task completion,and achieve notable efficiency gains by
incorporating cross-line operations, particularly for urgent tasks during
disruptions. This work highlights the role of global optimization and
cross-line coordination in multi-line metro system operations, providing
insights into the efficient and reliable functioning of public transportation
in smart cities.

</details>


### [2] [From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing](https://arxiv.org/abs/2509.14289)
*Lanxiao Huang,Daksh Dave,Ming Jin,Tyler Cody,Peter Beling*

Main category: cs.AI

TL;DR: LLM用于渗透测试的有效性和可靠性仍不明确，该研究评估了多种LLM代理在现实渗透测试场景中的性能，并通过增强功能（GCM、IAM、CCI、AP、RTM）提高了模块化代理的性能。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在渗透测试中的有效性和可靠性，并改进LLM代理的架构和功能。

Method: 对多种LLM代理（单代理到模块化设计）进行评估，并通过五个核心功能增强（GCM、IAM、CCI、AP、RTM）来隔离其影响。

Result: 定向增强显著提高了模块化代理的性能，尤其是在复杂、多步骤和实时渗透测试任务中。

Conclusion: LLM在渗透测试中具有潜力，但需要改进其架构和功能以提高有效性和可靠性。

Abstract: Large language models (LLMs) are increasingly used to automate or augment
penetration testing, but their effectiveness and reliability across attack
phases remain unclear. We present a comprehensive evaluation of multiple
LLM-based agents, from single-agent to modular designs, across realistic
penetration testing scenarios, measuring empirical performance and recurring
failure patterns. We also isolate the impact of five core functional
capabilities via targeted augmentations: Global Context Memory (GCM),
Inter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive
Planning (AP), and Real-Time Monitoring (RTM). These interventions support,
respectively: (i) context coherence and retention, (ii) inter-component
coordination and state management, (iii) tool use accuracy and selective
execution, (iv) multi-step strategic planning, error detection, and recovery,
and (v) real-time dynamic responsiveness. Our results show that while some
architectures natively exhibit subsets of these properties, targeted
augmentations substantially improve modular agent performance, especially in
complex, multi-step, and real-time penetration testing tasks.

</details>


### [3] [Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents](https://arxiv.org/abs/2509.14382)
*Daniel Röder,Akhil Juneja,Roland Roller,Sven Schmeier*

Main category: cs.AI

TL;DR: 该论文提出了一种模块化评估框架，用于对大型语言模型驱动的Web智能体的行为进行细粒度错误分析，以改进其鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注Web智能体的整体成功率，忽略了中间错误，导致难以深入了解其失效模式并进行改进。

Method: 提出了一种模块化评估框架，将智能体流程分解成可解释的阶段，以便进行详细的错误分析。以SeeAct框架和Mind2Web数据集为例进行了案例研究。

Result: 该方法揭示了标准指标无法发现的实际缺陷，为构建更强大和通用的Web智能体铺平了道路。

Conclusion: 细粒度的错误分析对于改进大型语言模型驱动的Web智能体至关重要。

Abstract: Web agents powered by large language models (LLMs) can autonomously perform
complex, multistep tasks in dynamic web environments. However, current
evaluations mostly focus on the overall success while overlooking intermediate
errors. This limits insight into failure modes and hinders systematic
improvement. This work analyzes existing benchmarks and highlights the lack of
fine-grained diagnostic tools. To address this gap, we propose a modular
evaluation framework that decomposes agent pipelines into interpretable stages
for detailed error analysis. Using the SeeAct framework and the Mind2Web
dataset as a case study, we show how this approach reveals actionable
weaknesses missed by standard metrics - paving the way for more robust and
generalizable web agents.

</details>


### [4] [VCBench: Benchmarking LLMs in Venture Capital](https://arxiv.org/abs/2509.14448)
*Rick Chen,Joseph Ternasky,Afriyie Samuel Kwesi,Ben Griffin,Aaron Ontoyin Yin,Zakari Salifu,Kelvin Amoaba,Xianling Mu,Fuat Alican,Yigit Ihlamur*

Main category: cs.AI

TL;DR: VCBench，首个预测风险投资创始人成功的基准测试，大型语言模型显著优于基准。


<details>
  <summary>Details</summary>
Motivation: 现有基准加速AGI发展，但缺乏针对风险投资领域稀疏信号、不确定结果的基准。

Method: 构建VCBench数据集（9000个匿名创始人档案），并评估九种最先进的大型语言模型的预测能力。

Result: DeepSeek-V3精确度是基线的六倍多，GPT-4o的F0.5最高，大多数模型优于人类基准。

Conclusion: VCBench为可重复和隐私保护的AGI早期风险预测评估建立了社区驱动的标准。

Abstract: Benchmarks such as SWE-bench and ARC-AGI demonstrate how shared datasets
accelerate progress toward artificial general intelligence (AGI). We introduce
VCBench, the first benchmark for predicting founder success in venture capital
(VC), a domain where signals are sparse, outcomes are uncertain, and even top
investors perform modestly. At inception, the market index achieves a precision
of 1.9%. Y Combinator outperforms the index by a factor of 1.7x, while tier-1
firms are 2.9x better. VCBench provides 9,000 anonymized founder profiles,
standardized to preserve predictive features while resisting identity leakage,
with adversarial tests showing more than 90% reduction in re-identification
risk. We evaluate nine state-of-the-art large language models (LLMs).
DeepSeek-V3 delivers over six times the baseline precision, GPT-4o achieves the
highest F0.5, and most models surpass human benchmarks. Designed as a public
and evolving resource available at vcbench.com, VCBench establishes a
community-driven standard for reproducible and privacy-preserving evaluation of
AGI in early-stage venture forecasting.

</details>


### [5] [From Mimicry to True Intelligence (TI) -- A New Paradigm for Artificial General Intelligence](https://arxiv.org/abs/2509.14474)
*Meltem Subasioglu,Nevzat Subasioglu*

Main category: cs.AI

TL;DR: 本文提出了一种基于人类大脑认知架构的通用人工智能（AGI）新范式，定义了“真智能”（TI）的六个核心组成部分，并提出了一个五级AGI分类法，为AGI研究提供了清晰的路线图。


<details>
  <summary>Details</summary>
Motivation: 当前基于性能的AGI定义不足以指导研究，本文旨在通过关注认知过程而非外部表现来定义AGI。

Method: 提出了一种新的AGI定义，该定义基于人类大脑的认知架构，并提出了一个五级AGI分类法。

Result: 提出了“真智能”（TI）的概念及其六个核心组成部分，以及一个基于这五个可衡量组成部分的五级AGI分类法。

Conclusion: 五级AGI在功能上与TI等效，为AGI研究提供了清晰的、可操作的路径。

Abstract: The debate around Artificial General Intelligence (AGI) remains open due to
two fundamentally different goals: replicating human-like performance versus
replicating human-like cognitive processes. We argue that current
performance-based definitions are inadequate because they provide no clear,
mechanism-focused roadmap for research, and they fail to properly define the
qualitative nature of genuine intelligence. Drawing inspiration from the human
brain, we propose a new paradigm that shifts the focus from external mimicry to
the development of foundational cognitive architectures. We define True
Intelligence (TI) as a system characterized by six core components: embodied
sensory fusion, core directives, dynamic schemata creation, a
highly-interconnected multi-expert architecture, an orchestration layer, and
lastly, the unmeasurable quality of Interconnectedness, which we hypothesize
results in consciousness and a subjective experience. We propose a practical,
five-level taxonomy of AGI based on the number of the first five measurable
components a system exhibits. This framework provides a clear path forward with
developmental milestones that directly address the challenge of building
genuinely intelligent systems. We contend that once a system achieves Level-5
AGI by implementing all five measurable components, the difference between it
and TI remains as a purely philosophical debate. For practical purposes - and
given theories indicate consciousness is an emergent byproduct of integrated,
higher-order cognition - we conclude that a fifth-level AGI is functionally and
practically equivalent to TI. This work synthesizes diverse insights from
analytical psychology, schema theory, metacognition, modern brain architectures
and latest works in AI to provide the first holistic, mechanism-based
definition of AGI that offers a clear and actionable path for the research
community.

</details>


### [6] [Beyond the high score: Prosocial ability profiles of multi-agent populations](https://arxiv.org/abs/2509.14485)
*Marko Tesic,Yue Zhao,Joel Z. Leibo,Rakshit S. Trivedi,Jose Hernandez-Orallo*

Main category: cs.AI

TL;DR: 本文使用贝叶斯方法评估了Melting Pot竞赛中多智能体系统的合作能力，发现高合作能力并不总是与高性能相关，顶级参赛作品可能利用了评估框架的局限性。


<details>
  <summary>Details</summary>
Motivation: 评估AI智能体的社会能力需要复杂的竞争与合作环境，而Melting Pot竞赛旨在评估AI系统的合作能力。

Method: 采用贝叶斯方法（Measurement Layouts）推断多智能体系统在Melting Pot竞赛中的能力概况。

Result: 高合作能力与高性能并非总是正相关；顶级参赛作品可能在不需要合作的场景中取得高分，这暴露出评估框架的局限性。

Conclusion: Measurement Layouts方法具有较高的预测准确性和可操作性，为在复杂社会环境中评估AI系统提供了一种更透明和更普适的方法。建议改进合作需求的标注，并对不同测试环境引入的偏差进行研究。

Abstract: The development and evaluation of social capabilities in AI agents require
complex environments where competitive and cooperative behaviours naturally
emerge. While game-theoretic properties can explain why certain teams or agent
populations outperform others, more abstract behaviours, such as convention
following, are harder to control in training and evaluation settings. The
Melting Pot contest is a social AI evaluation suite designed to assess the
cooperation capabilities of AI systems. In this paper, we apply a Bayesian
approach known as Measurement Layouts to infer the capability profiles of
multi-agent systems in the Melting Pot contest. We show that these capability
profiles not only predict future performance within the Melting Pot suite but
also reveal the underlying prosocial abilities of agents. Our analysis
indicates that while higher prosocial capabilities sometimes correlate with
better performance, this is not a universal trend-some lower-scoring agents
exhibit stronger cooperation abilities. Furthermore, we find that
top-performing contest submissions are more likely to achieve high scores in
scenarios where prosocial capabilities are not required. These findings,
together with reports that the contest winner used a hard-coded solution
tailored to specific environments, suggest that at least one top-performing
team may have optimised for conditions where cooperation was not necessary,
potentially exploiting limitations in the evaluation framework. We provide
recommendations for improving the annotation of cooperation demands and propose
future research directions to account for biases introduced by different
testing environments. Our results demonstrate that Measurement Layouts offer
both strong predictive accuracy and actionable insights, contributing to a more
transparent and generalisable approach to evaluating AI systems in complex
social settings.

</details>


### [7] [DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction](https://arxiv.org/abs/2509.14507)
*Jian Chen,Zhenyan Chen,Xuming Hu,Peilin Zhou,Yining Hua,Han Fang,Cissy Hing Yee Choy,Xinmei Ke,Jingfeng Luo,Zixuan Yuan*

Main category: cs.AI

TL;DR: DeKeyNLU数据集和DeKeySQL模型提高了NL2SQL的准确性


<details>
  <summary>Details</summary>
Motivation: 现有的NL2SQL模型在任务分解和关键词提取方面存在不足

Method: 构建DeKeyNLU数据集，并提出基于RAG的DeKeySQL模型，包含三个模块：用户问题理解、实体检索和SQL生成

Result: 在BIRD和Spider数据集上取得显著性能提升，分别从62.31%提升到69.10%和从84.2%提升到88.7%

Conclusion: DeKeyNLU和DeKeySQL有效提高了NL2SQL的准确性，为未来研究提供了新的方向

Abstract: Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that
simplifies database access for non-technical users by converting natural
language queries into SQL commands. Recent advancements, particularly those
integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)
reasoning, have made significant strides in enhancing NL2SQL performance.
However, challenges such as inaccurate task decomposition and keyword
extraction by LLMs remain major bottlenecks, often leading to errors in SQL
generation. While existing datasets aim to mitigate these issues by fine-tuning
models, they struggle with over-fragmentation of tasks and lack of
domain-specific keyword annotations, limiting their effectiveness. To address
these limitations, we present DeKeyNLU, a novel dataset which contains 1,500
meticulously annotated QA pairs aimed at refining task decomposition and
enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with
DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three
distinct modules for user question understanding, entity retrieval, and
generation to improve SQL generation accuracy. We benchmarked multiple model
configurations within DeKeySQL RAG pipeline. Experimental results demonstrate
that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy
on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.

</details>


### [8] [Rationality Check! Benchmarking the Rationality of Large Language Models](https://arxiv.org/abs/2509.14546)
*Zhilun Zhou,Jing Yi Wang,Nicholas Sukiennik,Chen Gao,Fengli Xu,Yong Li,James Evans*

Main category: cs.AI

TL;DR: 该论文提出了一种评估大型语言模型 (LLM) 理性性的基准测试方法，涵盖多个领域和模型，并提供工具包和实验结果。


<details>
  <summary>Details</summary>
Motivation: 评估LLM是否以及在何种情况下像人类一样思考和行动，理性是关键。

Method: 构建了一个涵盖广泛领域的LLM理性评估基准测试，包括易于使用的工具包和大量的实验结果。

Result: 该基准测试揭示了LLM与理想化人类理性之间的一致性和差异。

Conclusion: 该基准测试可作为LLM开发者和用户的基础工具。

Abstract: Large language models (LLMs), a recent advance in deep learning and machine
intelligence, have manifested astonishing capacities, now considered among the
most promising for artificial general intelligence. With human-like
capabilities, LLMs have been used to simulate humans and serve as AI assistants
across many applications. As a result, great concern has arisen about whether
and under what circumstances LLMs think and behave like real human agents.
Rationality is among the most important concepts in assessing human behavior,
both in thinking (i.e., theoretical rationality) and in taking action (i.e.,
practical rationality). In this work, we propose the first benchmark for
evaluating the omnibus rationality of LLMs, covering a wide range of domains
and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental
results, and analysis that illuminates where LLMs converge and diverge from
idealized human rationality. We believe the benchmark can serve as a
foundational tool for both developers and users of LLMs.

</details>


### [9] [(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration](https://arxiv.org/abs/2509.14547)
*Yi Lin,Lujin Zhao,Yijie Shi*

Main category: cs.AI

TL;DR: 该论文提出了一种用于自动化工作流构建的动态框架，该框架结合Q-table学习和任务特征评估，提高了效率和适应性，并在四个基准数据集上取得了比现有方法平均高4.05%的改进，且成本更低。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖历史经验构建工作流，效率和适应性有限，因此需要一种能够灵活响应任务特征的框架。

Method: 该框架利用Q-table学习优化决策空间，并根据当前任务进度进行先验决策，选择合适的执行agent和工作流结构，同时包含冷启动初始化、提前停止和剪枝等机制。

Result: 在四个基准数据集上，该方法平均提升了4.05%，且工作流构建和推理成本仅为现有方法的30.68%-48.31%。

Conclusion: 该论文提出的动态框架有效提高了LLMs工作流构建的效率和适应性，具有良好的应用前景。

Abstract: Recent studies have shown that carefully designed workflows coordinating
large language models(LLMs) significantly enhance task-solving capabilities
compared to using a single model. While an increasing number of works focus on
autonomous workflow construction, most existing approaches rely solely on
historical experience, leading to limitations in efficiency and adaptability.
We argue that while historical experience is valuable, workflow construction
should also flexibly respond to the unique characteristics of each task. To
this end, we propose an a priori dynamic framework for automated workflow
construction. Our framework first leverages Q-table learning to optimize the
decision space, guiding agent decisions and enabling effective use of
historical experience. At the same time, agents evaluate the current task
progress and make a priori decisions regarding the next executing agent,
allowing the system to proactively select the more suitable workflow structure
for each given task. Additionally, we incorporate mechanisms such as cold-start
initialization, early stopping, and pruning to further improve system
efficiency. Experimental evaluations on four benchmark datasets demonstrate the
feasibility and effectiveness of our approach. Compared to state-of-the-art
baselines, our method achieves an average improvement of 4.05%, while reducing
workflow construction and inference costs to only 30.68%-48.31% of those
required by existing methods.

</details>


### [10] [SynBench: A Benchmark for Differentially Private Text Generation](https://arxiv.org/abs/2509.14594)
*Yidan Sun,Viktor Schlegel,Srinivasan Nandakumar,Iqra Zahid,Yuping Wu,Yulong Wu,Hao Li,Jie Zhang,Warren Del-Pinto,Goran Nenadic,Siew Kei Lam,Anil Anthony Bharath*

Main category: cs.AI

TL;DR: 本文探究了在医疗和金融等高风险领域使用生成式AI合成数据面临的隐私挑战，并通过实证研究揭示了现有方法的不足，强调了严格隐私审计的必要性。


<details>
  <summary>Details</summary>
Motivation: 解决高风险领域数据共享的隐私问题，利用差分隐私技术生成高质量的合成数据。

Method: 构建了综合评估框架，基准测试了最先进的差分隐私文本生成方法和不同规模的LLM，并开发了一种针对合成文本的成员推断攻击方法。

Result: 实证研究表明，在差分隐私约束下生成高质量的特定领域合成数据仍然是一个挑战，并且公共数据集的使用可能会使隐私保证失效。

Conclusion: 需要更严格的隐私审计，并弥合开放领域和专业领域评估之间的差距，以负责任地部署生成式AI。

Abstract: Data-driven decision support in high-stakes domains like healthcare and
finance faces significant barriers to data sharing due to regulatory,
institutional, and privacy concerns. While recent generative AI models, such as
large language models, have shown impressive performance in open-domain tasks,
their adoption in sensitive environments remains limited by unpredictable
behaviors and insufficient privacy-preserving datasets for benchmarking.
Existing anonymization methods are often inadequate, especially for
unstructured text, as redaction and masking can still allow re-identification.
Differential Privacy (DP) offers a principled alternative, enabling the
generation of synthetic data with formal privacy assurances. In this work, we
address these challenges through three key contributions. First, we introduce a
comprehensive evaluation framework with standardized utility and fidelity
metrics, encompassing nine curated datasets that capture domain-specific
complexities such as technical jargon, long-context dependencies, and
specialized document structures. Second, we conduct a large-scale empirical
study benchmarking state-of-the-art DP text generation methods and LLMs of
varying sizes and different fine-tuning strategies, revealing that high-quality
domain-specific synthetic data generation under DP constraints remains an
unsolved challenge, with performance degrading as domain complexity increases.
Third, we develop a membership inference attack (MIA) methodology tailored for
synthetic text, providing first empirical evidence that the use of public
datasets - potentially present in pre-training corpora - can invalidate claimed
privacy guarantees. Our findings underscore the urgent need for rigorous
privacy auditing and highlight persistent gaps between open-domain and
specialist evaluations, informing responsible deployment of generative AI in
privacy-sensitive, high-stakes settings.

</details>


### [11] [AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production](https://arxiv.org/abs/2509.14647)
*NVJK Kartik,Garvit Sapra,Rishav Hada,Nikhil Pareek*

Main category: cs.AI

TL;DR: AgentCompass框架用于大型语言模型(LLM)驱动智能工作流的部署后监控和调试，通过多阶段分析流程识别、分类和量化错误，并实现持续学习。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法无法捕捉LLM驱动智能工作流的错误、涌现行为和系统性故障的风险。

Method: AgentCompass框架采用结构化的多阶段分析流程：错误识别和分类、主题聚类、定量评分和策略性总结，并结合情景记忆和语义记忆的双重记忆系统。

Result: 在实际部署和TRAIL基准测试中，AgentCompass取得了最先进的结果，发现了人工标注中遗漏的关键问题。

Conclusion: AgentCompass是一个强大的、以开发者为中心的工具，有助于可靠地监控和改进生产环境中的智能系统。

Abstract: With the growing adoption of Large Language Models (LLMs) in automating
complex, multi-agent workflows, organizations face mounting risks from errors,
emergent behaviors, and systemic failures that current evaluation methods fail
to capture. We present AgentCompass, the first evaluation framework designed
specifically for post-deployment monitoring and debugging of agentic workflows.
AgentCompass models the reasoning process of expert debuggers through a
structured, multi-stage analytical pipeline: error identification and
categorization, thematic clustering, quantitative scoring, and strategic
summarization. The framework is further enhanced with a dual memory
system-episodic and semantic-that enables continual learning across executions.
Through collaborations with design partners, we demonstrate the framework's
practical utility on real-world deployments, before establishing its efficacy
against the publicly available TRAIL benchmark. AgentCompass achieves
state-of-the-art results on key metrics, while uncovering critical issues
missed in human annotations, underscoring its role as a robust,
developer-centric tool for reliable monitoring and improvement of agentic
systems in production.

</details>


### [12] [Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory](https://arxiv.org/abs/2509.14662)
*Ming Li,Nan Zhang,Chenrui Fan,Hong Jiao,Yanbin Fu,Sydney Peters,Qingshu Xu,Robert Lissitz,Tianyi Zhou*

Main category: cs.AI

TL;DR: 用Schoenfeld的阶段理论分析大型推理模型的推理过程，构建了一个新的基准，用于对机器推理进行细粒度分析。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型(LRMs)产生大量的链式思维推理，但缺乏理解这些思想结构的原则性框架。

Method: 应用Schoenfeld的阶段理论，对模型生成的数学问题解决方案中的句子和段落进行标注，使用七个认知标签(例如，计划、实施、验证)。

Result: 构建了第一个公开的用于对机器推理进行细粒度分析的基准，包括大型标注语料库和详细的标注指南。初步分析揭示了LRM推理中的不同模式，例如认知状态之间的转换动态。

Conclusion: 该框架为解释LRM认知提供了一种理论基础的方法，并为未来构建更可控和透明的推理系统奠定了基础。

Abstract: While Large Reasoning Models (LRMs) generate extensive chain-of-thought
reasoning, we lack a principled framework for understanding how these thoughts
are structured. In this paper, we introduce a novel approach by applying
Schoenfeld's Episode Theory, a classic cognitive framework for human
mathematical problem-solving, to analyze the reasoning traces of LRMs. We
annotated thousands of sentences and paragraphs from model-generated solutions
to math problems using seven cognitive labels (e.g., Plan, Implement, Verify).
The result is the first publicly available benchmark for the fine-grained
analysis of machine reasoning, including a large annotated corpus and detailed
annotation guidebooks. Our preliminary analysis reveals distinct patterns in
LRM reasoning, such as the transition dynamics between cognitive states. This
framework provides a theoretically grounded methodology for interpreting LRM
cognition and enables future work on more controllable and transparent
reasoning systems.

</details>


### [13] [RationAnomaly: Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning](https://arxiv.org/abs/2509.14693)
*Song Xu,Yilun Liu,Minggui He,Mingchen Dai,Ziang Chen,Chunguang Zhao,Jingzhou Du,Shimin Tao,Weibin Meng,Shenglin Zhang,Yongqian Sun,Boxing Chen,Daimeng Wei*

Main category: cs.AI

TL;DR: RationAnomaly框架结合思维链(CoT)微调和强化学习，提高了日志异常检测的准确性和可解释性，并克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有日志异常检测方法存在可解释性和泛化能力不足等问题。

Method: 该框架首先使用高质量数据集进行CoT引导的监督微调，然后使用多方面奖励函数的强化学习来优化准确性和逻辑一致性。

Result: RationAnomaly优于现有技术，在关键基准测试中取得了更高的F1分数，并提供了透明的、逐步的分析输出。

Conclusion: RationAnomaly框架有效地解决了日志异常检测中的可解释性和准确性问题，并已开源相关资源。

Abstract: Logs constitute a form of evidence signaling the operational status of
software systems. Automated log anomaly detection is crucial for ensuring the
reliability of modern software systems. However, existing approaches face
significant limitations: traditional deep learning models lack interpretability
and generalization, while methods leveraging Large Language Models are often
hindered by unreliability and factual inaccuracies. To address these issues, we
propose RationAnomaly, a novel framework that enhances log anomaly detection by
synergizing Chain-of-Thought (CoT) fine-tuning with reinforcement learning. Our
approach first instills expert-like reasoning patterns using CoT-guided
supervised fine-tuning, grounded in a high-quality dataset corrected through a
rigorous expert-driven process. Subsequently, a reinforcement learning phase
with a multi-faceted reward function optimizes for accuracy and logical
consistency, effectively mitigating hallucinations. Experimentally,
RationAnomaly outperforms state-of-the-art baselines, achieving superior
F1-scores on key benchmarks while providing transparent, step-by-step
analytical outputs. We have released the corresponding resources, including
code and datasets.

</details>


### [14] [The NazoNazo Benchmark: A Cost-Effective and Extensible Test of Insight-Based Reasoning in LLMs](https://arxiv.org/abs/2509.14704)
*Masaharu Mizumoto,Dat Nguyen,Zhiheng Han,Jiyuan Fang,Heyuan Guan,Xingfu Li,Naoya Shiraishi,Xuyang Tian,Yo Nakawake,Le Minh Nguyen*

Main category: cs.AI

TL;DR: Nazonazo基准测试使用日本儿童谜语评估LLM的洞察力推理能力，发现除GPT-5外，现有模型性能远低于人类，模型大小与准确率无显著关联，并揭示模型存在验证失败的元认知缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估基准存在饱和和污染问题，难以可靠评估模型能力。

Method: 构建Nazonazo基准测试，使用120个（扩展到201个）日本儿童谜语评估38个前沿模型和126个成年人的洞察力推理能力。

Result: 除GPT-5外，模型性能均远低于人类（52.9%平均准确率）；推理模型显著优于非推理模型；模型大小与准确率无显著关联；发现模型存在验证失败的元认知缺陷。

Conclusion: Nazonazo基准测试提供了一种经济高效、可扩展且易于更新的评估方法，并指出了LLM未来改进方向。

Abstract: Benchmark saturation and contamination undermine confidence in LLM
evaluation. We present Nazonazo, a cost-effective and extensible benchmark
built from Japanese children's riddles to test insight-based reasoning. Items
are short (mostly one sentence), require no specialized domain knowledge, and
can be generated at scale, enabling rapid refresh of blind sets when leakage is
suspected. We evaluate 38 frontier models and 126 adults on 120 riddles. No
model except for GPT-5 is comparable to human performance, which achieves a
52.9% mean accuracy. Model comparison on extended 201 items shows that
reasoning models significantly outperform non-reasoning peers, while model size
shows no reliable association with accuracy. Beyond aggregate accuracy, an
informal candidate-tracking analysis of thought logs reveals many cases of
verification failure: models often produce the correct solution among
intermediate candidates yet fail to select it as the final answer, which we
illustrate with representative examples observed in multiple models. Nazonazo
thus offers a cost-effective, scalable, and easily renewable benchmark format
that addresses the current evaluation crisis while also suggesting a recurrent
meta-cognitive weakness, providing clear targets for future control and
calibration methods.

</details>


### [15] [Enhancing Retrieval Augmentation via Adversarial Collaboration](https://arxiv.org/abs/2509.14750)
*Letian Zhang,Guanghao Meng,Xudong Ren,Yiming Wang,Shu-Tao Xia*

Main category: cs.AI

TL;DR: 该论文提出了一种名为对抗协作检索增强生成（AC-RAG）的框架，以解决检索幻觉问题，显著提高了检索精度。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）模型容易出现“检索幻觉”问题，影响性能。

Method: 采用两个异构Agent：一个通用的检测器和一个专业的解决器，通过对抗协作迭代式地改进知识检索。

Result: 实验表明，AC-RAG显著提高了检索精度，优于现有RAG方法。

Conclusion: AC-RAG框架有效解决了检索幻觉问题，为领域特定LLM提供了改进方案。

Abstract: Retrieval-augmented Generation (RAG) is a prevalent approach for
domain-specific LLMs, yet it is often plagued by "Retrieval Hallucinations"--a
phenomenon where fine-tuned models fail to recognize and act upon poor-quality
retrieved documents, thus undermining performance. To address this, we propose
the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two
heterogeneous agents: a generalist Detector that identifies knowledge gaps, and
a domain-specialized Resolver that provides precise solutions. Guided by a
moderator, these agents engage in an adversarial collaboration, where the
Detector's persistent questioning challenges the Resolver's expertise. This
dynamic process allows for iterative problem dissection and refined knowledge
retrieval. Extensive experiments show that AC-RAG significantly improves
retrieval accuracy and outperforms state-of-the-art RAG methods across various
vertical domains.

</details>


### [16] [OpenLens AI: Fully Autonomous Research Agent for Health Infomatics](https://arxiv.org/abs/2509.14778)
*Yuxiao Cheng,Jinli Suo*

Main category: cs.AI

TL;DR: OpenLens AI是一个自动化框架，用于推进健康信息学研究，它集成了文献综述、数据分析、代码生成和手稿准备等专用代理，并通过视觉语言反馈和质量控制来增强医学可视化和可重复性。


<details>
  <summary>Details</summary>
Motivation: 健康信息学研究需要整合生物医学科学、数据分析和临床实践的见解，而基于代理的方法可以自动化知识探索、管理复杂的工作流程并生成具有临床意义的输出。

Method: OpenLens AI 集成了多个专用代理，并通过视觉语言反馈和质量控制来增强医学可视化和可重复性，自动化整个研究流程，生成可发表的 LaTeX 手稿。

Result: OpenLens AI 自动化了健康信息学研究的整个流程，产生具有透明可追溯工作流程的、可发表的 LaTeX 手稿。

Conclusion: OpenLens AI 为推进健康信息学研究提供了一种领域自适应的解决方案。

Abstract: Health informatics research is characterized by diverse data modalities,
rapid knowledge expansion, and the need to integrate insights across biomedical
science, data analytics, and clinical practice. These characteristics make it
particularly well-suited for agent-based approaches that can automate knowledge
exploration, manage complex workflows, and generate clinically meaningful
outputs. Recent progress in large language model (LLM)-based agents has
demonstrated promising capabilities in literature synthesis, data analysis, and
even end-to-end research execution. However, existing systems remain limited
for health informatics because they lack mechanisms to interpret medical
visualizations and often overlook domain-specific quality requirements. To
address these gaps, we introduce OpenLens AI, a fully automated framework
tailored to health informatics. OpenLens AI integrates specialized agents for
literature review, data analysis, code generation, and manuscript preparation,
enhanced by vision-language feedback for medical visualization and quality
control for reproducibility. The framework automates the entire research
pipeline, producing publication-ready LaTeX manuscripts with transparent and
traceable workflows, thereby offering a domain-adapted solution for advancing
health informatics research.

</details>
