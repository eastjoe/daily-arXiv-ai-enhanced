{"id": "2508.21204", "categories": ["cs.AI", "cs.CL", "I.2.7; I.2.11; I.2.6"], "pdf": "https://arxiv.org/pdf/2508.21204", "abs": "https://arxiv.org/abs/2508.21204", "authors": ["Vanessa Figueiredo"], "title": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "comment": null, "summary": "We study how architectural inductive biases influence the cognitive behavior\nof large language models (LLMs) in instructional dialogue. We introduce a\nsymbolic scaffolding mechanism paired with a short-term memory schema designed\nto promote adaptive, structured reasoning in Socratic tutoring. Using\ncontrolled ablation across five system variants, we evaluate model outputs via\nexpert-designed rubrics covering scaffolding, responsiveness, symbolic\nreasoning, and conversational memory. We present preliminary results using an\nLLM-based evaluation framework aligned to a cognitively grounded rubric. This\nenables scalable, systematic comparisons across architectural variants in\nearly-stage experimentation. The preliminary results show that our full system\nconsistently outperforms baseline variants. Analysis reveals that removing\nmemory or symbolic structure degrades key cognitive behaviors, including\nabstraction, adaptive probing, and conceptual continuity. These findings\nsupport a processing-level account in which architectural scaffolds can\nreliably shape emergent instructional strategies in LLMs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u67b6\u6784\u5f52\u7eb3\u504f\u7f6e\u5982\u4f55\u5f71\u54cd\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u6307\u4ee4\u5f0f\u5bf9\u8bdd\u4e2d\u7684\u8ba4\u77e5\u884c\u4e3a\uff0c\u53d1\u73b0\u6dfb\u52a0\u7b26\u53f7\u811a\u624b\u67b6\u548c\u77ed\u671f\u8bb0\u5fc6\u673a\u5236\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u9002\u5e94\u6027\u548c\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u67b6\u6784\u5f52\u7eb3\u504f\u7f6e\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6307\u4ee4\u5f0f\u5bf9\u8bdd\u4e2d\u8ba4\u77e5\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7b26\u53f7\u811a\u624b\u67b6\u673a\u5236\u548c\u77ed\u671f\u8bb0\u5fc6\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u63a7\u5236\u6d88\u878d\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u4e94\u4e2a\u7cfb\u7edf\u53d8\u4f53\u7684\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5b8c\u6574\u7cfb\u7edf\u4f18\u4e8e\u57fa\u7ebf\u7cfb\u7edf\uff0c\u79fb\u9664\u8bb0\u5fc6\u6216\u7b26\u53f7\u7ed3\u6784\u4f1a\u964d\u4f4e\u6a21\u578b\u7684\u62bd\u8c61\u3001\u81ea\u9002\u5e94\u63a2\u6d4b\u548c\u6982\u5ff5\u8fde\u7eed\u6027\u7b49\u5173\u952e\u8ba4\u77e5\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u4e86\u4e00\u79cd\u5904\u7406\u5c42\u9762\u7684\u89e3\u91ca\uff0c\u5373\u67b6\u6784\u652f\u67b6\u53ef\u4ee5\u53ef\u9760\u5730\u5851\u9020LLM\u4e2d\u65b0\u5174\u7684\u6559\u5b66\u7b56\u7565\u3002"}}
{"id": "2508.21238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21238", "abs": "https://arxiv.org/abs/2508.21238", "authors": ["Tingxuan Xu", "Jiarui Feng", "Justin Melendez", "Kaleigh Roberts", "Donghong Cai", "Mingfang Zhu", "Donald Elbert", "Yixin Chen", "Randall J. Bateman"], "title": "Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs", "comment": null, "summary": "In the past two years, large language model (LLM)-based chatbots, such as\nChatGPT, have revolutionized various domains by enabling diverse task\ncompletion and question-answering capabilities. However, their application in\nscientific research remains constrained by challenges such as hallucinations,\nlimited domain-specific knowledge, and lack of explainability or traceability\nfor the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has\nemerged as a promising approach to improving chatbot reliability by integrating\ndomain-specific contextual information before response generation, addressing\nsome limitations of standard LLMs. Despite its potential, there are only\nlimited studies that evaluate GraphRAG on specific domains that require\nintensive knowledge, like Alzheimer's disease or other biomedical domains. In\nthis paper, we assess the quality and traceability of two popular GraphRAG\nsystems. We compile a database of 50 papers and 70 expert questions related to\nAlzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as\nthe LLM for answering queries. We then compare the quality of responses\ngenerated by GraphRAG with those from a standard GPT-4o model. Additionally, we\ndiscuss and evaluate the traceability of several Retrieval-Augmented Generation\n(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a\npre-built Alzheimer's disease database for researchers to test the performance\nof both standard RAG and GraphRAG.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e24\u79cd\u6d41\u884c\u7684\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210(GraphRAG)\u7cfb\u7edf\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u9886\u57df\u7684\u6027\u80fd\uff0c\u5e76\u5c06\u5176\u4e0e\u6807\u51c6GPT-4o\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684\u754c\u9762\u3002", "motivation": "\u73b0\u6709LLM\u804a\u5929\u673a\u5668\u4eba\u5b58\u5728\u5e7b\u89c9\u3001\u9886\u57df\u77e5\u8bc6\u6709\u9650\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u7b49\u95ee\u9898\uff0cGraphRAG\u901a\u8fc7\u6574\u5408\u9886\u57df\u7279\u5b9a\u4e0a\u4e0b\u6587\u4fe1\u606f\u6765\u63d0\u9ad8\u53ef\u9760\u6027\uff0c\u4f46\u5176\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7b49\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u7684\u5e94\u7528\u7814\u7a76\u6709\u9650\u3002", "method": "\u6784\u5efa\u5305\u542b50\u7bc7\u8bba\u6587\u548c70\u4e2a\u4e13\u5bb6\u95ee\u9898\u7684\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u6570\u636e\u5e93\uff0c\u6784\u5efaGraphRAG\u77e5\u8bc6\u5e93\uff0c\u4f7f\u7528GPT-4o\u4f5c\u4e3aLLM\uff0c\u6bd4\u8f83GraphRAG\u548c\u6807\u51c6GPT-4o\u6a21\u578b\u7684\u56de\u7b54\u8d28\u91cf\uff0c\u5e76\u8bc4\u4f30RAG\u548cGraphRAG\u7cfb\u7edf\u7684\u53ef\u8ffd\u6eaf\u6027\u3002", "result": "\u6bd4\u8f83\u4e86GraphRAG\u548c\u6807\u51c6GPT-4o\u6a21\u578b\u7684\u56de\u7b54\u8d28\u91cf\uff0c\u5e76\u8bc4\u4f30\u4e86RAG\u548cGraphRAG\u7cfb\u7edf\u7684\u53ef\u8ffd\u6eaf\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5305\u542b\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u6570\u636e\u5e93\u7684\u6613\u4e8e\u4f7f\u7528\u7684\u754c\u9762\u3002", "conclusion": "GraphRAG\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7b49\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u5177\u6709\u5e94\u7528\u524d\u666f\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2508.21307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21307", "abs": "https://arxiv.org/abs/2508.21307", "authors": ["Sri Ram Macharla", "Sridhar Murthy J", "Anjaneyulu Pasala"], "title": "MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems", "comment": "Abstract accepted for presentation at ACM ISEC 2025", "summary": "MultiFluxAI is an innovative AI platform developed to address the challenges\nof managing and integrating vast, disparate data sources in product engineering\nacross application domains. It addresses both current and new service related\nqueries that enhance user engagement in the digital ecosystem. This platform\nleverages advanced AI techniques, such as Generative AI, vectorization, and\nagentic orchestration to provide dynamic and context-aware responses to complex\nuser queries.", "AI": {"tldr": "MultiFluxAI\u5e73\u53f0\u6574\u5408\u4ea7\u54c1\u5de5\u7a0b\u4e2d\u5927\u91cf\u5f02\u6784\u6570\u636e\u6e90\uff0c\u5229\u7528\u751f\u6210\u5f0fAI\u3001\u5411\u91cf\u5316\u548c\u81ea\u4e3b\u7f16\u6392\u7b49\u6280\u672f\uff0c\u52a8\u6001\u54cd\u5e94\u590d\u6742\u7528\u6237\u67e5\u8be2\uff0c\u589e\u5f3a\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "motivation": "\u89e3\u51b3\u4ea7\u54c1\u5de5\u7a0b\u4e2d\u6570\u636e\u7ba1\u7406\u548c\u6574\u5408\u96be\u9898\uff0c\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "method": "\u5229\u7528\u751f\u6210\u5f0fAI\u3001\u5411\u91cf\u5316\u548c\u81ea\u4e3b\u7f16\u6392\u7b49\u5148\u8fdbAI\u6280\u672f\u3002", "result": "\u63d0\u4f9b\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u590d\u6742\u7528\u6237\u67e5\u8be2\u54cd\u5e94\u3002", "conclusion": "MultiFluxAI\u5e73\u53f0\u6709\u6548\u6574\u5408\u6570\u636e\uff0c\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u4f53\u9a8c\u3002"}}
{"id": "2508.21320", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.21320", "abs": "https://arxiv.org/abs/2508.21320", "authors": ["Mohsen Nayebi Kerdabadi", "Arya Hadizadeh Moghaddam", "Dongjie Wang", "Zijun Yao"], "title": "Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation", "comment": "This work has been accepted as a full research paper at CIKM 2025", "summary": "Medical ontology graphs map external knowledge to medical codes in electronic\nhealth records via structured relationships. By leveraging domain-approved\nconnections (e.g., parent-child), predictive models can generate richer medical\nconcept representations by incorporating contextual information from related\nconcepts. However, existing literature primarily focuses on incorporating\ndomain knowledge from a single ontology system, or from multiple ontology\nsystems (e.g., diseases, drugs, and procedures) in isolation, without\nintegrating them into a unified learning structure. Consequently, concept\nrepresentation learning often remains limited to intra-ontology relationships,\noverlooking cross-ontology connections. In this paper, we propose LINKO, a\nlarge language model (LLM)-augmented integrative ontology learning framework\nthat leverages multiple ontology graphs simultaneously by enabling dual-axis\nknowledge propagation both within and across heterogeneous ontology systems to\nenhance medical concept representation learning. Specifically, LINKO first\nemploys LLMs to provide a graph-retrieval-augmented initialization for ontology\nconcept embedding, through an engineered prompt that includes concept\ndescriptions, and is further augmented with ontology context. Second, our\nmethod jointly learns the medical concepts in diverse ontology graphs by\nperforming knowledge propagation in two axes: (1) intra-ontology vertical\npropagation across hierarchical ontology levels and (2) inter-ontology\nhorizontal propagation within every level in parallel. Last, through extensive\nexperiments on two public datasets, we validate the superior performance of\nLINKO over state-of-the-art baselines. As a plug-in encoder compatible with\nexisting EHR predictive models, LINKO further demonstrates enhanced robustness\nin scenarios involving limited data availability and rare disease prediction.", "AI": {"tldr": "LINKO\u6846\u67b6\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u533b\u7597\u672c\u4f53\u5b66\u4e60\uff0c\u901a\u8fc7\u53cc\u8f74\u77e5\u8bc6\u4f20\u64ad\uff08\u672c\u4f53\u5185\u548c\u672c\u4f53\u95f4\uff09\u63d0\u5347\u533b\u7597\u6982\u5ff5\u8868\u793a\u5b66\u4e60\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u6216\u591a\u4e2a\u5b64\u7acb\u672c\u4f53\u7cfb\u7edf\uff0c\u5ffd\u7565\u4e86\u672c\u4f53\u95f4\u7684\u8054\u7cfb\uff0c\u9650\u5236\u4e86\u6982\u5ff5\u8868\u793a\u5b66\u4e60\u3002", "method": "LINKO\u6846\u67b6\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u672c\u4f53\u6982\u5ff5\u5d4c\u5165\u521d\u59cb\u5316\uff0c\u5e76\u901a\u8fc7\u672c\u4f53\u5185\u5782\u76f4\u4f20\u64ad\u548c\u672c\u4f53\u95f4\u6c34\u5e73\u4f20\u64ad\u8fdb\u884c\u8054\u5408\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eLINKO\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u6570\u636e\u6709\u9650\u548c\u7f55\u89c1\u75c5\u9884\u6d4b\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "LINKO\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u533b\u7597\u6982\u5ff5\u8868\u793a\u5b66\u4e60\uff0c\u4e3a\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u9884\u6d4b\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u63d2\u4ef6\u7f16\u7801\u5668\u3002"}}
{"id": "2508.21365", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21365", "abs": "https://arxiv.org/abs/2508.21365", "authors": ["Yi Liao", "Yu Gu", "Yuan Sui", "Zining Zhu", "Yifan Lu", "Guohua Tang", "Zhongqian Sun", "Wei Yang"], "title": "Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models", "comment": null, "summary": "Large language models (LLMs) excel at complex reasoning tasks such as\nmathematics and coding, yet they frequently struggle with simple interactive\ntasks that young children perform effortlessly. This discrepancy highlights a\ncritical gap between declarative knowledge (knowing about something) and\nprocedural knowledge (knowing how to do something). Although traditional\nreinforcement learning (RL) agents can acquire procedural knowledge through\nenvironmental interaction, they often operate as black boxes and require\nsubstantial training data. In contrast, LLMs possess extensive world knowledge\nand reasoning capabilities, but are unable to effectively convert this static\nknowledge into dynamic decision-making in interactive settings. To address this\nchallenge, we propose Think in Games (TiG), a novel framework that empowers\nLLMs to develop procedural understanding through direct interaction with game\nenvironments, while retaining their inherent reasoning and explanatory\nabilities. Specifically, TiG reformulates RL-based decision-making as a\nlanguage modeling task: LLMs generate language-guided policies, which are\nrefined iteratively through online reinforcement learning based on\nenvironmental feedback. Our experimental results show that TiG successfully\nbridges the gap between declarative and procedural knowledge, achieving\ncompetitive performance with dramatically lower data and computational demands\ncompared to conventional RL methods. Moreover, TiG provides step-by-step\nnatural language explanations for its decisions, greatly improving transparency\nand interpretability in complex interactive tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aThink in Games (TiG) \u7684\u6846\u67b6\uff0c\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u80fd\u591f\u901a\u8fc7\u4e0e\u6e38\u620f\u73af\u5883\u4ea4\u4e92\u5b66\u4e60\u7a0b\u5e8f\u6027\u77e5\u8bc6\uff0c\u5e76\u5728\u590d\u6742\u4ea4\u4e92\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e0e\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5177\u6709\u66f4\u9ad8\u7684\u6570\u636e\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u7b80\u5355\u7684\u4ea4\u4e92\u4efb\u52a1\u4e0a\u5374\u8868\u73b0\u4e0d\u4f73\uff0c\u8be5\u8bba\u6587\u65e8\u5728\u5f25\u5408\u58f0\u660e\u5f0f\u77e5\u8bc6\u548c\u7a0b\u5e8f\u5f0f\u77e5\u8bc6\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u8be5\u6846\u67b6\u5c06\u5f3a\u5316\u5b66\u4e60\u7684\u51b3\u7b56\u8fc7\u7a0b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\uff0cLLM\u751f\u6210\u8bed\u8a00\u6307\u5bfc\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u8fed\u4ee3\u6539\u8fdb\u3002", "result": "TiG\u5728\u6570\u636e\u6548\u7387\u548c\u8ba1\u7b97\u9700\u6c42\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u80fd\u63d0\u4f9b\u9010\u6b65\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "conclusion": "TiG\u6210\u529f\u5730\u5f25\u5408\u4e86\u58f0\u660e\u5f0f\u77e5\u8bc6\u548c\u7a0b\u5e8f\u5f0f\u77e5\u8bc6\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5728\u590d\u6742\u4ea4\u4e92\u4efb\u52a1\u4e2d\u63d0\u9ad8LLM\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.21376", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.21376", "abs": "https://arxiv.org/abs/2508.21376", "authors": ["Tony Lee", "Haoqin Tu", "Chi Heem Wong", "Zijun Wang", "Siwei Yang", "Yifan Mai", "Yuyin Zhou", "Cihang Xie", "Percy Liang"], "title": "AHELM: A Holistic Evaluation of Audio-Language Models", "comment": null, "summary": "Evaluations of audio-language models (ALMs) -- multimodal models that take\ninterleaved audio and text as input and output text -- are hindered by the lack\nof standardized benchmarks; most benchmarks measure only one or two\ncapabilities and omit evaluative aspects such as fairness or safety.\nFurthermore, comparison across models is difficult as separate evaluations test\na limited number of models and use different prompting methods and inference\nparameters. To address these shortfalls, we introduce AHELM, a benchmark that\naggregates various datasets -- including 2 new synthetic audio-text datasets\ncalled PARADE, which evaluates the ALMs on avoiding stereotypes, and\nCoRe-Bench, which measures reasoning over conversational audio through\ninferential multi-turn question answering -- to holistically measure the\nperformance of ALMs across 10 aspects we have identified as important to the\ndevelopment and usage of ALMs: audio perception, knowledge, reasoning, emotion\ndetection, bias, fairness, multilinguality, robustness, toxicity, and safety.\nWe also standardize the prompts, inference parameters, and evaluation metrics\nto ensure equitable comparisons across models. We test 14 open-weight and\nclosed-API ALMs from 3 developers and 3 additional simple baseline systems each\nconsisting of an automatic speech recognizer and a language model. Our results\nshow that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits\ngroup unfairness ($p=0.01$) on ASR tasks whereas most of the other models do\nnot. We also find that the baseline systems perform reasonably well on AHELM,\nwith one ranking 5th overall despite having only speech-to-text capabilities.\nFor transparency, all raw prompts, model generations, and outputs are available\non our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is\nintended to be a living benchmark and new datasets and models will be added\nover time.", "AI": {"tldr": "AHELM\uff0c\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5bf9\u97f3\u9891\u8bed\u8a00\u6a21\u578b(ALMs)\u768410\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u5305\u62ec\u97f3\u9891\u611f\u77e5\u3001\u63a8\u7406\u548c\u516c\u5e73\u6027\u7b49\uff0c\u5e76\u5bf914\u4e2aALMs\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u53d1\u73b0Gemini 2.5 Pro\u57285\u4e2a\u65b9\u9762\u6392\u540d\u7b2c\u4e00\uff0c\u4f46\u4e5f\u5b58\u5728\u7fa4\u4f53\u4e0d\u516c\u5e73\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684ALMs\u8bc4\u4f30\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u96be\u4ee5\u8fdb\u884c\u8de8\u6a21\u578b\u6bd4\u8f83\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aAHELM\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6574\u5408\u4e86\u591a\u4e2a\u6570\u636e\u96c6(\u5305\u62ec\u4e24\u4e2a\u65b0\u7684\u5408\u6210\u6570\u636e\u96c6PARADE\u548cCoRe-Bench)\uff0c\u5bf914\u4e2aALMs\u8fdb\u884c\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\uff0c\u6db5\u76d610\u4e2a\u91cd\u8981\u65b9\u9762\u3002", "result": "Gemini 2.5 Pro\u57285\u4e2a\u65b9\u9762\u6392\u540d\u7b2c\u4e00\uff0c\u4f46\u5b58\u5728\u7fa4\u4f53\u4e0d\u516c\u5e73\u95ee\u9898\uff1b\u57fa\u7ebf\u7cfb\u7edf\u8868\u73b0\u826f\u597d\uff0c\u5176\u4e2d\u4e00\u4e2a\u7cfb\u7edf\u6392\u540d\u7b2c\u4e94\u3002", "conclusion": "AHELM\u662f\u4e00\u4e2a\u52a8\u6001\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u672a\u6765\u4f1a\u4e0d\u65ad\u6dfb\u52a0\u65b0\u7684\u6570\u636e\u96c6\u548c\u6a21\u578b\uff0c\u4e3aALMs\u7684\u8bc4\u4f30\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u6807\u51c6\u3002"}}
{"id": "2508.21394", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21394", "abs": "https://arxiv.org/abs/2508.21394", "authors": ["Bor-Sung Liang"], "title": "AI Compute Architecture and Evolution Trends", "comment": "29 pages, 26 figures", "summary": "The focus of AI development has shifted from academic research to practical\napplications. However, AI development faces numerous challenges at various\nlevels. This article will attempt to analyze the opportunities and challenges\nof AI from several different perspectives using a structured approach. This\narticle proposes a seven-layer model for AI compute architecture, including\nPhysical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,\nOrchestrator Layer, and Application Layer, from bottom to top. It also explains\nhow AI computing has evolved into this 7-layer architecture through the\nthree-stage evolution on large-scale language models (LLMs). For each layer, we\ndescribe the development trajectory and key technologies. In Layers 1 and 2 we\ndiscuss AI computing issues and the impact of Scale-Up and Scale-Out strategies\non computing architecture. In Layer 3 we explore two different development\npaths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs\nand compares it to traditional processor memory. In Layers 5 to 7 we discuss\nthe trends of AI agents and explore the issues in evolution from a single AI\nagent to an AI-based ecosystem, and their impact on the AI industry.\nFurthermore, AI development involves not only technical challenges but also the\neconomic issues to build self-sustainable ecosystem. This article analyzes the\ninternet industry to provide predictions on the future trajectory of AI\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86AI\u53d1\u5c55\u7684\u673a\u9047\u548c\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e03\u5c42AI\u8ba1\u7b97\u67b6\u6784\u6a21\u578b\uff0c\u5e76\u63a2\u8ba8\u4e86AI\u4ece\u5355\u4e00\u667a\u80fd\u4f53\u5230AI\u751f\u6001\u7cfb\u7edf\u7684\u6f14\u8fdb\u4ee5\u53ca\u7ecf\u6d4e\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "motivation": "AI\u53d1\u5c55\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u9700\u8981\u4ece\u4e0d\u540c\u89c6\u89d2\u8fdb\u884c\u5206\u6790\u3002", "method": "\u63d0\u51fa\u4e03\u5c42AI\u8ba1\u7b97\u67b6\u6784\u6a21\u578b\uff0c\u5206\u6790AI\u53d1\u5c55\u4e09\u4e2a\u9636\u6bb5\uff0c\u63a2\u8ba8\u4e0d\u540c\u5c42\u9762\u7684\u5173\u952e\u6280\u672f\u548c\u6311\u6218\uff0c\u5e76\u501f\u9274\u4e92\u8054\u7f51\u4ea7\u4e1a\u53d1\u5c55\u8d8b\u52bf\u9884\u6d4bAI\u672a\u6765\u3002", "result": "\u6784\u5efa\u4e86\u4e03\u5c42AI\u8ba1\u7b97\u67b6\u6784\u6a21\u578b\uff0c\u9610\u8ff0\u4e86AI\u53d1\u5c55\u7684\u4e09\u4e2a\u9636\u6bb5\uff0c\u5206\u6790\u4e86\u5404\u5c42\u5173\u952e\u6280\u672f\u3001\u6311\u6218\u548c\u8d8b\u52bf\uff0c\u5e76\u5bf9AI\u4ea7\u4e1a\u672a\u6765\u53d1\u5c55\u65b9\u5411\u505a\u51fa\u9884\u6d4b\u3002", "conclusion": "AI\u53d1\u5c55\u673a\u9047\u4e0e\u6311\u6218\u5e76\u5b58\uff0c\u9700\u8981\u5173\u6ce8\u6280\u672f\u548c\u7ecf\u6d4e\u56e0\u7d20\uff0c\u6784\u5efa\u53ef\u6301\u7eed\u7684AI\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2508.21411", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21411", "abs": "https://arxiv.org/abs/2508.21411", "authors": ["Leonard Frank Neis", "Andre Antakli", "Matthias Klusch"], "title": "CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN", "comment": null, "summary": "User-friendly modeling and virtual simulation of urban traffic scenarios with\ndifferent types of interacting agents such as pedestrians, cyclists and\nautonomous vehicles remains a challenge. We present CARJAN, a novel tool for\nsemi-automated generation and simulation of such scenarios based on the\nmulti-agent engineering framework AJAN and the driving simulator CARLA. CARJAN\nprovides a visual user interface for the modeling, storage and maintenance of\ntraffic scenario layouts, and leverages SPARQL Behavior Tree-based\ndecision-making and interactions for agents in dynamic scenario simulations in\nCARLA. CARJAN provides a first integrated approach for interactive, intelligent\nagent-based generation and simulation of virtual traffic scenarios in CARLA.", "AI": {"tldr": "CARJAN\u5de5\u5177\u7ed3\u5408AJAN\u548cCARLA\u6a21\u62df\u57ce\u5e02\u4ea4\u901a\u573a\u666f\uff0c\u652f\u6301\u591a\u79cd\u4ea4\u4e92\u4ee3\u7406\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u96be\u4ee5\u5bf9\u5305\u542b\u884c\u4eba\u3001\u81ea\u884c\u8f66\u548c\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7b49\u591a\u79cd\u4ea4\u4e92\u4ee3\u7406\u7684\u57ce\u5e02\u4ea4\u901a\u573a\u666f\u8fdb\u884c\u7528\u6237\u53cb\u597d\u7684\u5efa\u6a21\u548c\u865a\u62df\u4eff\u771f\u3002", "method": "\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5de5\u7a0b\u6846\u67b6AJAN\u548c\u9a7e\u9a76\u6a21\u62df\u5668CARLA\uff0c\u4f7f\u7528SPARQL\u884c\u4e3a\u6811\u8fdb\u884c\u51b3\u7b56\u548c\u4ea4\u4e92\uff0c\u63d0\u4f9b\u53ef\u89c6\u5316\u7528\u6237\u754c\u9762\u8fdb\u884c\u5efa\u6a21\u3001\u5b58\u50a8\u548c\u7ef4\u62a4\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u4ea4\u4e92\u5f0f\u3001\u57fa\u4e8e\u667a\u80fd\u4ee3\u7406\u7684\u865a\u62df\u4ea4\u901a\u573a\u666f\u751f\u6210\u548c\u4eff\u771f\u65b9\u6cd5\u3002", "conclusion": "CARJAN\u662f\u9996\u4e2a\u96c6\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728CARLA\u4e2d\u4ea4\u4e92\u5f0f\u3001\u667a\u80fd\u5730\u57fa\u4e8e\u4ee3\u7406\u751f\u6210\u548c\u6a21\u62df\u865a\u62df\u4ea4\u901a\u573a\u666f\u3002"}}
{"id": "2508.21441", "categories": ["cs.AI", "68T30, 68T27"], "pdf": "https://arxiv.org/pdf/2508.21441", "abs": "https://arxiv.org/abs/2508.21441", "authors": ["Christoph Beierle", "Alexander Hahn", "Diana Howey", "Gabriele Kern-Isberner", "Kai Sauerwald"], "title": "A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions", "comment": null, "summary": "Forgetting as a knowledge management operation deliberately ignores parts of\nthe knowledge and beliefs of an agent, for various reasons. Forgetting has many\nfacets, one may want to forget parts of the syntax, a proposition, or a\nconditional. In the literature, two main operators suitable for performing\nforgetting have been proposed and investigated in depth: First, variable\nelimination is a syntactical method that blends out certain atomic variables to\nfocus on the rest of the language. It has been mainly used in the area of logic\nprogramming and answer set programming. Second, contraction in AGM belief\nrevision theory effectively removes propositions from belief sets under logical\ndeduction. Both operations rely mainly on classical logics. In this article, we\ntake an epistemic perspective and study forgetting operations in epistemic\nstates with richer semantic structures, but with clear links to propositional\nlogic. This allows us to investigate what forgetting in the epistemic\nbackground means, thereby lifting well-known and novel forgetting operations to\nthe epistemic level. We present five general types of epistemic forgetting and\ninstantiate them with seven concrete forgetting operations for Spohn's ranking\nfunctions. We take inspiration from postulates of forgetting both from logic\nprogramming and AGM theory to propose a rich landscape of axioms for evaluating\nforgetting operations. Finally, we evaluate all concrete forgetting operations\naccording to all postulates, leading to a novel comprehensive overview\nhighlighting differences and commonalities among the forgetting operators.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u77e5\u8bc6\u5e93\u4e2d\u9057\u5fd8\u64cd\u4f5c\u7684\u8bed\u4e49\u7ed3\u6784\uff0c\u63d0\u51fa\u4e86\u4e94\u79cd\u7c7b\u578b\u7684\u8ba4\u77e5\u9057\u5fd8\u548c\u4e03\u79cd\u5177\u4f53\u7684\u9057\u5fd8\u64cd\u4f5c\uff0c\u5e76\u57fa\u4e8e\u903b\u8f91\u7f16\u7a0b\u548cAGM\u7406\u8bba\u7684\u516c\u7406\u5bf9\u8fd9\u4e9b\u64cd\u4f5c\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u9057\u5fd8\u64cd\u4f5c\u4e3b\u8981\u57fa\u4e8e\u7ecf\u5178\u903b\u8f91\uff0c\u672c\u6587\u4ece\u8ba4\u77e5\u89d2\u5ea6\uff0c\u7814\u7a76\u66f4\u4e30\u5bcc\u7684\u8bed\u4e49\u7ed3\u6784\u4e0b\u7684\u9057\u5fd8\u64cd\u4f5c\u3002", "method": "\u63d0\u51fa\u4e94\u79cd\u7c7b\u578b\u7684\u8ba4\u77e5\u9057\u5fd8\u548c\u4e03\u79cd\u5177\u4f53\u7684\u9057\u5fd8\u64cd\u4f5c\uff0c\u5e76\u57fa\u4e8e\u903b\u8f91\u7f16\u7a0b\u548cAGM\u7406\u8bba\u7684\u516c\u7406\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5bf9\u4e03\u79cd\u9057\u5fd8\u64cd\u4f5c\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u4e4b\u95f4\u7684\u5dee\u5f02\u548c\u5171\u6027\u3002", "conclusion": "\u672c\u6587\u4e30\u5bcc\u4e86\u9057\u5fd8\u64cd\u4f5c\u7684\u7814\u7a76\uff0c\u4e3a\u8bc4\u4f30\u9057\u5fd8\u64cd\u4f5c\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6982\u8ff0\u3002"}}
{"id": "2508.21449", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21449", "abs": "https://arxiv.org/abs/2508.21449", "authors": ["Niklas Jansen", "Jonas G\u00f6sgens", "Hector Geffner"], "title": "Learning Lifted Action Models From Traces of Incomplete Actions and States", "comment": "To be presented at KR 2025", "summary": "Consider the problem of learning a lifted STRIPS model of the sliding-tile\npuzzle from random state-action traces where the states represent the location\nof the tiles only, and the actions are the labels up, down, left, and right,\nwith no arguments. Two challenges are involved in this problem. First, the\nstates are not full STRIPS states, as some predicates are missing, like the\natoms representing the position of the ``blank''. Second, the actions are not\nfull STRIPS either, as they do not reveal all the objects involved in the\nactions effects and preconditions. Previous approaches have addressed different\nversions of this model learning problem, but most assume that actions in the\ntraces are full STRIPS actions or that the domain predicates are all\nobservable. The new setting considered in this work is more ``realistic'', as\nthe atoms observed convey the state of the world but not full STRIPS states,\nand the actions reveal the arguments needed for selecting the action but not\nthe ones needed for modeling it in STRIPS. For formulating and addressing the\nlearning problem, we introduce a variant of STRIPS, which we call STRIPS+,\nwhere certain STRIPS action arguments can be left implicit in preconditions\nwhich can also involve a limited form of existential quantification. The\nlearning problem becomes the problem of learning STRIPS+ models from STRIPS+\nstate-action traces. For this, the proposed learning algorithm, called SYNTH,\nconstructs a stratified sequence (conjunction) of precondition expressions or\n``queries'' for each action, that denote unique objects in the state and ground\nthe implicit action arguments in STRIPS+. The correctness and completeness of\nSYNTH is established, and its scalability is tested on state-action traces\nobtained from STRIPS+ models derived from existing STRIPS domains.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4ece\u4e0d\u5b8c\u6574\u7684\u6ed1\u5757\u62fc\u56fe\u72b6\u6001-\u52a8\u4f5c\u8f68\u8ff9\u4e2d\u5b66\u4e60\u63d0\u5347\u7684STRIPS\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u52a8\u4f5c\u662f\u5b8c\u6574\u7684STRIPS\u52a8\u4f5c\u6216\u6240\u6709\u9886\u57df\u8c13\u8bcd\u90fd\u53ef\u89c2\u5bdf\uff0c\u8fd9\u4e0e\u73b0\u5b9e\u60c5\u51b5\u4e0d\u7b26\u3002\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u66f4\u73b0\u5b9e\u7684\u8bbe\u7f6e\uff0c\u5176\u4e2d\u89c2\u5bdf\u5230\u7684\u539f\u5b50\u4f20\u8fbe\u4e86\u4e16\u754c\u7684\u72b6\u6001\uff0c\u4f46\u4e0d\u662f\u5b8c\u6574\u7684STRIPS\u72b6\u6001\uff0c\u52a8\u4f5c\u63ed\u793a\u4e86\u9009\u62e9\u52a8\u4f5c\u6240\u9700\u7684\u8bba\u8bc1\uff0c\u4f46\u4e0d\u662f\u5728STRIPS\u4e2d\u5efa\u6a21\u6240\u9700\u7684\u8bba\u8bc1\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSTRIPS+\u7684STRIPS\u53d8\u4f53\u548c\u4e00\u79cd\u540d\u4e3aSYNTH\u7684\u5b66\u4e60\u7b97\u6cd5\u3002STRIPS+\u5141\u8bb8\u5728\u5148\u51b3\u6761\u4ef6\u4e2d\u7701\u7565\u67d0\u4e9bSTRIPS\u52a8\u4f5c\u53c2\u6570\uff0c\u5e76\u5141\u8bb8\u6709\u9650\u5f62\u5f0f\u7684\u5b58\u5728\u91cf\u5316\u3002SYNTH\u7b97\u6cd5\u6784\u5efa\u4e00\u4e2a\u5206\u5c42\u7684\u5148\u51b3\u6761\u4ef6\u8868\u8fbe\u5f0f\u5e8f\u5217\uff0c\u7528\u4e8e\u552f\u4e00\u5730\u8868\u793a\u72b6\u6001\u4e2d\u7684\u5bf9\u8c61\u5e76\u786e\u5b9aSTRIPS+\u4e2d\u9690\u5f0f\u52a8\u4f5c\u7684\u53c2\u6570\u3002", "result": "\u672c\u6587\u8bc1\u660e\u4e86SYNTH\u7b97\u6cd5\u7684\u6b63\u786e\u6027\u548c\u5b8c\u6574\u6027\uff0c\u5e76\u5728\u4ece\u73b0\u6709STRIPS\u9886\u57df\u5bfc\u51fa\u7684STRIPS+\u6a21\u578b\u83b7\u5f97\u7684\u72b6\u6001-\u52a8\u4f5c\u8f68\u8ff9\u4e0a\u6d4b\u8bd5\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684STRIPS+\u6a21\u578b\u548c\u5b66\u4e60\u7b97\u6cd5SYNTH\uff0c\u80fd\u591f\u4ece\u4e0d\u5b8c\u6574\u7684\u89c2\u6d4b\u6570\u636e\u4e2d\u5b66\u4e60\u63d0\u5347\u7684STRIPS\u6a21\u578b\uff0c\u4e3a\u66f4\u73b0\u5b9e\u7684\u6a21\u578b\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.21475", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21475", "abs": "https://arxiv.org/abs/2508.21475", "authors": ["Xijia Tao", "Yihua Teng", "Xinxing Su", "Xinyu Fu", "Jihao Wu", "Chaofan Tao", "Ziru Liu", "Haoli Bai", "Rui Liu", "Lingpeng Kong"], "title": "MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents", "comment": "Project Page: https://mmsearch-plus.github.io", "summary": "Large multimodal language models (MLLMs) are increasingly deployed as web\nagents, yet many multimodal browsing benchmarks can be solved by shallow, fixed\nworkflows that lean on high-recall image search and nearby text-masking the\ngenuinely multimodal challenges of fine-grained visual reasoning, provenance\nverification, and long-horizon tool use. We introduce MMSearch-Plus, a\nbenchmark of 311 tasks that highly demand multimodal understanding while\npreserving the difficulty profile of strong text-only browsing suites. Each\nitem is constructed to contain multiple weak, localized visual signals that\nmust be extracted, propagated through iterative text-image search, and\ncross-validated under retrieval noise before answering. Our curation procedure,\nSpatial-Temporal Extrapolation, seeds questions whose answers require\nextrapolating from spatial cues (micro-text, part-level appearance, layouts,\nsignage) and temporal traces (broadcast overlays, seasonal context) to\nout-of-image facts such as events, dates, and venues. We provide a\nmodel-agnostic agent framework with browsing tools and evaluate a range of\nclosed and open MLLMs. The strongest agent (o3) attains 15.1% without search\nand 36.0% accuracy with rollout under our framework, while a strong open-source\nmodel (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20\nrounds of search. Beyond answer accuracy, we assess bounding-box production and\ncropped-image search, and conduct an error analysis that surfaces failures in\nsource verification, part-based reasoning, and long-horizon planning.", "AI": {"tldr": "MMSearch-Plus\uff0c\u4e00\u4e2a\u5305\u542b311\u4e2a\u4efb\u52a1\u7684\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b(MLLM)\u5728\u590d\u6742\u591a\u6a21\u6001\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u7ec6\u7c92\u5ea6\u89c6\u89c9\u63a8\u7406\u3001\u6765\u6e90\u9a8c\u8bc1\u548c\u957f\u671f\u5de5\u5177\u4f7f\u7528\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5bb9\u6613\u88ab\u7b80\u5355\u7684\u56fa\u5b9a\u5de5\u4f5c\u6d41\u7a0b\u89e3\u51b3\uff0cMMSearch-Plus\u65e8\u5728\u63d0\u9ad8\u96be\u5ea6\uff0c\u9700\u8981\u6a21\u578b\u8fdb\u884c\u8fed\u4ee3\u7684\u6587\u672c\u56fe\u50cf\u641c\u7d22\u548c\u4ea4\u53c9\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6MMSearch-Plus\u548c\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u5e76\u5bf9\u4e00\u7cfb\u5217\u95ed\u6e90\u548c\u5f00\u6e90MLLM\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u51c6\u786e\u7387\u3001\u8fb9\u754c\u6846\u751f\u6210\u548c\u88c1\u526a\u56fe\u50cf\u641c\u7d22\u7b49\u3002", "result": "\u6700\u5f3a\u4ee3\u7406\u5728\u4f7f\u7528\u641c\u7d22\u7684\u60c5\u51b5\u4e0b\u8fbe\u523036.0%\u7684\u51c6\u786e\u7387\uff0c\u800c\u4e00\u4e2a\u5f3a\u5927\u7684\u5f00\u6e90\u6a21\u578bQwen-2.5-VL-72B-Instruct\u4ec5\u8fbe\u52306.9%\u3002\u9519\u8bef\u5206\u6790\u63ed\u793a\u4e86\u6a21\u578b\u5728\u6765\u6e90\u9a8c\u8bc1\u3001\u57fa\u4e8e\u90e8\u5206\u7684\u63a8\u7406\u548c\u957f\u671f\u89c4\u5212\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "conclusion": "MMSearch-Plus\u4e3a\u8bc4\u4f30MLLM\u7684\u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u5177\u6311\u6218\u6027\u7684\u57fa\u51c6\uff0c\u7a81\u663e\u4e86\u73b0\u6709\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2508.21517", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21517", "abs": "https://arxiv.org/abs/2508.21517", "authors": ["Sweta Kaman", "Ankita Sharma", "Romi Banerjee"], "title": "Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis", "comment": "total 17 pages, main manuscript 12 pages, supplementary 5 pages, 6\n  tables in main manuscript, 5 figures in main manuscript, 2 tables in\n  supplementary, and 3 figures in supplementary", "summary": "Background: Wisdom is a superordinate construct that embraces perspective\ntaking, reflectiveness, prosocial orientation, reflective empathetic action,\nand intellectual humility. Unlike conventional models of reasoning that are\nrigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,\nrequiring both graded evaluation and self-reflective humility. Current measures\ndepend on self-reports and seldom reflect the humility and uncertainty inherent\nin wise reasoning. A computational framework that takes into account both\nmultidimensionality and confidence has the potential to improve psychological\nscience and allow humane AI. Method: We present a fuzzy inference system with Z\nnumbers, each of the decisions being expressed in terms of a wisdom score\n(restriction) and confidence score (certainty). As part of this study,\nparticipants (N = 100) were exposed to culturally neutral pictorial moral\ndilemma tasks to which they generated think-aloud linguistic responses, which\nwere mapped into five theoretically based components of wisdom. The scores of\neach individual component were combined using a base of 21 rules, with\nmembership functions tuned via Gaussian kernel density estimation. Results: In\na proof of concept study, the system produced dual attribute wisdom\nrepresentations that correlated modestly but significantly with established\nscales while showing negligible relations with unrelated traits, supporting\nconvergent and divergent validity. Contribution: The contribution is to\nformalize wisdom as a multidimensional, uncertainty-conscious construct,\noperationalized in the form of Z-numbers. In addition to progressing\nmeasurement in psychology, it calculates how fuzzy Z numbers can provide AI\nsystems with interpretable, confidence-sensitive reasoning that affords a safe,\nmiddle ground between rigorous computation and human-like judgment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u548cZ\u6570\u7684\u667a\u6167\u5ea6\u91cf\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e2a\u4f53\u5728\u9762\u5bf9\u9053\u5fb7\u56f0\u5883\u65f6\u7684\u667a\u6167\u6c34\u5e73\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u667a\u6167\u5ea6\u91cf\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u540c\u65f6\u8003\u8651\u667a\u6167\u7684\u591a\u7ef4\u5ea6\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u8ba1\u7b97\u6846\u67b6\u3002", "method": "\u91c7\u7528\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u548cZ\u6570\uff0c\u7ed3\u5408\u53c2\u4e0e\u8005\u5bf9\u56fe\u7247\u9053\u5fb7\u56f0\u5883\u7684\u601d\u8003\u8fc7\u7a0b\uff0c\u8ba1\u7b97\u5176\u667a\u6167\u5f97\u5206\u548c\u7f6e\u4fe1\u5ea6\u5f97\u5206\u3002", "result": "\u8be5\u7cfb\u7edf\u751f\u6210\u7684\u667a\u6167\u8868\u8fbe\u4e0e\u65e2\u6709\u91cf\u8868\u9002\u5ea6\u76f8\u5173\uff0c\u652f\u6301\u5176\u6536\u655b\u6548\u5ea6\u548c\u533a\u5206\u6548\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5730\u5c06\u667a\u6167\u5f62\u5f0f\u5316\u4e3a\u4e86\u4e00\u4e2a\u591a\u7ef4\u5ea6\u3001\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u7684\u7ed3\u6784\uff0c\u4e3a\u5fc3\u7406\u5b66\u6d4b\u91cf\u548c\u4eba\u5de5\u667a\u80fd\u7684\u7f6e\u4fe1\u654f\u611f\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2508.21521", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21521", "abs": "https://arxiv.org/abs/2508.21521", "authors": ["Nicola Gigante", "Francesco Leofante", "Andrea Micheli"], "title": "Counterfactual Scenarios for Automated Planning", "comment": "Accepted at the 22nd International Conference on Principles of\n  Knowledge Representation and Reasoning (KR 2025)", "summary": "Counterfactual Explanations (CEs) are a powerful technique used to explain\nMachine Learning models by showing how the input to a model should be minimally\nchanged for the model to produce a different output. Similar proposals have\nbeen made in the context of Automated Planning, where CEs have been\ncharacterised in terms of minimal modifications to an existing plan that would\nresult in the satisfaction of a different goal. While such explanations may\nhelp diagnose faults and reason about the characteristics of a plan, they fail\nto capture higher-level properties of the problem being solved. To address this\nlimitation, we propose a novel explanation paradigm that is based on\ncounterfactual scenarios. In particular, given a planning problem $P$ and an\n\\ltlf formula $\\psi$ defining desired properties of a plan, counterfactual\nscenarios identify minimal modifications to $P$ such that it admits plans that\ncomply with $\\psi$. In this paper, we present two qualitative instantiations of\ncounterfactual scenarios based on an explicit quantification over plans that\nmust satisfy $\\psi$. We then characterise the computational complexity of\ngenerating such counterfactual scenarios when different types of changes are\nallowed on $P$. We show that producing counterfactual scenarios is often only\nas expensive as computing a plan for $P$, thus demonstrating the practical\nviability of our proposal and ultimately providing a framework to construct\npractical algorithms in this area.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u573a\u666f\u7684\u65b0\u7684\u89e3\u91ca\u8303\u5f0f\uff0c\u7528\u4e8e\u89e3\u91ca\u89c4\u5212\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u672a\u80fd\u6355\u6349\u5230\u6240\u89e3\u51b3\u95ee\u9898\u7684\u66f4\u9ad8\u5c42\u6b21\u5c5e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u573a\u666f\u7684\u65b0\u89e3\u91ca\u8303\u5f0f\uff0c\u5e76\u7ed9\u51fa\u4e86\u4e24\u79cd\u5b9a\u6027\u5b9e\u4f8b\u5316\u3002", "result": "\u523b\u753b\u4e86\u751f\u6210\u53cd\u4e8b\u5b9e\u573a\u666f\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8868\u660e\u5176\u8ba1\u7b97\u4ee3\u4ef7\u4e0e\u8ba1\u7b97\u89c4\u5212\u95ee\u9898\u89e3\u7684\u4ee3\u4ef7\u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u4e3a\u6784\u5efa\u5b9e\u9645\u7b97\u6cd5\u63d0\u4f9b\u4e86\u6846\u67b6\u3002"}}
{"id": "2508.21540", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21540", "abs": "https://arxiv.org/abs/2508.21540", "authors": ["Eduardo Illueca-Fernandez", "Kaile Chen", "Fernando Seoane", "Farhad Abtahi"], "title": "HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining", "comment": null, "summary": "Process mining has emerged as a powerful analytical technique for\nunderstanding complex healthcare workflows. However, its application faces\nsignificant barriers, including technical complexity, a lack of standardized\napproaches, and limited access to practical training resources. We introduce\nHealthProcessAI, a GenAI framework designed to simplify process mining\napplications in healthcare and epidemiology by providing a comprehensive\nwrapper around existing Python (PM4PY) and R (bupaR) libraries. To address\nunfamiliarity and improve accessibility, the framework integrates multiple\nLarge Language Models (LLMs) for automated process map interpretation and\nreport generation, helping translate technical analyses into outputs that\ndiverse users can readily understand. We validated the framework using sepsis\nprogression data as a proof-of-concept example and compared the outputs of five\nstate-of-the-art LLM models through the OpenRouter platform. To test its\nfunctionality, the framework successfully processed sepsis data across four\nproof-of-concept scenarios, demonstrating robust technical performance and its\ncapability to generate reports through automated LLM analysis. LLM evaluation\nusing five independent LLMs as automated evaluators revealed distinct model\nstrengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency\nscores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By\nintegrating multiple Large Language Models (LLMs) for automated interpretation\nand report generation, the framework addresses widespread unfamiliarity with\nprocess mining outputs, making them more accessible to clinicians, data\nscientists, and researchers. This structured analytics and AI-driven\ninterpretation combination represents a novel methodological advance in\ntranslating complex process mining results into potentially actionable insights\nfor healthcare applications.", "AI": {"tldr": "HealthProcessAI\u6846\u67b6\u4f7f\u7528GenAI\u7b80\u5316\u533b\u7597\u6d41\u7a0b\u6316\u6398\uff0c\u96c6\u6210LLM\u81ea\u52a8\u89e3\u91ca\u548c\u62a5\u544a\u751f\u6210\uff0c\u63d0\u9ad8\u53ef\u8bbf\u95ee\u6027\u3002", "motivation": "\u533b\u7597\u6d41\u7a0b\u6316\u6398\u5e94\u7528\u53d7\u6280\u672f\u590d\u6742\u6027\u3001\u7f3a\u4e4f\u6807\u51c6\u5316\u65b9\u6cd5\u548c\u57f9\u8bad\u8d44\u6e90\u9650\u5236\uff0cHealthProcessAI\u6846\u67b6\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u6574\u5408Python (PM4PY)\u548cR (bupaR)\u5e93\u7684GenAI\u6846\u67b6\uff0c\u96c6\u6210\u591a\u4e2aLLM\u8fdb\u884c\u81ea\u52a8\u5316\u6d41\u7a0b\u56fe\u89e3\u8bfb\u548c\u62a5\u544a\u751f\u6210\uff0c\u5e76\u7528\u8113\u6bd2\u75c7\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\uff0c\u6bd4\u8f83\u4e94\u4e2aLLM\u6a21\u578b\u7684\u8f93\u51fa\u3002", "result": "\u6210\u529f\u5904\u7406\u8113\u6bd2\u75c7\u6570\u636e\uff0c\u751f\u6210\u62a5\u544a\uff0cClaude Sonnet-4\u548cGemini 2.5-Pro\u7684LLM\u8bc4\u4f30\u4e00\u81f4\u6027\u5f97\u5206\u6700\u9ad8\u3002", "conclusion": "HealthProcessAI\u6846\u67b6\u901a\u8fc7\u6574\u5408LLM\u63d0\u9ad8\u4e86\u6d41\u7a0b\u6316\u6398\u7ed3\u679c\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u4e3a\u533b\u7597\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u662f\u533b\u7597\u6d41\u7a0b\u6316\u6398\u9886\u57df\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2508.21564", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21564", "abs": "https://arxiv.org/abs/2508.21564", "authors": ["Issa Hanou", "Sebastijan Duman\u010di\u0107", "Mathijs de Weerdt"], "title": "Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances", "comment": null, "summary": "We propose a new framework for discovering landmarks that automatically\ngeneralize across a domain. These generalized landmarks are learned from a set\nof solved instances and describe intermediate goals for planning problems where\ntraditional landmark extraction algorithms fall short. Our generalized\nlandmarks extend beyond the predicates of a domain by using state functions\nthat are independent of the objects of a specific problem and apply to all\nsimilar objects, thus capturing repetition. Based on these functions, we\nconstruct a directed generalized landmark graph that defines the landmark\nprogression, including loop possibilities for repetitive subplans. We show how\nto use this graph in a heuristic to solve new problem instances of the same\ndomain. Our results show that the generalized landmark graphs learned from a\nfew small instances are also effective for larger instances in the same domain.\nIf a loop that indicates repetition is identified, we see a significant\nimprovement in heuristic performance over the baseline. Generalized landmarks\ncapture domain information that is interpretable and useful to an automated\nplanner. This information can be discovered from a small set of plans for the\nsame domain.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u5b66\u4e60\u53ef\u6cdb\u5316\u4e8e\u6574\u4e2a\u9886\u57df\u7684\u6807\u5fd7\u6027\u8282\u70b9\uff0c\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf\u7b97\u6cd5\u96be\u4ee5\u5904\u7406\u7684\u89c4\u5212\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6807\u5fd7\u6027\u8282\u70b9\u63d0\u53d6\u7b97\u6cd5\u96be\u4ee5\u5904\u7406\u7684\u89c4\u5212\u95ee\u9898\u3002", "method": "\u5b66\u4e60\u57fa\u4e8e\u72b6\u6001\u51fd\u6570\u7684\u6cdb\u5316\u6807\u5fd7\u6027\u8282\u70b9\uff0c\u6784\u5efa\u6709\u5411\u56fe\uff0c\u7528\u4e8e\u542f\u53d1\u5f0f\u641c\u7d22\u3002", "result": "\u5728\u76f8\u540c\u9886\u57df\u7684\u5927\u578b\u5b9e\u4f8b\u4e2d\uff0c\u4ece\u5c11\u91cf\u5c0f\u578b\u5b9e\u4f8b\u5b66\u4e60\u5230\u7684\u6cdb\u5316\u6807\u5fd7\u6027\u8282\u70b9\u56fe\u540c\u6837\u6709\u6548\uff1b\u8bc6\u522b\u5faa\u73af\u53ef\u663e\u8457\u63d0\u5347\u542f\u53d1\u5f0f\u6027\u80fd\u3002", "conclusion": "\u6cdb\u5316\u6807\u5fd7\u6027\u8282\u70b9\u53ef\u6355\u83b7\u9886\u57df\u4fe1\u606f\uff0c\u53ef\u7528\u4e8e\u81ea\u52a8\u5316\u89c4\u5212\u5668\uff0c\u4e14\u53ef\u4ece\u5c11\u91cf\u540c\u9886\u57df\u8ba1\u5212\u4e2d\u5b66\u4e60\u5f97\u5230\u3002"}}
{"id": "2508.21595", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21595", "abs": "https://arxiv.org/abs/2508.21595", "authors": ["Yang You", "Alex Schutz", "Zhikun Li", "Bruno Lacerda", "Robert Skilton", "Nick Hawes"], "title": "Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics", "comment": null, "summary": "Many high-level multi-agent planning problems, including multi-robot\nnavigation and path planning, can be effectively modeled using deterministic\nactions and observations.\n  In this work, we focus on such domains and introduce the class of\nDeterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of\nDec-POMDPs characterized by deterministic transitions and observations\nconditioned on the state and joint actions.\n  We then propose a practical solver called Iterative Deterministic POMDP\nPlanning (IDPP). This method builds on the classic Joint Equilibrium Search for\nPolicies framework and is specifically optimized to handle large-scale\nDet-Dec-POMDPs that current Dec-POMDP solvers are unable to address\nefficiently.", "AI": {"tldr": "\u9488\u5bf9\u786e\u5b9a\u6027\u5206\u6563\u5f0fPOMDP(Det-Dec-POMDP)\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u540d\u4e3a\u8fed\u4ee3\u786e\u5b9a\u6027POMDP\u89c4\u5212(IDPP)\u7684\u5b9e\u7528\u6c42\u89e3\u5668\u3002", "motivation": "\u8bb8\u591a\u9ad8\u5c42\u6b21\u591a\u667a\u80fd\u4f53\u89c4\u5212\u95ee\u9898\uff0c\u4f8b\u5982\u591a\u673a\u5668\u4eba\u5bfc\u822a\u548c\u8def\u5f84\u89c4\u5212\uff0c\u53ef\u4ee5\u4f7f\u7528\u786e\u5b9a\u6027\u52a8\u4f5c\u548c\u89c2\u6d4b\u6709\u6548\u5efa\u6a21\u3002", "method": "IDPP\u65b9\u6cd5\u57fa\u4e8e\u7ecf\u5178\u7684\u8054\u5408\u5747\u8861\u7b56\u7565\u641c\u7d22\u6846\u67b6\uff0c\u9488\u5bf9\u5927\u89c4\u6a21Det-Dec-POMDP\u95ee\u9898\u8fdb\u884c\u4e86\u4f18\u5316\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5f53\u524dDec-POMDP\u6c42\u89e3\u5668\u96be\u4ee5\u9ad8\u6548\u5904\u7406\u7684\u5927\u89c4\u6a21Det-Dec-POMDP\u95ee\u9898\u3002", "conclusion": "IDPP\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u786e\u5b9a\u6027\u5206\u6563\u5f0fPOMDP\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
