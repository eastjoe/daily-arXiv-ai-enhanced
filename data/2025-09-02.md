<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding](https://arxiv.org/abs/2508.21204)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 本文研究了架构归纳偏差如何影响大型语言模型(LLM)在指令式对话中的认知行为，提出了一种符号脚手架机制和短期记忆模式，以促进苏格拉底式教学中的自适应结构化推理，结果表明，完整的系统持续优于基线变体，移除记忆或符号结构会降低关键认知行为。


<details>
  <summary>Details</summary>
Motivation: 研究架构归纳偏差对大型语言模型在指令式对话中认知行为的影响。

Method: 引入符号脚手架机制和短期记忆模式，并通过控制消融实验评估模型输出。

Result: 完整系统持续优于基线变体；移除记忆或符号结构会降低抽象、自适应探测和概念连续性等关键认知行为。

Conclusion: 架构脚手架可以可靠地塑造LLM中出现的指令策略。

Abstract: We study how architectural inductive biases influence the cognitive behavior
of large language models (LLMs) in instructional dialogue. We introduce a
symbolic scaffolding mechanism paired with a short-term memory schema designed
to promote adaptive, structured reasoning in Socratic tutoring. Using
controlled ablation across five system variants, we evaluate model outputs via
expert-designed rubrics covering scaffolding, responsiveness, symbolic
reasoning, and conversational memory. We present preliminary results using an
LLM-based evaluation framework aligned to a cognitively grounded rubric. This
enables scalable, systematic comparisons across architectural variants in
early-stage experimentation. The preliminary results show that our full system
consistently outperforms baseline variants. Analysis reveals that removing
memory or symbolic structure degrades key cognitive behaviors, including
abstraction, adaptive probing, and conceptual continuity. These findings
support a processing-level account in which architectural scaffolds can
reliably shape emergent instructional strategies in LLMs.

</details>


### [2] [Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](https://arxiv.org/abs/2508.21238)
*Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman*

Main category: cs.AI

TL;DR: 本论文评估了两种流行的基于图的检索增强生成（GraphRAG）系统在阿尔茨海默病领域的性能，并将其与标准GPT-4o模型进行比较，同时提供了一个易于使用的界面。


<details>
  <summary>Details</summary>
Motivation: 现有LLM聊天机器人存在幻觉、领域知识有限和缺乏可解释性等问题，GraphRAG通过整合领域特定上下文信息来提高可靠性，但其在阿尔茨海默病等知识密集型领域的应用研究有限。

Method: 构建包含50篇论文和70个专家问题的阿尔茨海默病数据库，构建GraphRAG知识库，使用GPT-4o作为LLM，比较GraphRAG和标准GPT-4o模型的回答质量，并评估RAG和GraphRAG系统的可追溯性。

Result: 比较了GraphRAG和标准GPT-4o模型的回答质量，并评估了RAG和GraphRAG系统的可追溯性，提供了一个包含阿尔茨海默病数据库的易于使用的界面。

Conclusion: GraphRAG在阿尔茨海默病等知识密集型领域具有应用潜力，但仍需进一步研究以提高其可靠性和可解释性。

Abstract: In the past two years, large language model (LLM)-based chatbots, such as
ChatGPT, have revolutionized various domains by enabling diverse task
completion and question-answering capabilities. However, their application in
scientific research remains constrained by challenges such as hallucinations,
limited domain-specific knowledge, and lack of explainability or traceability
for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has
emerged as a promising approach to improving chatbot reliability by integrating
domain-specific contextual information before response generation, addressing
some limitations of standard LLMs. Despite its potential, there are only
limited studies that evaluate GraphRAG on specific domains that require
intensive knowledge, like Alzheimer's disease or other biomedical domains. In
this paper, we assess the quality and traceability of two popular GraphRAG
systems. We compile a database of 50 papers and 70 expert questions related to
Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as
the LLM for answering queries. We then compare the quality of responses
generated by GraphRAG with those from a standard GPT-4o model. Additionally, we
discuss and evaluate the traceability of several Retrieval-Augmented Generation
(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a
pre-built Alzheimer's disease database for researchers to test the performance
of both standard RAG and GraphRAG.

</details>


### [3] [MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems](https://arxiv.org/abs/2508.21307)
*Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala*

Main category: cs.AI

TL;DR: MultiFluxAI平台整合产品工程中大量异构数据源，利用生成式AI、向量化和自主编排等技术，动态响应复杂用户查询，增强用户参与度。


<details>
  <summary>Details</summary>
Motivation: 解决产品工程中数据管理和集成难题，提升用户参与度。

Method: 利用生成式AI、向量化和自主编排等先进AI技术。

Result: 提供动态、上下文感知的复杂用户查询响应。

Conclusion: MultiFluxAI平台有效整合数据，提升用户体验和参与度。

Abstract: MultiFluxAI is an innovative AI platform developed to address the challenges
of managing and integrating vast, disparate data sources in product engineering
across application domains. It addresses both current and new service related
queries that enhance user engagement in the digital ecosystem. This platform
leverages advanced AI techniques, such as Generative AI, vectorization, and
agentic orchestration to provide dynamic and context-aware responses to complex
user queries.

</details>


### [4] [Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation](https://arxiv.org/abs/2508.21320)
*Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao*

Main category: cs.AI

TL;DR: LINKO框架利用LLM增强多本体图学习，实现跨本体知识传播，提升医学概念表示学习效果，尤其在数据有限和罕见病预测场景下表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了不同医学本体间的交叉联系，限制了概念表示学习。

Method: 提出LINKO框架，利用LLM增强本体概念嵌入初始化，并进行双轴知识传播（本体内垂直传播和本体间水平传播）。

Result: 在两个公共数据集上验证了LINKO的优越性能，尤其在数据有限和罕见病预测场景下表现更佳。

Conclusion: LINKO作为一种插件式编码器，能增强现有EHR预测模型的鲁棒性。

Abstract: Medical ontology graphs map external knowledge to medical codes in electronic
health records via structured relationships. By leveraging domain-approved
connections (e.g., parent-child), predictive models can generate richer medical
concept representations by incorporating contextual information from related
concepts. However, existing literature primarily focuses on incorporating
domain knowledge from a single ontology system, or from multiple ontology
systems (e.g., diseases, drugs, and procedures) in isolation, without
integrating them into a unified learning structure. Consequently, concept
representation learning often remains limited to intra-ontology relationships,
overlooking cross-ontology connections. In this paper, we propose LINKO, a
large language model (LLM)-augmented integrative ontology learning framework
that leverages multiple ontology graphs simultaneously by enabling dual-axis
knowledge propagation both within and across heterogeneous ontology systems to
enhance medical concept representation learning. Specifically, LINKO first
employs LLMs to provide a graph-retrieval-augmented initialization for ontology
concept embedding, through an engineered prompt that includes concept
descriptions, and is further augmented with ontology context. Second, our
method jointly learns the medical concepts in diverse ontology graphs by
performing knowledge propagation in two axes: (1) intra-ontology vertical
propagation across hierarchical ontology levels and (2) inter-ontology
horizontal propagation within every level in parallel. Last, through extensive
experiments on two public datasets, we validate the superior performance of
LINKO over state-of-the-art baselines. As a plug-in encoder compatible with
existing EHR predictive models, LINKO further demonstrates enhanced robustness
in scenarios involving limited data availability and rare disease prediction.

</details>


### [5] [Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models](https://arxiv.org/abs/2508.21365)
*Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang*

Main category: cs.AI

TL;DR: 该论文提出了一种新框架Think in Games (TiG)，使大型语言模型(LLM)能够通过与游戏环境的交互学习程序性知识，并在复杂交互任务中取得与传统强化学习方法相竞争的性能，同时具有更高的效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型擅长复杂推理，但在简单的交互任务上表现不佳，该论文旨在弥合声明性知识和程序性知识之间的差距。

Method: 将强化学习的决策过程转化为语言建模任务，LLM生成语言引导策略，并通过在线强化学习迭代优化。

Result: TiG成功弥合了声明性和程序性知识之间的差距，在数据和计算需求上远低于传统强化学习方法，并提供逐步的自然语言解释。

Conclusion: TiG框架有效地赋予了LLM程序性理解能力，提高了其在交互式任务中的性能和可解释性。

Abstract: Large language models (LLMs) excel at complex reasoning tasks such as
mathematics and coding, yet they frequently struggle with simple interactive
tasks that young children perform effortlessly. This discrepancy highlights a
critical gap between declarative knowledge (knowing about something) and
procedural knowledge (knowing how to do something). Although traditional
reinforcement learning (RL) agents can acquire procedural knowledge through
environmental interaction, they often operate as black boxes and require
substantial training data. In contrast, LLMs possess extensive world knowledge
and reasoning capabilities, but are unable to effectively convert this static
knowledge into dynamic decision-making in interactive settings. To address this
challenge, we propose Think in Games (TiG), a novel framework that empowers
LLMs to develop procedural understanding through direct interaction with game
environments, while retaining their inherent reasoning and explanatory
abilities. Specifically, TiG reformulates RL-based decision-making as a
language modeling task: LLMs generate language-guided policies, which are
refined iteratively through online reinforcement learning based on
environmental feedback. Our experimental results show that TiG successfully
bridges the gap between declarative and procedural knowledge, achieving
competitive performance with dramatically lower data and computational demands
compared to conventional RL methods. Moreover, TiG provides step-by-step
natural language explanations for its decisions, greatly improving transparency
and interpretability in complex interactive tasks.

</details>


### [6] [AHELM: A Holistic Evaluation of Audio-Language Models](https://arxiv.org/abs/2508.21376)
*Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang*

Main category: cs.AI

TL;DR: AHELM基准测试对14个音频语言模型(ALM)进行了评估，发现Gemini 2.5 Pro在10个方面中有5个排名第一，但存在群体不公平问题。


<details>
  <summary>Details</summary>
Motivation: 缺乏标准化的ALM基准测试，现有测试方法存在局限性。

Method: 构建AHELM基准测试，包含多个数据集，涵盖音频感知、推理、情感检测、公平性等10个方面，对14个ALM进行标准化评估。

Result: Gemini 2.5 Pro在5个方面排名第一，但存在群体不公平问题；一些简单的基线系统表现良好。

Conclusion: AHELM为ALM的全面评估提供了一个标准化基准，未来将持续更新。

Abstract: Evaluations of audio-language models (ALMs) -- multimodal models that take
interleaved audio and text as input and output text -- are hindered by the lack
of standardized benchmarks; most benchmarks measure only one or two
capabilities and omit evaluative aspects such as fairness or safety.
Furthermore, comparison across models is difficult as separate evaluations test
a limited number of models and use different prompting methods and inference
parameters. To address these shortfalls, we introduce AHELM, a benchmark that
aggregates various datasets -- including 2 new synthetic audio-text datasets
called PARADE, which evaluates the ALMs on avoiding stereotypes, and
CoRe-Bench, which measures reasoning over conversational audio through
inferential multi-turn question answering -- to holistically measure the
performance of ALMs across 10 aspects we have identified as important to the
development and usage of ALMs: audio perception, knowledge, reasoning, emotion
detection, bias, fairness, multilinguality, robustness, toxicity, and safety.
We also standardize the prompts, inference parameters, and evaluation metrics
to ensure equitable comparisons across models. We test 14 open-weight and
closed-API ALMs from 3 developers and 3 additional simple baseline systems each
consisting of an automatic speech recognizer and a language model. Our results
show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits
group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do
not. We also find that the baseline systems perform reasonably well on AHELM,
with one ranking 5th overall despite having only speech-to-text capabilities.
For transparency, all raw prompts, model generations, and outputs are available
on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is
intended to be a living benchmark and new datasets and models will be added
over time.

</details>


### [7] [AI Compute Architecture and Evolution Trends](https://arxiv.org/abs/2508.21394)
*Bor-Sung Liang*

Main category: cs.AI

TL;DR: 本文分析了AI发展的机遇和挑战，提出了一个七层AI计算架构模型，并探讨了AI从单一智能体到AI生态系统的演进以及经济因素的影响。


<details>
  <summary>Details</summary>
Motivation: AI发展从学术研究转向实际应用，面临诸多挑战，需要系统性分析。

Method: 构建七层AI计算架构模型，分析大型语言模型的演进阶段，探讨各层关键技术及发展趋势，并结合互联网产业发展预测AI未来走向。

Result: 提出了一个七层AI计算架构模型，阐述了大型语言模型的三阶段演进，分析了AI智能体发展趋势及经济可持续性问题。

Conclusion: AI发展需要关注技术和经济两方面，构建可持续的AI生态系统至关重要。未来AI发展将呈现出从单一智能体到复杂生态系统的演进趋势。

Abstract: The focus of AI development has shifted from academic research to practical
applications. However, AI development faces numerous challenges at various
levels. This article will attempt to analyze the opportunities and challenges
of AI from several different perspectives using a structured approach. This
article proposes a seven-layer model for AI compute architecture, including
Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,
Orchestrator Layer, and Application Layer, from bottom to top. It also explains
how AI computing has evolved into this 7-layer architecture through the
three-stage evolution on large-scale language models (LLMs). For each layer, we
describe the development trajectory and key technologies. In Layers 1 and 2 we
discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies
on computing architecture. In Layer 3 we explore two different development
paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs
and compares it to traditional processor memory. In Layers 5 to 7 we discuss
the trends of AI agents and explore the issues in evolution from a single AI
agent to an AI-based ecosystem, and their impact on the AI industry.
Furthermore, AI development involves not only technical challenges but also the
economic issues to build self-sustainable ecosystem. This article analyzes the
internet industry to provide predictions on the future trajectory of AI
development.

</details>


### [8] [CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN](https://arxiv.org/abs/2508.21411)
*Leonard Frank Neis,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: CARJAN工具结合AJAN和CARLA，实现城市交通场景的半自动化生成和仿真，支持多种交互代理（行人、自行车、自动驾驶车辆）。


<details>
  <summary>Details</summary>
Motivation: 现有工具难以便捷地模拟包含多种交互代理的城市交通场景。

Method: 基于多智能体工程框架AJAN和驾驶模拟器CARLA，采用SPARQL行为树进行决策和交互，提供可视化用户界面进行建模、存储和维护。

Result: 提供了一种交互式、智能的基于智能体的虚拟交通场景生成和仿真方法。

Conclusion: CARJAN是第一个集成交互式智能代理的CARLA虚拟交通场景生成和仿真工具。

Abstract: User-friendly modeling and virtual simulation of urban traffic scenarios with
different types of interacting agents such as pedestrians, cyclists and
autonomous vehicles remains a challenge. We present CARJAN, a novel tool for
semi-automated generation and simulation of such scenarios based on the
multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN
provides a visual user interface for the modeling, storage and maintenance of
traffic scenario layouts, and leverages SPARQL Behavior Tree-based
decision-making and interactions for agents in dynamic scenario simulations in
CARLA. CARJAN provides a first integrated approach for interactive, intelligent
agent-based generation and simulation of virtual traffic scenarios in CARLA.

</details>


### [9] [A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions](https://arxiv.org/abs/2508.21441)
*Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald*

Main category: cs.AI

TL;DR: 本文研究了知识库中“遗忘”操作的语义和公理化系统，提出了五种类型的认知遗忘操作和七种具体的遗忘操作，并根据既有公理对它们进行了评估。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘操作主要基于经典逻辑，本文从认知状态出发，研究更丰富的语义结构下的遗忘操作。

Method: 提出了五种类型的认知遗忘操作和七种具体的遗忘操作，并基于逻辑编程和AGM理论的公理对它们进行了评估。

Result: 对七种具体遗忘操作进行了全面的比较，揭示了它们之间的差异和共性。

Conclusion: 本文为认知状态下的遗忘操作提供了新的视角和全面的概述。

Abstract: Forgetting as a knowledge management operation deliberately ignores parts of
the knowledge and beliefs of an agent, for various reasons. Forgetting has many
facets, one may want to forget parts of the syntax, a proposition, or a
conditional. In the literature, two main operators suitable for performing
forgetting have been proposed and investigated in depth: First, variable
elimination is a syntactical method that blends out certain atomic variables to
focus on the rest of the language. It has been mainly used in the area of logic
programming and answer set programming. Second, contraction in AGM belief
revision theory effectively removes propositions from belief sets under logical
deduction. Both operations rely mainly on classical logics. In this article, we
take an epistemic perspective and study forgetting operations in epistemic
states with richer semantic structures, but with clear links to propositional
logic. This allows us to investigate what forgetting in the epistemic
background means, thereby lifting well-known and novel forgetting operations to
the epistemic level. We present five general types of epistemic forgetting and
instantiate them with seven concrete forgetting operations for Spohn's ranking
functions. We take inspiration from postulates of forgetting both from logic
programming and AGM theory to propose a rich landscape of axioms for evaluating
forgetting operations. Finally, we evaluate all concrete forgetting operations
according to all postulates, leading to a novel comprehensive overview
highlighting differences and commonalities among the forgetting operators.

</details>


### [10] [Learning Lifted Action Models From Traces of Incomplete Actions and States](https://arxiv.org/abs/2508.21449)
*Niklas Jansen,Jonas Gösgens,Hector Geffner*

Main category: cs.AI

TL;DR: 本文提出了一种学习滑动块拼图提升STRIPS模型的方法，该方法能够处理不完整状态和动作信息。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设动作是完整的STRIPS动作或所有领域谓词都可观察，这与实际情况不符。本文考虑更真实的场景，即观察到的原子传达了世界的状态，但不是完整的STRIPS状态，动作揭示了选择动作所需的论据，而不是在STRIPS中建模所需的论据。

Method: 本文引入了一种STRIPS的变体STRIPS+，其中某些STRIPS动作参数可以在先决条件中隐式地留下，先决条件也可以包含有限形式的存在量化。提出的学习算法SYNTH构建了一个分层的先决条件表达式序列，用于表示状态中的唯一对象，并对STRIPS+中的隐式动作参数进行接地。

Result: 证明了SYNTH的正确性和完整性，并在从现有STRIPS领域导出的STRIPS+模型获得的状态-动作轨迹上测试了其可扩展性。

Conclusion: 本文提出了一种有效的学习算法SYNTH，能够从不完整信息中学习STRIPS+模型，为解决更真实的模型学习问题提供了新的思路。

Abstract: Consider the problem of learning a lifted STRIPS model of the sliding-tile
puzzle from random state-action traces where the states represent the location
of the tiles only, and the actions are the labels up, down, left, and right,
with no arguments. Two challenges are involved in this problem. First, the
states are not full STRIPS states, as some predicates are missing, like the
atoms representing the position of the ``blank''. Second, the actions are not
full STRIPS either, as they do not reveal all the objects involved in the
actions effects and preconditions. Previous approaches have addressed different
versions of this model learning problem, but most assume that actions in the
traces are full STRIPS actions or that the domain predicates are all
observable. The new setting considered in this work is more ``realistic'', as
the atoms observed convey the state of the world but not full STRIPS states,
and the actions reveal the arguments needed for selecting the action but not
the ones needed for modeling it in STRIPS. For formulating and addressing the
learning problem, we introduce a variant of STRIPS, which we call STRIPS+,
where certain STRIPS action arguments can be left implicit in preconditions
which can also involve a limited form of existential quantification. The
learning problem becomes the problem of learning STRIPS+ models from STRIPS+
state-action traces. For this, the proposed learning algorithm, called SYNTH,
constructs a stratified sequence (conjunction) of precondition expressions or
``queries'' for each action, that denote unique objects in the state and ground
the implicit action arguments in STRIPS+. The correctness and completeness of
SYNTH is established, and its scalability is tested on state-action traces
obtained from STRIPS+ models derived from existing STRIPS domains.

</details>


### [11] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: MMSearch-Plus，一个包含311个任务的新基准，用于评估大型多模态语言模型（MLLM）在复杂的多模态推理方面的能力，结果表明目前的MLLM模型在处理需要细粒度视觉推理、来源验证和长期工具使用的任务上仍然存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试容易被简单的固定工作流程解决，难以真正评估MLLM的多模态理解能力。

Method: 构建MMSearch-Plus基准，包含需要迭代文本图像搜索和交叉验证的多步骤任务；使用空间时间外推法构建问题，答案需要从空间和时间线索中推断；评估一系列闭源和开源MLLM模型，并分析错误。

Result: 最强模型在使用搜索的情况下准确率达到36.0%，而强大的开源模型Qwen-2.5-VL-72B-Instruct仅达到6.9%。分析表明，模型在来源验证、基于部件的推理和长期规划方面存在不足。

Conclusion: MMSearch-Plus基准为评估MLLM的多模态理解能力提供了一个更具挑战性的平台，突显了未来研究方向。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [12] [Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis](https://arxiv.org/abs/2508.21517)
*Sweta Kaman,Ankita Sharma,Romi Banerjee*

Main category: cs.AI

TL;DR: 该论文提出一种基于模糊推理系统和Z数的智慧评估模型，该模型考虑了智慧的多维度和不确定性，并在概念验证研究中取得了初步成功。


<details>
  <summary>Details</summary>
Motivation: 现有智慧测量方法依赖于自我报告，难以反映智慧推理中固有的谦逊和不确定性。

Method: 采用模糊推理系统和Z数，将参与者的语言回应映射到五个基于理论的智慧构成要素，并结合21条规则计算智慧分数和置信度分数。

Result: 该系统生成的智慧表示与已建立的量表具有显著相关性，并显示出与无关特质的微弱关系，支持其收敛效度和区分效度。

Conclusion: 该研究将智慧形式化为多维度、不确定性感知的结构，并用Z数进行操作，这不仅推动了心理学测量的发展，也为人工智能系统提供了可解释的、置信度敏感的推理方法。

Abstract: Background: Wisdom is a superordinate construct that embraces perspective
taking, reflectiveness, prosocial orientation, reflective empathetic action,
and intellectual humility. Unlike conventional models of reasoning that are
rigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,
requiring both graded evaluation and self-reflective humility. Current measures
depend on self-reports and seldom reflect the humility and uncertainty inherent
in wise reasoning. A computational framework that takes into account both
multidimensionality and confidence has the potential to improve psychological
science and allow humane AI. Method: We present a fuzzy inference system with Z
numbers, each of the decisions being expressed in terms of a wisdom score
(restriction) and confidence score (certainty). As part of this study,
participants (N = 100) were exposed to culturally neutral pictorial moral
dilemma tasks to which they generated think-aloud linguistic responses, which
were mapped into five theoretically based components of wisdom. The scores of
each individual component were combined using a base of 21 rules, with
membership functions tuned via Gaussian kernel density estimation. Results: In
a proof of concept study, the system produced dual attribute wisdom
representations that correlated modestly but significantly with established
scales while showing negligible relations with unrelated traits, supporting
convergent and divergent validity. Contribution: The contribution is to
formalize wisdom as a multidimensional, uncertainty-conscious construct,
operationalized in the form of Z-numbers. In addition to progressing
measurement in psychology, it calculates how fuzzy Z numbers can provide AI
systems with interpretable, confidence-sensitive reasoning that affords a safe,
middle ground between rigorous computation and human-like judgment.

</details>


### [13] [Counterfactual Scenarios for Automated Planning](https://arxiv.org/abs/2508.21521)
*Nicola Gigante,Francesco Leofante,Andrea Micheli*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实场景的新的解释范式，用于解释规划问题。


<details>
  <summary>Details</summary>
Motivation: 现有的反事实解释方法未能捕捉到所解决问题的更高层次属性。

Method: 提出了一种基于反事实场景的新的解释范式，并给出了两种定性实例。

Result: 刻画了生成反事实场景的计算复杂度，证明了该方法的实用性。

Conclusion: 该方法为构建实际算法提供了一个框架。

Abstract: Counterfactual Explanations (CEs) are a powerful technique used to explain
Machine Learning models by showing how the input to a model should be minimally
changed for the model to produce a different output. Similar proposals have
been made in the context of Automated Planning, where CEs have been
characterised in terms of minimal modifications to an existing plan that would
result in the satisfaction of a different goal. While such explanations may
help diagnose faults and reason about the characteristics of a plan, they fail
to capture higher-level properties of the problem being solved. To address this
limitation, we propose a novel explanation paradigm that is based on
counterfactual scenarios. In particular, given a planning problem $P$ and an
\ltlf formula $\psi$ defining desired properties of a plan, counterfactual
scenarios identify minimal modifications to $P$ such that it admits plans that
comply with $\psi$. In this paper, we present two qualitative instantiations of
counterfactual scenarios based on an explicit quantification over plans that
must satisfy $\psi$. We then characterise the computational complexity of
generating such counterfactual scenarios when different types of changes are
allowed on $P$. We show that producing counterfactual scenarios is often only
as expensive as computing a plan for $P$, thus demonstrating the practical
viability of our proposal and ultimately providing a framework to construct
practical algorithms in this area.

</details>


### [14] [HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining](https://arxiv.org/abs/2508.21540)
*Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi*

Main category: cs.AI

TL;DR: HealthProcessAI框架简化医疗流程挖掘，整合LLM实现自动化报告生成，提升可访问性。Claude Sonnet-4和Gemini 2.5-Pro表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有流程挖掘技术应用于医疗保健领域面临技术复杂性、缺乏标准化方法和培训资源等挑战。

Method: 开发HealthProcessAI框架，整合Python(PM4PY)和R(bupaR)库，并集成多个LLM用于自动化流程图解读和报告生成。使用脓毒症数据进行验证，并通过OpenRouter平台比较五个LLM模型的输出。

Result: 成功处理脓毒症数据，生成报告，Claude Sonnet-4和Gemini 2.5-Pro的LLM评估一致性得分最高。

Conclusion: HealthProcessAI框架通过结合结构化分析和AI驱动的解释，将复杂的流程挖掘结果转化为可操作的医疗保健见解，具有显著的创新意义。

Abstract: Process mining has emerged as a powerful analytical technique for
understanding complex healthcare workflows. However, its application faces
significant barriers, including technical complexity, a lack of standardized
approaches, and limited access to practical training resources. We introduce
HealthProcessAI, a GenAI framework designed to simplify process mining
applications in healthcare and epidemiology by providing a comprehensive
wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address
unfamiliarity and improve accessibility, the framework integrates multiple
Large Language Models (LLMs) for automated process map interpretation and
report generation, helping translate technical analyses into outputs that
diverse users can readily understand. We validated the framework using sepsis
progression data as a proof-of-concept example and compared the outputs of five
state-of-the-art LLM models through the OpenRouter platform. To test its
functionality, the framework successfully processed sepsis data across four
proof-of-concept scenarios, demonstrating robust technical performance and its
capability to generate reports through automated LLM analysis. LLM evaluation
using five independent LLMs as automated evaluators revealed distinct model
strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency
scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By
integrating multiple Large Language Models (LLMs) for automated interpretation
and report generation, the framework addresses widespread unfamiliarity with
process mining outputs, making them more accessible to clinicians, data
scientists, and researchers. This structured analytics and AI-driven
interpretation combination represents a novel methodological advance in
translating complex process mining results into potentially actionable insights
for healthcare applications.

</details>


### [15] [Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances](https://arxiv.org/abs/2508.21564)
*Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt*

Main category: cs.AI

TL;DR: 提出一种新的框架来发现可自动泛化到整个领域的landmarks，该框架学习一系列已解决的实例，并描述传统landmark提取算法难以处理的规划问题的中间目标。


<details>
  <summary>Details</summary>
Motivation: 传统landmark提取算法难以处理复杂的规划问题，尤其是在存在重复子计划的情况下。

Method: 提出一种基于状态函数的泛化landmark框架，该框架使用与特定问题对象无关的状态函数来描述所有类似对象的中间目标，从而捕捉重复性，并构建一个有向泛化landmark图来定义landmark的进展，包括循环可能性。

Result: 实验结果表明，从少量小实例中学习到的泛化landmark图对同一领域中的更大实例也同样有效。如果识别到表示重复的循环，则启发式性能相较于基线有显著提高。

Conclusion: 泛化landmarks能够捕捉领域信息，这些信息对自动规划器来说是可解释且有用的，并且可以从同一领域的一小部分计划中发现。

Abstract: We propose a new framework for discovering landmarks that automatically
generalize across a domain. These generalized landmarks are learned from a set
of solved instances and describe intermediate goals for planning problems where
traditional landmark extraction algorithms fall short. Our generalized
landmarks extend beyond the predicates of a domain by using state functions
that are independent of the objects of a specific problem and apply to all
similar objects, thus capturing repetition. Based on these functions, we
construct a directed generalized landmark graph that defines the landmark
progression, including loop possibilities for repetitive subplans. We show how
to use this graph in a heuristic to solve new problem instances of the same
domain. Our results show that the generalized landmark graphs learned from a
few small instances are also effective for larger instances in the same domain.
If a loop that indicates repetition is identified, we see a significant
improvement in heuristic performance over the baseline. Generalized landmarks
capture domain information that is interpretable and useful to an automated
planner. This information can be discovered from a small set of plans for the
same domain.

</details>


### [16] [Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics](https://arxiv.org/abs/2508.21595)
*Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes*

Main category: cs.AI

TL;DR: 本文介绍了一种针对确定性分散式部分可观测马尔可夫决策过程(Det-Dec-POMDP)的实用求解器IDPP，该求解器能够有效处理大规模问题。


<details>
  <summary>Details</summary>
Motivation: 许多高层次多智能体规划问题，例如多机器人导航和路径规划，可以用确定性动作和观察结果有效建模。

Method: 提出了一种基于联合均衡策略搜索框架的迭代确定性POMDP规划(IDPP)方法，该方法针对大规模Det-Dec-POMDP进行了优化。

Result: IDPP能够有效解决当前Dec-POMDP求解器难以有效处理的大规模Det-Dec-POMDP问题。

Conclusion: IDPP为解决大规模确定性分散式部分可观测马尔可夫决策过程提供了一种有效的实用方法。

Abstract: Many high-level multi-agent planning problems, including multi-robot
navigation and path planning, can be effectively modeled using deterministic
actions and observations.
  In this work, we focus on such domains and introduce the class of
Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of
Dec-POMDPs characterized by deterministic transitions and observations
conditioned on the state and joint actions.
  We then propose a practical solver called Iterative Deterministic POMDP
Planning (IDPP). This method builds on the classic Joint Equilibrium Search for
Policies framework and is specifically optimized to handle large-scale
Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address
efficiently.

</details>
