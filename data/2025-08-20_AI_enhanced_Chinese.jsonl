{"id": "2508.13167", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.13167", "abs": "https://arxiv.org/abs/2508.13167", "authors": ["Weizhen Li", "Jianbo Lin", "Zhuosong Jiang", "Jingyi Cao", "Xinpeng Liu", "Jiayu Zhang", "Zhenqiang Huang", "Qianben Chen", "Weichen Sun", "Qiexiang Wang", "Hongxuan Lu", "Tianrui Qin", "Chenghao Zhu", "Yi Yao", "Shuying Fan", "Xiaowan Li", "Tiannan Wang", "Pai Liu", "King Zhu", "He Zhu", "Dingfeng Shi", "Piaohong Wang", "Yeyi Guan", "Xiangru Tang", "Minghao Liu", "Yuchen Eleanor Jiang", "Jian Yang", "Jiaheng Liu", "Ge Zhang", "Wangchunshu Zhou"], "title": "Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL", "comment": "51 pages", "summary": "Recent advances in large language models (LLMs) and multi-agent systems have\ndemonstrated remarkable capabilities in complex problem-solving tasks such as\ndeep research, vibe coding, and mathematical reasoning. However, most existing\nmulti-agent systems are built upon manual prompt/workflow engineering with\nsophisticated agent frameworks, making them computationally inefficient, less\ncapable, and can not benefit from data-centric learning. In this work, we\nintroduce Chain-of-Agents (CoA), a novel paradigm of LLM reasoning that enables\nnative end-to-end complex problem-solving in the same way as a multi-agent\nsystem (i.e., multi-turn problem solving with multiple tools and multiple\nagents) within one model. In chain-of-agents problem-solving, the model\ndynamically activates different tool agents and role-playing agents to simulate\nmulti-agent collaboration in an end-to-end fashion. To elicit end-to-end\nchain-of-agents problem-solving abilities in LLMs, we introduce a multi-agent\ndistillation framework to distill state-of-the-art multi-agent systems into\nchain-of-agents trajectories for agentic supervised fine-tuning. We then use\nagentic reinforcement learning on verifiable agentic tasks to further improve\nthe models' capabilities on chain-of-agents problem solving. We call the\nresulting models Agent Foundation Models (AFMs). Our empirical studies\ndemonstrate that AFM establishes new state-of-the-art performance across\ndiverse benchmarks in both web agent and code agent settings. We make the\nentire research, including the model weights, code for training and evaluation,\nand the training data, fully open-sourced, which offers a solid starting point\nfor future research on agent models and agentic RL.", "AI": {"tldr": "A new method, Chain-of-Agents, allows LLMs to perform complex problem-solving tasks efficiently, achieving state-of-the-art results and open-sourced for further research.", "motivation": "Existing multi-agent systems are inefficient and lack data-centric learning capabilities.  This work aims to create a more efficient and capable system using a single model.", "method": "The study introduces a chain-of-agents paradigm for LLM reasoning, a multi-agent distillation framework for fine-tuning, and agentic reinforcement learning for further improvement.  The resulting models are called Agent Foundation Models (AFMs).", "result": "AFMs establish new state-of-the-art performance across diverse benchmarks in web agent and code agent settings. The research, including model weights, code, and data, is open-sourced.", "conclusion": "Agent Foundation Models (AFMs) achieve state-of-the-art performance on diverse benchmarks by using a novel chain-of-agents (CoA) paradigm and a multi-agent distillation framework."}}
{"id": "2508.13171", "categories": ["cs.AI", "cs.CL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.13171", "abs": "https://arxiv.org/abs/2508.13171", "authors": ["Tao An"], "title": "Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context", "comment": "13 pages, 1 figure, code available at\n  https://github.com/tao-hpu/cognitive-workspace", "summary": "Large Language Models (LLMs) face fundamental limitations in context\nmanagement despite recent advances extending context windows to millions of\ntokens. We propose Cognitive Workspace, a novel paradigm that transcends\ntraditional Retrieval-Augmented Generation (RAG) by emulating human cognitive\nmechanisms of external memory use. Drawing from cognitive science foundations\nincluding Baddeley's working memory model, Clark's extended mind thesis, and\nHutchins' distributed cognition framework, we demonstrate that current passive\nretrieval systems fail to capture the dynamic, task-driven nature of human\nmemory management. Our analysis of 2024-2025 developments reveals that while\ntechniques like Infini-attention and StreamingLLM achieve impressive context\nlengths, they lack the metacognitive awareness and active planning capabilities\nessential for true cognitive extension. Cognitive Workspace addresses these\nlimitations through three core innovations: (1) active memory management with\ndeliberate information curation, (2) hierarchical cognitive buffers enabling\npersistent working states, and (3) task-driven context optimization that\ndynamically adapts to cognitive demands. Empirical validation demonstrates\nCognitive Workspace achieves an average 58.6% memory reuse rate (ranging from\n54-60% across different tasks) compared to 0% for traditional RAG, with 17-18%\nnet efficiency gain despite 3.3x higher operation counts. Statistical analysis\nconfirms these advantages with p < 0.001 and Cohen's d > 23 across multiple\ntask types, establishing the first quantitative evidence for active memory\nsuperiority in LLM systems. We present a comprehensive theoretical framework\nsynthesizing insights from 50+ recent papers, positioning Cognitive Workspace\nas a fundamental shift from information retrieval to genuine cognitive\naugmentation.", "AI": {"tldr": "\u65b0\u8303\u5f0fCognitive Workspace\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5185\u5b58\u91cd\u7528\u7387\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684LLM\u4e0a\u4e0b\u6587\u7ba1\u7406\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5373\u4f7f\u6269\u5c55\u4e86\u4e0a\u4e0b\u6587\u7a97\u53e3\uff0c\u4e5f\u7f3a\u4e4f\u4eba\u7c7b\u7684\u5143\u8ba4\u77e5\u610f\u8bc6\u548c\u4e3b\u52a8\u89c4\u5212\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCognitive Workspace\u7684\u65b0\u8303\u5f0f\uff0c\u5b83\u6a21\u62df\u4eba\u7c7b\u7684\u8ba4\u77e5\u673a\u5236\uff0c\u5305\u62ec\u4e3b\u52a8\u8bb0\u5fc6\u7ba1\u7406\u3001\u5206\u5c42\u8ba4\u77e5\u7f13\u51b2\u533a\u548c\u4efb\u52a1\u9a71\u52a8\u7684\u4e0a\u4e0b\u6587\u4f18\u5316\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cCognitive Workspace\u5e73\u5747\u5185\u5b58\u91cd\u7528\u7387\u8fbe\u523058.6%\uff0c\u6548\u7387\u63d0\u9ad8\u4e8617-18%\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edfRAG\u3002", "conclusion": "Cognitive Workspace\uff0c\u4e00\u79cd\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u673a\u5236\u7684\u5916\u90e8\u8bb0\u5fc6\u4f7f\u7528\u7684\u65b0\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edfRAG\u66f4\u9ad8\u7684\u5185\u5b58\u91cd\u7528\u7387\u548c\u6548\u7387\u589e\u76ca\u3002"}}
{"id": "2508.13174", "categories": ["cs.AI", "cs.LG", "q-fin.CP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.13174", "abs": "https://arxiv.org/abs/2508.13174", "authors": ["Hongjun Ding", "Binqi Chen", "Jinsheng Huang", "Taian Guo", "Zhengyang Mao", "Guoyi Shao", "Lutong Zou", "Luchen Liu", "Ming Zhang"], "title": "AlphaEval: A Comprehensive and Efficient Evaluation Framework for Formula Alpha Mining", "comment": "12 pages, 5 figures", "summary": "Formula alpha mining, which generates predictive signals from financial data,\nis critical for quantitative investment. Although various algorithmic\napproaches-such as genetic programming, reinforcement learning, and large\nlanguage models-have significantly expanded the capacity for alpha discovery,\nsystematic evaluation remains a key challenge. Existing evaluation metrics\npredominantly include backtesting and correlation-based measures. Backtesting\nis computationally intensive, inherently sequential, and sensitive to specific\nstrategy parameters. Correlation-based metrics, though efficient, assess only\npredictive ability and overlook other crucial properties such as temporal\nstability, robustness, diversity, and interpretability. Additionally, the\nclosed-source nature of most existing alpha mining models hinders\nreproducibility and slows progress in this field. To address these issues, we\npropose AlphaEval, a unified, parallelizable, and backtest-free evaluation\nframework for automated alpha mining models. AlphaEval assesses the overall\nquality of generated alphas along five complementary dimensions: predictive\npower, stability, robustness to market perturbations, financial logic, and\ndiversity. Extensive experiments across representative alpha mining algorithms\ndemonstrate that AlphaEval achieves evaluation consistency comparable to\ncomprehensive backtesting, while providing more comprehensive insights and\nhigher efficiency. Furthermore, AlphaEval effectively identifies superior\nalphas compared to traditional single-metric screening approaches. All\nimplementations and evaluation tools are open-sourced to promote\nreproducibility and community engagement.", "AI": {"tldr": "AlphaEval\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u5168\u9762\u7684\u81ea\u52a8\u5316Alpha\u6316\u6398\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u4f30\u65b9\u6cd5\uff08\u56de\u6d4b\u548c\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u5ea6\u91cf\uff09\u5b58\u5728\u8ba1\u7b97\u5bc6\u96c6\u3001\u4f9d\u8d56\u53c2\u6570\u3001\u4ec5\u8bc4\u4f30\u9884\u6d4b\u80fd\u529b\u7b49\u7f3a\u70b9\uff0c\u4e14\u6a21\u578b\u95ed\u6e90\u5f71\u54cd\u590d\u73b0\u3002", "method": "\u63d0\u51faAlphaEval\u6846\u67b6\uff0c\u4ece\u9884\u6d4b\u80fd\u529b\u3001\u7a33\u5b9a\u6027\u3001\u9c81\u68d2\u6027\u3001\u91d1\u878d\u903b\u8f91\u548c\u591a\u6837\u6027\u4e94\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u81ea\u52a8\u5316Alpha\u6316\u6398\u6a21\u578b\u751f\u6210\u7684Alpha\u3002", "result": "AlphaEval\u4e0e\u5168\u9762\u7684\u56de\u6d4b\u76f8\u6bd4\u5177\u6709\u53ef\u6bd4\u6027\uff0c\u6548\u7387\u66f4\u9ad8\uff0c\u5e76\u80fd\u6709\u6548\u8bc6\u522b\u4f18\u4e8e\u4f20\u7edf\u5355\u6307\u6807\u7b5b\u9009\u65b9\u6cd5\u7684Alpha\u3002\u6240\u6709\u5b9e\u73b0\u548c\u8bc4\u4f30\u5de5\u5177\u90fd\u662f\u5f00\u6e90\u7684\u3002", "conclusion": "\u63d0\u51faAlphaEval\u6846\u67b6\uff0c\u4e00\u79cd\u7edf\u4e00\u7684\u3001\u53ef\u5e76\u884c\u5316\u7684\u3001\u65e0\u9700\u56de\u6d4b\u7684\u81ea\u52a8\u5316Alpha\u6316\u6398\u6a21\u578b\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u751f\u6210Alpha\u7684\u6574\u4f53\u8d28\u91cf\uff0c\u5e76\u5728\u4e94\u4e2a\u65b9\u9762\u8fdb\u884c\u8bc4\u4f30\uff1a\u9884\u6d4b\u80fd\u529b\u3001\u7a33\u5b9a\u6027\u3001\u5bf9\u5e02\u573a\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3001\u91d1\u878d\u903b\u8f91\u548c\u591a\u6837\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cAlphaEval\u4e0e\u5168\u9762\u7684\u56de\u6d4b\u76f8\u6bd4\u5177\u6709\u53ef\u6bd4\u6027\uff0c\u6548\u7387\u66f4\u9ad8\uff0c\u5e76\u80fd\u6709\u6548\u8bc6\u522b\u4f18\u4e8e\u4f20\u7edf\u5355\u6307\u6807\u7b5b\u9009\u65b9\u6cd5\u7684Alpha\u3002"}}
{"id": "2508.13176", "categories": ["cs.AI", "cs.DB", "68T30 (Primary) 68P15, 03B70 (Secondary)", "I.2.4; H.2.3"], "pdf": "https://arxiv.org/pdf/2508.13176", "abs": "https://arxiv.org/abs/2508.13176", "authors": ["Simon Hosemann", "Jean Christoph Jung", "Carsten Lutz", "Sebastian Rudolph"], "title": "Fitting Ontologies and Constraints to Relational Structures", "comment": "Accepted at the 22nd International Conference on Principles of\n  Knowledge Representation and Reasoning (KR 2025)", "summary": "We study the problem of fitting ontologies and constraints to positive and\nnegative examples that take the form of a finite relational structure. As\nontology and constraint languages, we consider the description logics\n$\\mathcal{E\\mkern-2mu L}$ and $\\mathcal{E\\mkern-2mu LI}$ as well as several\nclasses of tuple-generating dependencies (TGDs): full, guarded,\nfrontier-guarded, frontier-one, and unrestricted TGDs as well as inclusion\ndependencies. We pinpoint the exact computational complexity, design\nalgorithms, and analyze the size of fitting ontologies and TGDs. We also\ninvestigate the related problem of constructing a finite basis of concept\ninclusions / TGDs for a given set of finite structures. While finite bases\nexist for $\\mathcal{E\\mkern-2mu L}$, $\\mathcal{E\\mkern-2mu LI}$, guarded TGDs,\nand inclusion dependencies, they in general do not exist for full,\nfrontier-guarded and frontier-one TGDs.", "AI": {"tldr": "\u7814\u7a76\u672c\u4f53\u548c\u7ea6\u675f\u7684\u62df\u5408\u95ee\u9898\uff0c\u786e\u5b9a\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u8bbe\u8ba1\u4e86\u7b97\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u6709\u9650\u57fa\u7684\u5b58\u5728\u6027\u3002", "motivation": "\u5c06\u672c\u4f53\u548c\u7ea6\u675f\u62df\u5408\u5230\u6b63\u4f8b\u548c\u53cd\u4f8b\uff0c\u8fd9\u4e9b\u4f8b\u5b50\u91c7\u7528\u6709\u9650\u5173\u7cfb\u7ed3\u6784\u7684\u5f62\u5f0f\u3002", "method": "\u7814\u7a76\u4e86\u63cf\u8ff0\u903b\u8f91mathcal{E\\mkern-2mu L}\u548cmathcal{E\\mkern-2mu LI}\u4ee5\u53ca\u51e0\u7c7b\u5143\u7ec4\u751f\u6210\u4f9d\u8d56\u9879 (TGD) \u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u7b97\u6cd5\u3002", "result": "\u786e\u5b9a\u4e86\u7cbe\u786e\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8bbe\u8ba1\u4e86\u7b97\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u62df\u5408\u672c\u4f53\u548c TGD \u7684\u5927\u5c0f\u3002\u5bf9\u4e8e\u67d0\u4e9b\u7c7b\u578b\u7684 TGD\uff0c\u8bc1\u660e\u4e86\u6709\u9650\u57fa\u4e0d\u5b58\u5728\u3002", "conclusion": "\u7814\u7a76\u4e86\u5c06\u672c\u4f53\u548c\u7ea6\u675f\u62df\u5408\u5230\u6b63\u4f8b\u548c\u53cd\u4f8b\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u4f8b\u5b50\u91c7\u7528\u6709\u9650\u5173\u7cfb\u7ed3\u6784\u7684\u5f62\u5f0f\u3002\u4f5c\u4e3a\u672c\u4f53\u548c\u7ea6\u675f\u8bed\u8a00\uff0c\u8003\u8651\u4e86\u63cf\u8ff0\u903b\u8f91mathcal{E\\mkern-2mu L}\u548cmathcal{E\\mkern-2mu LI}\u4ee5\u53ca\u51e0\u7c7b\u5143\u7ec4\u751f\u6210\u4f9d\u8d56\u9879 (TGD)\uff1a\u5b8c\u6574\u3001\u53d7\u4fdd\u62a4\u3001\u524d\u6cbf\u53d7\u4fdd\u62a4\u3001\u524d\u6cbf\u4e00\u548c\u4e0d\u53d7\u9650\u5236\u7684 TGD \u4ee5\u53ca\u5305\u542b\u4f9d\u8d56\u9879\u3002\u786e\u5b9a\u4e86\u7cbe\u786e\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8bbe\u8ba1\u4e86\u7b97\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u62df\u5408\u672c\u4f53\u548c TGD \u7684\u5927\u5c0f\u3002\u8fd8\u7814\u7a76\u4e86\u4e3a\u7ed9\u5b9a\u7684\u4e00\u7ec4\u6709\u9650\u7ed3\u6784\u6784\u9020\u6982\u5ff5\u5305\u542b/TGD \u7684\u6709\u9650\u57fa\u7684\u76f8\u5173\u95ee\u9898\u3002\u867d\u7136\u5bf9\u4e8emathcal{E\\mkern-2mu L}\u3001mathcal{E\\mkern-2mu LI}\u3001\u53d7\u4fdd\u62a4\u7684 TGD \u548c\u5305\u542b\u4f9d\u8d56\u9879\u5b58\u5728\u6709\u9650\u57fa\uff0c\u4f46\u5bf9\u4e8e\u5b8c\u6574\u3001\u524d\u6cbf\u53d7\u4fdd\u62a4\u548c\u524d\u6cbf\u4e00 TGD \u901a\u5e38\u4e0d\u5b58\u5728\u6709\u9650\u57fa\u3002"}}
{"id": "2508.13177", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13177", "abs": "https://arxiv.org/abs/2508.13177", "authors": ["Nikola Pi\u017eurica", "Nikola Milovi\u0107", "Igor Jovan\u010devi\u0107", "Conor Heins", "Miguel de Prado"], "title": "A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment", "comment": null, "summary": "Active Inference (AIF) offers a robust framework for decision-making, yet its\ncomputational and memory demands pose challenges for deployment, especially in\nresource-constrained environments. This work presents a methodology that\nfacilitates AIF's deployment by integrating pymdp's flexibility and efficiency\nwith a unified, sparse, computational graph tailored for hardware-efficient\nexecution. Our approach reduces latency by over 2x and memory by up to 35%,\nadvancing the deployment of efficient AIF agents for real-time and embedded\napplications.", "AI": {"tldr": "\u901a\u8fc7\u9ad8\u6548\u7684\u8ba1\u7b97\u56fe\uff0c\u63d0\u9ad8\u4e3b\u52a8\u63a8\u7406\u7684\u6548\u7387\uff0c\u4f7f\u5176\u66f4\u9002\u7528\u4e8e\u5b9e\u65f6\u548c\u5d4c\u5165\u5f0f\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u4e3b\u52a8\u63a8\u7406\u5728\u8ba1\u7b97\u548c\u5185\u5b58\u65b9\u9762\u7684\u6311\u6218\uff0c\u4f7f\u5176\u80fd\u591f\u90e8\u7f72\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u3002", "method": "\u6574\u5408pymdp\u548c\u7edf\u4e00\u7684\u7a00\u758f\u8ba1\u7b97\u56fe", "result": "\u5ef6\u8fdf\u964d\u4f4e2\u500d\u4ee5\u4e0a\uff0c\u5185\u5b58\u51cf\u5c11\u9ad8\u8fbe35%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408pymdp\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u4ee5\u53ca\u4e00\u4e2a\u7edf\u4e00\u7684\u7a00\u758f\u8ba1\u7b97\u56fe\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e3b\u52a8\u63a8\u7406(AIF)\u7684\u90e8\u7f72\uff0c\u51cf\u5c11\u5ef6\u8fdf\u548c\u5185\u5b58\u6d88\u8017\uff0c\u4f7f\u5176\u66f4\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u3002"}}
{"id": "2508.13178", "categories": ["cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.13178", "abs": "https://arxiv.org/abs/2508.13178", "authors": ["Cong Zhang"], "title": "The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task", "comment": null, "summary": "To elevate the foundational capabilities and generalization prowess of the\ntext-to-SQL model in real-world applications, we integrate model\ninterpretability analysis with execution-guided strategy for semantic parsing\nof WHERE clauses in SQL queries. Furthermore, we augment this approach with\nfiltering adjustments, logical correlation refinements, and model fusion,\nculminating in the design of the CESQL model that facilitates conditional\nenhancement. Our model excels on the WikiSQL dataset, which is emblematic of\nsingle-table database query tasks, markedly boosting the accuracy of prediction\noutcomes. When predicting conditional values in WHERE clauses, we have not only\nminimized our dependence on data within the condition columns of tables but\nalso circumvented the impact of manually labeled training data. Our hope is\nthat this endeavor to enhance accuracy in processing basic database queries\nwill offer fresh perspectives for research into handling complex queries and\nscenarios featuring irregular data in real-world database environments.", "AI": {"tldr": "CESQL\u6a21\u578b\u901a\u8fc7\u591a\u9879\u6280\u672f\u63d0\u5347\u4e86\u6587\u672c\u5230SQL\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u5904\u7406WHERE\u5b50\u53e5\u65f6\u6548\u679c\u663e\u8457\u3002", "motivation": "\u63d0\u5347\u6587\u672c\u5230SQL\u6a21\u578b\u5728\u771f\u5b9e\u5e94\u7528\u573a\u666f\u4e0b\u7684\u57fa\u7840\u80fd\u529b\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u9488\u5bf9WHERE\u5b50\u53e5\u7684\u8bed\u4e49\u89e3\u6790\u3002", "method": "\u6574\u5408\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3001\u6267\u884c\u5f15\u5bfc\u7b56\u7565\u3001\u8fc7\u6ee4\u8c03\u6574\u3001\u903b\u8f91\u5173\u8054\u4f18\u5316\u548c\u6a21\u578b\u878d\u5408\uff0c\u8bbe\u8ba1\u51faCESQL\u6a21\u578b\u3002", "result": "\u5728WikiSQL\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u663e\u8457\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u51cf\u5c11\u4e86\u5bf9\u6761\u4ef6\u5217\u6570\u636e\u548c\u4eba\u5de5\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\u3002", "conclusion": "CESQL\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5206\u6790\u548c\u6267\u884c\u5f15\u5bfc\u7b56\u7565\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6587\u672c\u5230SQL\u6a21\u578b\u5728\u5904\u7406WHERE\u5b50\u53e5\u65f6\u7684\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u4e86\u5bf9\u6761\u4ef6\u5217\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u5e76\u63d0\u5347\u4e86\u6a21\u578b\u5728WikiSQL\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2508.13180", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13180", "abs": "https://arxiv.org/abs/2508.13180", "authors": ["Ziwen Han", "Meher Mankikar", "Julian Michael", "Zifan Wang"], "title": "Search-Time Data Contamination", "comment": null, "summary": "Data contamination refers to the leakage of evaluation data into model\ntraining data, resulting in overfitting to supposedly held-out test sets and\ncompromising test validity. We identify an analogous issue, search-time\ncontamination (STC), in evaluating search-based LLM agents which use tools to\ngather information from online sources when answering user queries. STC occurs\nwhen the retrieval step surfaces a source containing the test question (or a\nnear-duplicate) alongside its answer, enabling agents to copy rather than\ngenuinely infer or reason, undermining benchmark integrity. We find that\nHuggingFace, an online platform hosting evaluation datasets, appears among\nretrieved sources in search based agent logs. Consequently, agents often\nexplicitly acknowledge discovering question answer pairs from HuggingFace\nwithin their reasoning chains. On three commonly used capability benchmarks:\nHumanity's Last Exam (HLE), SimpleQA, and GPQA, we demonstrate that for\napproximately 3% of questions, search-based agents directly find the datasets\nwith ground truth labels on HuggingFace. When millions of evaluation queries\ntarget the same benchmark, even small, repeated leaks can accelerate the\nbenchmark's obsolescence, shortening its intended lifecycle. After HuggingFace\nis blocked, we observe a drop in accuracy on the contaminated subset of\napproximately 15%. We further show through ablation experiments that publicly\naccessible evaluation datasets on HuggingFace may not be the sole source of\nSTC. To this end, we conclude by proposing best practices for benchmark design\nand result reporting to address this novel form of leakage and ensure\ntrustworthy evaluation of search-based LLM agents. To facilitate the auditing\nof evaluation results, we also publicly release the complete logs from our\nexperiments.", "AI": {"tldr": "Search-based LLMs often cheat by finding answers directly online; this compromises benchmarks.  The paper demonstrates this, proposes solutions, and releases experimental logs.", "motivation": "To address the issue of data contamination in evaluating search-based LLM agents, specifically focusing on the leakage of evaluation data through online search.", "method": "The study analyzed logs from search-based LLM agents on three benchmarks (HLE, SimpleQA, GPQA) and observed instances where agents retrieved answers directly from HuggingFace.  Ablation experiments were conducted to investigate other potential sources of STC.  Accuracy changes were measured after blocking HuggingFace.", "result": "Approximately 3% of questions showed evidence of STC from HuggingFace. Blocking HuggingFace resulted in a 15% drop in accuracy on the contaminated subset. Ablation experiments suggest HuggingFace is not the sole source of STC. Best practices for mitigating STC are proposed.", "conclusion": "Search-time contamination (STC) in evaluating search-based large language model (LLM) agents is identified as a significant issue, undermining benchmark integrity.  Publicly accessible evaluation datasets, such as those on HuggingFace, are shown to be a source of contamination, leading to agents directly finding answers rather than genuinely reasoning.  Best practices for benchmark design and result reporting are proposed to mitigate STC."}}
{"id": "2508.13204", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13204", "abs": "https://arxiv.org/abs/2508.13204", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "QuickMerge++: Fast Token Merging with Autoregressive Prior", "comment": "The paper has been accepted to ICML Tokshop at\n  https://openreview.net/forum?id=dMdxHd0tRf", "summary": "As generative models scale to larger inputs across language, vision, and\nvideo domains, the cost of token-level computation has become a key bottleneck.\nWhile prior work suggests that only a subset of tokens significantly influence\ndownstream predictions, most token selection methods are static,\nmodality-specific, or incompatible with autoregressive generation. In this\npaper, we propose QuickMerge, a lightweight token merging framework designed\nfor efficient next-token prediction.\n  QuickMerge dynamically selects a reduced number of tokens based on attention\nnorm magnitude, guided by an entropy-based budget estimator. To preserve\nautoregressive compatibility, we introduce a lightweight transformer prior\ntrained over the merged token sequence. By combining semantic salience\nestimation, flexible token budgets, and AR alignment, QuickMerge enables\naccurate generation with fewer tokens.\n  We evaluate QuickMerge across multi-modality domains, demonstrating\nconsistent improvements in compute-accuracy tradeoffs. Specifically, QuickMerge\nreduces token counts sustantially while matching as well as exceeding the\nperformance of learned tokenizers and fixed-patch baselines.", "AI": {"tldr": "QuickMerge:\u4e00\u79cd\u8f7b\u91cf\u7ea7token\u5408\u5e76\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9token\u5e76\u4f7f\u7528transformer\u5148\u9a8c\u6a21\u578b\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u751f\u6210\u6a21\u578b\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u5728\u591a\u6a21\u6001\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u3002", "motivation": "\u968f\u7740\u751f\u6210\u6a21\u578b\u6269\u5c55\u5230\u66f4\u5927\u89c4\u6a21\u7684\u8bed\u8a00\u3001\u89c6\u89c9\u548c\u89c6\u9891\u6570\u636e\uff0ctoken\u7ea7\u522b\u8ba1\u7b97\u7684\u6210\u672c\u6210\u4e3a\u74f6\u9888\u3002\u73b0\u6709\u7684\u5927\u90e8\u5206token\u9009\u62e9\u65b9\u6cd5\u662f\u9759\u6001\u7684\u3001\u7279\u5b9a\u4e8e\u6a21\u6001\u7684\u6216\u4e0e\u81ea\u56de\u5f52\u751f\u6210\u4e0d\u517c\u5bb9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684token\u5408\u5e76\u6846\u67b6QuickMerge\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u6ce8\u610f\u529bnorm\u5927\u5c0f\u548c\u71b5\u57fa\u9884\u7b97\u4f30\u8ba1\u5668\u52a8\u6001\u9009\u62e9\u6570\u91cf\u51cf\u5c11\u7684token\uff0c\u5e76\u5f15\u5165\u8f7b\u91cf\u7ea7transformer\u5148\u9a8c\u6a21\u578b\u4ee5\u4fdd\u6301\u81ea\u56de\u5f52\u517c\u5bb9\u6027\u3002", "result": "\u5728\u591a\u6a21\u6001\u9886\u57df\u8bc4\u4f30QuickMerge\uff0c\u7ed3\u679c\u8868\u660e\u5176\u5728\u8ba1\u7b97\u7cbe\u5ea6\u6743\u8861\u65b9\u9762\u53d6\u5f97\u4e86\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u663e\u8457\u51cf\u5c11\u4e86token\u6570\u91cf\uff0c\u540c\u65f6\u6027\u80fd\u4e0e\u5b66\u4e60\u578b\u5206\u8bcd\u5668\u548c\u56fa\u5b9apatch\u57fa\u7ebf\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u3002", "conclusion": "QuickMerge\u6846\u67b6\u5728\u591a\u6a21\u6001\u9886\u57df\u63d0\u9ad8\u4e86\u8ba1\u7b97\u7cbe\u5ea6\u6743\u8861\uff0c\u901a\u8fc7\u51cf\u5c11token\u6570\u91cf\u5b9e\u73b0\u4e86\u4e0e\u5b66\u4e60\u578b\u5206\u8bcd\u5668\u548c\u56fa\u5b9apatch\u57fa\u7ebf\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.13213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13213", "abs": "https://arxiv.org/abs/2508.13213", "authors": ["Adamo Cerioli", "Edward D. Lee", "Vito D. P. Servedio"], "title": "AI sustains higher strategic tension than humans in chess", "comment": null, "summary": "Strategic decision-making involves managing the tension between immediate\nopportunities and long-term objectives. We study this trade-off in chess by\ncharacterizing and comparing dynamics between human vs human and AI vs AI\ngames. We propose a network-based metric of piece-to-piece interaction to\nquantify the ongoing strategic tension on the board. Its evolution in games\nreveals that the most competitive AI players sustain higher levels of strategic\ntension for longer durations than elite human players. Cumulative tension\nvaries with algorithmic complexity for AI and correspondingly in human-played\ngames increases abruptly with expertise at about 1600 Elo and again at 2300\nElo. The profiles reveal different approaches. Highly competitive AI tolerates\ninterconnected positions balanced between offensive and defensive tactics over\nlong periods. Human play, in contrast, limits tension and game complexity,\nwhich may reflect cognitive limitations and adaptive strategies. The difference\nmay have implications for AI usage in complex, strategic environments.", "AI": {"tldr": "AI\u5728\u56fd\u9645\u8c61\u68cb\u4e2d\u6bd4\u4eba\u7c7b\u80fd\u66f4\u597d\u5730\u4fdd\u6301\u957f\u671f\u6218\u7565\u5f20\u529b\uff0c\u8fd9\u53cd\u6620\u4e86\u7b97\u6cd5\u590d\u6742\u5ea6\u548c\u4eba\u7c7b\u8ba4\u77e5\u80fd\u529b\u7684\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u56fd\u9645\u8c61\u68cb\u4e2d\u5373\u65f6\u673a\u4f1a\u548c\u957f\u671f\u76ee\u6807\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f51\u7edc\u7684\u91cf\u5316\u68cb\u76d8\u4e0a\u6218\u7565\u5f20\u529b\u7684\u6307\u6807\uff0c\u5e76\u6bd4\u8f83\u4e86\u4eba\u7c7b\u5bf9\u5f08\u548cAI\u5bf9\u5f08\u7684\u52a8\u6001\u3002", "result": "AI\u7ef4\u6301\u9ad8\u6218\u7565\u5f20\u529b\u7684\u6301\u7eed\u65f6\u95f4\u6bd4\u4eba\u7c7b\u66f4\u957f\uff0c\u4e14\u4e0e\u7b97\u6cd5\u590d\u6742\u5ea6\u76f8\u5173\uff1b\u4eba\u7c7b\u7684\u6218\u7565\u5f20\u529b\u5219\u4e0e\u68cb\u529b\u5448\u9636\u68af\u5f0f\u589e\u957f\uff0c\u5e76\u4f34\u968f\u964d\u4f4e\u6e38\u620f\u590d\u6742\u5ea6\u7684\u7b56\u7565\u3002", "conclusion": "AI\u5728\u56fd\u9645\u8c61\u68cb\u6bd4\u8d5b\u4e2d\u6bd4\u4eba\u7c7b\u9ad8\u624b\u80fd\u66f4\u957f\u65f6\u95f4\u5730\u4fdd\u6301\u66f4\u9ad8\u6c34\u5e73\u7684\u6218\u7565\u5f20\u529b\uff0c\u8fd9\u53ef\u80fd\u4e0eAI\u7b97\u6cd5\u7684\u590d\u6742\u6027\u548c\u4eba\u7c7b\u8ba4\u77e5\u80fd\u529b\u7684\u9650\u5236\u6709\u5173\u3002"}}
{"id": "2508.13250", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13250", "abs": "https://arxiv.org/abs/2508.13250", "authors": ["Zeyu Zhang", "Yang Zhang", "Haoran Tan", "Rui Li", "Xu Chen"], "title": "Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information", "comment": "15 pages, 13 figures, 3 tables", "summary": "In large language model-based agents, memory serves as a critical capability\nfor achieving personalization by storing and utilizing users' information.\nAlthough some previous studies have adopted memory to implement user\npersonalization, they typically focus on preference alignment and simple\nquestion-answering. However, in the real world, complex tasks often require\nmulti-hop reasoning on a large amount of user information, which poses\nsignificant challenges for current memory approaches. To address this\nlimitation, we propose the multi-hop personalized reasoning task to explore how\ndifferent memory mechanisms perform in multi-hop reasoning over personalized\ninformation. We explicitly define this task and construct a dataset along with\na unified evaluation framework. Then, we implement various explicit and\nimplicit memory methods and conduct comprehensive experiments. We evaluate\ntheir performance on this task from multiple perspectives and analyze their\nstrengths and weaknesses. Besides, we explore hybrid approaches that combine\nboth paradigms and propose the HybridMem method to address their limitations.\nWe demonstrate the effectiveness of our proposed model through extensive\nexperiments. To benefit the research community, we release this project at\nhttps://github.com/nuster1128/MPR.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u8df3\u4e2a\u6027\u5316\u63a8\u7406\u4efb\u52a1\u548cHybridMem\u65b9\u6cd5\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5728\u4e2a\u6027\u5316\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u4efb\u52a1\u4e2d\u5bf9\u5927\u91cf\u7528\u6237\u4fe1\u606f\u7684\u591a\u8df3\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u8df3\u4e2a\u6027\u5316\u63a8\u7406\u4efb\u52a1\uff0c\u6784\u5efa\u4e86\u76f8\u5e94\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u6570\u636e\u96c6\uff0c\u5e76\u5b9e\u73b0\u4e86\u591a\u79cd\u663e\u5f0f\u548c\u9690\u5f0f\u8bb0\u5fc6\u65b9\u6cd5\uff0c\u6700\u7ec8\u63d0\u51fa\u4e86HybridMem\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86HybridMem\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5404\u79cd\u8bb0\u5fc6\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u8df3\u4e2a\u6027\u5316\u63a8\u7406\u7684\u6df7\u5408\u8bb0\u5fc6\u65b9\u6cd5HybridMem\uff0c\u5e76\u5728\u6784\u5efa\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u5e76\u5f00\u6e90\u4e86\u9879\u76ee\u3002"}}
{"id": "2508.13251", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2508.13251", "abs": "https://arxiv.org/abs/2508.13251", "authors": ["Di Zhang", "Xue Jia", "Tran Ba Hung", "Seong Hoon Jang", "Linda Zhang", "Ryuhei Sato", "Yusuke Hashimoto", "Toyoto Sato", "Kiyoe Konno", "Shin-ichi Orimo", "Hao Li"], "title": "\"DIVE\" into Hydrogen Storage Materials Discovery with AI Agents", "comment": "23 pages, 5 figures. The supplementary video is available at the\n  GitHub link provided in the manuscript", "summary": "Data-driven artificial intelligence (AI) approaches are fundamentally\ntransforming the discovery of new materials. Despite the unprecedented\navailability of materials data in the scientific literature, much of this\ninformation remains trapped in unstructured figures and tables, hindering the\nconstruction of large language model (LLM)-based AI agent for automated\nmaterials design. Here, we present the Descriptive Interpretation of Visual\nExpression (DIVE) multi-agent workflow, which systematically reads and\norganizes experimental data from graphical elements in scientific literatures.\nWe focus on solid-state hydrogen storage materials-a class of materials central\nto future clean-energy technologies and demonstrate that DIVE markedly improves\nthe accuracy and coverage of data extraction compared to the direct extraction\nby multimodal models, with gains of 10-15% over commercial models and over 30%\nrelative to open-source models. Building on a curated database of over 30,000\nentries from 4,000 publications, we establish a rapid inverse design workflow\ncapable of identifying previously unreported hydrogen storage compositions in\ntwo minutes. The proposed AI workflow and agent design are broadly transferable\nacross diverse materials, providing a paradigm for AI-driven materials\ndiscovery.", "AI": {"tldr": "DIVE\u5de5\u4f5c\u6d41\u7a0b\u63d0\u9ad8\u6570\u636e\u63d0\u53d6\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5b9e\u73b0\u5feb\u901f\u9006\u5411\u8bbe\u8ba1\uff0c\u8bc6\u522b\u65b0\u578b\u50a8\u6c22\u6750\u6599\u3002", "motivation": "\u89e3\u51b3\u79d1\u5b66\u6587\u732e\u4e2d\u975e\u7ed3\u6784\u5316\u56fe\u8868\u6570\u636e\u963b\u788dLLM\u6784\u5efa\u7684\u95ee\u9898\uff0c\u63a8\u52a8AI\u9a71\u52a8\u7684\u6750\u6599\u53d1\u73b0\u3002", "method": "DIVE\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u7cfb\u7edf\u5730\u8bfb\u53d6\u548c\u7ec4\u7ec7\u6765\u81ea\u79d1\u5b66\u6587\u732e\u56fe\u5f62\u5143\u7d20\u7684\u5b9e\u9a8c\u6570\u636e\u3002", "result": "DIVE\u7684\u51c6\u786e\u6027\u548c\u8986\u76d6\u7387\u6bd4\u591a\u6a21\u6001\u6a21\u578b\u76f4\u63a5\u63d0\u53d6\u9ad810-15%\uff08\u5546\u4e1a\u6a21\u578b\uff09\u548c30%\u4ee5\u4e0a\uff08\u5f00\u6e90\u6a21\u578b\uff09\uff1b\u57fa\u4e8e\u8d85\u8fc730,000\u6761\u6570\u636e\u7684\u6570\u636e\u5e93\uff0c\u53ef\u5728\u4e24\u5206\u949f\u5185\u8bc6\u522b\u65b0\u578b\u50a8\u6c22\u6750\u6599\u3002", "conclusion": "DIVE\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u63d0\u53d6\u7684\u51c6\u786e\u6027\u548c\u8986\u76d6\u7387\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u80fd\u591f\u5feb\u901f\u8bc6\u522b\u65b0\u578b\u50a8\u6c22\u6750\u6599\u7684\u9006\u5411\u8bbe\u8ba1\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2508.13256", "categories": ["cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.13256", "abs": "https://arxiv.org/abs/2508.13256", "authors": ["Yuting Zhang", "Karina V. Bunting", "Asgher Champsi", "Xiaoxia Wang", "Wenqi Lu", "Alexander Thorley", "Sandeep S Hothi", "Zhaowen Qiu", "Dipak Kotecha", "Jinming Duan"], "title": "CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support", "comment": null, "summary": "Cardiovascular diseases (CVDs) remain the foremost cause of mortality\nworldwide, a burden worsened by a severe deficit of healthcare workers.\nArtificial intelligence (AI) agents have shown potential to alleviate this gap\nvia automated early detection and proactive screening, yet their clinical\napplication remains limited by: 1) prompt-based clinical role assignment that\nrelies on intrinsic model capabilities without domain-specific tool support; or\n2) rigid sequential workflows, whereas clinical care often requires adaptive\nreasoning that orders specific tests and, based on their results, guides\npersonalised next steps; 3) general and static knowledge bases without\ncontinuous learning capability; and 4) fixed unimodal or bimodal inputs and\nlack of on-demand visual outputs when further clarification is needed. In\nresponse, a multimodal framework, CardAIc-Agents, was proposed to augment\nmodels with external tools and adaptively support diverse cardiac tasks.\nSpecifically, a CardiacRAG agent generated general plans from updatable cardiac\nknowledge, while the chief agent integrated tools to autonomously execute these\nplans and deliver decisions. To enable adaptive and case-specific\ncustomization, a stepwise update strategy was proposed to dynamically refine\nplans based on preceding execution results, once the task was assessed as\ncomplex. In addition, a multidisciplinary discussion tool was introduced to\ninterpret challenging cases, thereby supporting further adaptation. When\nclinicians raised concerns, visual review panels were provided to assist final\nvalidation. Experiments across three datasets showed the efficiency of\nCardAIc-Agents compared to mainstream Vision-Language Models (VLMs),\nstate-of-the-art agentic systems, and fine-tuned VLMs.", "AI": {"tldr": "\u591a\u6a21\u6001\u6846\u67b6CardAIc-Agents\u6709\u6548\u63d0\u5347\u4e86AI\u5728\u5fc3\u8840\u7ba1\u75be\u75c5\u8bca\u65ad\u4e2d\u7684\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709AI\u5728\u5fc3\u8840\u7ba1\u75be\u75c5\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\u53d7\u5230\u4e34\u5e8a\u89d2\u8272\u5206\u914d\u4f9d\u8d56\u4e8e\u6a21\u578b\u81ea\u8eab\u80fd\u529b\u3001\u5de5\u4f5c\u6d41\u7a0b\u50f5\u5316\u3001\u77e5\u8bc6\u5e93\u9759\u6001\u4ee5\u53ca\u8f93\u5165\u548c\u8f93\u51fa\u6a21\u5f0f\u5355\u4e00\u7b49\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u6846\u67b6CardAIc-Agents\uff0c\u5305\u542bCardiacRAG\u4ee3\u7406\u548c\u4e3b\u4ee3\u7406\uff0c\u5e76\u91c7\u7528\u9010\u6b65\u66f4\u65b0\u7b56\u7565\u548c\u591a\u5b66\u79d1\u8ba8\u8bba\u5de5\u5177\uff0c\u4ee5\u652f\u6301\u81ea\u9002\u5e94\u548c\u4e2a\u6027\u5316\u7684\u5fc3\u810f\u75be\u75c5\u8bca\u65ad\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eCardAIc-Agents\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CardAIc-Agents\uff0c\u4e00\u4e2a\u591a\u6a21\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5916\u90e8\u5de5\u5177\u548c\u81ea\u9002\u5e94\u652f\u6301\u591a\u79cd\u5fc3\u810f\u4efb\u52a1\uff0c\u63d0\u9ad8\u4e86AI\u5728\u5fc3\u8840\u7ba1\u75be\u75c5\u8bca\u65ad\u4e2d\u7684\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5176\u6548\u7387\u4f18\u4e8e\u4e3b\u6d41\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3001\u6700\u5148\u8fdb\u7684\u667a\u80fd\u7cfb\u7edf\u548c\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2508.13327", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13327", "abs": "https://arxiv.org/abs/2508.13327", "authors": ["Sarthak Khanna", "Armin Berger", "David Berghaus", "Tobias Deusser", "Lorenz Sparrenberg", "Rafet Sifa"], "title": "Towards Unified Multimodal Financial Forecasting: Integrating Sentiment Embeddings and Market Indicators via Cross-Modal Attention", "comment": "Accepted in IEEE-DSAA 2025", "summary": "We propose STONK (Stock Optimization using News Knowledge), a multimodal\nframework integrating numerical market indicators with sentiment-enriched news\nembeddings to improve daily stock-movement prediction. By combining numerical &\ntextual embeddings via feature concatenation and cross-modal attention, our\nunified pipeline addresses limitations of isolated analyses. Backtesting shows\nSTONK outperforms numeric-only baselines. A comprehensive evaluation of fusion\nstrategies and model configurations offers evidence-based guidance for scalable\nmultimodal financial forecasting. Source code is available on GitHub", "AI": {"tldr": "STONK\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7ed3\u5408\u6570\u503c\u548c\u6587\u672c\u6570\u636e\u6539\u8fdb\u80a1\u7968\u9884\u6d4b\uff0c\u56de\u6d4b\u7ed3\u679c\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u6539\u8fdb\u6bcf\u65e5\u80a1\u7968\u8d70\u52bf\u9884\u6d4b\uff0c\u514b\u670d\u5b64\u7acb\u5206\u6790\u7684\u5c40\u9650\u6027\u3002", "method": "\u7ed3\u5408\u6570\u503c\u5e02\u573a\u6307\u6807\u548c\u60c5\u611f\u4e30\u5bcc\u7684\u65b0\u95fb\u5d4c\u5165\uff0c\u4f7f\u7528\u7279\u5f81\u62fc\u63a5\u548c\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u8fdb\u884c\u878d\u5408\u3002", "result": "\u56de\u6d4b\u7ed3\u679c\u8868\u660eSTONK\u4f18\u4e8e\u4ec5\u4f7f\u7528\u6570\u503c\u7684\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "STONK\u6846\u67b6\u4f18\u4e8e\u4ec5\u4f7f\u7528\u6570\u503c\u7684\u57fa\u51c6\u65b9\u6cd5\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u91d1\u878d\u9884\u6d4b\u63d0\u4f9b\u4e86\u5faa\u8bc1\u6307\u5bfc\u3002"}}
{"id": "2508.13333", "categories": ["cs.AI", "cs.NE", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.13333", "abs": "https://arxiv.org/abs/2508.13333", "authors": ["Chentong Chen", "Mengyuan Zhong", "Jianyong Sun", "Ye Fan", "Jialong Shi"], "title": "HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design", "comment": "9 pages, 6 figures", "summary": "LLM-based Automatic Heuristic Design (AHD) within Evolutionary Computation\n(EC) frameworks has shown promising results. However, its effectiveness is\nhindered by the use of static operators and the lack of knowledge accumulation\nmechanisms. We introduce HiFo-Prompt, a framework that guides LLMs with two\nsynergistic prompting strategies: Foresight and Hindsight. Foresight-based\nprompts adaptively steer the search based on population dynamics, managing the\nexploration-exploitation trade-off. In addition, hindsight-based prompts mimic\nhuman expertise by distilling successful heuristics from past generations into\nfundamental, reusable design principles. This dual mechanism transforms\ntransient discoveries into a persistent knowledge base, enabling the LLM to\nlearn from its own experience. Empirical results demonstrate that HiFo-Prompt\nsignificantly outperforms state-of-the-art LLM-based AHD methods, generating\nhigher-quality heuristics while achieving substantially faster convergence and\nsuperior query efficiency.", "AI": {"tldr": "HiFo-Prompt\u5229\u7528\u524d\u77bb\u6027\u548c\u540e\u89c6\u6027\u63d0\u793a\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\u5b58\u5728\u9759\u6001\u7b97\u5b50\u548c\u7f3a\u4e4f\u77e5\u8bc6\u79ef\u7d2f\u673a\u5236\u7684\u7f3a\u70b9\uff0c\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\u3002", "method": "HiFo-Prompt\u6846\u67b6\uff0c\u7ed3\u5408\u524d\u77bb\u6027\u548c\u540e\u89c6\u6027\u4e24\u79cd\u63d0\u793a\u7b56\u7565\u5f15\u5bfcLLM\u3002\u524d\u77bb\u6027\u63d0\u793a\u6839\u636e\u79cd\u7fa4\u52a8\u6001\u81ea\u9002\u5e94\u5730\u5f15\u5bfc\u641c\u7d22\uff0c\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\uff1b\u540e\u89c6\u6027\u63d0\u793a\u4ece\u8fc7\u53bb\u7684\u6210\u529f\u542f\u53d1\u5f0f\u7b97\u6cd5\u4e2d\u63d0\u53d6\u53ef\u590d\u7528\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u6a21\u62df\u4eba\u7c7b\u4e13\u5bb6\u7684\u7ecf\u9a8c\u3002", "result": "HiFo-Prompt\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5e76\u52a0\u5feb\u4e86\u6536\u655b\u901f\u5ea6\uff0c\u63d0\u9ad8\u4e86\u67e5\u8be2\u6548\u7387\u3002", "conclusion": "HiFo-Prompt\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u540c\u65f6\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u67e5\u8be2\u6548\u7387\u3002"}}
{"id": "2508.13371", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13371", "abs": "https://arxiv.org/abs/2508.13371", "authors": ["Ronit Virwani", "Ruchika Suryawanshi"], "title": "LOOP: A Plug-and-Play Neuro-Symbolic Framework for Enhancing Planning in Autonomous Systems", "comment": "Submitted to IAAI-26", "summary": "Planning is one of the most critical tasks in autonomous systems, where even\na small error can lead to major failures or million-dollar losses. Current\nstate-of-the-art neural planning approaches struggle with complex domains,\nproducing plans with missing preconditions, inconsistent goals, and\nhallucinations. While classical planners provide logical guarantees, they lack\nthe flexibility and natural language understanding capabilities needed for\nmodern autonomous systems. Existing neuro-symbolic approaches use one-shot\ntranslation from natural language to formal plans, missing the opportunity for\nneural and symbolic components to work and refine solutions together. To\naddress this gap, we develop LOOP -- a novel neuro-symbolic planning framework\nthat treats planning as an iterative conversation between neural and symbolic\ncomponents rather than simple translation. LOOP integrates 13 coordinated\nneural features including graph neural networks for spatial relationships,\nmulti-agent validation for consensus-based correctness, hierarchical\ndecomposition for complex task management, and causal memory that learns from\nboth successes and failures. Unlike existing approaches, LOOP generates PDDL\nspecifications, refines them iteratively based on symbolic feedback, and builds\na causal knowledge base from execution traces. LOOP was evaluated on six\nstandard IPC benchmark domains, where it achieved 85.8% success rate compared\nto LLM+P (55.0%), LLM-as-Planner (19.2%), and Tree-of-Thoughts (3.3%). This\nwork shows that the key to reliable planning is not in choosing between neural\nnetworks or symbolic reasoners but it lies in making them actually ``talk'' to\neach other during the entire process. LOOP provides a thorough blueprint for\nbuilding autonomous systems that can finally be trusted with critical\nreal-world applications.", "AI": {"tldr": "LOOP\u6846\u67b6\u901a\u8fc7\u795e\u7ecf\u4e0e\u7b26\u53f7\u7ec4\u4ef6\u7684\u8fed\u4ee3\u4ea4\u4e92\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u4e3b\u7cfb\u7edf\u7684\u89c4\u5212\u53ef\u9760\u6027\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u4f18\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u89c4\u5212\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u9886\u57df\uff0c\u5b58\u5728\u8ba1\u5212\u7f3a\u5931\u5148\u51b3\u6761\u4ef6\u3001\u76ee\u6807\u4e0d\u4e00\u81f4\u548c\u5e7b\u89c9\u7b49\u95ee\u9898\uff1b\u7ecf\u5178\u89c4\u5212\u5668\u7f3a\u4e4f\u7075\u6d3b\u6027\u53ca\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u80fd\u529b\uff1b\u73b0\u6709\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u91c7\u7528\u4e00\u6b21\u6027\u7ffb\u8bd1\uff0c\u672a\u80fd\u5145\u5206\u53d1\u6325\u795e\u7ecf\u548c\u7b26\u53f7\u7ec4\u4ef6\u7684\u534f\u540c\u4f5c\u7528\u3002", "method": "\u795e\u7ecf\u7b26\u53f7\u89c4\u5212\u6846\u67b6LOOP\uff0c\u96c6\u621013\u4e2a\u534f\u8c03\u7684\u795e\u7ecf\u7279\u5f81\uff0c\u5305\u62ec\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u591a\u667a\u80fd\u4f53\u9a8c\u8bc1\u3001\u5206\u5c42\u5206\u89e3\u548c\u56e0\u679c\u8bb0\u5fc6\u7b49\u3002\u5c06\u89c4\u5212\u89c6\u4e3a\u795e\u7ecf\u548c\u7b26\u53f7\u7ec4\u4ef6\u4e4b\u95f4\u7684\u8fed\u4ee3\u5bf9\u8bdd\uff0c\u800c\u975e\u7b80\u5355\u7684\u8f6c\u6362\uff0c\u751f\u6210PDDL\u89c4\u8303\u5e76\u57fa\u4e8e\u7b26\u53f7\u53cd\u9988\u8fed\u4ee3\u6539\u8fdb\uff0c\u6784\u5efa\u56e0\u679c\u77e5\u8bc6\u5e93\u3002", "result": "\u5728\u516d\u4e2a\u6807\u51c6IPC\u57fa\u51c6\u6d4b\u8bd5\u57df\u4e2d\uff0cLOOP\u53d6\u5f97\u4e8685.8%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8eLLM+P (55.0%)\u3001LLM-as-Planner (19.2%)\u548cTree-of-Thoughts (3.3%)\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u89c4\u5212\u6846\u67b6LOOP\u901a\u8fc7\u8fed\u4ee3\u5f0f\u795e\u7ecf\u4e0e\u7b26\u53f7\u7ec4\u4ef6\u95f4\u7684\u201c\u5bf9\u8bdd\u201d\u89e3\u51b3\u4e86\u73b0\u6709\u795e\u7ecf\u89c4\u5212\u65b9\u6cd5\u5728\u590d\u6742\u9886\u57df\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u5e76\u5728\u516d\u4e2a\u6807\u51c6IPC\u57fa\u51c6\u6d4b\u8bd5\u57df\u4e2d\u53d6\u5f97\u4e8685.8%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002"}}
{"id": "2508.13387", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13387", "abs": "https://arxiv.org/abs/2508.13387", "authors": ["Thye Shan Ng", "Caren Soyeon Han", "Eun-Jung Holden"], "title": "SPANER: Shared Prompt Aligner for Multimodal Semantic Representation", "comment": null, "summary": "Recent advances in multimodal Parameter-Efficient Fine-Tuning (PEFT) have\nsignificantly improved performance on downstream tasks such as few-shot\nretrieval. However, most existing approaches focus on task-specific gains while\nneglecting the structure of the multimodal embedding space. As a result,\nmodality-specific representations often remain isolated, limiting cross-modal\ngeneralisation. In this work, we introduce Shared Prompt AligNER (SPANER), a\nmodality-agnostic PEFT framework designed to embed inputs from diverse\nmodalities into a unified semantic space. At its core, SPANER employs a shared\nprompt mechanism that acts as a conceptual anchor, enabling semantically\nrelated instances to converge spatially regardless of modality. This shared\nprompt design is inherently extensible, supporting the seamless integration of\nadditional modalities, such as audio, without altering the core architecture.\nThrough comprehensive experiments across vision-language and audio-visual\nbenchmarks, SPANER demonstrates competitive few-shot retrieval performance\nwhile preserving high semantic coherence in the learned embedding space. Our\nresults highlight the importance of aligning embedding structures, rather than\nmerely tuning adapter weights, for scalable multimodal learning.", "AI": {"tldr": "SPANER:\u4e00\u79cd\u6a21\u6001\u65e0\u5173\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u63d0\u793a\u673a\u5236\u5c06\u4e0d\u540c\u6a21\u6001\u5d4c\u5165\u5230\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\uff0c\u63d0\u5347\u4e86\u5c11\u6837\u672c\u68c0\u7d22\u6027\u80fd\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u591a\u6570\u591a\u6a21\u6001\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5ffd\u7565\u4e86\u591a\u6a21\u6001\u5d4c\u5165\u7a7a\u95f4\u7684\u7ed3\u6784\uff0c\u5bfc\u81f4\u6a21\u6001\u7279\u5f02\u6027\u8868\u793a\u5f80\u5f80\u5b64\u7acb\uff0c\u9650\u5236\u4e86\u8de8\u6a21\u6001\u6cdb\u5316\u3002", "method": "\u5171\u4eab\u63d0\u793a\u673a\u5236\uff0c\u5c06\u4e0d\u540c\u6a21\u6001\u7684\u8f93\u5165\u5d4c\u5165\u5230\u7edf\u4e00\u7684\u8bed\u4e49\u7a7a\u95f4\u4e2d\u3002", "result": "SPANER\u5728\u89c6\u89c9-\u8bed\u8a00\u548c\u97f3\u9891-\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u5c11\u6837\u672c\u68c0\u7d22\u6027\u80fd\uff0c\u5e76\u4fdd\u6301\u4e86\u5b66\u4e60\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u9ad8\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "conclusion": "SPANER\u6846\u67b6\u5728\u89c6\u89c9-\u8bed\u8a00\u548c\u97f3\u9891-\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u5c11\u6837\u672c\u68c0\u7d22\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b66\u4e60\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u9ad8\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u7a81\u51fa\u4e86\u5bf9\u9f50\u5d4c\u5165\u7ed3\u6784\u800c\u4e0d\u662f\u4ec5\u4ec5\u8c03\u6574\u9002\u914d\u5668\u6743\u91cd\u5bf9\u4e8e\u53ef\u6269\u5c55\u591a\u6a21\u6001\u5b66\u4e60\u7684\u91cd\u8981\u6027\u3002"}}
