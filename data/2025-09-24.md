<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services](https://arxiv.org/abs/2509.18101)
*Guanzhong Pan,Haibo Wang*

Main category: cs.AI

TL;DR: 本文分析了本地部署开源LLM与订阅商业LLM服务的成本效益，以帮助组织制定LLM策略。


<details>
  <summary>Details</summary>
Motivation: 企业需要在本地部署开源LLM和订阅商业LLM服务之间做出选择，本文旨在提供成本效益分析框架以辅助决策。

Method: 对包括Qwen、Llama、Mistral等在内的最新开源模型的硬件需求、运营成本和性能基准进行了分析，并将其与主要云提供商的订阅费用进行了比较，从而得出盈亏平衡点。

Result: 基于使用水平和性能需求，本文给出了本地部署开源LLM在经济上可行的估计盈亏平衡点。

Conclusion: 该研究为组织规划LLM战略提供了实用框架。

Abstract: Large language models (LLMs) are becoming increasingly widespread.
Organizations that want to use AI for productivity now face an important
decision. They can subscribe to commercial LLM services or deploy models on
their own infrastructure. Cloud services from providers such as OpenAI,
Anthropic, and Google are attractive because they provide easy access to
state-of-the-art models and are easy to scale. However, concerns about data
privacy, the difficulty of switching service providers, and long-term operating
costs have driven interest in local deployment of open-source models. This
paper presents a cost-benefit analysis framework to help organizations
determine when on-premise LLM deployment becomes economically viable compared
to commercial subscription services. We consider the hardware requirements,
operational expenses, and performance benchmarks of the latest open-source
models, including Qwen, Llama, Mistral, and etc. Then we compare the total cost
of deploying these models locally with the major cloud providers subscription
fee. Our findings provide an estimated breakeven point based on usage levels
and performance needs. These results give organizations a practical framework
for planning their LLM strategies.

</details>


### [2] [SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture](https://arxiv.org/abs/2509.18123)
*Yeonju Lee,Rui Qi Chen,Joseph Oboamah,Po Nien Su,Wei-zhen Liang,Yeyin Shi,Lu Gan,Yongsheng Chen,Xin Qiao,Jing Li*

Main category: cs.AI

TL;DR: 利用大型语言模型(LLM)进行土壤湿度时间序列分析，实现灌溉模式和异常检测，提高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在土壤湿度时间序列分析中存在局限性，难以兼顾准确性和可解释性。

Method: 提出SPADE框架，利用ChatGPT-4.1将时间序列数据转换为文本表示，进行零样本分析，识别灌溉事件、估计净灌溉增益、检测和分类异常，并生成结构化报告。

Result: SPADE在异常检测中优于现有方法，具有更高的召回率和F1分数，并能准确分类异常类型；在检测灌溉事件方面也具有高精度和召回率。

Conclusion: 大型语言模型具有成为精准农业中可扩展、适应性强的工具的潜力，能够整合定性知识和数据驱动推理，从而改进土壤湿度监测和灌溉调度。

Abstract: Accurate interpretation of soil moisture patterns is critical for irrigation
scheduling and crop management, yet existing approaches for soil moisture
time-series analysis either rely on threshold-based rules or data-hungry
machine learning or deep learning models that are limited in adaptability and
interpretability. In this study, we introduce SPADE (Soil moisture Pattern and
Anomaly DEtection), an integrated framework that leverages large language
models (LLMs) to jointly detect irrigation patterns and anomalies in soil
moisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced
reasoning and instruction-following capabilities, enabling zero-shot analysis
without requiring task-specific annotation or fine-tuning. By converting
time-series data into a textual representation and designing domain-informed
prompt templates, SPADE identifies irrigation events, estimates net irrigation
gains, detects, classifies anomalies, and produces structured, interpretable
reports. Experiments were conducted on real-world soil moisture sensor data
from commercial and experimental farms cultivating multiple crops across the
United States. Results demonstrate that SPADE outperforms the existing method
in anomaly detection, achieving higher recall and F1 scores and accurately
classifying anomaly types. Furthermore, SPADE achieved high precision and
recall in detecting irrigation events, indicating its strong capability to
capture irrigation patterns accurately. SPADE's reports provide
interpretability and usability of soil moisture analytics. This study
highlights the potential of LLMs as scalable, adaptable tools for precision
agriculture, which is capable of integrating qualitative knowledge and
data-driven reasoning to produce actionable insights for accurate soil moisture
monitoring and improved irrigation scheduling from soil moisture time-series
data.

</details>


### [3] [Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI](https://arxiv.org/abs/2509.18132)
*Xiuyi Fan*

Main category: cs.AI

TL;DR: 该论文提出了一种可解释的不确定性估计方法(XUE)，以提高医学AI系统的可信度和可用性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学AI系统无法明确量化或传达不确定性，这与临床推理不符。

Method: 系统地将医学不确定性映射到AI不确定性概念，并确定实现XUE的关键挑战，提出技术方向，例如多模态不确定性量化、模型无关的可视化技术和不确定性感知的决策支持系统。

Result: 提出了一种结合可解释性和不确定性量化的方法，以增强医学AI的可信度。

Conclusion: XUE方法能够生成可靠的预测，并以临床有意义的方式表达置信度，从而促进医学AI的信任和采用。

Abstract: Uncertainty is a fundamental challenge in medical practice, but current
medical AI systems fail to explicitly quantify or communicate uncertainty in a
way that aligns with clinical reasoning. Existing XAI works focus on
interpreting model predictions but do not capture the confidence or reliability
of these predictions. Conversely, uncertainty estimation (UE) techniques
provide confidence measures but lack intuitive explanations. The disconnect
between these two areas limits AI adoption in medicine. To address this gap, we
propose Explainable Uncertainty Estimation (XUE) that integrates explainability
with uncertainty quantification to enhance trust and usability in medical AI.
We systematically map medical uncertainty to AI uncertainty concepts and
identify key challenges in implementing XUE. We outline technical directions
for advancing XUE, including multimodal uncertainty quantification,
model-agnostic visualization techniques, and uncertainty-aware decision support
systems. Lastly, we propose guiding principles to ensure effective XUE
realisation. Our analysis highlights the need for AI systems that not only
generate reliable predictions but also articulate confidence levels in a
clinically meaningful way. This work contributes to the development of
trustworthy medical AI by bridging explainability and uncertainty, paving the
way for AI systems that are aligned with real-world clinical complexities.

</details>


### [4] [HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics](https://arxiv.org/abs/2509.18168)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: 本文提出了一种新的分层段图记忆网络（HSGM）用于长文档语义解析，它将长文档分解成多个语义片段，构建局部语义图并提取摘要节点形成全局图，从而降低了计算复杂度并提高了效率。


<details>
  <summary>Details</summary>
Motivation: 现有的长文档语义解析方法面临二次复杂度增长和内存需求大的问题。

Method: HSGM框架将长度为N的输入分解成M个语义片段，为每个片段构建局部语义图，并提取紧凑的摘要节点形成全局图记忆。支持增量更新和分层查询处理。

Result: 在三个基准测试中，HSGM实现了2-4倍的推理速度提升，峰值内存降低超过60%，同时保持了95%以上的基准精度。

Conclusion: HSGM为超长文本的语义建模提供了可扩展、准确的解决方案，使实时和资源受限的NLP应用成为可能。

Abstract: Semantic parsing of long documents remains challenging due to quadratic
growth in pairwise composition and memory requirements. We introduce
\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that
decomposes an input of length $N$ into $M$ meaningful segments, constructs
\emph{Local Semantic Graphs} on each segment, and extracts compact
\emph{summary nodes} to form a \emph{Global Graph Memory}. HSGM supports
\emph{incremental updates} -- only newly arrived segments incur local graph
construction and summary-node integration -- while \emph{Hierarchical Query
Processing} locates relevant segments via top-$K$ retrieval over summary nodes
and then performs fine-grained reasoning within their local graphs.
  Theoretically, HSGM reduces worst-case complexity from $O(N^2)$ to
$O\!\left(N\,k + (N/k)^2\right)$, with segment size $k \ll N$, and we derive
Frobenius-norm bounds on the approximation error introduced by node
summarization and sparsification thresholds. Empirically, on three benchmarks
-- long-document AMR parsing, segment-level semantic role labeling (OntoNotes),
and legal event extraction -- HSGM achieves \emph{2--4$\times$ inference
speedup}, \emph{$>60\%$ reduction} in peak memory, and \emph{$\ge 95\%$} of
baseline accuracy. Our approach unlocks scalable, accurate semantic modeling
for ultra-long texts, enabling real-time and resource-constrained NLP
applications.

</details>


### [5] [Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM](https://arxiv.org/abs/2509.18178)
*Ling Yue,Nithin Somasekharan,Tingwen Zhang,Yadi Cao,Shaowu Pan*

Main category: cs.AI

TL;DR: Foam-Agent是一个多智能体框架，可通过自然语言提示自动执行OpenFOAM工作流程，显著提高了CFD模拟的易用性。


<details>
  <summary>Details</summary>
Motivation: 现有的CFD模拟工具学习曲线陡峭且设置复杂，阻碍了其广泛应用。

Method: 开发了一个多智能体框架Foam-Agent，集成了网格生成、HPC提交脚本生成和后处理可视化等功能，并利用Hierarchical Multi-Index RAG提高配置生成的准确性。

Result: 在110个模拟任务的基准测试中，Foam-Agent的成功率达到88.2%，显著优于现有框架。

Conclusion: Foam-Agent降低了CFD的专业门槛，展示了多智能体系统在复杂科学计算中的应用潜力。

Abstract: Computational Fluid Dynamics (CFD) is an essential simulation tool in
engineering, yet its steep learning curve and complex manual setup create
significant barriers. To address these challenges, we introduce Foam-Agent, a
multi-agent framework that automates the entire end-to-end OpenFOAM workflow
from a single natural language prompt. Our key innovations address critical
gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation:
Foam-Agent is the first system to manage the full simulation pipeline,
including advanced pre-processing with a versatile Meshing Agent capable of
handling external mesh files and generating new geometries via Gmsh, automatic
generation of HPC submission scripts, and post-simulation visualization via
ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent,
the framework uses Model Context Protocol (MCP) to expose its core functions as
discrete, callable tools. This allows for flexible integration and use by other
agentic systems, such as Claude-code, for more exploratory workflows. 3.
High-Fidelity Configuration Generation: We achieve superior accuracy through a
Hierarchical Multi-Index RAG for precise context retrieval and a
dependency-aware generation process that ensures configuration consistency.
Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2%
success rate with Claude 3.5 Sonnet, significantly outperforming existing
frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the
expertise barrier for CFD, demonstrating how specialized multi-agent systems
can democratize complex scientific computing. The code is public at
https://github.com/csml-rpi/Foam-Agent.

</details>


### [6] [Large Language Models and Operations Research: A Structured Survey](https://arxiv.org/abs/2509.18180)
*Yang Wang,Kai Li*

Main category: cs.AI

TL;DR: 本文综述了大型语言模型 (LLM) 在运筹学 (OR) 中的应用，将方法分为自动建模、辅助优化和直接求解三个方向，并指出了该领域的关键挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统的运筹学方法难以处理大型、动态和多约束问题，而LLM有潜力解决这些局限性。

Method: 对现有将LLM集成到OR方法的文献进行综述，按自动建模、辅助优化和直接求解三个方向组织。

Result: 综述了LLM在OR中的应用现状、评估基准和特定领域应用，并指出了关键的开放性问题，例如语义到结构映射的不稳定性、研究进展的零散性、泛化能力有限以及评估体系不足。

Conclusion: 概述了推进LLM在OR中作用的可能研究途径。

Abstract: Operations research (OR) provides fundamental methodologies for complex
system decision-making, with established applications in transportation, supply
chain management, and production scheduling. Traditional approaches, which
depend on expert-based modeling and manual parameter adjustment, often face
challenges in handling large-scale, dynamic, and multi-constraint problems.
Recently, large language models (LLMs) have shown potential to address these
limitations through semantic understanding, structured generation, and
reasoning control. LLMs can translate natural language descriptions into
mathematical models or executable code, generate heuristics, evolve algorithms,
and directly tackle optimization tasks. This paper surveys recent progress on
the integration of LLMs into OR, organizing methods into three main directions:
automatic modeling, auxiliary optimization, and direct solving. It further
reviews evaluation benchmarks and domain-specific applications, and summarizes
key open issues such as unstable semantic-to-structure mapping, fragmented
research progress, limited generalization, and insufficient evaluation systems.
Finally, the survey outlines possible research avenues for advancing the role
of LLMs in OR.

</details>


### [7] [Synthesizing Attitudes, Predicting Actions (SAPA): Behavioral Theory-Guided LLMs for Ridesourcing Mode Choice Modeling](https://arxiv.org/abs/2509.18181)
*Mustafa Sameen,Xiaojian Zhang,Xilei Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种名为SAPA的框架，利用大型语言模型(LLM)合成理论基础的潜在态度来预测出行方式选择，显著提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以捕捉关键的心理因素且存在严重的类别不平衡问题，导致预测精度有限。

Method: SAPA框架首先使用LLM从出行调查数据中生成定性旅客画像，然后训练倾向性评分模型，最后结合潜在变量得分和可观测的出行属性来预测出行方式选择。

Result: 实验结果表明，SAPA框架的PR-AUC指标比现有方法提高了75.9%。

Conclusion: SAPA框架为准确预测出行方式选择提供了一种强大的工具，该方法易于迁移到其他应用领域。

Abstract: Accurate modeling of ridesourcing mode choices is essential for designing and
implementing effective traffic management policies for reducing congestion,
improving mobility, and allocating resources more efficiently. Existing models
for predicting ridesourcing mode choices often suffer from limited predictive
accuracy due to their inability to capture key psychological factors, and are
further challenged by severe class imbalance, as ridesourcing trips comprise
only a small fraction of individuals' daily travel. To address these
limitations, this paper introduces the Synthesizing Attitudes, Predicting
Actions (SAPA) framework, a hierarchical approach that uses Large Language
Models (LLMs) to synthesize theory-grounded latent attitudes to predict
ridesourcing choices. SAPA first uses an LLM to generate qualitative traveler
personas from raw travel survey data and then trains a propensity-score model
on demographic and behavioral features, enriched by those personas, to produce
an individual-level score. Next, the LLM assigns quantitative scores to
theory-driven latent variables (e.g., time and cost sensitivity), and a final
classifier integrates the propensity score, latent-variable scores (with their
interaction terms), and observable trip attributes to predict ridesourcing mode
choice. Experiments on a large-scale, multi-year travel survey show that SAPA
significantly outperforms state-of-the-art baselines, improving ridesourcing
choice predictions by up to 75.9% in terms of PR-AUC on a held-out test set.
This study provides a powerful tool for accurately predicting ridesourcing mode
choices, and provides a methodology that is readily transferable to various
applications.

</details>


### [8] [An Outcome-Based Educational Recommender System](https://arxiv.org/abs/2509.18186)
*Nursultan Askarbekuly,Timur Fayzrakhmanov,Sladjan Babarogić,Ivan Luković*

Main category: cs.AI

TL;DR: OBER，一个基于学习成果的教育推荐系统，通过将学习成果和评估项目嵌入数据模式，直接评估推荐算法对学生掌握知识的促进作用。


<details>
  <summary>Details</summary>
Motivation: 现有教育推荐系统主要基于点击或评分进行评估，忽略了其真正的教学效果。

Method: 构建了基于实体关系的简约模型、基于日志的掌握度公式和插件式架构，并进行了为期两周的随机分组测试，比较了固定专家路径、协同过滤和基于知识的过滤三种方法。

Result: 协同过滤最大化了知识的保持率，但固定路径实现了最高的掌握度。OBER能同时衡量业务、相关性和学习指标。

Conclusion: OBER框架方法无关，易于扩展到未来的自适应或上下文感知推荐器，为评估教育推荐系统的教学效果提供了新方法。

Abstract: Most educational recommender systems are tuned and judged on click- or
rating-based relevance, leaving their true pedagogical impact unclear. We
introduce OBER-an Outcome-Based Educational Recommender that embeds learning
outcomes and assessment items directly into the data schema, so any algorithm
can be evaluated on the mastery it fosters. OBER uses a minimalist
entity-relation model, a log-driven mastery formula, and a plug-in
architecture. Integrated into an e-learning system in non-formal domain, it was
evaluated trough a two-week randomized split test with over 5 700 learners
across three methods: fixed expert trajectory, collaborative filtering (CF),
and knowledge-based (KB) filtering. CF maximized retention, but the fixed path
achieved the highest mastery. Because OBER derives business, relevance, and
learning metrics from the same logs, it lets practitioners weigh relevance and
engagement against outcome mastery with no extra testing overhead. The
framework is method-agnostic and readily extensible to future adaptive or
context-aware recommenders.

</details>


### [9] [MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation](https://arxiv.org/abs/2509.18198)
*Rui Liu,Zikang Wang,Peng Gao,Yu Shen,Pratap Tokekar,Ming Lin*

Main category: cs.AI

TL;DR: 该论文提出一种名为MMCD的多模态协同决策框架，用于提高自动驾驶系统在事故易发环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设训练和测试过程中所有数据模式和联网车辆都可用，这是不切实际的。

Method: 提出了一种基于跨模态知识蒸馏的师生模型结构，使模型能够有效地处理缺失数据模式的情况。

Result: 在地面车辆和空地车辆协同自动驾驶实验中，该方法将驾驶安全性提高了最多20.7%。

Conclusion: MMCD框架提高了自动驾驶系统在挑战性条件下的决策能力和鲁棒性。

Abstract: Autonomous systems have advanced significantly, but challenges persist in
accident-prone environments where robust decision-making is crucial. A single
vehicle's limited sensor range and obstructed views increase the likelihood of
accidents. Multi-vehicle connected systems and multi-modal approaches,
leveraging RGB images and LiDAR point clouds, have emerged as promising
solutions. However, existing methods often assume the availability of all data
modalities and connected vehicles during both training and testing, which is
impractical due to potential sensor failures or missing connected vehicles. To
address these challenges, we introduce a novel framework MMCD (Multi-Modal
Collaborative Decision-making) for connected autonomy. Our framework fuses
multi-modal observations from ego and collaborative vehicles to enhance
decision-making under challenging conditions. To ensure robust performance when
certain data modalities are unavailable during testing, we propose an approach
based on cross-modal knowledge distillation with a teacher-student model
structure. The teacher model is trained with multiple data modalities, while
the student model is designed to operate effectively with reduced modalities.
In experiments on $\textit{connected autonomous driving with ground vehicles}$
and $\textit{aerial-ground vehicles collaboration}$, our method improves
driving safety by up to ${\it 20.7}\%$, surpassing the best-existing baseline
in detecting potential accidents and making safe driving decisions. More
information can be found on our website https://ruiiu.github.io/mmcd.

</details>


### [10] [Change in Quantitative Bipolar Argumentation: Sufficient, Necessary, and Counterfactual Explanations](https://arxiv.org/abs/2509.18215)
*Timotheus Kampik,Kristijonas Čyras,José Ruiz Alarcón*

Main category: cs.AI

TL;DR: 本文提出了一种形式化方法来解释定量双极论证框架 (QBAF) 中推理变化。


<details>
  <summary>Details</summary>
Motivation: 追踪 QBAF 更新前后论证强度偏序的变化，解释推理变化的原因。

Method: 形式化方法，追踪强度不一致性，识别充分、必要和反事实解释，并提供基于启发式搜索的实现。

Result: 识别了强度不一致性的充分、必要和反事实解释，并证明了强度不一致性解释的存在性与更新导致强度不一致性之间的等价关系。

Conclusion: 提出了一种解释 QBAF 推理变化的形式化方法，并提供了一种基于启发式的实现，用于寻找强度不一致性解释。

Abstract: This paper presents a formal approach to explaining change of inference in
Quantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions
from a QBAF and updating the QBAF to then again draw conclusions (and so on),
our approach traces changes -- which we call strength inconsistencies -- in the
partial order over argument strengths that a semantics establishes on some
arguments of interest, called topic arguments. We trace the causes of strength
inconsistencies to specific arguments, which then serve as explanations. We
identify sufficient, necessary, and counterfactual explanations for strength
inconsistencies and show that strength inconsistency explanations exist if and
only if an update leads to strength inconsistency. We define a heuristic-based
approach to facilitate the search for strength inconsistency explanations, for
which we also provide an implementation.

</details>


### [11] [nDNA -- the Semantic Helix of Artificial Cognition](https://arxiv.org/abs/2509.18216)
*Amitava Das*

Main category: cs.AI

TL;DR: 该论文提出了一种名为神经 DNA (nDNA) 的方法，用于捕捉 AI 基础模型的潜在认知特征，类似于生物 DNA，它编码模型的谱系、突变和语义继承。


<details>
  <summary>Details</summary>
Motivation: 现有基准侧重于模型行为，忽略了模型内在的认知身份。

Method: 通过分析模型潜在几何结构的三个维度（谱曲率、热力学长度和信念向量场）来合成 nDNA。

Result: nDNA 可以用于追踪模型的演化、诊断风险以及控制模型随时间的变化。

Conclusion: nDNA 的提出开创了神经基因组学领域，将 AI 模型视为具有可追踪内在认知的数字语义有机体。

Abstract: As AI foundation models grow in capability, a deeper question emerges: What
shapes their internal cognitive identity -- beyond fluency and output?
Benchmarks measure behavior, but the soul of a model resides in its latent
geometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic
representation that captures this latent identity through the intrinsic
geometry of belief. At its core, nDNA is synthesized from three principled and
indispensable dimensions of latent geometry: spectral curvature, which reveals
the curvature of conceptual flow across layers; thermodynamic length, which
quantifies the semantic effort required to traverse representational
transitions through layers; and belief vector field, which delineates the
semantic torsion fields that guide a model's belief directional orientations.
Like biological DNA, it encodes ancestry, mutation, and semantic inheritance,
found in finetuning and alignment scars, cultural imprints, and architectural
drift. In naming it, we open a new field: Neural Genomics, where models are not
just tools, but digital semantic organisms with traceable inner cognition.
  Modeling statement. We read AI foundation models as semantic fluid--dynamics:
meaning is transported through layers like fluid in a shaped conduit; nDNA is
the physics-grade readout of that flow -- a geometry-first measure of how
meaning is bent, paid for, and pushed -- yielding a stable, coordinate-free
neural DNA fingerprint tied to on-input behavior; with this fingerprint we
cross into biology: tracing lineages across pretraining, fine-tuning,
alignment, pruning, distillation, and merges; measuring inheritance between
checkpoints; detecting drift as traits shift under new data or objectives; and,
ultimately, studying the evolution of artificial cognition to compare models,
diagnose risks, and govern change over time.

</details>


### [12] [Similarity Field Theory: A Mathematical Framework for Intelligence](https://arxiv.org/abs/2509.18218)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 本文提出了相似性场理论，一个将相似性关系作为动态系统结构基础的数学框架，并用它来定义和研究智能系统。


<details>
  <summary>Details</summary>
Motivation: 理解和构建智能系统的基础是理解动态系统中持续变化的相似性关系。

Method: 提出相似性场理论，定义相似性场、系统演化、概念和生成算子，并证明了两个关于相似性场演化的定理。

Result: 提出了相似性场理论框架，并用它形式化地定义了智能，证明了两个关于相似性场演化的定理，并探讨了如何用该框架解释大型语言模型。

Conclusion: 相似性场理论为刻画、比较和构建智能系统提供了一种基础语言，并为研究社会认知提供了新的视角。

Abstract: We posit that persisting and transforming similarity relations form the
structural basis of any comprehensible dynamic system. This paper introduces
Similarity Field Theory, a mathematical framework that formalizes the
principles governing similarity values among entities and their evolution. We
define: (1) a similarity field $S: U \times U \to [0,1]$ over a universe of
entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed
relational field (asymmetry and non-transitivity are allowed); (2) the
evolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by
$p=0,1,2,\ldots$; (3) concepts $K$ as entities that induce fibers
$F_{\alpha}(K) = { E \in U \mid S(E,K) \ge \alpha }$, i.e., superlevel sets of
the unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that
produces new entities. Within this framework, we formalize a generative
definition of intelligence: an operator $G$ is intelligent with respect to a
concept $K$ if, given a system containing entities belonging to the fiber of
$K$, it generates new entities that also belong to that fiber. Similarity Field
Theory thus offers a foundational language for characterizing, comparing, and
constructing intelligent systems. We prove two theorems: (i) asymmetry blocks
mutual inclusion; and (ii) stability requires either an anchor coordinate or
eventual confinement within a level set of $f$. These results ensure that the
evolution of similarity fields is both constrained and interpretable,
culminating in an exploration of how the framework allows us to interpret large
language models and use them as experimental probes into societal cognition.

</details>


### [13] [Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models](https://arxiv.org/abs/2509.18221)
*Dingxin Lu,Shurui Wu,Xinyi Huang*

Main category: cs.AI

TL;DR: VL-RiskFormer，一种基于Transformer的多模态AI框架，用于预测个人健康风险，在MIMIC-IV数据集上取得了AUC 0.90的良好效果。


<details>
  <summary>Details</summary>
Motivation: 全球慢性病负担日益增加，迫切需要一种统一的多模态AI框架来预测个人健康风险。

Method: 提出了一种分层堆叠的视觉语言多模态Transformer模型VL-RiskFormer，该模型结合了动量更新编码器、去偏InfoNCE损失、时间融合模块和疾病本体映射适配器等技术。

Result: 在MIMIC-IV纵向队列上，VL-RiskFormer的平均AUROC达到0.90，预期校准误差为2.7%。

Conclusion: VL-RiskFormer为多模态健康风险预测提供了一种有效的方法。

Abstract: With the rising global burden of chronic diseases and the multimodal and
heterogeneous clinical data (medical imaging, free-text recordings, wearable
sensor streams, etc.), there is an urgent need for a unified multimodal AI
framework that can proactively predict individual health risks. We propose
VL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer
with a large language model (LLM) inference head embedded in its top layer. The
system builds on the dual-stream architecture of existing visual-linguistic
models (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with
cross-modal comparison and fine-grained alignment of radiological images,
fundus maps, and wearable device photos with corresponding clinical narratives
using momentum update encoders and debiased InfoNCE losses; (ii) a time fusion
block that integrates irregular visit sequences into the causal Transformer
decoder through adaptive time interval position coding; (iii) a disease
ontology map adapter that injects ICD-10 codes into visual and textual channels
in layers and infers comorbid patterns with the help of a graph attention
mechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an
average AUROC of 0.90 with an expected calibration error of 2.7 percent.

</details>


### [14] [From "What to Eat?" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation](https://arxiv.org/abs/2509.18226)
*Yu Fu,Linyue Cai,Ruoyu Wu,Yong Zhao*

Main category: cs.AI

TL;DR: ChefMind，一种混合架构，结合了探索链、知识图谱、检索增强生成和大型语言模型，用于个性化食谱推荐，显著提高了准确性、相关性、完整性和清晰度。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化食谱推荐系统难以处理模糊的用户意图、保证语义准确性和提供足够的细节覆盖。

Method: 结合探索链（CoE）、知识图谱（KG）、检索增强生成（RAG）和大型语言模型（LLM）的混合架构。

Result: 在Xiachufang数据集上评估，ChefMind的平均得分（8.7）显著高于基线模型（6.4-6.7），并且将未处理查询减少到1.6%。

Conclusion: ChefMind有效解决了模糊用户意图和细节覆盖不足的问题，为个性化食谱推荐提供了一种更准确、完整和清晰的解决方案。

Abstract: Personalized recipe recommendation faces challenges in handling fuzzy user
intent, ensuring semantic accuracy, and providing sufficient detail coverage.
We propose ChefMind, a hybrid architecture combining Chain of Exploration
(CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large
Language Model (LLM). CoE refines ambiguous queries into structured conditions,
KG offers semantic reasoning and interpretability, RAG supplements contextual
culinary details, and LLM integrates outputs into coherent recommendations. We
evaluate ChefMind on the Xiachufang dataset and manually annotated queries,
comparing it with LLM-only, KG-only, and RAG-only baselines. Results show that
ChefMind achieves superior performance in accuracy, relevance, completeness,
and clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models.
Moreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in
handling fuzzy demands.

</details>


### [15] [An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems](https://arxiv.org/abs/2509.18229)
*Anthony Patera,Rohan Abeyaratne*

Main category: cs.AI

TL;DR: 利用多个GPT实例分析机械工程问题，提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有GPT模型在机械工程问题求解上的可靠性不足（仅85%）。

Method: 提出N+1代理模型，包含N个独立的求解代理和一个比较代理，通过比较多个结果提高准确性。

Result: 与商业多代理模型Grok Heavy相比，具有相似性能，但在透明度和教学价值方面有所侧重。

Conclusion: 该方法能有效提高GPT在机械工程问题求解中的可靠性，并具有较高的教学价值。

Abstract: Generative AI, and specifically GPT, can produce a remarkable solution to a
mechanical engineering analysis problem - but also, on occasion, a flawed
solution. For example, an elementary mechanics problem is solved flawlessly in
one GPT instance and incorrectly in a subsequent GPT instance, with a success
probability of only 85%. This unreliability renders "out-of-the-box" GPT
unsuitable for deployment in education or engineering practice. We introduce an
"N-Plus-1" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering
Problem Statements. Agency first launches N instantiations of Agent Solve to
yield N independent Proposed Problem Solution Realizations; Agency then invokes
Agent Compare to summarize and compare the N Proposed Problem Solution
Realizations and to provide a Recommended Problem Solution. We argue from
Condorcet's Jury Theorem that, for a Problem Statement characterized by
per-Solve success probability greater than 1/2 (and N sufficiently large), the
Predominant (Agent Compare) Proposed Problem Solution will, with high
probability, correspond to a Correct Proposed Problem Solution. Furthermore,
Agent Compare can also incorporate aspects of Secondary (Agent Compare)
Proposed Problem Solutions, in particular when the latter represent alternative
Problem Statement interpretations - different Mathematical Models - or
alternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a
commercial multi-agent model, show similarities in design and performance, but
also important differences in emphasis: our Agency focuses on transparency and
pedagogical value.

</details>


### [16] [Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces](https://arxiv.org/abs/2509.18230)
*Zihan Dong,Xinyu Fan,Zixiang Tang,Yunqing Li*

Main category: cs.AI

TL;DR: ComputerAgent，一种轻量级分层强化学习框架，显著提升了桌面应用软件控制效率，并在模型大小和推理时间上取得了重大突破。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态大型语言模型控制桌面应用存在延迟高、样本效率低和设备部署困难等问题。

Method: 提出了一种分层强化学习框架ComputerAgent，包含双层选项过程（管理器和子策略）、三模态状态编码器（屏幕截图、任务ID、数值状态）、元动作与提前停止机制以及紧凑型视觉主干网络和小型策略网络。

Result: 在135个真实世界桌面任务中，ComputerAgent在简单任务（<8步）上的成功率达到92.1%，在困难任务（>=8步）上的成功率达到58.8%，与2000亿参数的MLLM基线在简单场景下性能相当甚至更好，同时模型大小减少了四个数量级以上，推理时间减少了一半。

Conclusion: 分层强化学习为计算机控制提供了一种实用且可扩展的替代方案，优于单体MLLM方法。

Abstract: Controlling desktop applications via software remains a fundamental yet
under-served problem. Existing multi-modal large language models (MLLMs) ingest
screenshots and task instructions to generate keystrokes and mouse events, but
they suffer from prohibitive inference latency, poor sample efficiency on
long-horizon sparse-reward tasks, and infeasible on-device deployment. We
introduce a lightweight hierarchical reinforcement learning framework,
ComputerAgent, that formulates OS control as a two-level option process
(manager and subpolicy), employs a triple-modal state encoder (screenshot, task
ID, numeric state) to handle visual and contextual diversity, integrates
meta-actions with an early-stop mechanism to reduce wasted interactions, and
uses a compact vision backbone plus small policy networks for on-device
inference (15M parameters). On a suite of 135 real-world desktop tasks,
ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on
hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on
simple scenarios while reducing model size by over four orders of magnitude and
halving inference time. These results demonstrate that hierarchical RL offers a
practical, scalable alternative to monolithic MLLM-based automation for
computer control.

</details>
