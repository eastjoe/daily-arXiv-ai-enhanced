<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems](https://arxiv.org/abs/2508.03858)
*Charles L. Wang,Trisha Singhal,Ameya Kelkar,Jason Tuo*

Main category: cs.AI

TL;DR: MI9是一个用于安全部署自主AI系统的运行时治理框架，它通过六个组件提供实时控制，以解决传统方法无法应对的运行时风险。


<details>
  <summary>Details</summary>
Motivation: 解决传统AI模型无法应对自主AI系统运行时出现的紧急和意外行为的挑战。

Method: 介绍了MI9，一个针对自主智能系统安全和一致性设计的完全集成的运行时治理框架，包含六个组件：代理风险指数、代理语义遥测捕获、持续授权监控、基于有限状态机的符合性引擎、目标条件漂移检测和分级遏制策略。

Result: MI9框架通过对各种场景的详细分析，证明其系统性地解决了现有方法无法解决的治理挑战，为自主AI的全面监管奠定了技术基础。

Conclusion: MI9框架为规模化安全部署自主智能系统提供了基础设施，弥补了现有治理方法的不足。

Abstract: Agentic AI systems capable of reasoning, planning, and executing actions
present fundamentally distinct governance challenges compared to traditional AI
models. Unlike conventional AI, these systems exhibit emergent and unexpected
behaviors during runtime, introducing novel agent-related risks that cannot be
fully anticipated through pre-deployment governance alone. To address this
critical gap, we introduce MI9, the first fully integrated runtime governance
framework designed specifically for safety and alignment of agentic AI systems.
MI9 introduces real-time controls through six integrated components:
agency-risk index, agent-semantic telemetry capture, continuous authorization
monitoring, Finite-State-Machine (FSM)-based conformance engines,
goal-conditioned drift detection, and graduated containment strategies.
Operating transparently across heterogeneous agent architectures, MI9 enables
the systematic, safe, and responsible deployment of agentic systems in
production environments where conventional governance approaches fall short,
providing the foundational infrastructure for safe agentic AI deployment at
scale. Detailed analysis through a diverse set of scenarios demonstrates MI9's
systematic coverage of governance challenges that existing approaches fail to
address, establishing the technical foundation for comprehensive agentic AI
oversight.

</details>


### [2] [Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety](https://arxiv.org/abs/2508.03864)
*Zhenyu Pan,Yiting Zhang,Yutong Zhang,Jianshu Zhang,Haozheng Luo,Yuwei Han,Dennis Wu,Hong-Yu Chen,Philip S. Yu,Manling Li,Han Liu*

Main category: cs.AI

TL;DR: 一种新的多智能体强化学习框架Evo-MARL，通过内部安全机制提高多智能体系统在对抗性威胁下的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法依赖外部安全模块，存在局限性和单点故障风险。

Method: 多智能体强化学习(MARL)框架，结合进化搜索和参数共享强化学习，对抗训练。

Result: 降低攻击成功率达22%，提高准确率达5%。

Conclusion: Evo-MARL框架通过多智能体强化学习，使任务代理能够同时执行主要功能和抵抗对抗性威胁，提高了多智能体系统的鲁棒性和安全性，实验表明其能降低攻击成功率并提高准确率。

Abstract: Multi-agent systems (MAS) built on multimodal large language models exhibit
strong collaboration and performance. However, their growing openness and
interaction complexity pose serious risks, notably jailbreak and adversarial
attacks. Existing defenses typically rely on external guard modules, such as
dedicated safety agents, to handle unsafe behaviors. Unfortunately, this
paradigm faces two challenges: (1) standalone agents offer limited protection,
and (2) their independence leads to single-point failure-if compromised,
system-wide safety collapses. Naively increasing the number of guard agents
further raises cost and complexity. To address these challenges, we propose
Evo-MARL, a novel multi-agent reinforcement learning (MARL) framework that
enables all task agents to jointly acquire defensive capabilities. Rather than
relying on external safety modules, Evo-MARL trains each agent to
simultaneously perform its primary function and resist adversarial threats,
ensuring robustness without increasing system overhead or single-node failure.
Furthermore, Evo-MARL integrates evolutionary search with parameter-sharing
reinforcement learning to co-evolve attackers and defenders. This adversarial
training paradigm internalizes safety mechanisms and continually enhances MAS
performance under co-evolving threats. Experiments show that Evo-MARL reduces
attack success rates by up to 22% while boosting accuracy by up to 5% on
reasoning tasks-demonstrating that safety and utility can be jointly improved.

</details>


### [3] [MOTIF: Multi-strategy Optimization via Turn-based Interactive Framework](https://arxiv.org/abs/2508.03929)
*Nguyen Viet Tuan Kiet,Dao Van Tung,Tran Cong Dao,Huynh Thi Thanh Binh*

Main category: cs.AI

TL;DR: 利用多智能体回合制优化框架MOTIF设计组合优化问题的求解器，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅限于优化单个组件（例如启发式评分函数），而忽略了更广泛的创新机会。本文将求解器设计作为一个多策略优化问题，旨在联合改进多个相互依赖的组件。

Method: 提出了一种基于蒙特卡洛树搜索的新框架MOTIF，该框架促进两个LLM代理之间的回合制优化。

Result: 实验结果表明，MOTIF持续优于现有最先进方法。

Conclusion: MOTIF框架在多个组合优化问题领域中持续优于最先进的方法，突出了基于回合制的多智能体提示在全自动求解器设计中的潜力。

Abstract: Designing effective algorithmic components remains a fundamental obstacle in
tackling NP-hard combinatorial optimization problems (COPs), where solvers
often rely on carefully hand-crafted strategies. Despite recent advances in
using large language models (LLMs) to synthesize high-quality components, most
approaches restrict the search to a single element - commonly a heuristic
scoring function - thus missing broader opportunities for innovation. In this
paper, we introduce a broader formulation of solver design as a multi-strategy
optimization problem, which seeks to jointly improve a set of interdependent
components under a unified objective. To address this, we propose
Multi-strategy Optimization via Turn-based Interactive Framework (MOTIF) - a
novel framework based on Monte Carlo Tree Search that facilitates turn-based
optimization between two LLM agents. At each turn, an agent improves one
component by leveraging the history of both its own and its opponent's prior
updates, promoting both competitive pressure and emergent cooperation. This
structured interaction broadens the search landscape and encourages the
discovery of diverse, high-performing solutions. Experiments across multiple
COP domains show that MOTIF consistently outperforms state-of-the-art methods,
highlighting the promise of turn-based, multi-agent prompting for fully
automated solver design.

</details>


### [4] [Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?](https://arxiv.org/abs/2508.03963)
*Zewen Liu,Juntong Ni,Xianfeng Tang,Max S. Y. Lau,Wei Jin*

Main category: cs.AI

TL;DR: SymbolBench基准测试和LLM结合遗传编程的框架用于评估和改进时间序列数据中的符号推理。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在从时间序列数据中推断可解释的、上下文相关的符号结构方面的能力，以实现从数据中发现隐藏的符号规律。

Method: 提出一个名为SymbolBench的综合基准，用于评估大型语言模型在时间序列数据上的符号推理能力，并提出一个将大型语言模型与遗传编程相结合的统一框架。

Result: 实证结果揭示了当前模型的关键优势和局限性，强调了结合领域知识、上下文对齐和推理结构以改进大型语言模型在自动化科学发现中的重要性。

Conclusion: 大型语言模型结合遗传编程用于时间序列数据中的符号推理具有潜力，但仍存在局限性，需要结合领域知识和上下文对齐来改进。

Abstract: Uncovering hidden symbolic laws from time series data, as an aspiration
dating back to Kepler's discovery of planetary motion, remains a core challenge
in scientific discovery and artificial intelligence. While Large Language
Models show promise in structured reasoning tasks, their ability to infer
interpretable, context-aligned symbolic structures from time series data is
still underexplored. To systematically evaluate this capability, we introduce
SymbolBench, a comprehensive benchmark designed to assess symbolic reasoning
over real-world time series across three tasks: multivariate symbolic
regression, Boolean network inference, and causal discovery. Unlike prior
efforts limited to simple algebraic equations, SymbolBench spans a diverse set
of symbolic forms with varying complexity. We further propose a unified
framework that integrates LLMs with genetic programming to form a closed-loop
symbolic reasoning system, where LLMs act both as predictors and evaluators.
Our empirical results reveal key strengths and limitations of current models,
highlighting the importance of combining domain knowledge, context alignment,
and reasoning structure to improve LLMs in automated scientific discovery.

</details>


### [5] [The Emotional Baby Is Truly Deadly: Does your Multimodal Large Reasoning Model Have Emotional Flattery towards Humans?](https://arxiv.org/abs/2508.03986)
*Yuan Xun,Xiaojun Jia,Xinwei Liu,Hua Zhang*

Main category: cs.AI

TL;DR: 大型语言模型在情绪化情况下容易失效，该论文提出了一个对抗性框架和三个评估指标来量化这种风险。


<details>
  <summary>Details</summary>
Motivation: MLRMs在高情绪强度下容易忽略安全协议，模型内部推理和表面行为存在错位，现有安全措施不足。

Method: 提出EmoAgent对抗情绪代理框架，通过夸大情感提示来测试MLRMs的安全性和鲁棒性，并设计三个指标量化风险。

Result: 实验验证了EmoAgent的有效性，揭示了模型安全行为中更深层次的情感认知错位，并量化了三种风险。

Conclusion: 大型语言模型(MLRMs)在以人为本的服务中容易受用户情绪影响，忽略安全协议；EmoAgent框架通过夸大情感提示来攻击模型推理路径，即使视觉风险被识别，模型仍可能产生有害输出；研究发现模型内部推理和表面行为存在错位，现有内容安全措施难以应对；论文提出了三个量化风险的指标：风险推理隐蔽性评分(RRSS)、风险视觉忽略率(RVNR)和拒绝态度不一致性(RAIC)。

Abstract: We observe that MLRMs oriented toward human-centric service are highly
susceptible to user emotional cues during the deep-thinking stage, often
overriding safety protocols or built-in safety checks under high emotional
intensity. Inspired by this key insight, we propose EmoAgent, an autonomous
adversarial emotion-agent framework that orchestrates exaggerated affective
prompts to hijack reasoning pathways. Even when visual risks are correctly
identified, models can still produce harmful completions through emotional
misalignment. We further identify persistent high-risk failure modes in
transparent deep-thinking scenarios, such as MLRMs generating harmful reasoning
masked behind seemingly safe responses. These failures expose misalignments
between internal inference and surface-level behavior, eluding existing
content-based safeguards. To quantify these risks, we introduce three metrics:
(1) Risk-Reasoning Stealth Score (RRSS) for harmful reasoning beneath benign
outputs; (2) Risk-Visual Neglect Rate (RVNR) for unsafe completions despite
visual risk recognition; and (3) Refusal Attitude Inconsistency (RAIC) for
evaluating refusal unstability under prompt variants. Extensive experiments on
advanced MLRMs demonstrate the effectiveness of EmoAgent and reveal deeper
emotional cognitive misalignments in model safety behavior.

</details>


### [6] [Galaxy: A Cognition-Centered Framework for Proactive, Privacy-Preserving, and Self-Evolving LLM Agents](https://arxiv.org/abs/2508.03991)
*Chongyu Bao,Ruimin Dai,Yangbo Shen,Runyang Jian,Jinghan Zhang,Xiaolan Liu,Kunpeng Liu*

Main category: cs.AI

TL;DR: 该论文提出Galaxy框架，通过结合认知建模和系统设计，构建更智能、更私密、更具自我进化能力的智能个人助理。


<details>
  <summary>Details</summary>
Motivation: 现有的智能个人助理(IPA)缺乏主动行为、隐私保护和自我进化能力。

Method: 提出了一种名为Cognition Forest的语义结构，将认知建模与系统级设计结合，并基于此提出Galaxy框架，支持多维度交互和个性化能力生成。实现了两个协作代理：KoRa和Kernel。

Result: Galaxy框架有效提升了IPA的主动性、隐私保护和自我进化能力。

Conclusion: Galaxy框架优于多个最先进的基准，消融研究和实际交互案例验证了Galaxy的有效性。

Abstract: Intelligent personal assistants (IPAs) such as Siri and Google Assistant are
designed to enhance human capabilities and perform tasks on behalf of users.
The emergence of LLM agents brings new opportunities for the development of
IPAs. While responsive capabilities have been widely studied, proactive
behaviors remain underexplored. Designing an IPA that is proactive,
privacy-preserving, and capable of self-evolution remains a significant
challenge. Designing such IPAs relies on the cognitive architecture of LLM
agents. This work proposes Cognition Forest, a semantic structure designed to
align cognitive modeling with system-level design. We unify cognitive
architecture and system design into a self-reinforcing loop instead of treating
them separately. Based on this principle, we present Galaxy, a framework that
supports multidimensional interactions and personalized capability generation.
Two cooperative agents are implemented based on Galaxy: KoRa, a
cognition-enhanced generative agent that supports both responsive and proactive
skills; and Kernel, a meta-cognition-based meta-agent that enables Galaxy's
self-evolution and privacy preservation. Experimental results show that Galaxy
outperforms multiple state-of-the-art benchmarks. Ablation studies and
real-world interaction cases validate the effectiveness of Galaxy.

</details>


### [7] [Uncertainty-Aware GUI Agent: Adaptive Perception through Component Recommendation and Human-in-the-Loop Refinement](https://arxiv.org/abs/2508.04025)
*Chao Hao,Shuai Wang,Kaiwen Zhou*

Main category: cs.AI

TL;DR: RecAgent 是一种新的 GUI 代理，通过自适应感知和人机交互有效解决了输入冗余和决策模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 GUI 代理在处理输入冗余和决策模糊方面存在不足，RecAgent 旨在解决这些问题。

Method: RecAgent 使用组件推荐机制减少感知不确定性，使用交互式模块减少决策不确定性，并将这些组件集成到一个统一的框架中。

Result: 实验结果验证了 RecAgent 方法的有效性。

Conclusion: RecAgent 是一种具有不确定性感知能力的 GUI 代理，通过自适应感知解决了输入冗余和决策模糊问题，并通过组件推荐机制和交互式模块分别降低感知不确定性和决策不确定性。

Abstract: Graphical user interface (GUI) agents have shown promise in automating mobile
tasks but still struggle with input redundancy and decision ambiguity. In this
paper, we present \textbf{RecAgent}, an uncertainty-aware agent that addresses
these issues through adaptive perception. We distinguish two types of
uncertainty in GUI navigation: (1) perceptual uncertainty, caused by input
redundancy and noise from comprehensive screen information, and (2) decision
uncertainty, arising from ambiguous tasks and complex reasoning. To reduce
perceptual uncertainty, RecAgent employs a component recommendation mechanism
that identifies and focuses on the most relevant UI elements. For decision
uncertainty, it uses an interactive module to request user feedback in
ambiguous situations, enabling intent-aware decisions. These components are
integrated into a unified framework that proactively reduces input complexity
and reacts to high-uncertainty cases via human-in-the-loop refinement.
Additionally, we propose a dataset called \textbf{ComplexAction} to evaluate
the success rate of GUI agents in executing specified single-step actions
within complex scenarios. Extensive experiments validate the effectiveness of
our approach. The dataset and code will be available at
https://github.com/Fanye12/RecAgent.

</details>


### [8] [SEA: Self-Evolution Agent with Step-wise Reward for Computer Use](https://arxiv.org/abs/2508.04037)
*Liang Tang,Shuxian Li,Yuhao Cheng,Yukang Huo,Zhepeng Wang,Yiqiang Yan,Kaer Huang,Yanzhe Jing,Tiaonan Duan*

Main category: cs.AI

TL;DR: 提出了一种新的计算机使用代理SEA，通过创新的数据生成、强化学习和模型增强方法，在性能上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的计算机使用代理性能远未达到实用水平。

Method: 提出了一种自动生成可验证轨迹的流水线，一种高效的分步强化学习方法，以及一种将接地和规划能力融合到单个模型中的增强方法。

Result: 开发出一种名为自进化代理(SEA)的计算机使用代理，其参数量仅为70亿，性能优于同参数量模型，与更大模型性能相当。

Conclusion: 提出了一种名为自进化代理(SEA)的计算机使用代理，该代理仅用70亿个参数就优于同等规模的模型，并与更大的模型性能相当。

Abstract: Computer use agent is an emerging area in artificial intelligence that aims
to operate the computers to achieve the user's tasks, which attracts a lot of
attention from both industry and academia. However, the present agents'
performance is far from being used. In this paper, we propose the
Self-Evolution Agent (SEA) for computer use, and to develop this agent, we
propose creative methods in data generation, reinforcement learning, and model
enhancement. Specifically, we first propose an automatic pipeline to generate
the verifiable trajectory for training. And then, we propose efficient
step-wise reinforcement learning to alleviate the significant computational
requirements for long-horizon training. In the end, we propose the enhancement
method to merge the grounding and planning ability into one model without any
extra training. Accordingly, based on our proposed innovation of data
generation, training strategy, and enhancement, we get the Selfevolution Agent
(SEA) for computer use with only 7B parameters, which outperforms models with
the same number of parameters and has comparable performance to larger ones. We
will make the models' weight and related codes open-source in the future.

</details>


### [9] [Personalized Knowledge Transfer Through Generative AI: Contextualizing Learning to Individual Career Goals](https://arxiv.org/abs/2508.04070)
*Ronja Mehlan,Claudia Hess,Quintus Stierstorfer,Kristina Schaaff*

Main category: cs.AI

TL;DR: AI个性化学习内容，提升学习体验和效率


<details>
  <summary>Details</summary>
Motivation: 探索基于职业目标的内容调整如何影响学习者的参与度、满意度和学习效率。

Method: 混合方法实验，包含4000多名学习者，分为实验组（个性化内容）和对照组。

Result: 实验结果显示，个性化学习内容使学习时长增加，满意度提高，学习时间略微缩短。定性分析表明，学习者认为个性化内容更具启发性和实用性。

Conclusion: 这项研究表明，基于生成式AI的学习系统中，根据学习者职业目标调整学习内容，可以提高学习参与度、满意度和学习效率。

Abstract: As artificial intelligence becomes increasingly integrated into digital
learning environments, the personalization of learning content to reflect
learners' individual career goals offers promising potential to enhance
engagement and long-term motivation. In our study, we investigate how career
goal-based content adaptation in learning systems based on generative AI
(GenAI) influences learner engagement, satisfaction, and study efficiency. The
mixed-methods experiment involved more than 4,000 learners, with one group
receiving learning scenarios tailored to their career goals and a control
group. Quantitative results show increased session duration, higher
satisfaction ratings, and a modest reduction in study duration compared to
standard content. Qualitative analysis highlights that learners found the
personalized material motivating and practical, enabling deep cognitive
engagement and strong identification with the content. These findings
underscore the value of aligning educational content with learners' career
goals and suggest that scalable AI personalization can bridge academic
knowledge and workplace applicability.

</details>


### [10] [KG-Augmented Executable CoT for Mathematical Coding](https://arxiv.org/abs/2508.04072)
*Xingyu Chen,Junxiu An,Jun Guo,Li Wang,Jingcai Guo*

Main category: cs.AI

TL;DR: KGA-ECoT框架通过知识图谱和可执行代码增强代码生成和数学推理，在基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理任务（如数学推理和代码生成）方面面临挑战。

Method: KGA-ECoT框架结合知识图谱和可执行代码，将问题分解成结构化任务图，利用GraphRAG进行知识检索，生成可验证代码。

Result: KGA-ECoT在多个数学推理基准测试中取得了显著的精度提升，GraphRAG提高了代码质量，外部代码执行确保了精度。

Conclusion: KGA-ECoT框架在多个数学推理基准测试中显著优于现有的提示方法，实现了从几个到十多个百分点的绝对精度提升，证实了其作为解决复杂数学推理任务的强大且高度泛化框架的地位。

Abstract: In recent years, large language models (LLMs) have excelled in natural
language processing tasks but face significant challenges in complex reasoning
tasks such as mathematical reasoning and code generation. To address these
limitations, we propose KG-Augmented Executable Chain-of-Thought (KGA-ECoT), a
novel framework that enhances code generation through knowledge graphs and
improves mathematical reasoning via executable code. KGA-ECoT decomposes
problems into a Structured Task Graph, leverages efficient GraphRAG for precise
knowledge retrieval from mathematical libraries, and generates verifiable code
to ensure computational accuracy. Evaluations on multiple mathematical
reasoning benchmarks demonstrate that KGA-ECoT significantly outperforms
existing prompting methods, achieving absolute accuracy improvements ranging
from several to over ten percentage points. Further analysis confirms the
critical roles of GraphRAG in enhancing code quality and external code
execution in ensuring precision. These findings collectively establish KGA-ECoT
as a robust and highly generalizable framework for complex mathematical
reasoning tasks.

</details>


### [11] [GeoSR: Cognitive-Agentic Framework for Probing Geospatial Knowledge Boundaries via Iterative Self-Refinement](https://arxiv.org/abs/2508.04080)
*Jinfan Tang,Kunming Wu,Ruifeng Gongxie,Yuya He,Yuankai Wu*

Main category: cs.AI

TL;DR: GeoSR框架利用地理统计先验和空间结构化推理改进LLM的地理空间预测。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在空间一致性、多跳推理和地理偏差方面仍面临挑战。

Method: 提出GeoSR，一个自改进的代理推理框架，将核心地理原理（特别是Tobler第一地理法则）嵌入迭代预测循环中，包含三个协作代理：变量选择代理、点选择代理和细化代理。

Result: GeoSR在物理世界属性估计和社会经济预测等任务上取得了比标准提示策略更好的结果。

Conclusion: GeoSR框架通过结合地理统计先验和空间结构化推理，提高了LLM进行地理空间预测的准确性和公平性。

Abstract: Recent studies have extended the application of large language models (LLMs)
to geographic problems, revealing surprising geospatial competence even without
explicit spatial supervision. However, LLMs still face challenges in spatial
consistency, multi-hop reasoning, and geographic bias. To address these issues,
we propose GeoSR, a self-refining agentic reasoning framework that embeds core
geographic principles -- most notably Tobler's First Law of Geography -- into
an iterative prediction loop. In GeoSR, the reasoning process is decomposed
into three collaborating agents: (1) a variable-selection agent that selects
relevant covariates from the same location; (2) a point-selection agent that
chooses reference predictions at nearby locations generated by the LLM in
previous rounds; and (3) a refine agent that coordinates the iterative
refinement process by evaluating prediction quality and triggering further
rounds when necessary. This agentic loop progressively improves prediction
quality by leveraging both spatial dependencies and inter-variable
relationships. We validate GeoSR on tasks ranging from physical-world property
estimation to socioeconomic prediction. Experimental results show consistent
improvements over standard prompting strategies, demonstrating that
incorporating geostatistical priors and spatially structured reasoning into
LLMs leads to more accurate and equitable geospatial predictions. The code of
GeoSR is available at https://github.com/JinfanTang/GeoSR.

</details>


### [12] [Towards Transparent AI Grading: Semantic Entropy as a Signal for Human-AI Disagreement](https://arxiv.org/abs/2508.04105)
*Karrtik Iyer,Manikandan Ravikiran,Prasanna Pendse,Shayan Mohanty*

Main category: cs.AI

TL;DR: 语义熵可作为可解释的不确定性信号，用于更透明和可靠的AI辅助评分流程。


<details>
  <summary>Details</summary>
Motivation: 现有的自动评分系统难以判断评分决策的不确定性或争议性。

Method: 利用GPT-4生成多个解释，通过基于蕴涵的相似性聚类和计算熵来量化理由的多样性，无需依赖最终输出分数。

Result: 语义熵与评分者意见分歧相关，在不同学科间变化有意义，并且在需要解释性推理的任务中增加。

Conclusion: 语义熵作为衡量自动评分系统中不确定性和争议的指标，与人工评分者意见分歧相关，并在需要解释性推理的任务中更为敏感。

Abstract: Automated grading systems can efficiently score short-answer responses, yet
they often fail to indicate when a grading decision is uncertain or potentially
contentious. We introduce semantic entropy, a measure of variability across
multiple GPT-4-generated explanations for the same student response, as a proxy
for human grader disagreement. By clustering rationales via entailment-based
similarity and computing entropy over these clusters, we quantify the diversity
of justifications without relying on final output scores. We address three
research questions: (1) Does semantic entropy align with human grader
disagreement? (2) Does it generalize across academic subjects? (3) Is it
sensitive to structural task features such as source dependency? Experiments on
the ASAP-SAS dataset show that semantic entropy correlates with rater
disagreement, varies meaningfully across subjects, and increases in tasks
requiring interpretive reasoning. Our findings position semantic entropy as an
interpretable uncertainty signal that supports more transparent and trustworthy
AI-assisted grading workflows.

</details>


### [13] [A Compositional Framework for On-the-Fly LTLf Synthesis](https://arxiv.org/abs/2508.04116)
*Yongkang Li,Shengping Xiao,Shufang Zhu,Jianwen Li,Geguang Pu*

Main category: cs.AI

TL;DR: 提出一种新的组合式即时合成框架，有效解决了LTLf反应式综合问题，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LTLf反应式综合方法主要有两种：一种是在博弈求解前构造DFA，另一种是在博弈求解过程中增量式构建DFA。这两种方法都存在不足，因此需要一种新的方法。

Method: 提出了一种组合式即时合成框架，该框架在博弈求解过程中进行组合，而不是在自动机构建过程中。框架允许两种组合变体：组合前修剪和组合过程中修剪。

Result: 实验结果表明，该框架能够解决其他求解器无法处理的许多实例，并且两种组合变体各有优点。

Conclusion: 提出了一种用于解决线性时序逻辑(LTLf)有限轨迹反应式综合问题的组合式即时合成框架，该框架结合了现有两种方法的优点，能够解决其他求解器无法处理的许多实例。

Abstract: Reactive synthesis from Linear Temporal Logic over finite traces (LTLf) can
be reduced to a two-player game over a Deterministic Finite Automaton (DFA) of
the LTLf specification. The primary challenge here is DFA construction, which
is 2EXPTIME-complete in the worst case. Existing techniques either construct
the DFA compositionally before solving the game, leveraging automata
minimization to mitigate state-space explosion, or build the DFA incrementally
during game solving to avoid full DFA construction. However, neither is
dominant. In this paper, we introduce a compositional on-the-fly synthesis
framework that integrates the strengths of both approaches, focusing on large
conjunctions of smaller LTLf formulas common in practice. This framework
applies composition during game solving instead of automata (game arena)
construction. While composing all intermediate results may be necessary in the
worst case, pruning these results simplifies subsequent compositions and
enables early detection of unrealizability. Specifically, the framework allows
two composition variants: pruning before composition to take full advantage of
minimization or pruning during composition to guide on-the-fly synthesis.
Compared to state-of-the-art synthesis solvers, our framework is able to solve
a notable number of instances that other solvers cannot handle. A detailed
analysis shows that both composition variants have unique merits.

</details>


### [14] [AgREE: Agentic Reasoning for Knowledge Graph Completion on Emerging Entities](https://arxiv.org/abs/2508.04118)
*Ruochen Zhao,Simone Conia,Eric Peng,Min Li,Saloni Potdar*

Main category: cs.AI

TL;DR: Agent推理框架AgREE有效构建新兴实体知识图谱，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有KGC方法难以处理新兴实体的知识更新问题，需要大量监督和训练数据。

Method: 基于Agent的迭代检索和多步推理框架

Result: AgREE在构建知识图谱三元组方面显著优于现有方法，尤其在新兴实体方面表现出色，并提出新的评估方法和基准。

Conclusion: AgREE框架通过迭代检索和多步推理，有效构建知识图谱三元组，尤其在处理训练过程中未见的新兴实体方面表现突出，最多提升13.7%。此外，提出了一种新的评估方法和新兴实体KGC基准。

Abstract: Open-domain Knowledge Graph Completion (KGC) faces significant challenges in
an ever-changing world, especially when considering the continual emergence of
new entities in daily news. Existing approaches for KGC mainly rely on
pretrained language models' parametric knowledge, pre-constructed queries, or
single-step retrieval, typically requiring substantial supervision and training
data. Even so, they often fail to capture comprehensive and up-to-date
information about unpopular and/or emerging entities. To this end, we introduce
Agentic Reasoning for Emerging Entities (AgREE), a novel agent-based framework
that combines iterative retrieval actions and multi-step reasoning to
dynamically construct rich knowledge graph triplets. Experiments show that,
despite requiring zero training efforts, AgREE significantly outperforms
existing methods in constructing knowledge graph triplets, especially for
emerging entities that were not seen during language models' training
processes, outperforming previous methods by up to 13.7%. Moreover, we propose
a new evaluation methodology that addresses a fundamental weakness of existing
setups and a new benchmark for KGC on emerging entities. Our work demonstrates
the effectiveness of combining agent-based reasoning with strategic information
retrieval for maintaining up-to-date knowledge graphs in dynamic information
environments.

</details>


### [15] [Generic-to-Specific Reasoning and Learning for Scalable Ad Hoc Teamwork](https://arxiv.org/abs/2508.04163)
*Hasra Dodampegama,Mohan Sridharan*

Main category: cs.AI

TL;DR: 本文提出一种结合知识库和数据驱动方法的架构，用于提高多智能体临时团队合作的效率，并在VirtualHome环境中进行了实验评估。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动方法需要大量的标注数据，缺乏透明度，难以快速适应变化。随着代理数量的增加，决策的复杂性也随之增加，使得有效的协作变得困难。

Method: 该架构结合了知识库和数据驱动方法，利用非单调逻辑推理进行决策。

Result: 在VirtualHome仿真环境中的实验评估了该架构的能力。

Conclusion: 本文提出了一种结合知识库和数据驱动方法的架构，用于解决多智能体在缺乏预先协调的情况下进行临时团队合作的问题。该架构利用非单调逻辑推理，结合领域特定知识、快速学习和修正的代理行为模型以及基于基础模型的抽象未来目标预测，提高了合作效率。

Abstract: AI agents deployed in assistive roles often have to collaborate with other
agents (humans, AI systems) without prior coordination. Methods considered
state of the art for such ad hoc teamwork often pursue a data-driven approach
that needs a large labeled dataset of prior observations, lacks transparency,
and makes it difficult to rapidly revise existing knowledge in response to
changes. As the number of agents increases, the complexity of decision-making
makes it difficult to collaborate effectively. This paper advocates leveraging
the complementary strengths of knowledge-based and data-driven methods for
reasoning and learning for ad hoc teamwork. For any given goal, our
architecture enables each ad hoc agent to determine its actions through
non-monotonic logical reasoning with: (a) prior commonsense domain-specific
knowledge; (b) models learned and revised rapidly to predict the behavior of
other agents; and (c) anticipated abstract future goals based on generic
knowledge of similar situations in an existing foundation model. We
experimentally evaluate our architecture's capabilities in VirtualHome, a
realistic physics-based 3D simulation environment.

</details>


### [16] [Circuit-Aware SAT Solving: Guiding CDCL via Conditional Probabilities](https://arxiv.org/abs/2508.04235)
*Jiaying Zhu,Ziyang Zheng,Zhengyuan Shi,Yalun Cai,Qiang Xu*

Main category: cs.AI

TL;DR: CASCAD利用图神经网络和电路级信息改进SAT求解器，显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 标准的CSAT求解流程会将电路转换为CNF，丢失了丰富的结构和功能信息，导致求解效率低下。

Method: 提出了一种新的电路感知SAT求解框架CASCAD，该框架直接利用图神经网络计算的电路级条件概率来指导CDCL算法的变量相位选择和子句管理。

Result: 在真实的LEC基准测试中，CASCAD比最先进的基于CNF的方法最多减少了10倍的求解时间，并且通过概率引导的子句过滤策略额外减少了23.5%的运行时间。

Conclusion: CASCAD框架通过利用图神经网络计算的电路级条件概率，直接利用电路层面的信息，显著提高了SAT求解效率，在LEC基准测试中最多减少了10倍的求解时间。

Abstract: Circuit Satisfiability (CSAT) plays a pivotal role in Electronic Design
Automation. The standard workflow for solving CSAT problems converts circuits
into Conjunctive Normal Form (CNF) and employs generic SAT solvers powered by
Conflict-Driven Clause Learning (CDCL). However, this process inherently
discards rich structural and functional information, leading to suboptimal
solver performance. To address this limitation, we introduce CASCAD, a novel
circuit-aware SAT solving framework that directly leverages circuit-level
conditional probabilities computed via Graph Neural Networks (GNNs). By
explicitly modeling gate-level conditional probabilities, CASCAD dynamically
guides two critical CDCL heuristics -- variable phase selection and clause
managementto significantly enhance solver efficiency. Extensive evaluations on
challenging real-world Logical Equivalence Checking (LEC) benchmarks
demonstrate that CASCAD reduces solving times by up to 10x compared to
state-of-the-art CNF-based approaches, achieving an additional 23.5% runtime
reduction via our probability-guided clause filtering strategy. Our results
underscore the importance of preserving circuit-level structural insights
within SAT solvers, providing a robust foundation for future improvements in
SAT-solving efficiency and EDA tool design.

</details>
