{"id": "2509.19456", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19456", "abs": "https://arxiv.org/abs/2509.19456", "authors": ["Krisztian Balog", "ChengXiang Zhai"], "title": "The Indispensable Role of User Simulation in the Pursuit of AGI", "comment": "Accepted for publication in Communications of the ACM", "summary": "Progress toward Artificial General Intelligence (AGI) faces significant\nbottlenecks, particularly in rigorously evaluating complex interactive systems\nand acquiring the vast interaction data needed for training adaptive agents.\nThis paper posits that user simulation -- creating computational agents that\nmimic human interaction with AI systems -- is not merely a useful tool, but is\na critical catalyst required to overcome these bottlenecks and accelerate AGI\ndevelopment. We argue that realistic simulators provide the necessary\nenvironments for scalable evaluation, data generation for interactive learning,\nand fostering the adaptive capabilities central to AGI. Therefore, research\ninto user simulation technology and intelligent task agents are deeply\nsynergistic and must advance hand-in-hand. This article elaborates on the\ncritical role of user simulation for AGI, explores the interdisciplinary nature\nof building realistic simulators, identifies key challenges including those\nposed by large language models, and proposes a future research agenda.", "AI": {"tldr": "\"\u7528\u6237\u6a21\u62df\u662f\u52a0\u901f AGI \u53d1\u5c55\u7684\u5173\u952e\u50ac\u5316\u5242\"", "motivation": "\"\u89e3\u51b3\u8bc4\u4f30\u590d\u6742\u4ea4\u4e92\u7cfb\u7edf\u548c\u83b7\u53d6\u6d77\u91cf\u4ea4\u4e92\u6570\u636e\u7684\u74f6\u9888\"", "method": "\"\u6784\u5efa\u6a21\u62df\u4eba\u7c7b\u4e0e AI \u7cfb\u7edf\u4ea4\u4e92\u7684\u8ba1\u7b97\u4ee3\u7406\"", "result": "\"\u53ef\u6269\u5c55\u8bc4\u4f30\u3001\u4ea4\u4e92\u5b66\u4e60\u6570\u636e\u751f\u6210\u548c\u589e\u5f3a\u81ea\u9002\u5e94\u80fd\u529b\"", "conclusion": "\"\u7528\u6237\u6a21\u62df\u6280\u672f\u548c\u667a\u80fd\u4efb\u52a1\u4ee3\u7406\u7814\u7a76\u9700\u540c\u6b65\u53d1\u5c55\""}}
{"id": "2509.19464", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19464", "abs": "https://arxiv.org/abs/2509.19464", "authors": ["Shripad Vilasrao Deshmukh", "Will Schwarzer", "Scott Niekum"], "title": "Evaluation-Aware Reinforcement Learning", "comment": "9 pages, under submission", "summary": "Policy evaluation is often a prerequisite for deploying safety- and\nperformance-critical systems. Existing evaluation approaches frequently suffer\nfrom high variance due to limited data and long-horizon tasks, or high bias due\nto unequal support or inaccurate environmental models. We posit that these\nchallenges arise, in part, from the standard reinforcement learning (RL)\nparadigm of policy learning without explicit consideration of evaluation. As an\nalternative, we propose evaluation-aware reinforcement learning (EvA-RL), in\nwhich a policy is trained to maximize expected return while simultaneously\nminimizing expected evaluation error under a given value prediction scheme --\nin other words, being \"easy\" to evaluate. We formalize a framework for EvA-RL\nand design an instantiation that enables accurate policy evaluation,\nconditioned on a small number of rollouts in an assessment environment that can\nbe different than the deployment environment. However, our theoretical analysis\nand empirical results show that there is often a tradeoff between evaluation\naccuracy and policy performance when using a fixed value-prediction scheme\nwithin EvA-RL. To mitigate this tradeoff, we extend our approach to co-learn an\nassessment-conditioned state-value predictor alongside the policy. Empirical\nresults across diverse discrete and continuous action domains demonstrate that\nEvA-RL can substantially reduce evaluation error while maintaining competitive\nreturns. This work lays the foundation for a broad new class of RL methods that\ntreat reliable evaluation as a first-class principle during training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5EvA-RL\uff0c\u8be5\u65b9\u6cd5\u5728\u8bad\u7ec3\u7b56\u7565\u65f6\u540c\u65f6\u6700\u5c0f\u5316\u8bc4\u4f30\u8bef\u5dee\uff0c\u4ece\u800c\u63d0\u9ad8\u7b56\u7565\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7b56\u7565\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u65b9\u5dee\u5927\u6216\u504f\u5dee\u5927\u7684\u95ee\u9898\uff0cEvA-RL\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "EvA-RL\u6846\u67b6\uff0c\u4ee5\u53ca\u4e00\u4e2a\u8bc4\u4f30\u6761\u4ef6\u72b6\u6001\u503c\u9884\u6d4b\u5668\u4e0e\u7b56\u7565\u7684\u8054\u5408\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eEvA-RL\u80fd\u663e\u8457\u964d\u4f4e\u8bc4\u4f30\u8bef\u5dee\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u56de\u62a5\u3002", "conclusion": "EvA-RL\u4e3a\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u601d\u8def\uff0c\u5373\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c06\u53ef\u9760\u7684\u8bc4\u4f30\u4f5c\u4e3a\u9996\u8981\u539f\u5219\u3002"}}
{"id": "2509.19489", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19489", "abs": "https://arxiv.org/abs/2509.19489", "authors": ["Robert Nowak"], "title": "Estimating the Self-Consistency of LLMs", "comment": "5 pages", "summary": "Systems often repeat the same prompt to large language models (LLMs) and\naggregate responses to improve reliability. This short note analyzes an\nestimator of the self-consistency of LLMs and the tradeoffs it induces under a\nfixed compute budget $B=mn$, where $m$ is the number of prompts sampled from\nthe task distribution and $n$ is the number of repeated LLM calls per prompt;\nthe resulting analysis favors a rough split $m,n\\propto\\sqrt{B}$.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u81ea\u4e00\u81f4\u6027\u7684\u4f30\u8ba1\u91cf\u53ca\u5176\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u6743\u8861\u3002", "motivation": "LLM\u7cfb\u7edf\u901a\u5e38\u4f1a\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u91cd\u590d\u76f8\u540c\u7684\u63d0\u793a\u5e76\u805a\u5408\u54cd\u5e94\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "method": "\u5206\u6790\u4e86\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\uff0c\u4ece\u4efb\u52a1\u5206\u5e03\u4e2d\u91c7\u6837\u7684\u63d0\u793a\u6570\u91cfm\u548c\u6bcf\u4e2a\u63d0\u793a\u7684\u91cd\u590dLLM\u8c03\u7528\u6b21\u6570n\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u5206\u6790\u7ed3\u679c\u8868\u660e\uff0cm\u548cn\u5927\u81f4\u76f8\u7b49\u65f6\uff0c\u6548\u679c\u6700\u4f73\u3002", "conclusion": "\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\uff0c\u5bf9\u63d0\u793a\u6570\u91cf\u548c\u91cd\u590d\u6b21\u6570\u8fdb\u884c\u5408\u7406\u5206\u914d\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8LLM\u7684\u81ea\u4e00\u81f4\u6027\u3002"}}
{"id": "2509.19517", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.19517", "abs": "https://arxiv.org/abs/2509.19517", "authors": ["Sai Teja Reddy Adapala"], "title": "Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning", "comment": null, "summary": "The scaling of Large Language Models (LLMs) has exposed a critical gap\nbetween their performance on static benchmarks and their fragility in dynamic,\ninformation-rich environments. While models excel at isolated tasks, the\ncomputational limits that govern their reasoning under cognitive load remain\npoorly understood. In this work, we introduce a formal theory of computational\ncognitive load, positing that extraneous, task-irrelevant information (Context\nSaturation) and interference from task-switching (Attentional Residue) are key\nmechanisms that degrade performance. We designed the Interleaved Cognitive\nEvaluation (ICE), a deconfounded benchmark to systematically manipulate these\nload factors on challenging multi-hop reasoning tasks. A comprehensive study (N\n= 10 replications per item across 200 questions) revealed significant\nperformance variations across five instruction-tuned models. Smaller\nopen-source architectures (Llama-3-8B-Instruct, Mistral-7B-Instruct-v0.2)\nexhibited baseline brittleness, achieving 0% accuracy (SEM = 0.0) across all\nconditions, including clean controls, on this high-intrinsic-load task. In\ncontrast, Gemini-2.0-Flash-001 showed partial resilience, achieving 85%\naccuracy in control conditions, with a statistically significant degradation\nunder context saturation ($\\beta = -0.003$ per % load, $p < 0.001$). These\nfindings provide preliminary evidence that cognitive load is a key contributor\nto reasoning failures, supporting theories of hallucination-as-guessing under\nuncertainty. We conclude that dynamic, cognitive-aware stress testing, as\nexemplified by the ICE benchmark, is essential for evaluating the true\nresilience and safety of advanced AI systems.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u8868\u73b0\u4e0d\u5982\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90a3\u4e48\u597d\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u8ba4\u77e5\u8d1f\u8377\u7684\u7406\u8bba\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u8ba4\u77e5\u8d1f\u8377\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u4fe1\u606f\u73af\u5883\u4e0b\u6027\u80fd\u4e0d\u4f73\u7684\u539f\u56e0\uff0c\u4ee5\u53ca\u5982\u4f55\u8bc4\u4f30\u9ad8\u7ea7AI\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u8ba1\u7b97\u8ba4\u77e5\u8d1f\u8377\u7684\u7406\u8bba\uff0c\u5e76\u8bbe\u8ba1\u4e86Interleaved Cognitive Evaluation (ICE)\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5bf9\u4e94\u4e2a\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u4e0d\u540c\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\u663e\u8457\uff0c\u5c0f\u578b\u5f00\u6e90\u67b6\u6784\u6a21\u578b\u8868\u73b0\u8106\u5f31\uff0c\u800cGemini-2.0-Flash-001\u8868\u73b0\u51fa\u4e00\u5b9a\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u4e0a\u4e0b\u6587\u9971\u548c\u5ea6\u589e\u52a0\u65f6\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u8ba4\u77e5\u8d1f\u8377\u662f\u5bfc\u81f4\u63a8\u7406\u5931\u8d25\u7684\u5173\u952e\u56e0\u7d20\u4e4b\u4e00\uff0c\u52a8\u6001\u7684\u8ba4\u77e5\u611f\u77e5\u538b\u529b\u6d4b\u8bd5\u5bf9\u4e8e\u8bc4\u4f30\u9ad8\u7ea7AI\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.19524", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19524", "abs": "https://arxiv.org/abs/2509.19524", "authors": ["Ramy ElMallah", "Krish Chhajer", "Chi-Guhn Lee"], "title": "Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation", "comment": "Accepted to the CoRL 2025 Eval&Deploy Workshop", "summary": "Robot learning papers typically report a single binary success rate (SR),\nwhich obscures where a policy succeeds or fails along a multi-step manipulation\ntask. We argue that subgoal-level reporting should become routine: for each\ntrajectory, a vector of per-subgoal SRs that makes partial competence visible\n(e.g., grasp vs. pour). We propose a blueprint for StepEval, a cost-aware\nplug-in evaluation framework that utilizes vision-language models (VLMs) as\nautomated judges of subgoal outcomes from recorded images or videos. Rather\nthan proposing new benchmarks or APIs, our contribution is to outline design\nprinciples for a scalable, community-driven open-source project. In StepEval,\nthe primary artifact for policy evaluation is the per-subgoal SR vector;\nhowever, other quantities (e.g., latency or cost estimates) are also considered\nfor framework-optimization diagnostics to help the community tune evaluation\nefficiency and accuracy when ground-truth subgoal success labels are available.\nWe discuss how such a framework can remain model-agnostic, support single- or\nmulti-view inputs, and be lightweight enough to adopt across labs. The intended\ncontribution is a shared direction: a minimal, extensible seed that invites\nopen-source contributions, so that scoring the steps, not just the final goal,\nbecomes a standard and reproducible practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faStepEval\u6846\u67b6\uff0c\u7528\u4e8e\u66f4\u7ec6\u81f4\u5730\u8bc4\u4f30\u673a\u5668\u4eba\u5b66\u4e60\u4e2d\u591a\u6b65\u9aa4\u64cd\u4f5c\u4efb\u52a1\u7684\u7b56\u7565\u6210\u529f\u7387\uff0c\u800c\u975e\u4ec5\u4f9d\u8d56\u5355\u4e00\u7684\u6700\u7ec8\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u4eba\u5b66\u4e60\u8bba\u6587\u901a\u5e38\u53ea\u62a5\u544a\u5355\u4e00\u7684\u4e8c\u5143\u6210\u529f\u7387\uff0c\u65e0\u6cd5\u4f53\u73b0\u7b56\u7565\u5728\u591a\u6b65\u9aa4\u4efb\u52a1\u4e2d\u5404\u4e2a\u5b50\u76ee\u6807\u4e0a\u7684\u6210\u529f\u4e0e\u5931\u8d25\u60c5\u51b5\u3002", "method": "\u63d0\u51faStepEval\u6846\u67b6\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u81ea\u52a8\u5224\u65ad\u5b50\u76ee\u6807\u7ed3\u679c\uff0c\u5e76\u8003\u8651\u6210\u672c\u56e0\u7d20\uff0c\u652f\u6301\u5355\u89c6\u56fe\u6216\u591a\u89c6\u56fe\u8f93\u5165\uff0c\u65e8\u5728\u6210\u4e3a\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5f00\u6e90\u9879\u76ee\u3002", "result": "\u63d0\u51fa\u4e86StepEval\u6846\u67b6\u7684\u8bbe\u8ba1\u84dd\u56fe\uff0c\u5f3a\u8c03\u4e86\u4ee5\u5b50\u76ee\u6807\u6210\u529f\u7387\u5411\u91cf\u4f5c\u4e3a\u4e3b\u8981\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u8003\u8651\u5176\u4ed6\u56e0\u7d20\u4f8b\u5982\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "conclusion": "StepEval\u6846\u67b6\u65e8\u5728\u4fc3\u8fdb\u673a\u5668\u4eba\u5b66\u4e60\u9886\u57df\u8bc4\u4f30\u6807\u51c6\u5316\u548c\u53ef\u91cd\u590d\u6027\uff0c\u9f13\u52b1\u793e\u533a\u8d21\u732e\uff0c\u63a8\u52a8\u4ee5\u5b50\u76ee\u6807\u4e3a\u5355\u4f4d\u7684\u8bc4\u4f30\u6210\u4e3a\u6807\u51c6\u5b9e\u8df5\u3002"}}
{"id": "2509.19566", "categories": ["cs.AI", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2509.19566", "abs": "https://arxiv.org/abs/2509.19566", "authors": ["George Hong", "Daniel Trejo Banos"], "title": "Nano Bio-Agents (NBA): Small Language Model Agents for Genomics", "comment": null, "summary": "We investigate the application of Small Language Models (<10 billion\nparameters) for genomics question answering via agentic framework to address\nhallucination issues and computational cost challenges. The Nano Bio-Agent\n(NBA) framework we implemented incorporates task decomposition, tool\norchestration, and API access into well-established systems such as NCBI and\nAlphaGenome. Results show that SLMs combined with such agentic framework can\nachieve comparable and in many cases superior performance versus existing\napproaches utilising larger models, with our best model-agent combination\nachieving 98% accuracy on the GeneTuring benchmark. Notably, small 3-10B\nparameter models consistently achieve 85-97% accuracy while requiring much\nlower computational resources than conventional approaches. This demonstrates\npromising potential for efficiency gains, cost savings, and democratization of\nML-powered genomics tools while retaining highly robust and accurate\nperformance.", "AI": {"tldr": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u4ee3\u7406\u6846\u67b6\u53ef\u7528\u4e8e\u57fa\u56e0\u7ec4\u5b66\u95ee\u7b54\uff0c\u5728GeneTuring\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u9ad8\u8fbe98%\uff0c\u4e14\u8d44\u6e90\u6d88\u8017\u8fdc\u4f4e\u4e8e\u5927\u578b\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u56e0\u7ec4\u5b66\u95ee\u7b54\u4e2d\u5b58\u5728\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002", "method": "\u4f7f\u7528Nano Bio-Agent (NBA)\u6846\u67b6\uff0c\u7ed3\u5408\u4efb\u52a1\u5206\u89e3\u3001\u5de5\u5177\u7f16\u6392\u548cAPI\u8bbf\u95ee\uff08NCBI\u548cAlphaGenome\uff09\u3002", "result": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(3-10B\u53c2\u6570)\u5728GeneTuring\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u8fbe\u523085-97%\uff0c\u4f18\u4e8e\u8bb8\u591a\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u4ee3\u7406\u6846\u67b6\u5728\u57fa\u56e0\u7ec4\u5b66\u95ee\u7b54\u4e2d\u5177\u6709\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u548c\u9ad8\u6027\u80fd\u7684\u4f18\u52bf\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u57fa\u56e0\u7ec4\u5b66\u5de5\u5177\u7684\u666e\u53ca\u3002"}}
{"id": "2509.19590", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19590", "abs": "https://arxiv.org/abs/2509.19590", "authors": ["Nathanael Jo", "Ashia Wilson"], "title": "What Does Your Benchmark Really Measure? A Framework for Robust Inference of AI Capabilities", "comment": null, "summary": "Evaluations of generative models on benchmark data are now ubiquitous, and\ntheir outcomes critically shape public and scientific expectations of AI's\ncapabilities. Yet growing skepticism surrounds their reliability. How can we\nknow that a reported accuracy genuinely reflects a model's true performance?\nEvaluations are often presented as simple measurements, but in reality they are\ninferences: to treat benchmark scores as evidence of capability is already to\nassume a theory of what capability is and how it manifests in a test. We make\nthis step explicit by proposing a principled framework for evaluation as\ninference: begin from a theory of capability, and then derive methods for\nestimating it. This perspective, familiar in fields such as psychometrics, has\nnot yet become commonplace in AI evaluation. As a proof of concept, we address\na central challenge that undermines reliability: sensitivity to perturbations.\nAfter formulating a model of ability, we introduce methods that infer ability\nwhile accounting for uncertainty from sensitivity and finite samples, including\nan adaptive algorithm that significantly reduces sample complexity. Together,\nthese contributions lay the groundwork for more reliable and trustworthy\nestimates of AI capabilities as measured through benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8d28\u7591\u4e86\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u7684\u53ef\u9760\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u529b\u7406\u8bba\u7684\u63a8\u8bba\u6846\u67b6\uff0c\u4ee5\u66f4\u53ef\u9760\u5730\u8bc4\u4f30AI\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u53ef\u9760\u6027\u5b58\u7591\uff0c\u96be\u4ee5\u771f\u5b9e\u53cd\u6620\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5c06\u8bc4\u4f30\u4f5c\u4e3a\u63a8\u7406\u7684\u6846\u67b6\uff0c\u4ece\u80fd\u529b\u7406\u8bba\u51fa\u53d1\uff0c\u63a8\u5bfc\u51fa\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u51cf\u5c11\u6837\u672c\u590d\u6742\u5ea6\u7684\u81ea\u9002\u5e94\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u53ef\u9760\u5730\u4f30\u8ba1AI\u80fd\u529b\uff0c\u5e76\u964d\u4f4e\u4e86\u5bf9\u6270\u52a8\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u66f4\u53ef\u9760\u3001\u66f4\u503c\u5f97\u4fe1\u8d56\u7684AI\u80fd\u529b\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.19623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19623", "abs": "https://arxiv.org/abs/2509.19623", "authors": ["Xutao Mao", "Tao Liu", "Hongying Zan"], "title": "SteinerSQL: Graph-Guided Mathematical Reasoning for Text-to-SQL Generation", "comment": "Accept in Non-archival EMNLP 2025 MathNLP", "summary": "Large Language Models (LLMs) struggle with complex Text-to-SQL queries that\ndemand both sophisticated mathematical reasoning and intricate schema\nnavigation. Existing methods often tackle these challenges in isolation,\ncreating a fractured reasoning process that compromises logical and structural\ncorrectness. To resolve this, we introduce SteinerSQL, a framework that unifies\nthese dual challenges into a single, graph-centric optimization problem.\nSteinerSQL operates in three stages: mathematical decomposition to identify\nrequired tables (terminals), optimal reasoning scaffold construction via a\nSteiner tree problem, and multi-level validation to ensure correctness. On the\nchallenging LogicCat and Spider2.0-Lite benchmarks, SteinerSQL establishes a\nnew state-of-the-art with 36.10% and 40.04% execution accuracy, respectively,\nusing Gemini-2.5-Pro. Beyond accuracy, SteinerSQL presents a new, unified\nparadigm for Text-to-SQL, paving the way for more robust and principled\nsolutions to complex reasoning tasks.", "AI": {"tldr": "SteinerSQL\u6846\u67b6\u901a\u8fc7\u5c06\u6570\u5b66\u63a8\u7406\u548c\u6a21\u5f0f\u5bfc\u822a\u7edf\u4e00\u5230\u4e00\u4e2a\u56fe\u4f18\u5316\u95ee\u9898\u4e2d\uff0c\u63d0\u9ad8\u4e86\u590d\u6742Text-to-SQL\u67e5\u8be2\u7684\u51c6\u786e\u6027\uff0c\u5728LogicCat\u548cSpider2.0-Lite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5206\u522b\u5904\u7406\u6570\u5b66\u63a8\u7406\u548c\u6a21\u5f0f\u5bfc\u822a\uff0c\u5bfc\u81f4Text-to-SQL\u67e5\u8be2\u7684\u903b\u8f91\u548c\u7ed3\u6784\u9519\u8bef\u3002", "method": "SteinerSQL\u5206\u4e09\u4e2a\u9636\u6bb5\uff1a\u6570\u5b66\u5206\u89e3\u3001\u901a\u8fc7Steiner\u6811\u95ee\u9898\u6784\u5efa\u6700\u4f18\u63a8\u7406\u652f\u67b6\u548c\u591a\u7ea7\u9a8c\u8bc1\u3002", "result": "\u5728LogicCat\u548cSpider2.0-Lite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSteinerSQL\u5206\u522b\u8fbe\u5230\u4e8636.10%\u548c40.04%\u7684\u6267\u884c\u51c6\u786e\u7387\u3002", "conclusion": "SteinerSQL\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u7edf\u4e00\u7684Text-to-SQL\u8303\u5f0f\uff0c\u4e3a\u66f4\u5065\u58ee\u548c\u6709\u539f\u5219\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u89e3\u51b3\u65b9\u6848\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2509.19681", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19681", "abs": "https://arxiv.org/abs/2509.19681", "authors": ["Anisha Garg", "Engin Tekin", "Yash More", "David Bick", "Nishit Neema", "Ganesh Venkatesh"], "title": "Calibrated Reasoning: An Explanatory Verifier for Dynamic and Efficient Problem-Solving", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Workshop: Efficient Reasoning", "summary": "Advanced test-time computing strategies are essential for scaling reasoning\nmodels, but their effectiveness is capped by the models' poor self-evaluation.\nWe propose a pairwise Explanatory Verifier, trained via reinforcement learning\n(GRPO), that produces calibrated confidence scores and associated natural\nlanguage reasoning for generated solutions. Our verifier improves the accuracy\nand efficiency of test-time strategies like best-of-n and self-reflection.\nCrucially, it excels at identifying challenging failure modes, such as when\nboth candidate solutions are identically incorrect, succeeding where standard\nmethods like majority voting fail.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6210\u5bf9\u89e3\u91ca\u9a8c\u8bc1\u5668\uff0c\u7528\u4e8e\u6539\u8fdb\u63a8\u7406\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u7b56\u7565\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u7684\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\u5dee\uff0c\u9650\u5236\u4e86\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60 (GRPO) \u7684\u6210\u5bf9\u89e3\u91ca\u9a8c\u8bc1\u5668\uff0c\u751f\u6210\u6821\u51c6\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u3002", "result": "\u8be5\u9a8c\u8bc1\u5668\u63d0\u9ad8\u4e86\u6700\u4f73n\u548c\u81ea\u7701\u7b49\u6d4b\u8bd5\u65f6\u7b56\u7565\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u5c24\u5176\u64c5\u957f\u8bc6\u522b\u6807\u51c6\u65b9\u6cd5\uff08\u5982\u591a\u6570\u6295\u7968\uff09\u96be\u4ee5\u89e3\u51b3\u7684\u6311\u6218\u6027\u5931\u6548\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u6210\u5bf9\u89e3\u91ca\u9a8c\u8bc1\u5668\u6709\u6548\u63d0\u5347\u4e86\u63a8\u7406\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u7b56\u7565\uff0c\u4e3a\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2509.19736", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19736", "abs": "https://arxiv.org/abs/2509.19736", "authors": ["Cheng Qian", "Zuxin Liu", "Akshara Prabhakar", "Jielin Qiu", "Zhiwei Liu", "Haolin Chen", "Shirley Kokane", "Heng Ji", "Weiran Yao", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong", "Huan Wang"], "title": "UserRL: Training Interactive User-Centric Agent via Reinforcement Learning", "comment": "28 Pages, 15 Figures, 6 Tables; Built upon latest UserBench release:\n  arXiv:2507.22034", "summary": "Reinforcement learning (RL) has shown promise in training agentic models that\nmove beyond static benchmarks to engage in dynamic, multi-turn interactions.\nYet, the ultimate value of such agents lies in their ability to assist users, a\nsetting where diversity and dynamics of user interaction pose challenges. In\nthis work, we propose UserRL, a unified framework for training and evaluating\nuser-centric abilities through standardized gym environments paired with\nsimulated users. We systematically vary turn-level reward assignment and\ntrajectory-level score calculation to analyze how different formulations affect\nlearning under the GRPO algorithm. Our experiments across Qwen3 models reveal\nthree key findings: (i) SFT cold start is critical for unlocking initial\ninteraction ability and enabling sustained RL improvements; (ii) deliberate\ntrajectory scoring yields more efficient and effective multi-turn interactions;\nand (iii) while stronger simulated users (e.g., GPT-4o) facilitates training,\nopen-source simulators (e.g., Qwen3-32B) remain a cost-effective and\ntransferable option. Together, these results highlight that careful design of\nreward shaping and user simulation choice is as crucial as model scale, and\nestablish UserRL as a practical pathway for developing robust user-centric\nagentic models. All codes and data are public for future research.", "AI": {"tldr": "UserRL\u6846\u67b6\u901a\u8fc7\u6807\u51c6\u5316gym\u73af\u5883\u548c\u6a21\u62df\u7528\u6237\uff0c\u8bad\u7ec3\u548c\u8bc4\u4f30\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u667a\u80fd\u4f53\u80fd\u529b\uff0c\u7814\u7a76\u53d1\u73b0SFT\u51b7\u542f\u52a8\u3001\u5468\u5168\u7684\u8f68\u8ff9\u8bc4\u5206\u548c\u5f00\u6e90\u6a21\u62df\u5668\u5bf9\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u4e0e\u7528\u6237\u7684\u52a8\u6001\u591a\u8f6e\u4ea4\u4e92\u4e2d\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u66f4\u597d\u5730\u8f85\u52a9\u7528\u6237\u3002", "method": "\u63d0\u51faUserRL\u6846\u67b6\uff0c\u7ed3\u5408\u6807\u51c6\u5316gym\u73af\u5883\u548c\u6a21\u62df\u7528\u6237\uff0c\u7cfb\u7edf\u6027\u5730\u6539\u53d8\u56de\u5408\u5956\u52b1\u5206\u914d\u548c\u8f68\u8ff9\u8bc4\u5206\u8ba1\u7b97\uff0c\u5e76\u4f7f\u7528GRPO\u7b97\u6cd5\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0SFT\u51b7\u542f\u52a8\u3001\u5468\u5168\u7684\u8f68\u8ff9\u8bc4\u5206\u548c\u9009\u62e9\u5408\u9002\u7684\u6a21\u62df\u7528\u6237\uff08\u5373\u4f7f\u662f\u5f00\u6e90\u7684\uff09\u5bf9\u8bad\u7ec3\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u5956\u52b1\u5851\u9020\u548c\u7528\u6237\u6a21\u62df\u9009\u62e9\u7684\u8bbe\u8ba1\u4e0e\u6a21\u578b\u89c4\u6a21\u540c\u7b49\u91cd\u8981\uff0cUserRL\u4e3a\u5f00\u53d1\u5f3a\u5927\u7684\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u667a\u80fd\u4f53\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2509.19762", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19762", "abs": "https://arxiv.org/abs/2509.19762", "authors": ["Yuanxin Wang", "Pawel Filipczuk", "Anisha Garg", "Amaan Dhada", "Mohammad Hassanpour", "David Bick", "Ganesh Venkatesh"], "title": "The Conductor and the Engine: A Path Towards Co-Designed Reasoning", "comment": null, "summary": "Modern LLM reasoning relies on extensive test-time computation, driven by\ninternal model training and external agentic orchestration. However, this\nsynergy is often inefficient, as model verbosity and poor instruction following\nlead to wasted compute. We analyze this capability-cost trade-off and introduce\nan optimized reasoning workflow (\\cepo) that empowers smaller open-source\nmodels to outperform models multiple times their size. We will open-source this\nworkflow to enable further research. Our work demonstrates a clear path toward\nco-designing orchestration frameworks with the underlying model capabilities to\nunlock powerful reasoning in small-to-medium sized models.", "AI": {"tldr": "\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u901a\u8fc7\u4f18\u5316\u7684\u63a8\u7406\u6d41\u7a0b\uff08CEPO\uff09\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u5927\u578b\u6a21\u578b\uff0c\u8be5\u6d41\u7a0b\u51cf\u5c11\u4e86\u5197\u4f59\u8ba1\u7b97\uff0c\u63d0\u9ad8\u4e86\u6307\u4ee4\u9075\u5faa\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4f9d\u8d56\u5927\u91cf\u6d4b\u8bd5\u65f6\u8ba1\u7b97\uff0c\u4f46\u6a21\u578b\u5197\u4f59\u548c\u6307\u4ee4\u9075\u5faa\u4e0d\u4f73\u5bfc\u81f4\u8ba1\u7b97\u6d6a\u8d39\uff0c\u672c\u6587\u65e8\u5728\u4f18\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u7684\u63a8\u7406\u6d41\u7a0b\uff08CEPO\uff09\uff0c\u4f7f\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u80fd\u591f\u8d85\u8d8a\u66f4\u5927\u6a21\u578b\u3002", "result": "\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u5728\u63a8\u7406\u6027\u80fd\u4e0a\u8d85\u8fc7\u66f4\u5927\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u6a21\u578b\u80fd\u529b\u4e0e\u534f\u8c03\u6846\u67b6\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u5c0f\u578b\u5230\u4e2d\u7b49\u89c4\u6a21\u7684\u6a21\u578b\u4e5f\u80fd\u5b9e\u73b0\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2509.19783", "categories": ["cs.AI", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.19783", "abs": "https://arxiv.org/abs/2509.19783", "authors": ["Jiexi Xu"], "title": "Agentic Metacognition: Designing a \"Self-Aware\" Low-Code Agent for Failure Prediction and Human Handoff", "comment": "7 pages, 2 tables", "summary": "The inherent non-deterministic nature of autonomous agents, particularly\nwithin low-code/no-code (LCNC) environments, presents significant reliability\nchallenges. Agents can become trapped in unforeseen loops, generate inaccurate\noutputs, or encounter unrecoverable failures, leading to user frustration and a\nbreakdown of trust. This report proposes a novel architectural pattern to\naddress these issues: the integration of a secondary, \"metacognitive\" layer\nthat actively monitors the primary LCNC agent. Inspired by human introspection,\nthis layer is designed to predict impending task failures based on a defined\nset of triggers, such as excessive latency or repetitive actions. Upon\npredicting a failure, the metacognitive agent proactively initiates a human\nhandoff, providing the user with a clear summary of the agent's \"thought\nprocess\" and a detailed explanation of why it could not proceed. An empirical\nanalysis of a prototype system demonstrates that this approach significantly\nincreases the overall task success rate. However, this performance gain comes\nwith a notable increase in computational overhead. The findings reframe human\nhandoffs not as an admission of defeat but as a core design feature that\nenhances system resilience, improves user experience, and builds trust by\nproviding transparency into the agent's internal state. The report discusses\nthe practical and ethical implications of this approach and identifies key\ndirections for future research.", "AI": {"tldr": "\u4f4e\u4ee3\u7801/\u65e0\u4ee3\u7801\u73af\u5883\u4e0b\u7684\u81ea\u4e3b\u4ee3\u7406\u7684\u975e\u786e\u5b9a\u6027\u672c\u8d28\u4f1a\u5bfc\u81f4\u53ef\u9760\u6027\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5143\u8ba4\u77e5\u5c42\u67b6\u6784\u6765\u9884\u6d4b\u5e76\u5904\u7406\u4ee3\u7406\u7684\u5931\u8d25\uff0c\u901a\u8fc7\u4e3b\u52a8\u5c06\u4efb\u52a1\u79fb\u4ea4\u7ed9\u4eba\u7c7b\u6765\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\uff0c\u4f46\u8fd9\u4f1a\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u89e3\u51b3\u4f4e\u4ee3\u7801/\u65e0\u4ee3\u7801\u73af\u5883\u4e0b\u81ea\u4e3b\u4ee3\u7406\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u7528\u6237\u4fe1\u4efb\u5ea6\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5305\u542b\u5143\u8ba4\u77e5\u5c42\u7684\u67b6\u6784\uff0c\u8be5\u5c42\u76d1\u63a7\u4e3b\u4ee3\u7406\uff0c\u9884\u6d4b\u6f5c\u5728\u7684\u5931\u8d25\u5e76\u8fdb\u884c\u4eba\u5de5\u5e72\u9884\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\uff0c\u4f46\u589e\u52a0\u4e86\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u5c06\u4eba\u5de5\u5e72\u9884\u4f5c\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u7684\u4e00\u4e2a\u6838\u5fc3\u7279\u6027\uff0c\u63d0\u9ad8\u7cfb\u7edf\u5f39\u6027\uff0c\u6539\u5584\u7528\u6237\u4f53\u9a8c\uff0c\u5e76\u901a\u8fc7\u900f\u660e\u5316\u4ee3\u7406\u7684\u5185\u90e8\u72b6\u6001\u6765\u5efa\u7acb\u4fe1\u4efb\u3002"}}
{"id": "2509.19800", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19800", "abs": "https://arxiv.org/abs/2509.19800", "authors": ["Donghwan Lee", "Hyukjun Yang", "Bum Geun Park"], "title": "Analysis of approximate linear programming solution to Markov decision problem with log barrier function", "comment": null, "summary": "There are two primary approaches to solving Markov decision problems (MDPs):\ndynamic programming based on the Bellman equation and linear programming (LP).\nDynamic programming methods are the most widely used and form the foundation of\nboth classical and modern reinforcement learning (RL). By contrast, LP-based\nmethods have been less commonly employed, although they have recently gained\nattention in contexts such as offline RL. The relative underuse of the LP-based\nmethods stems from the fact that it leads to an inequality-constrained\noptimization problem, which is generally more challenging to solve effectively\ncompared with Bellman-equation-based methods. The purpose of this paper is to\nestablish a theoretical foundation for solving LP-based MDPs in a more\neffective and practical manner. Our key idea is to leverage the log-barrier\nfunction, widely used in inequality-constrained optimization, to transform the\nLP formulation of the MDP into an unconstrained optimization problem. This\nreformulation enables approximate solutions to be obtained easily via gradient\ndescent. While the method may appear simple, to the best of our knowledge, a\nthorough theoretical interpretation of this approach has not yet been\ndeveloped. This paper aims to bridge this gap.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6570\u969c\u788d\u51fd\u6570\u7684\u6c42\u89e3\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7ebf\u6027\u89c4\u5212\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u4e0d\u7b49\u5f0f\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u4fbf\u4e8e\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\u6c42\u89e3\u3002", "motivation": "\u73b0\u6709\u6c42\u89e3\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u65b9\u6cd5\u4e3b\u8981\u6709\u57fa\u4e8e\u8d1d\u5c14\u66fc\u65b9\u7a0b\u7684\u52a8\u6001\u89c4\u5212\u548c\u7ebf\u6027\u89c4\u5212\u4e24\u79cd\uff0c\u7ebf\u6027\u89c4\u5212\u65b9\u6cd5\u56e0\u6c42\u89e3\u56f0\u96be\u800c\u8f83\u5c11\u4f7f\u7528\uff0c\u672c\u6587\u65e8\u5728\u6539\u8fdb\u7ebf\u6027\u89c4\u5212\u65b9\u6cd5\u7684\u6c42\u89e3\u6548\u7387\u3002", "method": "\u5229\u7528\u5bf9\u6570\u969c\u788d\u51fd\u6570\u5c06\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u7ebf\u6027\u89c4\u5212\u516c\u5f0f\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u7136\u540e\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\u6c42\u89e3\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5bf9\u6570\u969c\u788d\u51fd\u6570\u7684\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\u65b9\u6cd5\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u3002", "conclusion": "\u672c\u6587\u4e3a\u9ad8\u6548\u6c42\u89e3\u57fa\u4e8e\u7ebf\u6027\u89c4\u5212\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u8be5\u65b9\u6cd5\u7b80\u5355\u6709\u6548\uff0c\u4e14\u5177\u6709\u8f83\u597d\u7684\u7406\u8bba\u89e3\u91ca\u3002"}}
{"id": "2509.19839", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19839", "abs": "https://arxiv.org/abs/2509.19839", "authors": ["Huizhen Shu", "Xuying Li", "Zhuo Li"], "title": "LatentGuard: Controllable Latent Steering for Robust Refusal of Attacks and Reliable Response Generation", "comment": "9-page NeurIPS 2025 preprint including 3 figures and 1 table, with\n  additional appendix material. Prepared using the NeurIPS 2025 preprint\n  template and compiled with pdfLaTeX. All references are included via the\n  provided .bbl file. Figures are in PDF format. No external supplementary\n  files. All necessary style files and images are included", "summary": "Achieving robust safety alignment in large language models (LLMs) while\npreserving their utility remains a fundamental challenge. Existing approaches\noften struggle to balance comprehensive safety with fine-grained\ncontrollability at the representation level. We introduce LATENTGUARD, a novel\nthree-stage framework that combines behavioral alignment with supervised latent\nspace control for interpretable and precise safety steering. Our approach\nbegins by fine-tuning an LLM on rationalized datasets containing both\nreasoning-enhanced refusal responses to adversarial prompts and\nreasoning-enhanced normal responses to benign queries, establishing robust\nbehavioral priors across both safety-critical and utility-preserving scenarios.\nWe then train a structured variational autoencoder (VAE) on intermediate MLP\nactivations, supervised by multi-label annotations including attack types,\nattack methods, and benign indicators. This supervision enables the VAE to\nlearn disentangled latent representations that capture distinct adversarial\ncharacteristics while maintaining semantic interpretability. Through targeted\nmanipulation of learned latent dimensions, LATENTGUARD achieves selective\nrefusal behavior, effectively blocking harmful requests while preserving\nhelpfulness for legitimate use cases. Experiments on Qwen3-8B demonstrate\nsignificant improvements in both safety controllability and response\ninterpretability without compromising utility. Cross-architecture validation on\nMistral-7B confirms the generalizability of our latent steering approach,\nshowing consistent effectiveness across different model families. Our results\nsuggest that structured representation-level intervention offers a promising\npathway toward building safer yet practical LLM systems.", "AI": {"tldr": "LATENTGUARD\u6846\u67b6\u7ed3\u5408\u884c\u4e3a\u5bf9\u9f50\u548c\u76d1\u7763\u6f5c\u5728\u7a7a\u95f4\u63a7\u5236\uff0c\u5b9e\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u53ef\u63a7\u6027\u548c\u5b9e\u7528\u6027\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\uff0c\u5c24\u5176\u662f\u5728\u8868\u793a\u5c42\u9762\u7684\u7cbe\u7ec6\u63a7\u5236\u3002", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1. \u57fa\u4e8e\u7406\u6027\u5316\u6570\u636e\u96c6\u5fae\u8c03LLM\uff1b2. \u8bad\u7ec3\u7ed3\u6784\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668(VAE)\u5b66\u4e60\u89e3\u7ea0\u7f20\u7684\u6f5c\u5728\u8868\u793a\uff1b3. \u901a\u8fc7\u64cd\u63a7\u6f5c\u5728\u7ef4\u5ea6\u5b9e\u73b0\u9009\u62e9\u6027\u62d2\u7edd\u884c\u4e3a\u3002", "result": "\u5728Qwen3-8B\u548cMistral-7B\u6a21\u578b\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cLATENTGUARD\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u53ef\u63a7\u6027\u548c\u54cd\u5e94\u53ef\u89e3\u91ca\u6027\uff0c\u4e14\u672a\u5f71\u54cd\u5b9e\u7528\u6027\u3002", "conclusion": "\u7ed3\u6784\u5316\u8868\u793a\u5c42\u5e72\u9884\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u5b9e\u7528\u7684LLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2509.19925", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19925", "abs": "https://arxiv.org/abs/2509.19925", "authors": ["Ajeet Kumar Singh", "Rajsabi Surya", "Anurag Tripathi", "Santanu Choudhury", "Sudhir Bisane"], "title": "CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain", "comment": null, "summary": "As enterprises increasingly integrate cloud-based large language models\n(LLMs) such as ChatGPT and Gemini into their legal document workflows,\nprotecting sensitive contractual information - including Personally\nIdentifiable Information (PII) and commercially sensitive clauses - has emerged\nas a critical challenge. In this work, we propose CON-QA, a hybrid\nprivacy-preserving framework designed specifically for secure question\nanswering over enterprise contracts, effectively combining local and\ncloud-hosted LLMs. The CON-QA framework operates through three stages: (i)\nsemantic query decomposition and query-aware document chunk retrieval using a\nlocally deployed LLM analysis, (ii) anonymization of detected sensitive\nentities via a structured one-to-many mapping scheme, ensuring semantic\ncoherence while preventing cross-session entity inference attacks, and (iii)\nanonymized response generation by a cloud-based LLM, with accurate\nreconstruction of the original answer locally using a session-consistent\nmany-to-one reverse mapping. To rigorously evaluate CON-QA, we introduce\nCUAD-QA, a corpus of 85k question-answer pairs generated over 510 real-world\nCUAD contract documents, encompassing simple, complex, and summarization-style\nqueries. Empirical evaluations, complemented by detailed human assessments,\nconfirm that CON-QA effectively maintains both privacy and utility, preserves\nanswer quality, maintains fidelity to legal clause semantics, and significantly\nmitigates privacy risks, demonstrating its practical suitability for secure,\nenterprise-level contract documents.", "AI": {"tldr": "CON-QA\u6846\u67b6\u7ed3\u5408\u672c\u5730\u548c\u4e91\u7aefLLM\uff0c\u5b89\u5168\u5730\u5bf9\u4f01\u4e1a\u5408\u540c\u8fdb\u884c\u95ee\u7b54\uff0c\u5728\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u7684\u540c\u65f6\u4fdd\u8bc1\u7b54\u6848\u8d28\u91cf\u3002", "motivation": "\u4f01\u4e1a\u5c06LLM\u5e94\u7528\u4e8e\u6cd5\u5f8b\u6587\u6863\u5904\u7406\u65f6\uff0c\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\uff08\u5982PII\uff09\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002", "method": "CON-QA\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a\u8bed\u4e49\u67e5\u8be2\u5206\u89e3\u548c\u67e5\u8be2\u611f\u77e5\u6587\u6863\u5757\u68c0\u7d22\uff08\u672c\u5730LLM\uff09\uff1b\u654f\u611f\u5b9e\u4f53\u533f\u540d\u5316\uff08\u7ed3\u6784\u5316\u4e00\u5bf9\u591a\u6620\u5c04\uff09\uff1b\u533f\u540d\u5316\u54cd\u5e94\u751f\u6210\u548c\u672c\u5730\u7b54\u6848\u91cd\u5efa\uff08\u4e91\u7aefLLM\u548c\u672c\u5730\u53cd\u5411\u6620\u5c04\uff09\u3002", "result": "\u5728CUAD-QA\u6570\u636e\u96c6\uff088.5\u4e07\u4e2a\u95ee\u7b54\u5bf9\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660eCON-QA\u6709\u6548\u5730\u4fdd\u62a4\u4e86\u9690\u79c1\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7b54\u6848\u8d28\u91cf\u548c\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u9690\u79c1\u98ce\u9669\u3002", "conclusion": "CON-QA\u6846\u67b6\u9002\u7528\u4e8e\u4f01\u4e1a\u7ea7\u5408\u540c\u6587\u6863\u7684\u5b89\u5168\u95ee\u7b54\uff0c\u517c\u987e\u9690\u79c1\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.20021", "categories": ["cs.AI", "cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.20021", "abs": "https://arxiv.org/abs/2509.20021", "authors": ["Tongtong Feng", "Xin Wang", "Yu-Gang Jiang", "Wenwu Zhu"], "title": "Embodied AI: From LLMs to World Models", "comment": "Accepted by IEEE CASM", "summary": "Embodied Artificial Intelligence (AI) is an intelligent system paradigm for\nachieving Artificial General Intelligence (AGI), serving as the cornerstone for\nvarious applications and driving the evolution from cyberspace to physical\nsystems. Recent breakthroughs in Large Language Models (LLMs) and World Models\n(WMs) have drawn significant attention for embodied AI. On the one hand, LLMs\nempower embodied AI via semantic reasoning and task decomposition, bringing\nhigh-level natural language instructions and low-level natural language actions\ninto embodied cognition. On the other hand, WMs empower embodied AI by building\ninternal representations and future predictions of the external world,\nfacilitating physical law-compliant embodied interactions. As such, this paper\ncomprehensively explores the literature in embodied AI from basics to advances,\ncovering both LLM driven and WM driven works. In particular, we first present\nthe history, key technologies, key components, and hardware systems of embodied\nAI, as well as discuss its development via looking from unimodal to multimodal\nangle. We then scrutinize the two burgeoning fields of embodied AI, i.e.,\nembodied AI with LLMs/multimodal LLMs (MLLMs) and embodied AI with WMs,\nmeticulously delineating their indispensable roles in end-to-end embodied\ncognition and physical laws-driven embodied interactions. Building upon the\nabove advances, we further share our insights on the necessity of the joint\nMLLM-WM driven embodied AI architecture, shedding light on its profound\nsignificance in enabling complex tasks within physical worlds. In addition, we\nexamine representative applications of embodied AI, demonstrating its wide\napplicability in real-world scenarios. Last but not least, we point out future\nresearch directions of embodied AI that deserve further investigation.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5177\u8eabAI\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u7279\u522b\u662f\u7ed3\u5408LLM\u548cWM\u7684\u5e94\u7528\u3002", "motivation": "\u5177\u8eabAI\u662f\u5b9e\u73b0AGI\u7684\u5173\u952e\uff0cLLM\u548cWM\u7684\u7a81\u7834\u4e3a\u5176\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u52a8\u529b\u3002", "method": "\u5bf9\u73b0\u6709\u6587\u732e\u8fdb\u884c\u7efc\u8ff0\uff0c\u5206\u6790LLM\u548cWM\u5728\u5177\u8eabAI\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u5c55\u671b\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "\u5bf9LLM\u9a71\u52a8\u548cWM\u9a71\u52a8\u7684\u5177\u8eabAI\u8fdb\u884c\u4e86\u6df1\u5165\u63a2\u8ba8\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408MLLM\u548cWM\u7684\u67b6\u6784\uff0c\u5e76\u5217\u4e3e\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6848\u4f8b\u3002", "conclusion": "\u5177\u8eabAI\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\uff0c\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8MLLM-WM\u878d\u5408\u67b6\u6784\u4ee5\u53ca\u66f4\u590d\u6742\u7684\u7269\u7406\u4e16\u754c\u4ea4\u4e92\u3002"}}
