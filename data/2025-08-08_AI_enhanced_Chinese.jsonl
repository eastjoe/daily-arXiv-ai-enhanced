{"id": "2508.04714", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.04714", "abs": "https://arxiv.org/abs/2508.04714", "authors": ["Chitranshu Harbola", "Anupam Purwar"], "title": "Prescriptive Agents based on Rag for Automated Maintenance (PARAM)", "comment": null, "summary": "Industrial machinery maintenance requires timely intervention to prevent\ncatastrophic failures and optimize operational efficiency. This paper presents\nan integrated Large Language Model (LLM)-based intelligent system for\nprescriptive maintenance that extends beyond traditional anomaly detection to\nprovide actionable maintenance recommendations. Building upon our prior LAMP\nframework for numerical data analysis, we develop a comprehensive solution that\ncombines bearing vibration frequency analysis with multi agentic generation for\nintelligent maintenance planning. Our approach serializes bearing vibration\ndata (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM\nprocessing, enabling few-shot anomaly detection with high accuracy. The system\nclassifies fault types (inner race, outer race, ball/roller, cage faults) and\nassesses severity levels. A multi-agentic component processes maintenance\nmanuals using vector embeddings and semantic search, while also conducting web\nsearches to retrieve comprehensive procedural knowledge and access up-to-date\nmaintenance practices for more accurate and in-depth recommendations. The\nGemini model then generates structured maintenance recommendations includes\nimmediate actions, inspection checklists, corrective measures, parts\nrequirements, and timeline specifications. Experimental validation in bearing\nvibration datasets demonstrates effective anomaly detection and contextually\nrelevant maintenance guidance. The system successfully bridges the gap between\ncondition monitoring and actionable maintenance planning, providing industrial\npractitioners with intelligent decision support. This work advances the\napplication of LLMs in industrial maintenance, offering a scalable framework\nfor prescriptive maintenance across machinery components and industrial\nsectors.", "AI": {"tldr": "LLM\u8d4b\u80fd\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u7cfb\u7edf\uff0c\u7ed3\u5408\u632f\u52a8\u5206\u6790\u548c\u591a\u667a\u80fd\u4f53\u4fe1\u606f\u68c0\u7d22\uff0c\u5b9e\u73b0\u7cbe\u51c6\u7684\u6545\u969c\u8bca\u65ad\u548c\u7ef4\u62a4\u5efa\u8bae\u751f\u6210\u3002", "motivation": "\u53ca\u65f6\u7ef4\u62a4\u5de5\u4e1a\u673a\u68b0\u4ee5\u9632\u6b62\u707e\u96be\u6027\u6545\u969c\u5e76\u4f18\u5316\u8fd0\u8425\u6548\u7387\u3002", "method": "\u8be5\u7cfb\u7edf\u5c06\u8f74\u627f\u632f\u52a8\u6570\u636e\u5e8f\u5217\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\uff0c\u5229\u7528LLM\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u548c\u6545\u969c\u5206\u7c7b\uff0c\u5e76\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u7ec4\u4ef6\u5904\u7406\u7ef4\u62a4\u624b\u518c\u548c\u7f51\u7edc\u641c\u7d22\u7ed3\u679c\uff0c\u6700\u7ec8\u751f\u6210\u7ed3\u6784\u5316\u7684\u7ef4\u62a4\u5efa\u8bae\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5f02\u5e38\u5e76\u63d0\u4f9b\u76f8\u5173\u7684\u7ef4\u62a4\u6307\u5bfc\uff0c\u5728\u8f74\u627f\u632f\u52a8\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u667a\u80fd\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u7ed3\u5408\u8f74\u627f\u632f\u52a8\u9891\u7387\u5206\u6790\u548c\u591a\u667a\u80fd\u4f53\u751f\u6210\uff0c\u80fd\u591f\u5bf9\u5de5\u4e1a\u673a\u68b0\u6545\u969c\u8fdb\u884c\u51c6\u786e\u68c0\u6d4b\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u7ef4\u62a4\u5efa\u8bae\uff0c\u5f25\u5408\u4e86\u72b6\u6001\u76d1\u6d4b\u548c\u53ef\u64cd\u4f5c\u7ef4\u62a4\u89c4\u5212\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2508.04719", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04719", "abs": "https://arxiv.org/abs/2508.04719", "authors": ["Amulya Bhattaram", "Justin Chung", "Stanley Chung", "Ranit Gupta", "Janani Ramamoorthy", "Kartikeya Gullapalli", "Diana Marculescu", "Dimitrios Stamoulis"], "title": "GeoFlow: Agentic Workflow Automation for Geospatial Tasks", "comment": "Accepted to ACM SIGSPATIAL 2025", "summary": "We present GeoFlow, a method that automatically generates agentic workflows\nfor geospatial tasks. Unlike prior work that focuses on reasoning decomposition\nand leaves API selection implicit, our method provides each agent with detailed\ntool-calling objectives to guide geospatial API invocation at runtime. GeoFlow\nincreases agentic success by 6.8% and reduces token usage by up to fourfold\nacross major LLM families compared to state-of-the-art approaches.", "AI": {"tldr": "GeoFlow \u81ea\u52a8\u751f\u6210\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\uff0c\u63d0\u9ad8\u6548\u7387\u5e76\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u63a8\u7406\u5206\u89e3\uff0c\u800c\u5ffd\u7565\u4e86 API \u9009\u62e9\uff0cGeoFlow \u901a\u8fc7\u63d0\u4f9b\u8be6\u7ec6\u7684\u5de5\u5177\u8c03\u7528\u76ee\u6807\u6765\u6539\u8fdb\u3002", "method": "GeoFlow \u65b9\u6cd5\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u4ee3\u7406\u63d0\u4f9b\u8be6\u7ec6\u7684\u5de5\u5177\u8c03\u7528\u76ee\u6807\u6765\u6307\u5bfc\u5730\u7406\u7a7a\u95f4 API \u7684\u8fd0\u884c\u65f6\u8c03\u7528\u3002", "result": "GeoFlow \u5c06\u4ee3\u7406\u6210\u529f\u7387\u63d0\u9ad8\u4e86 6.8%\uff0c\u5e76\u5c06\u4e3b\u8981 LLM \u7cfb\u5217\u7684\u4ee4\u724c\u4f7f\u7528\u91cf\u51cf\u5c11\u4e86\u591a\u8fbe\u56db\u500d\u3002", "conclusion": "GeoFlow \u662f\u4e00\u79cd\u81ea\u52a8\u751f\u6210\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u7684\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u4ee3\u7406\u63d0\u4f9b\u8be6\u7ec6\u7684\u5de5\u5177\u8c03\u7528\u76ee\u6807\u6765\u6307\u5bfc\u5730\u7406\u7a7a\u95f4 API \u7684\u8fd0\u884c\u65f6\u8c03\u7528\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u4ee3\u7406\u7684\u6210\u529f\u7387\u5e76\u51cf\u5c11\u4e86\u4ee4\u724c\u7684\u4f7f\u7528\u3002"}}
{"id": "2508.04720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04720", "abs": "https://arxiv.org/abs/2508.04720", "authors": ["Yingjie Zhou", "Jiezhang Cao", "Farong Wen", "Li Xu", "Yanwei Jiang", "Jun Jia", "Ronghui Li", "Xiaohong Liu", "Yu Zhou", "Xiongkuo Min", "Jie Guo", "Zicheng Zhang", "Guangtao Zhai"], "title": "Who is a Better Player: LLM against LLM", "comment": null, "summary": "Adversarial board games, as a paradigmatic domain of strategic reasoning and\nintelligence, have long served as both a popular competitive activity and a\nbenchmark for evaluating artificial intelligence (AI) systems. Building on this\nfoundation, we propose an adversarial benchmarking framework to assess the\ncomprehensive performance of Large Language Models (LLMs) through board games\ncompetition, compensating the limitation of data dependency of the mainstream\nQuestion-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a\nspecialized evaluation platform that supports 5 widely played games and\ninvolves 20 LLM-driven players. The platform employs both the Elo rating system\nand a novel Performance Loop Graph (PLG) to quantitatively evaluate the\ntechnical capabilities of LLMs, while also capturing Positive Sentiment Score\n(PSS) throughout gameplay to assess mental fitness. The evaluation is\nstructured as a round-robin tournament, enabling systematic comparison across\nplayers. Experimental results indicate that, despite technical differences,\nmost LLMs remain optimistic about winning and losing, demonstrating greater\nadaptability to high-stress adversarial environments than humans. On the other\nhand, the complex relationship between cyclic wins and losses in PLGs exposes\nthe instability of LLMs' skill play during games, warranting further\nexplanation and exploration.", "AI": {"tldr": "\u4f7f\u7528\u5bf9\u6297\u6027\u68cb\u76d8\u6e38\u620f\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0LLM\u9002\u5e94\u6027\u5f3a\u4f46\u6280\u80fd\u4e0d\u7a33\u5b9a\u3002", "motivation": "\u73b0\u6709\u95ee\u7b54\u5f0f\u57fa\u51c6\u65b9\u6cd5\u5b58\u5728\u6570\u636e\u4f9d\u8d56\u6027\u9650\u5236\uff0c\u96be\u4ee5\u5168\u9762\u8bc4\u4f30LLM\u7684\u6027\u80fd\u3002\u5bf9\u6297\u6027\u68cb\u76d8\u6e38\u620f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8bc4\u4f30\u7b56\u7565\u63a8\u7406\u548c\u667a\u80fd\u7684\u7406\u60f3\u73af\u5883\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3a\u201cQi Town\u201d\u7684\u8bc4\u4f30\u5e73\u53f0\uff0c\u652f\u6301\u4e94\u79cd\u68cb\u76d8\u6e38\u620f\uff0c\u5e76\u91c7\u7528Elo\u8bc4\u7ea7\u7cfb\u7edf\u548c\u6027\u80fd\u5faa\u73af\u56fe\uff08PLG\uff09\u5bf9LLM\u8fdb\u884c\u91cf\u5316\u8bc4\u4f30\uff0c\u540c\u65f6\u6355\u6349\u6e38\u620f\u8fc7\u7a0b\u4e2d\u7684\u79ef\u6781\u60c5\u7eea\u8bc4\u5206\uff08PSS\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5927\u591a\u6570LLM\u5728\u8f93\u8d62\u65b9\u9762\u90fd\u4fdd\u6301\u4e50\u89c2\uff0c\u9002\u5e94\u9ad8\u538b\u529b\u5bf9\u6297\u73af\u5883\u7684\u80fd\u529b\u5f3a\u4e8e\u4eba\u7c7b\u3002\u4f46PLG\u63ed\u793a\u4e86LLM\u6280\u80fd\u7684\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6297\u6027\u68cb\u76d8\u6e38\u620f\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5f25\u8865\u4e86\u4e3b\u6d41\u95ee\u7b54\u5f0f\u57fa\u51c6\u65b9\u6cd5\u7684\u6570\u636e\u4f9d\u8d56\u6027\u9650\u5236\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLM\u5728\u9ad8\u538b\u529b\u5bf9\u6297\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u6bd4\u4eba\u7c7b\u66f4\u5f3a\u7684\u9002\u5e94\u6027\uff0c\u4f46\u4e5f\u66b4\u9732\u51fa\u5176\u6280\u80fd\u7684\u4e0d\u7a33\u5b9a\u6027\u3002"}}
{"id": "2508.04846", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04846", "abs": "https://arxiv.org/abs/2508.04846", "authors": ["Mahdi Nazari Ashani", "Ali Asghar Alesheikh", "Saba Kazemi", "Kimya Kheirkhah", "Yasin Mohammadi", "Fatemeh Rezaie", "Amir Mahdi Manafi", "Hedieh Zarkesh"], "title": "Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)", "comment": null, "summary": "Autonomous web-based geographical information systems (AWebGIS) aim to\nperform geospatial operations from natural language input, providing intuitive,\nintelligent, and hands-free interaction. However, most current solutions rely\non cloud-based large language models (LLMs), which require continuous internet\naccess and raise users' privacy and scalability issues due to centralized\nserver processing. This study compares three approaches to enabling AWebGIS:\n(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)\na semi-automated offline method using classical machine learning classifiers\nsuch as support vector machine and random forest; and (3) a fully autonomous\noffline (client-side) method based on a fine-tuned small language model (SLM),\nspecifically T5-small model, executed in the client's web browser. The third\napproach, which leverages SLMs, achieved the highest accuracy among all\nmethods, with an exact matching accuracy of 0.93, Levenshtein similarity of\n0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L\nscores of 0.98. Crucially, this client-side computation strategy reduces the\nload on backend servers by offloading processing to the user's device,\neliminating the need for server-based inference. These results highlight the\nfeasibility of browser-executable models for AWebGIS solutions.", "AI": {"tldr": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5ba2\u6237\u7aef\u7684\u6267\u884c\u4e3a\u81ea\u4e3b\u5f0fWebGIS\u63d0\u4f9b\u4e86\u9ad8\u51c6\u786e\u7387\u3001\u9ad8\u6548\u7387\u548c\u9ad8\u9690\u79c1\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u4e91\u7684LLM\u7684\u81ea\u4e3b\u5f0fWebGIS\u65b9\u6848\u5b58\u5728\u9700\u8981\u6301\u7eed\u7f51\u7edc\u8bbf\u95ee\u3001\u9690\u79c1\u95ee\u9898\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u6bd4\u8f83\u4e86\u4e09\u79cd\u5b9e\u73b0\u81ea\u4e3b\u5f0fWebGIS\u7684\u65b9\u6cd5\uff1a(1) \u57fa\u4e8e\u4e91\u7684LLM\u7684\u5b8c\u5168\u81ea\u52a8\u5316\u5728\u7ebf\u65b9\u6cd5\uff1b(2) \u4f7f\u7528\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u7684\u534a\u81ea\u52a8\u5316\u79bb\u7ebf\u65b9\u6cd5\uff1b(3) \u57fa\u4e8e\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(SLM)\u7684\u5b8c\u5168\u81ea\u4e3b\u5f0f\u79bb\u7ebf\u5ba2\u6237\u7aef\u65b9\u6cd5\u3002", "result": "\u57fa\u4e8e\u5fae\u8c03\u7684T5-small\u6a21\u578b\u7684\u5ba2\u6237\u7aef\u65b9\u6cd5\u5728\u7cbe\u786e\u5339\u914d\u51c6\u786e\u7387\u3001Levenshtein\u76f8\u4f3c\u5ea6\u548cROUGE\u8bc4\u5206\u4e0a\u5747\u53d6\u5f97\u4e86\u6700\u4f73\u7ed3\u679c\uff08\u51c6\u786e\u73870.93\uff0cLevenshtein\u76f8\u4f3c\u5ea60.99\uff0cROUGE-1\u548cROUGE-L\u5f97\u5206\u4e3a0.98\uff09\u3002", "conclusion": "\u5ba2\u6237\u7aef\u6267\u884c\u7684\u5fae\u578b\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u5728\u81ea\u4e3b\u5f0fWeb\u5730\u7406\u4fe1\u606f\u7cfb\u7edf\u4e2d\u53d6\u5f97\u4e86\u6700\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u6d88\u9664\u4e86\u5bf9\u670d\u52a1\u5668\u7aef\u63a8\u7406\u7684\u9700\u6c42\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u9690\u79c1\u6027\u3002"}}
{"id": "2508.04848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04848", "abs": "https://arxiv.org/abs/2508.04848", "authors": ["Chang Tian", "Matthew B. Blaschko", "Mingzhe Xing", "Xiuxing Li", "Yinliang Yue", "Marie-Francine Moens"], "title": "Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning", "comment": "large language models, large vision-language model, reasoning,\n  non-ideal conditions, reinforcement learning", "summary": "Reinforcement learning (RL) has become a key technique for enhancing the\nreasoning abilities of large language models (LLMs), with policy-gradient\nalgorithms dominating the post-training stage because of their efficiency and\neffectiveness. However, most existing benchmarks evaluate large-language-model\nreasoning under idealized settings, overlooking performance in realistic,\nnon-ideal scenarios. We identify three representative non-ideal scenarios with\npractical relevance: summary inference, fine-grained noise suppression, and\ncontextual filtering. We introduce a new research direction guided by\nbrain-science findings that human reasoning remains reliable under imperfect\ninputs. We formally define and evaluate these challenging scenarios. We\nfine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)\nusing RL with a representative policy-gradient algorithm and then test their\nperformance on eight public datasets. Our results reveal that while RL\nfine-tuning improves baseline reasoning under idealized settings, performance\ndeclines significantly across all three non-ideal scenarios, exposing critical\nlimitations in advanced reasoning capabilities. Although we propose a\nscenario-specific remediation method, our results suggest current methods leave\nthese reasoning deficits largely unresolved. This work highlights that the\nreasoning abilities of large models are often overstated and underscores the\nimportance of evaluating models under non-ideal scenarios. The code and data\nwill be released at XXXX.", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u7814\u7a76\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5728\u975e\u7406\u60f3\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5ffd\u7565\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u975e\u7406\u60f3\u573a\u666f\u4e0b\u7684\u63a8\u7406\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5728\u516b\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u63d0\u9ad8\u4e86\u7406\u60f3\u573a\u666f\u4e0b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u975e\u7406\u60f3\u573a\u666f\uff08\u6458\u8981\u63a8\u7406\u3001\u7ec6\u7c92\u5ea6\u566a\u58f0\u6291\u5236\u548c\u4e0a\u4e0b\u6587\u8fc7\u6ee4\uff09\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\u5728\u975e\u7406\u60f3\u573a\u666f\u4e0b\u6548\u679c\u663e\u8457\u4e0b\u964d\uff0c\u66b4\u9732\u51fa\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.04915", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.04915", "abs": "https://arxiv.org/abs/2508.04915", "authors": ["Huiya Zhao", "Yinghao Zhu", "Zixiang Wang", "Yasha Wang", "Junyi Gao", "Liantao Ma"], "title": "ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis", "comment": "Code: https://github.com/PKU-AICare/ConfAgents", "summary": "The efficacy of AI agents in healthcare research is hindered by their\nreliance on static, predefined strategies. This creates a critical limitation:\nagents can become better tool-users but cannot learn to become better strategic\nplanners, a crucial skill for complex domains like healthcare. We introduce\nHealthFlow, a self-evolving AI agent that overcomes this limitation through a\nnovel meta-level evolution mechanism. HealthFlow autonomously refines its own\nhigh-level problem-solving policies by distilling procedural successes and\nfailures into a durable, strategic knowledge base. To anchor our research and\nfacilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark\nfeaturing complex, realistic health data analysis tasks derived from\npeer-reviewed clinical research. Our comprehensive experiments demonstrate that\nHealthFlow's self-evolving approach significantly outperforms state-of-the-art\nagent frameworks. This work marks a necessary shift from building better\ntool-users to designing smarter, self-evolving task-managers, paving the way\nfor more autonomous and effective AI for scientific discovery.", "AI": {"tldr": "Self-evolving AI agent HealthFlow surpasses existing methods in healthcare data analysis, showcasing the potential of self-improving task managers for scientific discovery.", "motivation": "Addresses the limitation of static, predefined strategies in AI agents for healthcare research, aiming to improve strategic planning capabilities.", "method": "Introduces a novel meta-level evolution mechanism for AI agents to autonomously refine high-level problem-solving policies by distilling procedural successes and failures.  Utilizes EHRFlowBench, a new benchmark with realistic health data analysis tasks.", "result": "HealthFlow significantly outperforms existing methods.  EHRFlowBench benchmark facilitates reproducible evaluation.", "conclusion": "HealthFlow, a self-evolving AI agent, significantly outperforms state-of-the-art agent frameworks in complex health data analysis tasks, demonstrating the effectiveness of self-evolving task-managers for scientific discovery."}}
{"id": "2508.05006", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05006", "abs": "https://arxiv.org/abs/2508.05006", "authors": ["Youzhi Zhang", "Yufei Li", "Gaofeng Meng", "Hongbin Liu", "Jiebo Luo"], "title": "The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding", "comment": "21 pages, 9 figures", "summary": "Molecular docking is a crucial aspect of drug discovery, as it predicts the\nbinding interactions between small-molecule ligands and protein pockets.\nHowever, current multi-task learning models for docking often show inferior\nperformance in ligand docking compared to protein pocket docking. This\ndisparity arises largely due to the distinct structural complexities of ligands\nand proteins. To address this issue, we propose a novel game-theoretic\nframework that models the protein-ligand interaction as a two-player game\ncalled the Docking Game, with the ligand docking module acting as the ligand\nplayer and the protein pocket docking module as the protein player. To solve\nthis game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which\nalternately trains these players through a two-level loop. In the outer loop,\nthe players exchange predicted poses, allowing each to incorporate the other's\nstructural predictions, which fosters mutual adaptation over multiple\niterations. In the inner loop, each player dynamically refines its predictions\nby incorporating its own predicted ligand or pocket poses back into its model.\nWe theoretically show the convergence of LoopPlay, ensuring stable\noptimization. Extensive experiments conducted on public benchmark datasets\ndemonstrate that LoopPlay achieves approximately a 10\\% improvement in\npredicting accurate binding modes compared to previous state-of-the-art\nmethods. This highlights its potential to enhance the accuracy of molecular\ndocking in drug discovery.", "AI": {"tldr": "\u5229\u7528\u535a\u5f08\u8bba\u6846\u67b6\u548cLoopPlay\u7b97\u6cd5\u6539\u8fdb\u5206\u5b50\u5bf9\u63a5\uff0c\u63d0\u9ad8\u4e86\u7ea610%\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u591a\u4efb\u52a1\u5b66\u4e60\u6a21\u578b\u5728\u914d\u4f53\u5bf9\u63a5\u65b9\u9762\u6027\u80fd\u4e0d\u5982\u86cb\u767d\u8d28\u53e3\u888b\u5bf9\u63a5\uff0c\u8fd9\u662f\u7531\u4e8e\u914d\u4f53\u548c\u86cb\u767d\u8d28\u7684\u7ed3\u6784\u590d\u6742\u6027\u4e0d\u540c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5bf9\u63a5\u535a\u5f08\u201d\u7684\u4e8c\u4eba\u535a\u5f08\u6846\u67b6\u548cLoopPlay\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u4e24\u5c42\u5faa\u73af\u8fed\u4ee3\u8bad\u7ec3\u914d\u4f53\u548c\u86cb\u767d\u8d28\u53e3\u888b\u5bf9\u63a5\u6a21\u5757\uff0c\u5b9e\u73b0\u76f8\u4e92\u9002\u5e94\u548c\u52a8\u6001\u4f18\u5316\u3002", "result": "LoopPlay\u7b97\u6cd5\u5728\u9884\u6d4b\u51c6\u786e\u7ed3\u5408\u6a21\u5f0f\u65b9\u9762\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u9ad8\u4e86\u7ea610%\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u535a\u5f08\u8bba\u6846\u67b6LoopPlay\uff0c\u7528\u4e8e\u89e3\u51b3\u5206\u5b50\u5bf9\u63a5\u4efb\u52a1\u4e2d\u914d\u4f53\u5bf9\u63a5\u548c\u86cb\u767d\u8d28\u53e3\u888b\u5bf9\u63a5\u6027\u80fd\u5dee\u5f02\u7684\u95ee\u9898\uff0c\u5e76\u5728\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u5927\u7ea610%\u7684\u6539\u8fdb\u3002"}}
{"id": "2508.05009", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05009", "abs": "https://arxiv.org/abs/2508.05009", "authors": ["Bin Han", "Robert Wolfe", "Anat Caspi", "Bill Howe"], "title": "Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses", "comment": null, "summary": "We explore the application of large language models (LLMs) to empower domain\nexperts in integrating large, heterogeneous, and noisy urban spatial datasets.\nTraditional rule-based integration methods are unable to cover all edge cases,\nrequiring manual verification and repair. Machine learning approaches require\ncollecting and labeling of large numbers of task-specific samples. In this\nstudy, we investigate the potential of LLMs for spatial data integration. Our\nanalysis first considers how LLMs reason about environmental spatial\nrelationships mediated by human experience, such as between roads and\nsidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they\nstruggle to connect the macro-scale environment with the relevant computational\ngeometry tasks, often producing logically incoherent responses. But when\nprovided relevant features, thereby reducing dependence on spatial reasoning,\nLLMs are able to generate high-performing results. We then adapt a\nreview-and-refine method, which proves remarkably effective in correcting\nerroneous initial responses while preserving accurate responses. We discuss\npractical implications of employing LLMs for spatial data integration in\nreal-world contexts and outline future research directions, including\npost-training, multi-modal integration methods, and support for diverse data\nformats. Our findings position LLMs as a promising and flexible alternative to\ntraditional rule-based heuristics, advancing the capabilities of adaptive\nspatial data integration.", "AI": {"tldr": "LLM\u53ef\u7528\u4e8e\u7a7a\u95f4\u6570\u636e\u6574\u5408\uff0c\u4f46\u9700\u7ed3\u5408\u7279\u5f81\u5de5\u7a0b\u548c\u8fed\u4ee3\u6539\u8fdb\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7a7a\u95f4\u6570\u636e\u6574\u5408\u4e2d\u7684\u5404\u79cd\u8fb9\u7f18\u60c5\u51b5\uff0c\u800c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7279\u5b9a\u4efb\u52a1\u6837\u672c\uff0c\u56e0\u6b64\u7814\u7a76LLM\u4f5c\u4e3a\u4e00\u79cd\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u7814\u7a76\u4e86LLM\u5728\u7a7a\u95f4\u6570\u636e\u6574\u5408\u4e2d\u7684\u5e94\u7528\uff0c\u91c7\u7528\u7279\u5f81\u5de5\u7a0b\u51cf\u5c11LLM\u5bf9\u7a7a\u95f4\u63a8\u7406\u7684\u4f9d\u8d56\uff0c\u5e76\u7ed3\u5408\u8fed\u4ee3\u6539\u8fdb\u65b9\u6cd5\u4fee\u6b63\u9519\u8bef\u3002", "result": "LLM\u5728\u63d0\u4f9b\u76f8\u5173\u7279\u5f81\u540e\u80fd\u751f\u6210\u9ad8\u6027\u80fd\u7ed3\u679c\uff0c\u8fed\u4ee3\u6539\u8fdb\u65b9\u6cd5\u80fd\u6709\u6548\u7ea0\u6b63\u9519\u8bef\uff0c\u8868\u660eLLM\u5177\u6709\u4f5c\u4e3a\u81ea\u9002\u5e94\u7a7a\u95f4\u6570\u636e\u6574\u5408\u65b9\u6cd5\u7684\u6f5c\u529b\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u6574\u5408\u5927\u578b\u3001\u5f02\u6784\u548c\u5608\u6742\u7684\u57ce\u5e02\u7a7a\u95f4\u6570\u636e\u96c6\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u867d\u7136\u5b58\u5728\u903b\u8f91\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u4f46\u7ed3\u5408\u7279\u5f81\u5de5\u7a0b\u548c\u8fed\u4ee3\u6539\u8fdb\u65b9\u6cd5\uff0cLLM\u80fd\u751f\u6210\u9ad8\u6027\u80fd\u7ed3\u679c\uff0c\u4e3a\u81ea\u9002\u5e94\u7a7a\u95f4\u6570\u636e\u6574\u5408\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2508.05081", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.05081", "abs": "https://arxiv.org/abs/2508.05081", "authors": ["Jiarun Liu", "Chunhong Zhang", "Zheng Hu"], "title": "Cognitive Duality for Adaptive Web Agents", "comment": null, "summary": "Web navigation represents a critical and challenging domain for evaluating\nartificial general intelligence (AGI), demanding complex decision-making within\nhigh-entropy, dynamic environments with combinatorially explosive action\nspaces. Current approaches to building autonomous web agents either focus on\noffline imitation learning or online exploration, but rarely integrate both\nparadigms effectively. Inspired by the dual-process theory of human cognition,\nwe derive a principled decomposition into fast System 1 and slow System 2\ncognitive processes. This decomposition provides a unifying perspective on\nexisting web agent methodologies, bridging the gap between offline learning of\nintuitive reactive behaviors and online acquisition of deliberative planning\ncapabilities. We implement this framework in CogniWeb, a modular agent\narchitecture that adaptively toggles between fast intuitive processing and\ndeliberate reasoning based on task complexity. Our evaluation on WebArena\ndemonstrates that CogniWeb achieves competitive performance (43.96% success\nrate) while maintaining significantly higher efficiency (75% reduction in token\nusage).", "AI": {"tldr": "CogniWeb: a dual-process web agent achieving high efficiency and competitive performance in WebArena.", "motivation": "To address the challenges of web navigation in AGI evaluation by effectively integrating offline imitation learning and online exploration.", "method": "Developed CogniWeb, a modular agent architecture that integrates offline imitation learning and online exploration based on dual-process theory.", "result": "CogniWeb achieves 43.96% success rate on WebArena with 75% reduction in token usage compared to existing methods.", "conclusion": "CogniWeb, a modular web agent architecture inspired by dual-process theory, achieves competitive performance with higher efficiency by adaptively switching between fast intuitive processing and deliberate reasoning."}}
{"id": "2508.05083", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05083", "abs": "https://arxiv.org/abs/2508.05083", "authors": ["Dexuan Xu", "Jieyi Wang", "Zhongyan Chai", "Yongzhi Cao", "Hanpin Wang", "Huamin Zhang", "Yu Huang"], "title": "MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models", "comment": "18 pages", "summary": "Recent advances in multimodal large language models (MLLMs) have\nsignificantly improved medical AI, enabling it to unify the understanding of\nvisual and textual information. However, as medical knowledge continues to\nevolve, it is critical to allow these models to efficiently update outdated or\nincorrect information without retraining from scratch. Although textual\nknowledge editing has been widely studied, there is still a lack of systematic\nbenchmarks for multimodal medical knowledge editing involving image and text\nmodalities. To fill this gap, we present MedMKEB, the first comprehensive\nbenchmark designed to evaluate the reliability, generality, locality,\nportability, and robustness of knowledge editing in medical multimodal large\nlanguage models. MedMKEB is built on a high-quality medical visual\nquestion-answering dataset and enriched with carefully constructed editing\ntasks, including counterfactual correction, semantic generalization, knowledge\ntransfer, and adversarial robustness. We incorporate human expert validation to\nensure the accuracy and reliability of the benchmark. Extensive single editing\nand sequential editing experiments on state-of-the-art general and medical\nMLLMs demonstrate the limitations of existing knowledge-based editing\napproaches in medicine, highlighting the need to develop specialized editing\nstrategies. MedMKEB will serve as a standard benchmark to promote the\ndevelopment of trustworthy and efficient medical knowledge editing algorithms.", "AI": {"tldr": "\u63d0\u51faMedMKEB\u57fa\u51c6\uff0c\u8bc4\u4f30\u533b\u7597\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u7f16\u8f91\u80fd\u529b\uff0c\u5e76\u63ed\u793a\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u533b\u7597\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u6709\u6548\u66f4\u65b0\u8fc7\u65f6\u6216\u9519\u8bef\u4fe1\u606f\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u591a\u6a21\u6001\u533b\u7597\u77e5\u8bc6\u7f16\u8f91\u57fa\u51c6\u3002", "method": "\u6784\u5efaMedMKEB\u57fa\u51c6\uff0c\u5305\u542b\u53cd\u4e8b\u5b9e\u6821\u6b63\u3001\u8bed\u4e49\u6cdb\u5316\u3001\u77e5\u8bc6\u8fc1\u79fb\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u7b49\u7f16\u8f91\u4efb\u52a1\uff0c\u5e76\u8fdb\u884c\u4eba\u5de5\u4e13\u5bb6\u9a8c\u8bc1\u3002\u5728\u6700\u5148\u8fdb\u7684\u901a\u7528\u548c\u533b\u7597MLLM\u4e0a\u8fdb\u884c\u5355\u6b21\u548c\u8fde\u7eed\u7f16\u8f91\u5b9e\u9a8c\u3002", "result": "\u63ed\u793a\u4e86\u73b0\u6709\u57fa\u4e8e\u77e5\u8bc6\u7684\u7f16\u8f91\u65b9\u6cd5\u5728\u533b\u5b66\u9886\u57df\u7684\u5c40\u9650\u6027\uff0c\u8bc1\u660e\u4e86\u5f00\u53d1\u4e13\u95e8\u7684\u7f16\u8f91\u7b56\u7565\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u4e3a\u5f00\u53d1\u503c\u5f97\u4fe1\u8d56\u548c\u9ad8\u6548\u7684\u533b\u7597\u77e5\u8bc6\u7f16\u8f91\u7b97\u6cd5\u63d0\u4f9b\u6807\u51c6\u57fa\u51c6\u3002", "conclusion": "MedMKEB\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u533b\u7597\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u7f16\u8f91\u53ef\u9760\u6027\u3001\u901a\u7528\u6027\u3001\u5c40\u90e8\u6027\u3001\u53ef\u79fb\u690d\u6027\u548c\u9c81\u68d2\u6027\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u88ab\u63d0\u51fa\u7528\u4e8e\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u6709\u6548\u66f4\u65b0\u8fc7\u65f6\u6216\u9519\u8bef\u4fe1\u606f\u7684\u95ee\u9898\u3002"}}
{"id": "2508.05113", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05113", "abs": "https://arxiv.org/abs/2508.05113", "authors": ["Xinyue Wu", "Fan Hu", "Shaik Jani Babu", "Yi Zhao", "Xinfei Guo"], "title": "EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search", "comment": null, "summary": "Analog circuit design is a time-consuming, experience-driven task in chip\ndevelopment. Despite advances in AI, developing universal, fast, and stable\ngate sizing methods for analog circuits remains a significant challenge. Recent\napproaches combine Large Language Models (LLMs) with heuristic search\ntechniques to enhance generalizability, but they often depend on large model\nsizes and lack portability across different technology nodes. To overcome these\nlimitations, we propose EasySize, the first lightweight gate sizing framework\nbased on a finetuned Qwen3-8B model, designed for universal applicability\nacross process nodes, design specifications, and circuit topologies. EasySize\nexploits the varying Ease of Attainability (EOA) of performance metrics to\ndynamically construct task-specific loss functions, enabling efficient\nheuristic search through global Differential Evolution (DE) and local Particle\nSwarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned\nsolely on 350nm node data, EasySize achieves strong performance on 5\noperational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology\nnodes without additional targeted training, and outperforms AutoCkt, a\nwidely-used Reinforcement Learning based sizing framework, on 86.67\\% of tasks\nwith more than 96.67\\% of simulation resources reduction. We argue that\nEasySize can significantly reduce the reliance on human expertise and\ncomputational resources in gate sizing, thereby accelerating and simplifying\nthe analog circuit design process. EasySize will be open-sourced at a later\ndate.", "AI": {"tldr": "EasySize: \u8f7b\u91cf\u7ea7\u3001\u901a\u7528\u7684\u6a21\u62df\u7535\u8def\u95e8\u5c3a\u5bf8\u8c03\u6574\u6846\u67b6\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u548c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u89e3\u51b3\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u4e2d\u8017\u65f6\u4e14\u4f9d\u8d56\u7ecf\u9a8c\u7684\u95e8\u5c3a\u5bf8\u8c03\u6574\u95ee\u9898\u3002", "method": "EasySize\u5229\u7528\u6027\u80fd\u6307\u6807\u7684\u53ef\u8fbe\u6027\uff08EOA\uff09\u52a8\u6001\u6784\u5efa\u7279\u5b9a\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570\uff0c\u5e76\u7ed3\u5408\u5168\u5c40\u5dee\u5206\u8fdb\u5316\uff08DE\uff09\u548c\u5c40\u90e8\u7c92\u5b50\u7fa4\u4f18\u5316\uff08PSO\uff09\u7b97\u6cd5\u8fdb\u884c\u9ad8\u6548\u542f\u53d1\u5f0f\u641c\u7d22\u3002", "result": "\u5728\u4e0d\u540c\u5de5\u827a\u8282\u70b9\uff08180nm\u300145nm\u300122nm\uff09\u76845\u4e2a\u8fd0\u7b97\u653e\u5927\u5668\u7535\u8def\u7f51\u8868\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6027\u80fd\uff0c\u5e76\u572886.67%\u7684\u4efb\u52a1\u4e2d\u4f18\u4e8eAutoCkt\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8d85\u8fc796.67%\u7684\u4eff\u771f\u8d44\u6e90\u3002", "conclusion": "EasySize\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5fae\u8c03Qwen3-8B\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u95e8\u5c3a\u5bf8\u8c03\u6574\u6846\u67b6\uff0c\u5728\u8de8\u5de5\u827a\u8282\u70b9\u3001\u8bbe\u8ba1\u89c4\u8303\u548c\u7535\u8def\u62d3\u6251\u7ed3\u6784\u7684\u901a\u7528\u9002\u7528\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4f18\u4e8eAutoCkt\u7b49\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.05116", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.05116", "abs": "https://arxiv.org/abs/2508.05116", "authors": ["Peer-Benedikt Degen", "Igor Asanov"], "title": "Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures", "comment": null, "summary": "Generative AI is no longer a peripheral tool in higher education. It is\nrapidly evolving into a general-purpose infrastructure that reshapes how\nknowledge is generated, mediated, and validated. This paper presents findings\nfrom a controlled experiment evaluating a Socratic AI Tutor, a large language\nmodel designed to scaffold student research question development through\nstructured dialogue grounded in constructivist theory. Conducted with 65\npre-service teacher students in Germany, the study compares interaction with\nthe Socratic Tutor to engagement with an uninstructed AI chatbot. Students\nusing the Socratic Tutor reported significantly greater support for critical,\nindependent, and reflective thinking, suggesting that dialogic AI can stimulate\nmetacognitive engagement and challenging recent narratives of de-skilling due\nto generative AI usage. These findings serve as a proof of concept for a\nbroader pedagogical shift: the use of multi-agent systems (MAS) composed of\nspecialised AI agents. To conceptualise this, we introduce the notion of\norchestrated MAS, modular, pedagogically aligned agent constellations, curated\nby educators, that support diverse learning trajectories through differentiated\nroles and coordinated interaction. To anchor this shift, we propose an adapted\noffer-and-use model, in which students appropriate instructional offers from\nthese agents. Beyond technical feasibility, we examine system-level\nimplications for higher education institutions and students, including funding\nnecessities, changes to faculty roles, curriculars, competencies and assessment\npractices. We conclude with a comparative cost-effectiveness analysis\nhighlighting the scalability of such systems. In sum, this study contributes\nboth empirical evidence and a conceptual roadmap for hybrid learning ecosystems\nthat embed human-AI co-agency and pedagogical alignment.", "AI": {"tldr": "Socratic AI tutors improve student critical thinking;  study proposes scalable, orchestrated AI systems for education.", "motivation": "To evaluate the impact of a Socratic AI tutor on student research question development and critical thinking, challenging narratives of de-skilling due to generative AI.", "method": "Controlled experiment comparing a Socratic AI tutor with an uninstructed AI chatbot, involving 65 pre-service teacher students in Germany.", "result": "Students using the Socratic AI tutor showed significantly greater support for critical, independent, and reflective thinking. The study proposes orchestrated multi-agent systems (MAS) for diverse learning trajectories.", "conclusion": "This study provides empirical evidence and a conceptual roadmap for hybrid learning ecosystems incorporating human-AI co-agency and pedagogical alignment, showing that dialogic AI can enhance metacognitive engagement in students.  A cost-effectiveness analysis suggests scalability."}}
{"id": "2508.05145", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05145", "abs": "https://arxiv.org/abs/2508.05145", "authors": ["Sebastiano Dissegna", "Chiara Di Francescomarino", "Massimiliano Ronzani"], "title": "Graph-based Event Log Repair", "comment": null, "summary": "The quality of event logs in Process Mining is crucial when applying any form\nof analysis to them. In real-world event logs, the acquisition of data can be\nnon-trivial (e.g., due to the execution of manual activities and related manual\nrecording or to issues in collecting, for each event, all its attributes), and\noften may end up with events recorded with some missing information. Standard\napproaches to the problem of trace (or log) reconstruction either require the\navailability of a process model that is used to fill missing values by\nleveraging different reasoning techniques or employ a Machine Learning/Deep\nLearning model to restore the missing values by learning from similar cases. In\nrecent years, a new type of Deep Learning model that is capable of handling\ninput data encoded as graphs has emerged, namely Graph Neural Networks. Graph\nNeural Network models, and even more so Heterogeneous Graph Neural Networks,\noffer the advantage of working with a more natural representation of complex\nmulti-modal sequences like the execution traces in Process Mining, allowing for\nmore expressive and semantically rich encodings.\n  In this work, we focus on the development of a Heterogeneous Graph Neural\nNetwork model that, given a trace containing some incomplete events, will\nreturn the full set of attributes missing from those events. We evaluate our\nwork against a state-of-the-art approach leveraging autoencoders on two\nsynthetic logs and four real event logs, on different types of missing values.\nDifferent from state-of-the-art model-free approaches, which mainly focus on\nrepairing a subset of event attributes, the proposed approach shows very good\nperformance in reconstructing all different event attributes.", "AI": {"tldr": "\u4f7f\u7528\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6709\u6548\u586b\u8865\u6d41\u7a0b\u6316\u6398\u4e2d\u4e8b\u4ef6\u65e5\u5fd7\u7684\u7f3a\u5931\u4fe1\u606f\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u6d41\u7a0b\u65e5\u5fd7\u91cd\u5efa\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u8fc7\u7a0b\u6a21\u578b\uff0c\u8981\u4e48\u4f9d\u8d56\u673a\u5668\u5b66\u4e60/\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u800c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6a21\u578b\uff0c\u4ee5\u66f4\u81ea\u7136\u7684\u65b9\u5f0f\u8868\u793a\u590d\u6742\u7684\u591a\u6a21\u6001\u5e8f\u5217\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u7f3a\u5931\u4fe1\u606f\u586b\u8865\u7684\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u5904\u7406\u7f16\u7801\u4e3a\u56fe\u7684\u8f93\u5165\u6570\u636e\uff0c\u5e76\u5229\u7528\u5176\u4f18\u52bf\u5904\u7406\u6d41\u7a0b\u6316\u6398\u4e2d\u590d\u6742\u7684\u591a\u6a21\u6001\u5e8f\u5217\u6267\u884c\u8f68\u8ff9\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u5408\u6210\u65e5\u5fd7\u548c\u56db\u4e2a\u771f\u5b9e\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u91cd\u6784\u6240\u6709\u4e0d\u540c\u4e8b\u4ef6\u5c5e\u6027\u65b9\u9762\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u65e0\u6a21\u578b\u65b9\u6cd5\u3002", "conclusion": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u586b\u8865\u6d41\u7a0b\u6316\u6398\u4e2d\u4e8b\u4ef6\u65e5\u5fd7\u4e2d\u7f3a\u5931\u7684\u4fe1\u606f\uff0c\u5e76\u5728\u5408\u6210\u65e5\u5fd7\u548c\u771f\u5b9e\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u91cd\u6784\u6240\u6709\u4e0d\u540c\u4e8b\u4ef6\u5c5e\u6027\u65b9\u9762\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.05197", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.05197", "abs": "https://arxiv.org/abs/2508.05197", "authors": ["Zhuohang Jiang", "Pangjing Wu", "Xu Yuan", "Wenqi Fan", "Qing Li"], "title": "QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering", "comment": "The source code for our system is released in\n  https://github.com/jzzzzh/QA-Dragon", "summary": "Retrieval-Augmented Generation (RAG) has been introduced to mitigate\nhallucinations in Multimodal Large Language Models (MLLMs) by incorporating\nexternal knowledge into the generation process, and it has become a widely\nadopted approach for knowledge-intensive Visual Question Answering (VQA).\nHowever, existing RAG methods typically retrieve from either text or images in\nisolation, limiting their ability to address complex queries that require\nmulti-hop reasoning or up-to-date factual knowledge. To address this\nlimitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for\nKnowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to\nidentify the query's subject domain for domain-specific reasoning, along with a\nsearch router that dynamically selects optimal retrieval strategies. By\norchestrating both text and image search agents in a hybrid setup, our system\nsupports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle\ncomplex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM\nChallenge at KDD Cup 2025, where it significantly enhances the reasoning\nperformance of base models under challenging scenarios. Our framework achieves\nsubstantial improvements in both answer accuracy and knowledge overlap scores,\noutperforming baselines by 5.06% on the single-source task, 6.35% on the\nmulti-source task, and 5.03% on the multi-turn task.", "AI": {"tldr": "QA-Dragon\u662f\u4e00\u4e2a\u7528\u4e8e\u77e5\u8bc6\u5bc6\u96c6\u578bVQA\u7684\u52a8\u6001RAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u3001\u591a\u8df3\u63a8\u7406\u663e\u8457\u63d0\u5347\u4e86\u95ee\u7b54\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u7684RAG\u65b9\u6cd5\u901a\u5e38\u53ea\u4ece\u6587\u672c\u6216\u56fe\u50cf\u4e2d\u5355\u72ec\u68c0\u7d22\u4fe1\u606f\uff0c\u96be\u4ee5\u5904\u7406\u9700\u8981\u591a\u8df3\u63a8\u7406\u6216\u6700\u65b0\u4e8b\u5b9e\u77e5\u8bc6\u7684\u590d\u6742\u67e5\u8be2\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u67e5\u8be2\u611f\u77e5\u7684\u52a8\u6001RAG\u7cfb\u7edfQA-Dragon\uff0c\u8be5\u7cfb\u7edf\u5305\u542b\u9886\u57df\u8def\u7531\u5668\u548c\u641c\u7d22\u8def\u7531\u5668\uff0c\u80fd\u591f\u52a8\u6001\u9009\u62e9\u6700\u4f18\u7684\u68c0\u7d22\u7b56\u7565\uff0c\u652f\u6301\u591a\u6a21\u6001\u3001\u591a\u8f6e\u548c\u591a\u8df3\u63a8\u7406\u3002", "result": "\u5728KDD Cup 2025\u7684Meta CRAG-MM\u6311\u6218\u8d5b\u4e2d\uff0cQA-Dragon\u5728\u5355\u6e90\u4efb\u52a1\u3001\u591a\u6e90\u4efb\u52a1\u548c\u591a\u8f6e\u4efb\u52a1\u4e0a\u5206\u522b\u63d0\u9ad8\u4e865.06%\u30016.35%\u548c5.03%\u7684\u51c6\u786e\u7387\u548c\u77e5\u8bc6\u91cd\u53e0\u5ea6\u3002", "conclusion": "QA-Dragon\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u5bc6\u96c6\u578bVQA\u4efb\u52a1\u7684\u63a8\u7406\u6027\u80fd\uff0c\u5728\u5355\u6e90\u3001\u591a\u6e90\u548c\u591a\u8f6e\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u7684\u6210\u679c\u3002"}}
{"id": "2508.05267", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05267", "abs": "https://arxiv.org/abs/2508.05267", "authors": ["V\u00edtor N. Louren\u00e7o", "Mohnish Dubey", "Yunfei Bai", "Audrey Depeige", "Vivek Jain"], "title": "An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication", "comment": "Accepted to publication at the 24th International Semantic Web\n  Conference Industry Track, ISWC 2025", "summary": "In large-scale maintenance organizations, identifying subject matter experts\nand managing communications across complex entities relationships poses\nsignificant challenges -- including information overload and longer response\ntimes -- that traditional communication approaches fail to address effectively.\nWe propose a novel framework that combines RDF graph databases with LLMs to\nprocess natural language queries for precise audience targeting, while\nproviding transparent reasoning through a planning-orchestration architecture.\nOur solution enables communication owners to formulate intuitive queries\ncombining concepts such as equipment, manufacturers, maintenance engineers, and\nfacilities, delivering explainable results that maintain trust in the system\nwhile improving communication efficiency across the organization.", "AI": {"tldr": "\u5229\u7528RDF\u56fe\u6570\u636e\u5e93\u548cLLM\u6784\u5efa\u6846\u67b6\uff0c\u63d0\u5347\u5927\u578b\u7ef4\u62a4\u7ec4\u7ec7\u5185\u90e8\u7684\u6c9f\u901a\u6548\u7387\u548c\u7cbe\u51c6\u5ea6\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u7ef4\u62a4\u7ec4\u7ec7\u4e2d\u8bc6\u522b\u4e3b\u9898\u4e13\u5bb6\u548c\u8de8\u590d\u6742\u5b9e\u4f53\u5173\u7cfb\u7ba1\u7406\u6c9f\u901a\u7684\u6311\u6218\uff0c\u4f8b\u5982\u4fe1\u606f\u8fc7\u8f7d\u548c\u54cd\u5e94\u65f6\u95f4\u957f\u7b49\u95ee\u9898\u3002", "method": "\u7ed3\u5408RDF\u56fe\u6570\u636e\u5e93\u548cLLMs\u5904\u7406\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\uff0c\u5b9e\u73b0\u7cbe\u51c6\u7684\u53d7\u4f17\u5b9a\u4f4d\uff0c\u5e76\u901a\u8fc7\u89c4\u5212-\u534f\u8c03\u67b6\u6784\u63d0\u4f9b\u900f\u660e\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u80fd\u591f\u8ba9\u6c9f\u901a\u8d1f\u8d23\u4eba\u4f7f\u7528\u76f4\u89c2\u7684\u67e5\u8be2\u7ec4\u5408\u6982\u5ff5\uff08\u5982\u8bbe\u5907\u3001\u5236\u9020\u5546\u3001\u7ef4\u62a4\u5de5\u7a0b\u5e08\u548c\u8bbe\u65bd\uff09\uff0c\u7ed9\u51fa\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\uff0c\u63d0\u9ad8\u6c9f\u901a\u6548\u7387\uff0c\u5e76\u4fdd\u6301\u5bf9\u7cfb\u7edf\u7684\u4fe1\u4efb\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408RDF\u56fe\u6570\u636e\u5e93\u548cLLM\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5927\u578b\u7ef4\u62a4\u7ec4\u7ec7\u4e2d\u9ad8\u6548\u7cbe\u51c6\u5730\u5b9a\u4f4d\u4e3b\u9898\u4e13\u5bb6\u5e76\u7ba1\u7406\u6c9f\u901a\uff0c\u63d0\u9ad8\u6c9f\u901a\u6548\u7387\uff0c\u5e76\u4fdd\u8bc1\u7cfb\u7edf\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.05311", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05311", "abs": "https://arxiv.org/abs/2508.05311", "authors": ["Andrew Kiruluta"], "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "comment": null, "summary": "We propose a hybrid architecture that integrates decision tree-based symbolic\nreasoning with the generative capabilities of large language models (LLMs)\nwithin a coordinated multi-agent framework. Unlike prior approaches that\nloosely couple symbolic and neural modules, our design embeds decision trees\nand random forests as callable oracles within a unified reasoning system.\nTree-based modules enable interpretable rule inference and causal logic, while\nLLM agents handle abductive reasoning, generalization, and interactive\nplanning. A central orchestrator maintains belief state consistency and\nmediates communication across agents and external tools, enabling reasoning\nover both structured and unstructured inputs.\n  The system achieves strong performance on reasoning benchmarks. On\n\\textit{ProofWriter}, it improves entailment consistency by +7.2\\% through\nlogic-grounded tree validation. On GSM8k, it achieves +5.3\\% accuracy gains in\nmultistep mathematical problems via symbolic augmentation. On \\textit{ARC}, it\nboosts abstraction accuracy by +6.0\\% through integration of symbolic oracles.\nApplications in clinical decision support and scientific discovery show how the\nsystem encodes domain rules symbolically while leveraging LLMs for contextual\ninference and hypothesis generation. This architecture offers a robust,\ninterpretable, and extensible solution for general-purpose neuro-symbolic\nreasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u67b6\u6784\uff0c\u7ed3\u5408\u51b3\u7b56\u6811\u548cLLM\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u677e\u6563\u5730\u8026\u5408\u7b26\u53f7\u548c\u795e\u7ecf\u6a21\u5757\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u66f4\u7d27\u5bc6\u96c6\u6210\u7b26\u53f7\u548c\u795e\u7ecf\u63a8\u7406\u80fd\u529b\u7684\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u63a8\u7406\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u67b6\u6784\uff0c\u5c06\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u7b26\u53f7\u63a8\u7406\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u751f\u6210\u80fd\u529b\u96c6\u6210\u5728\u4e00\u4e2a\u534f\u8c03\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4e2d\u3002\u51b3\u7b56\u6811\u548c\u968f\u673a\u68ee\u6797\u4f5c\u4e3a\u53ef\u8c03\u7528\u7684\u9884\u8a00\u673a\u5d4c\u5165\u5230\u7edf\u4e00\u7684\u63a8\u7406\u7cfb\u7edf\u4e2d\uff0cLLM \u667a\u80fd\u4f53\u8d1f\u8d23\u6eaf\u56e0\u63a8\u7406\u3001\u6cdb\u5316\u548c\u4ea4\u4e92\u5f0f\u89c4\u5212\uff0c\u4e2d\u592e\u534f\u8c03\u5668\u7ef4\u62a4\u4fe1\u5ff5\u72b6\u6001\u4e00\u81f4\u6027\u5e76\u534f\u8c03\u667a\u80fd\u4f53\u548c\u5916\u90e8\u5de5\u5177\u4e4b\u95f4\u7684\u901a\u4fe1\u3002", "result": "\u5728ProofWriter\u3001GSM8k\u548cARC\u7b49\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u7cfb\u7edf\u5206\u522b\u5728\u8574\u542b\u4e00\u81f4\u6027\u3001\u591a\u6b65\u6570\u5b66\u95ee\u9898\u6c42\u89e3\u548c\u62bd\u8c61\u7cbe\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u6269\u5c55\u7684\u901a\u7528\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u5e76\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u548c\u79d1\u5b66\u53d1\u73b0\u7b49\u5e94\u7528\u4e2d\u5c55\u73b0\u4e86\u5176\u4f18\u52bf\u3002"}}
{"id": "2508.05338", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.05338", "abs": "https://arxiv.org/abs/2508.05338", "authors": ["Brinnae Bent"], "title": "The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition", "comment": "Accepted to AIES 2025", "summary": "The term 'agent' in artificial intelligence has long carried multiple\ninterpretations across different subfields. Recent developments in AI\ncapabilities, particularly in large language model systems, have amplified this\nambiguity, creating significant challenges in research communication, system\nevaluation and reproducibility, and policy development. This paper argues that\nthe term 'agent' requires redefinition. Drawing from historical analysis and\ncontemporary usage patterns, we propose a framework that defines clear minimum\nrequirements for a system to be considered an agent while characterizing\nsystems along a multidimensional spectrum of environmental interaction,\nlearning and adaptation, autonomy, goal complexity, and temporal coherence.\nThis approach provides precise vocabulary for system description while\npreserving the term's historically multifaceted nature. After examining\npotential counterarguments and implementation challenges, we provide specific\nrecommendations for moving forward as a field, including suggestions for\nterminology standardization and framework adoption. The proposed approach\noffers practical tools for improving research clarity and reproducibility while\nsupporting more effective policy development.", "AI": {"tldr": "This paper proposes a new framework to clearly define 'AI agent' across multiple dimensions to improve research and policy.", "motivation": "Ambiguity in the definition of 'agent' hinders research communication, system evaluation, reproducibility, and policy development.", "method": "Historical analysis and contemporary usage patterns are used to propose a framework for defining AI agents.", "result": "A framework defining minimum requirements for an AI agent is proposed, characterized by environmental interaction, learning, autonomy, goal complexity, and temporal coherence.  Recommendations for terminology standardization and framework adoption are provided.", "conclusion": "The term 'agent' needs redefinition due to its ambiguity in AI, especially with large language models.  A new framework is proposed to clarify minimum requirements and characterize systems along multiple dimensions."}}
