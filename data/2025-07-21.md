<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination](https://arxiv.org/abs/2507.13511)
*Nabil Abdelaziz Ferhat Taleb,Abdolazim Rezaei,Raj Atulkumar Patel,Mehdi Sookhak*

Main category: cs.AI

TL;DR: GraphTrafficGPT通过图架构提升LLM驱动交通应用效率，显著降低token消耗和延迟，并支持多查询并发处理。


<details>
  <summary>Details</summary>
Motivation: 现有的基于链的系统（如TrafficGPT）在处理复杂的现实世界场景时，存在顺序任务执行、高token使用率和可扩展性差等问题。

Method: 提出了一种基于图的架构GraphTrafficGPT，该架构将任务及其依赖关系表示为有向图中的节点和边，实现了高效的并行执行和动态资源分配。核心是一个大脑代理，负责分解用户查询，构建优化的依赖图，并协调专门代理网络进行数据检索、分析、可视化和仿真。

Result: 实验结果表明，与TrafficGPT相比，GraphTrafficGPT将token消耗减少了50.2%，平均响应延迟减少了19.0%，同时支持并发多查询执行，效率提高了23.0%。

Conclusion: GraphTrafficGPT，一种新颖的基于图的架构，通过并行执行和动态资源分配提高了LLM驱动交通应用的效率，减少了token消耗和平均响应延迟，并支持并发多查询处理。

Abstract: Large Language Models (LLMs) offer significant promise for intelligent
traffic management; however, current chain-based systems like TrafficGPT are
hindered by sequential task execution, high token usage, and poor scalability,
making them inefficient for complex, real-world scenarios. To address these
limitations, we propose GraphTrafficGPT, a novel graph-based architecture,
which fundamentally redesigns the task coordination process for LLM-driven
traffic applications. GraphTrafficGPT represents tasks and their dependencies
as nodes and edges in a directed graph, enabling efficient parallel execution
and dynamic resource allocation. The main idea behind the proposed model is a
Brain Agent that decomposes user queries, constructs optimized dependency
graphs, and coordinates a network of specialized agents for data retrieval,
analysis, visualization, and simulation. By introducing advanced context-aware
token management and supporting concurrent multi-query processing, the proposed
architecture handles interdependent tasks typical of modern urban mobility
environments. Experimental results demonstrate that GraphTrafficGPT reduces
token consumption by 50.2% and average response latency by 19.0% compared to
TrafficGPT, while supporting simultaneous multi-query execution with up to
23.0% improvement in efficiency.

</details>


### [2] [PrefPalette: Personalized Preference Modeling with Latent Attributes](https://arxiv.org/abs/2507.13541)
*Shuyue Stella Li,Melanie Sclar,Hunter Lang,Ansong Ni,Jacqueline He,Puxin Xu,Andrew Cohen,Chan Young Park,Yulia Tsvetkov,Asli Celikyilmaz*

Main category: cs.AI

TL;DR: PrefPalette框架通过分解偏好属性和社区价值观，提高了AI个性化推荐的准确性和可解释性，并在Reddit实验中显著优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 当前的偏好模型通常将人的判断视为黑盒，无法理解偏好背后的原因。PrefPalette旨在通过理解偏好背后的原因来实现AI系统的个性化。

Method: PrefPalette采用反事实属性合成步骤生成合成训练数据，并使用基于注意力的偏好模型学习不同社会社区如何动态地权衡这些属性。

Result: PrefPalette在预测准确率方面优于GPT-4o，并揭示了社区特有的偏好特征，例如学术社区重视冗长性和刺激性，而冲突型社区则重视讽刺和直接性。

Conclusion: PrefPalette框架通过分解偏好属性维度并根据不同的社会社区价值观定制偏好预测，改进了AI系统的个性化，在Reddit的45个社交社区评估中，其平均预测准确率比GPT-4o高46.6%。

Abstract: Personalizing AI systems requires understanding not just what users prefer,
but the reasons that underlie those preferences - yet current preference models
typically treat human judgment as a black box. We introduce PrefPalette, a
framework that decomposes preferences into attribute dimensions and tailors its
preference prediction to distinct social community values in a
human-interpretable manner. PrefPalette operationalizes a cognitive science
principle known as multi-attribute decision making in two ways: (1) a scalable
counterfactual attribute synthesis step that involves generating synthetic
training data to isolate for individual attribute effects (e.g., formality,
humor, cultural values), and (2) attention-based preference modeling that
learns how different social communities dynamically weight these attributes.
This approach moves beyond aggregate preference modeling to capture the diverse
evaluation frameworks that drive human judgment. When evaluated on 45 social
communities from the online platform Reddit, PrefPalette outperforms GPT-4o by
46.6% in average prediction accuracy. Beyond raw predictive improvements,
PrefPalette also shed light on intuitive, community-specific profiles:
scholarly communities prioritize verbosity and stimulation, conflict-oriented
communities value sarcasm and directness, and support-based communities
emphasize empathy. By modeling the attribute-mediated structure of human
judgment, PrefPalette delivers both superior preference modeling and
transparent, interpretable insights, and serves as a first step toward more
trustworthy, value-aware personalized applications.

</details>


### [3] [GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models](https://arxiv.org/abs/2507.13550)
*Eduardo C. Garrido-Merchán,Cristina Puente*

Main category: cs.AI

TL;DR: 提出一种结合LLM的召回能力和符号系统的精确性的混合方法，用于开发可靠的专家系统。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在知识型系统中存在幻觉或自信地生成不正确事实的问题。

Method: 限制领域，使用结构化提示提取方法，将知识表示为Prolog形式。

Result: 生成的知识库具有较高的准确性和语义一致性，可解释性、可扩展性和可靠性。

Conclusion: 本文介绍了一种使用LLM开发可控透明专家系统的新方法，该方法通过限制领域和使用结构化提示提取方法，将知识表示为Prolog形式，从而保证可解释性、可扩展性和可靠性。实验结果表明，该方法生成的知识库具有较高的准确性和语义一致性，为在敏感领域开发可靠的AI应用奠定了基础。

Abstract: The development of large language models (LLMs) has successfully transformed
knowledge-based systems such as open domain question nswering, which can
automatically produce vast amounts of seemingly coherent information. Yet,
those models have several disadvantages like hallucinations or confident
generation of incorrect or unverifiable facts. In this paper, we introduce a
new approach to the development of expert systems using LLMs in a controlled
and transparent way. By limiting the domain and employing a well-structured
prompt-based extraction approach, we produce a symbolic representation of
knowledge in Prolog, which can be validated and corrected by human experts.
This approach also guarantees interpretability, scalability and reliability of
the developed expert systems. Via quantitative and qualitative experiments with
Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic
coherence on our generated knowledge bases. We present a transparent hybrid
solution that combines the recall capacity of LLMs with the precision of
symbolic systems, thereby laying the foundation for dependable AI applications
in sensitive domains.

</details>


### [4] [Why Isn't Relational Learning Taking Over the World?](https://arxiv.org/abs/2507.13558)
*David Poole*

Main category: cs.AI

TL;DR: Relational learning is powerful but underutilized; this paper explains why and suggests improvements.


<details>
  <summary>Details</summary>
Motivation: To explain why relational learning isn't as prevalent as other AI approaches and identify areas for improvement.

Method: Analysis of the current state of relational learning and its limitations.

Result: Highlights the gap between relational learning's theoretical advantages and its practical application, suggesting future research directions.

Conclusion: Relational learning, despite its potential for modeling real-world entities and relationships, hasn't achieved widespread adoption due to limitations in handling complex relations.  Further advancements are needed to realize its full potential.

Abstract: AI seems to be taking over the world with systems that model pixels, words,
and phonemes. The world is arguably made up, not of pixels, words, and phonemes
but of entities (objects, things, including events) with properties and
relations among them. Surely we should model these, not the perception or
description of them. You might suspect that concentrating on modeling words and
pixels is because all of the (valuable) data in the world is in terms of text
and images. If you look into almost any company you will find their most
valuable data is in spreadsheets, databases and other relational formats. These
are not the form that are studied in introductory machine learning, but are
full of product numbers, student numbers, transaction numbers and other
identifiers that can't be interpreted naively as numbers. The field that
studies this sort of data has various names including relational learning,
statistical relational AI, and many others. This paper explains why relational
learning is not taking over the world -- except in a few cases with restricted
relations -- and what needs to be done to bring it to it's rightful prominence.

</details>


### [5] [BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety](https://arxiv.org/abs/2507.13625)
*Yuxin Zhang,Xi Wang,Mo Hu,Zhenyu Zhang*

Main category: cs.AI

TL;DR: BifrostRAG双图RAG系统通过混合检索机制显著提升了复杂安全条例文本信息检索和问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统难以处理安全条例中多跳问题，因为条例文本的语言和结构复杂性。

Method: 提出了一种双图RAG集成系统BifrostRAG，该系统显式地建模语言关系（通过实体网络图）和文档结构（通过文档导航图），结合图遍历和基于向量的语义搜索，实现混合检索机制。

Result: 在多跳问题数据集上，BifrostRAG达到92.8%的精确率，85.5%的召回率和87.3%的F1分数，显著优于仅向量或仅图的RAG基线。

Conclusion: BifrostRAG系统在多跳问题数据集上取得了显著优于现有方法的结果，证明了其作为LLM驱动合规性检查的强大知识引擎的潜力。其双图混合检索机制为应对复杂技术文档提供了一种可迁移的蓝图。

Abstract: Information retrieval and question answering from safety regulations are
essential for automated construction compliance checking but are hindered by
the linguistic and structural complexity of regulatory text. Many
compliance-related queries are multi-hop, requiring synthesis of information
across interlinked clauses. This poses a challenge for traditional
retrieval-augmented generation (RAG) systems. To overcome this, we introduce
BifrostRAG: a dual-graph RAG-integrated system that explicitly models both
linguistic relationships (via an Entity Network Graph) and document structure
(via a Document Navigator Graph). This architecture powers a hybrid retrieval
mechanism that combines graph traversal with vector-based semantic search,
enabling large language models to reason over both the meaning and the
structure of the text. Evaluation on a multi-hop question dataset shows that
BifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1
score of 87.3 percent. These results significantly outperform vector-only and
graph-only RAG baselines that represent current leading approaches. Error
analysis further highlights the comparative advantages of our hybrid method
over single-modality RAGs. These findings establish BifrostRAG as a robust
knowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid
retrieval mechanism offers a transferable blueprint for navigating complex
technical documents across knowledge-intensive engineering domains.

</details>


### [6] [Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks](https://arxiv.org/abs/2507.13651)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 利用最终答案诊断学生合并步骤的错误，有效提高了诊断效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决智能辅导系统中由于学生合并步骤导致的组合爆炸问题，从而难以进行错误诊断。

Method: 基于最终答案的自动化错误诊断方法。通过自动完成中间输入并诊断其解法来诊断中间输入。

Result: 最终答案评估能够诊断29.4%的步骤，与教师诊断吻合度达97%。

Conclusion: 最终答案评估能够诊断29.4%的学生步骤，并且与教师诊断的吻合度高达97%。这为进一步探索该方法提供了基础。

Abstract: Many intelligent tutoring systems can support a student in solving a stepwise
task. When a student combines several steps in one step, the number of possible
paths connecting consecutive inputs may be very large. This combinatorial
explosion makes error diagnosis hard. Using a final answer to diagnose a
combination of steps can mitigate the combinatorial explosion, because there
are generally fewer possible (erroneous) final answers than (erroneous)
solution paths. An intermediate input for a task can be diagnosed by
automatically completing it according to the task solution strategy and
diagnosing this solution. This study explores the potential of automated error
diagnosis based on a final answer. We investigate the design of a service that
provides a buggy rule diagnosis when a student combines several steps. To
validate the approach, we apply the service to an existing dataset (n=1939) of
unique student steps when solving quadratic equations, which could not be
diagnosed by a buggy rule service that tries to connect consecutive inputs with
a single rule. Results show that final answer evaluation can diagnose 29,4% of
these steps. Moreover, a comparison of the generated diagnoses with teacher
diagnoses on a subset (n=115) shows that the diagnoses align in 97% of the
cases. These results can be considered a basis for further exploration of the
approach.

</details>


### [7] [Combining model tracing and constraint-based modeling for multistep strategy diagnoses](https://arxiv.org/abs/2507.13652)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 结合模型追踪和约束建模，提出一种新的学生分步任务输入诊断方法，并通过实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的模型追踪和约束建模方法在诊断学生分步任务输入时各有局限性，该研究旨在结合两种方法的优势，提高诊断的准确性和适用性。

Method: 该研究提出了一种结合模型追踪和约束建模的方法，通过定义约束作为学生输入与策略步骤的共同属性，即使学生组合了多个步骤，也能提供诊断。

Result: 对包含学生解二次方程步骤的数据集(n=2136)进行诊断，并与教师编码(n=140)进行比较，结果显示系统诊断与教师编码完全一致。

Conclusion: 该研究提出了一种结合模型追踪和约束建模的诊断方法，用于诊断学生在分步任务中的输入，并通过对解二次方程数据集的诊断评估验证了该方法的有效性，结果显示系统诊断与教师编码完全一致。

Abstract: Model tracing and constraint-based modeling are two approaches to diagnose
student input in stepwise tasks. Model tracing supports identifying consecutive
problem-solving steps taken by a student, whereas constraint-based modeling
supports student input diagnosis even when several steps are combined into one
step. We propose an approach that merges both paradigms. By defining
constraints as properties that a student input has in common with a step of a
strategy, it is possible to provide a diagnosis when a student deviates from a
strategy even when the student combines several steps. In this study we explore
the design of a system for multistep strategy diagnoses, and evaluate these
diagnoses. As a proof of concept, we generate diagnoses for an existing dataset
containing steps students take when solving quadratic equations (n=2136). To
compare with human diagnoses, two teachers coded a random sample of deviations
(n=70) and applications of the strategy (n=70). Results show that that the
system diagnosis aligned with the teacher coding in all of the 140 student
steps.

</details>


### [8] [DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs](https://arxiv.org/abs/2507.13737)
*Ye Tian,Xiaoyuan Ren,Zihao Wang,Onat Gungor,Xiaofan Yu,Tajana Rosing*

Main category: cs.AI

TL;DR: DailyLLM是一个高效、准确的活动日志生成和摘要系统，利用轻量级LLM模型在资源受限的设备上实现了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的活动日志生成方法在准确性、效率和语义丰富度方面存在局限性。

Method: DailyLLM采用轻量级基于LLM的框架，结合结构化提示和高效特征提取，整合了位置、运动、环境和生理四个维度的上下文活动信息。

Result: DailyLLM在日志生成BERTScore精度方面比700亿参数的SOTA基线提高了17%，推理速度提高了近10倍。

Conclusion: DailyLLM系统在活动日志生成方面超越了现有技术，实现了更高的精度和效率，并且能够在个人电脑和树莓派等设备上高效部署。

Abstract: Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

</details>


### [9] [OntView: What you See is What you Meant](https://arxiv.org/abs/2507.13759)
*Carlos Bobed,Carlota Quintana,Eduardo Mena,Jorge Bobed,Fernando Bobillo*

Main category: cs.AI

TL;DR: OntView: 一款新的本体可视化工具，提供直观、简化的视图，支持GCIs可视化。


<details>
  <summary>Details</summary>
Motivation: 现有的本体编辑器和查看器难以有效地可视化大型本体结构，限制了用户理解依赖关系和属性的能力。

Method: 利用DL推理器，遵循所见即所得的原则，并提供多种简化视图方法，例如根据不同算法评估概念重要性创建本体摘要、关注两个给定类之间的TBox元素、动态隐藏/显示不同分支等。

Result: 开发了OntView 本体查看器，并以开源方式发布。

Conclusion: OntView 是一种新颖的本体可视化工具，能够直观地展示本体概念及其形式化定义，并支持多种简化视图以避免信息过载。

Abstract: In the field of knowledge management and computer science, ontologies provide
a structured framework for modeling domain-specific knowledge by defining
concepts and their relationships. However, the lack of tools that provide
effective visualization is still a significant challenge. While numerous
ontology editors and viewers exist, most of them fail to graphically represent
ontology structures in a meaningful and non-overwhelming way, limiting users'
ability to comprehend dependencies and properties within large ontological
frameworks.
  In this paper, we present OntView, an ontology viewer that is designed to
provide users with an intuitive visual representation of ontology concepts and
their formal definitions through a user-friendly interface. Building on the use
of a DL reasoner, OntView follows a "What you see is what you meant" paradigm,
showing the actual inferred knowledge. One key aspect for this is its ability
to visualize General Concept Inclusions (GCI), a feature absent in existing
visualization tools. Moreover, to avoid a possible information overload,
OntView also offers different ways to show a simplified view of the ontology
by: 1) creating ontology summaries by assessing the importance of the concepts
(according to different available algorithms), 2) focusing the visualization on
the existing TBox elements between two given classes and 3) allowing to
hide/show different branches in a dynamic way without losing the semantics.
OntView has been released with an open-source license for the whole community.

</details>


### [10] [From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning](https://arxiv.org/abs/2507.13768)
*Renato Ghisellini,Remo Pareschi,Marco Pedroni,Giovanni Battista Raggi*

Main category: cs.AI

TL;DR: 该论文提出了一种新颖的混合架构，用于增强代理的战略推理，通过融合多种启发式方法，实现了更有效和具有语境感知能力的决策。


<details>
  <summary>Details</summary>
Motivation: 为解决传统决策引擎在处理复杂战略问题时的局限性，该论文提出了一种新的混合架构，以实现更有效和具有语境感知能力的战略推理。

Method: 该模型通过语义交互建模和修辞框架，融合了来自不同来源的多种启发式方法，而非选择最佳规则。

Result: 通过Meta vs. FTC案例研究，初步验证了该框架的有效性，并使用语义指标进行评估。

Conclusion: 该论文提出了一种混合架构，用于增强代理的战略推理，结合了启发式提取、语义激活和组合合成，并通过案例研究进行了初步验证，但仍存在局限性，并提出了改进方向。

Abstract: We present a hybrid architecture for agent-augmented strategic reasoning,
combining heuristic extraction, semantic activation, and compositional
synthesis. Drawing on sources ranging from classical military theory to
contemporary corporate strategy, our model activates and composes multiple
heuristics through a process of semantic interdependence inspired by research
in quantum cognition. Unlike traditional decision engines that select the best
rule, our system fuses conflicting heuristics into coherent and
context-sensitive narratives, guided by semantic interaction modeling and
rhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,
with preliminary validation through semantic metrics. Limitations and
extensions (e.g., dynamic interference tuning) are discussed.

</details>


### [11] [When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction](https://arxiv.org/abs/2507.13825)
*Haoyang Li,Yuming Xu,Yiming Li,Hanmo Liu,Darian Li,Chen Jason Zhang,Lei Chen,Qing Li*

Main category: cs.AI

TL;DR: EAGLE是一个轻量级框架，通过结合短期时间近期性和长期全局结构模式，高效且有效地进行动态图中的时间链接预测。


<details>
  <summary>Details</summary>
Motivation: 现有的T-GNNs存在可扩展性和效率挑战，计算开销大。

Method: EAGLE框架集成了短期时间近期性和长期全局结构模式，包含时间感知模块和结构感知模块，并采用自适应加权机制。它避免了复杂的多跳消息传递或内存密集型机制。

Result: EAGLE在有效性和效率方面均优于现有T-GNNs，实现了超过50倍的加速。

Conclusion: EAGLE框架在有效性和效率上均优于最先进的T-GNNs，在七个真实世界的时间图上取得了显著成果，实现了超过50倍的加速。

Abstract: Temporal link prediction in dynamic graphs is a critical task with
applications in diverse domains such as social networks, recommendation
systems, and e-commerce platforms. While existing Temporal Graph Neural
Networks (T-GNNs) have achieved notable success by leveraging complex
architectures to model temporal and structural dependencies, they often suffer
from scalability and efficiency challenges due to high computational overhead.
In this paper, we propose EAGLE, a lightweight framework that integrates
short-term temporal recency and long-term global structural patterns. EAGLE
consists of a time-aware module that aggregates information from a node's most
recent neighbors to reflect its immediate preferences, and a structure-aware
module that leverages temporal personalized PageRank to capture the influence
of globally important nodes. To balance these attributes, EAGLE employs an
adaptive weighting mechanism to dynamically adjust their contributions based on
data characteristics. Also, EAGLE eliminates the need for complex multi-hop
message passing or memory-intensive mechanisms, enabling significant
improvements in efficiency. Extensive experiments on seven real-world temporal
graphs demonstrate that EAGLE consistently achieves superior performance
against state-of-the-art T-GNNs in both effectiveness and efficiency,
delivering more than a 50x speedup over effective transformer-based T-GNNs.

</details>


### [12] [Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2507.13846)
*Kathrin Korte,Christian Medeiros Adriano,Sona Ghahremani,Holger Giese*

Main category: cs.AI

TL;DR: 一种新的因果知识迁移框架，通过共享碰撞恢复策略的宏，使MARL智能体能够在非平稳环境中高效适应。


<details>
  <summary>Details</summary>
Motivation: 传统的MARL知识迁移方法难以泛化，智能体需要代价高昂的再训练才能适应变化的环境。

Method: 该框架通过将碰撞建模为因果干预，并将其表示为一系列恢复动作（宏），实现零样本知识迁移，无需重新训练。

Result: 实验结果表明，该方法能够帮助具有异质目标的智能体在适应新环境时，缩小随机探索和完全重新训练策略之间的差距，且效果受环境复杂性和智能体异质目标的相互作用影响。

Conclusion: 本文介绍了一种因果知识迁移框架，使强化学习智能体能够学习和共享环境中路径的紧凑因果表示，从而在非平稳环境中适应新的障碍物，提高了适应性。

Abstract: [Context] Multi-agent reinforcement learning (MARL) has achieved notable
success in environments where agents must learn coordinated behaviors. However,
transferring knowledge across agents remains challenging in non-stationary
environments with changing goals. [Problem] Traditional knowledge transfer
methods in MARL struggle to generalize, and agents often require costly
retraining to adapt. [Approach] This paper introduces a causal knowledge
transfer framework that enables RL agents to learn and share compact causal
representations of paths within a non-stationary environment. As the
environment changes (new obstacles), agents' collisions require adaptive
recovery strategies. We model each collision as a causal intervention
instantiated as a sequence of recovery actions (a macro) whose effect
corresponds to a causal knowledge of how to circumvent the obstacle while
increasing the chances of achieving the agent's goal (maximizing cumulative
reward). This recovery action macro is transferred online from a second agent
and is applied in a zero-shot fashion, i.e., without retraining, just by
querying a lookup model with local context information (collisions). [Results]
Our findings reveal two key insights: (1) agents with heterogeneous goals were
able to bridge about half of the gap between random exploration and a fully
retrained policy when adapting to new environments, and (2) the impact of
causal knowledge transfer depends on the interplay between environment
complexity and agents' heterogeneous goals.

</details>


### [13] [Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery](https://arxiv.org/abs/2507.13874)
*Mateusz Bystroński,Mikołaj Hołysz,Grzegorz Piotrowski,Nitesh V. Chawla,Tomasz Kajdanowicz*

Main category: cs.AI

TL;DR: 提出了一种模型无关的潜在空间构思框架，用于实现可控、可扩展的AI创意生成。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)在生成新颖且相关的输出方面存在困难，因为它们往往会复制训练期间看到的模式，限制了它们的创造力。

Method: 提出了一种模型无关的潜在空间构思框架。

Result: 介绍了该方法的早期原型，概述了概念框架和初步结果，突出了其作为人机协作通用共同构思者的潜力。

Conclusion: 提出了一种模型无关的潜在空间构思框架，用于通过导航思想的连续嵌入空间来实现可控、可扩展的创造力。该框架不需要手工规则，易于适应不同的领域、输入格式和创造性任务。

Abstract: Innovative idea generation remains a core challenge in AI, as large language
models (LLMs) often struggle to produce outputs that are both novel and
relevant. Despite their fluency, LLMs tend to replicate patterns seen during
training, limiting their ability to diverge creatively without extensive prompt
engineering. Prior work has addressed this through domain-specific heuristics
and structured prompting pipelines, but such solutions are brittle and
difficult to generalize. In this paper, we propose a model-agnostic
latent-space ideation framework that enables controlled, scalable creativity by
navigating the continuous embedding space of ideas. Unlike prior methods, our
framework requires no handcrafted rules and adapts easily to different domains,
input formats, and creative tasks. This paper introduces an early-stage
prototype of our method, outlining the conceptual framework and preliminary
results highlighting its potential as a general-purpose co-ideator for human-AI
collaboration.

</details>


### [14] [Cross-modal Causal Intervention for Alzheimer's Disease Prediction](https://arxiv.org/abs/2507.13956)
*Yutao Jin,Haowen Xiao,Jielei Chu,Fengmao Lv,Yuxiao Li,Tianrui Li*

Main category: cs.AI

TL;DR: 利用视觉语言因果干预框架ADPC，通过LLM处理多模态数据(MRI, fMRI, 文本)，实现对阿尔茨海默病的精确诊断。


<details>
  <summary>Details</summary>
Motivation: 由于多模态数据的选择偏差和变量之间复杂的关系，诊断AD仍然是一项重大挑战。

Method: 该研究采用大型语言模型(LLM)总结临床数据，并利用MRI、fMRI图像和LLM生成的文本数据对参与者进行分类。

Result: 实验结果表明，该方法在区分CN/MCI/AD病例方面具有优异的性能，在大多数评估指标上都达到了最先进的水平(SOTA)。

Conclusion: 该研究提出了一种名为ADPC的新型视觉语言因果干预框架，用于阿尔茨海默病的诊断辅助，该框架通过因果干预隐式消除混杂因素，在区分CN/MCI/AD病例方面取得了最先进的性能。

Abstract: Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's
Disease (AD), where early identification and intervention can effectively slow
the progression to dementia. However, diagnosing AD remains a significant
challenge in neurology due to the confounders caused mainly by the selection
bias of multimodal data and the complex relationships between variables. To
address these issues, we propose a novel visual-language causal intervention
framework named Alzheimer's Disease Prediction with Cross-modal Causal
Intervention (ADPC) for diagnostic assistance. Our ADPC employs large language
model (LLM) to summarize clinical data under strict templates, maintaining
structured text outputs even with incomplete or unevenly distributed datasets.
The ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)
images and textual data generated by LLM to classify participants into
Cognitively Normal (CN), MCI, and AD categories. Because of the presence of
confounders, such as neuroimaging artifacts and age-related biomarkers,
non-causal models are likely to capture spurious input-output correlations,
generating less reliable results. Our framework implicitly eliminates
confounders through causal intervention. Experimental results demonstrate the
outstanding performance of our method in distinguishing CN/MCI/AD cases,
achieving state-of-the-art (SOTA) metrics across most evaluation metrics. The
study showcases the potential of integrating causal reasoning with multi-modal
learning for neurological disease diagnosis.

</details>


### [15] [Towards Constraint Temporal Answer Set Programming](https://arxiv.org/abs/2507.13958)
*Pedro Cabalar,Martín Diéguez,François Olivier,Torsten Schaub,Igor Stéphan*

Main category: cs.AI

TL;DR: 提出一种新的ASP扩展，用于非单调的时间推理和数值约束，从而能够推理高分辨率的动态系统。


<details>
  <summary>Details</summary>
Motivation: 现有的基于逻辑的方法难以处理具有细粒度时间和数值分辨率的动态系统。

Method: 该方法结合了线性时间逻辑Here-and-There和带约束的Here-and-There逻辑，实现了非单调的时间推理和数值约束的直接整合。

Result: 建立了一个处理高分辨率复杂动态系统的基础逻辑框架。

Conclusion: 本文介绍了一种新的基于逻辑的、时间和约束的Answer Set Programming (ASP)扩展，用于推理具有细粒度时间和数值分辨率的动态系统。

Abstract: Reasoning about dynamic systems with a fine-grained temporal and numeric
resolution presents significant challenges for logic-based approaches like
Answer Set Programming (ASP). To address this, we introduce and elaborate upon
a novel temporal and constraint-based extension of the logic of Here-and-There
and its nonmonotonic equilibrium extension, representing, to the best of our
knowledge, the first approach to nonmonotonic temporal reasoning with
constraints specifically tailored for ASP. This expressive system is achieved
by a synergistic combination of two foundational ASP extensions: the
linear-time logic of Here-and-There, providing robust nonmonotonic temporal
reasoning capabilities, and the logic of Here-and-There with constraints,
enabling the direct integration and manipulation of numeric constraints, among
others. This work establishes the foundational logical framework for tackling
complex dynamic systems with high resolution within the ASP paradigm.

</details>
