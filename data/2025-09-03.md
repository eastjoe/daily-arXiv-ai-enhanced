<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding](https://arxiv.org/abs/2508.21204)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 本文研究了架构归纳偏置如何影响大型语言模型(LLM)在指令式对话中的认知行为，发现添加符号脚手架和短期记忆机制可以提高模型的适应性和结构化推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究架构归纳偏置对大型语言模型在指令式对话中认知行为的影响。

Method: 介绍了一种符号脚手架机制和短期记忆模式，并通过控制消融实验评估了五个系统变体的模型输出。

Result: 结果表明，完整系统优于基线系统，移除记忆或符号结构会降低模型的抽象、自适应探测和概念连续性等关键认知行为。

Conclusion: 研究结果支持了一种处理层面的解释，即架构支架可以可靠地塑造LLM中新兴的教学策略。

Abstract: We study how architectural inductive biases influence the cognitive behavior
of large language models (LLMs) in instructional dialogue. We introduce a
symbolic scaffolding mechanism paired with a short-term memory schema designed
to promote adaptive, structured reasoning in Socratic tutoring. Using
controlled ablation across five system variants, we evaluate model outputs via
expert-designed rubrics covering scaffolding, responsiveness, symbolic
reasoning, and conversational memory. We present preliminary results using an
LLM-based evaluation framework aligned to a cognitively grounded rubric. This
enables scalable, systematic comparisons across architectural variants in
early-stage experimentation. The preliminary results show that our full system
consistently outperforms baseline variants. Analysis reveals that removing
memory or symbolic structure degrades key cognitive behaviors, including
abstraction, adaptive probing, and conceptual continuity. These findings
support a processing-level account in which architectural scaffolds can
reliably shape emergent instructional strategies in LLMs.

</details>


### [2] [Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](https://arxiv.org/abs/2508.21238)
*Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman*

Main category: cs.AI

TL;DR: 本文评估了两种流行的基于图的检索增强生成(GraphRAG)系统在阿尔茨海默病领域的性能，并将其与标准GPT-4o模型进行了比较，还提供了一个易于使用的界面。


<details>
  <summary>Details</summary>
Motivation: 现有LLM聊天机器人存在幻觉、领域知识有限和缺乏可解释性等问题，GraphRAG通过整合领域特定上下文信息来提高可靠性，但其在阿尔茨海默病等知识密集型领域的应用研究有限。

Method: 构建包含50篇论文和70个专家问题的阿尔茨海默病数据库，构建GraphRAG知识库，使用GPT-4o作为LLM，比较GraphRAG和标准GPT-4o模型的回答质量，并评估RAG和GraphRAG系统的可追溯性。

Result: 比较了GraphRAG和标准GPT-4o模型的回答质量，并评估了RAG和GraphRAG系统的可追溯性，提供了一个包含阿尔茨海默病数据库的易于使用的界面。

Conclusion: GraphRAG在阿尔茨海默病等知识密集型领域具有应用前景，但仍需进一步改进。

Abstract: In the past two years, large language model (LLM)-based chatbots, such as
ChatGPT, have revolutionized various domains by enabling diverse task
completion and question-answering capabilities. However, their application in
scientific research remains constrained by challenges such as hallucinations,
limited domain-specific knowledge, and lack of explainability or traceability
for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has
emerged as a promising approach to improving chatbot reliability by integrating
domain-specific contextual information before response generation, addressing
some limitations of standard LLMs. Despite its potential, there are only
limited studies that evaluate GraphRAG on specific domains that require
intensive knowledge, like Alzheimer's disease or other biomedical domains. In
this paper, we assess the quality and traceability of two popular GraphRAG
systems. We compile a database of 50 papers and 70 expert questions related to
Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as
the LLM for answering queries. We then compare the quality of responses
generated by GraphRAG with those from a standard GPT-4o model. Additionally, we
discuss and evaluate the traceability of several Retrieval-Augmented Generation
(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a
pre-built Alzheimer's disease database for researchers to test the performance
of both standard RAG and GraphRAG.

</details>


### [3] [MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems](https://arxiv.org/abs/2508.21307)
*Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala*

Main category: cs.AI

TL;DR: MultiFluxAI平台整合产品工程中大量异构数据源，利用生成式AI、向量化和自主编排等技术，动态响应复杂用户查询，增强用户参与度。


<details>
  <summary>Details</summary>
Motivation: 解决产品工程中数据管理和整合难题，提升用户参与度。

Method: 利用生成式AI、向量化和自主编排等先进AI技术。

Result: 提供动态、上下文感知的复杂用户查询响应。

Conclusion: MultiFluxAI平台有效整合数据，提升用户参与度和体验。

Abstract: MultiFluxAI is an innovative AI platform developed to address the challenges
of managing and integrating vast, disparate data sources in product engineering
across application domains. It addresses both current and new service related
queries that enhance user engagement in the digital ecosystem. This platform
leverages advanced AI techniques, such as Generative AI, vectorization, and
agentic orchestration to provide dynamic and context-aware responses to complex
user queries.

</details>


### [4] [Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation](https://arxiv.org/abs/2508.21320)
*Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao*

Main category: cs.AI

TL;DR: LINKO框架利用大型语言模型增强医疗本体学习，通过双轴知识传播（本体内和本体间）提升医疗概念表示学习，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注单一或多个孤立本体系统，忽略了本体间的联系，限制了概念表示学习。

Method: LINKO框架利用大型语言模型进行本体概念嵌入初始化，并通过本体内垂直传播和本体间水平传播进行联合学习。

Result: 实验结果表明LINKO优于现有方法，并在数据有限和罕见病预测场景中表现出增强的鲁棒性。

Conclusion: LINKO框架有效提升了医疗概念表示学习，为电子健康记录预测模型提供了一种有效的插件编码器。

Abstract: Medical ontology graphs map external knowledge to medical codes in electronic
health records via structured relationships. By leveraging domain-approved
connections (e.g., parent-child), predictive models can generate richer medical
concept representations by incorporating contextual information from related
concepts. However, existing literature primarily focuses on incorporating
domain knowledge from a single ontology system, or from multiple ontology
systems (e.g., diseases, drugs, and procedures) in isolation, without
integrating them into a unified learning structure. Consequently, concept
representation learning often remains limited to intra-ontology relationships,
overlooking cross-ontology connections. In this paper, we propose LINKO, a
large language model (LLM)-augmented integrative ontology learning framework
that leverages multiple ontology graphs simultaneously by enabling dual-axis
knowledge propagation both within and across heterogeneous ontology systems to
enhance medical concept representation learning. Specifically, LINKO first
employs LLMs to provide a graph-retrieval-augmented initialization for ontology
concept embedding, through an engineered prompt that includes concept
descriptions, and is further augmented with ontology context. Second, our
method jointly learns the medical concepts in diverse ontology graphs by
performing knowledge propagation in two axes: (1) intra-ontology vertical
propagation across hierarchical ontology levels and (2) inter-ontology
horizontal propagation within every level in parallel. Last, through extensive
experiments on two public datasets, we validate the superior performance of
LINKO over state-of-the-art baselines. As a plug-in encoder compatible with
existing EHR predictive models, LINKO further demonstrates enhanced robustness
in scenarios involving limited data availability and rare disease prediction.

</details>


### [5] [Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models](https://arxiv.org/abs/2508.21365)
*Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang*

Main category: cs.AI

TL;DR: 该论文提出了一种名为Think in Games (TiG) 的框架，使大型语言模型(LLM)能够通过与游戏环境交互学习程序性知识，并在复杂交互任务中取得与传统强化学习方法相当的性能，同时具有更高的数据效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理任务上表现出色，但在简单的交互任务上却表现不佳，该论文旨在弥合声明式知识和程序式知识之间的差距。

Method: 该框架将强化学习的决策过程重新定义为语言建模任务，LLM生成语言指导策略，并通过在线强化学习迭代改进。

Result: TiG在数据效率和计算需求上显著优于传统强化学习方法，并能提供逐步的自然语言解释。

Conclusion: TiG成功地弥合了声明式知识和程序式知识之间的差距，为在复杂交互任务中提高LLM的性能和可解释性提供了一种有效的方法。

Abstract: Large language models (LLMs) excel at complex reasoning tasks such as
mathematics and coding, yet they frequently struggle with simple interactive
tasks that young children perform effortlessly. This discrepancy highlights a
critical gap between declarative knowledge (knowing about something) and
procedural knowledge (knowing how to do something). Although traditional
reinforcement learning (RL) agents can acquire procedural knowledge through
environmental interaction, they often operate as black boxes and require
substantial training data. In contrast, LLMs possess extensive world knowledge
and reasoning capabilities, but are unable to effectively convert this static
knowledge into dynamic decision-making in interactive settings. To address this
challenge, we propose Think in Games (TiG), a novel framework that empowers
LLMs to develop procedural understanding through direct interaction with game
environments, while retaining their inherent reasoning and explanatory
abilities. Specifically, TiG reformulates RL-based decision-making as a
language modeling task: LLMs generate language-guided policies, which are
refined iteratively through online reinforcement learning based on
environmental feedback. Our experimental results show that TiG successfully
bridges the gap between declarative and procedural knowledge, achieving
competitive performance with dramatically lower data and computational demands
compared to conventional RL methods. Moreover, TiG provides step-by-step
natural language explanations for its decisions, greatly improving transparency
and interpretability in complex interactive tasks.

</details>


### [6] [AHELM: A Holistic Evaluation of Audio-Language Models](https://arxiv.org/abs/2508.21376)
*Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang*

Main category: cs.AI

TL;DR: AHELM，一个新的基准测试，对音频语言模型(ALMs)的10个方面进行了全面评估，包括音频感知、推理和公平性等，并对14个ALMs进行了测试，发现Gemini 2.5 Pro在5个方面排名第一，但也存在群体不公平问题。


<details>
  <summary>Details</summary>
Motivation: 现有的ALMs评估缺乏标准化基准，难以进行跨模型比较。

Method: 构建了一个名为AHELM的基准测试，整合了多个数据集(包括两个新的合成数据集PARADE和CoRe-Bench)，对14个ALMs进行了标准化评估，涵盖10个重要方面。

Result: Gemini 2.5 Pro在5个方面排名第一，但存在群体不公平问题；基线系统表现良好，其中一个系统排名第五。

Conclusion: AHELM是一个动态的基准测试，未来会不断添加新的数据集和模型，为ALMs的评估提供更全面的标准。

Abstract: Evaluations of audio-language models (ALMs) -- multimodal models that take
interleaved audio and text as input and output text -- are hindered by the lack
of standardized benchmarks; most benchmarks measure only one or two
capabilities and omit evaluative aspects such as fairness or safety.
Furthermore, comparison across models is difficult as separate evaluations test
a limited number of models and use different prompting methods and inference
parameters. To address these shortfalls, we introduce AHELM, a benchmark that
aggregates various datasets -- including 2 new synthetic audio-text datasets
called PARADE, which evaluates the ALMs on avoiding stereotypes, and
CoRe-Bench, which measures reasoning over conversational audio through
inferential multi-turn question answering -- to holistically measure the
performance of ALMs across 10 aspects we have identified as important to the
development and usage of ALMs: audio perception, knowledge, reasoning, emotion
detection, bias, fairness, multilinguality, robustness, toxicity, and safety.
We also standardize the prompts, inference parameters, and evaluation metrics
to ensure equitable comparisons across models. We test 14 open-weight and
closed-API ALMs from 3 developers and 3 additional simple baseline systems each
consisting of an automatic speech recognizer and a language model. Our results
show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits
group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do
not. We also find that the baseline systems perform reasonably well on AHELM,
with one ranking 5th overall despite having only speech-to-text capabilities.
For transparency, all raw prompts, model generations, and outputs are available
on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is
intended to be a living benchmark and new datasets and models will be added
over time.

</details>


### [7] [AI Compute Architecture and Evolution Trends](https://arxiv.org/abs/2508.21394)
*Bor-Sung Liang*

Main category: cs.AI

TL;DR: 本文分析了AI发展的机遇和挑战，提出了一个七层AI计算架构模型，并探讨了AI从单一智能体到AI生态系统的演进以及经济因素的影响。


<details>
  <summary>Details</summary>
Motivation: AI发展面临诸多挑战，需要从不同视角进行分析。

Method: 提出七层AI计算架构模型，分析AI发展三个阶段，探讨不同层面的关键技术和挑战，并借鉴互联网产业发展趋势预测AI未来。

Result: 构建了七层AI计算架构模型，阐述了AI发展的三个阶段，分析了各层关键技术、挑战和趋势，并对AI产业未来发展方向做出预测。

Conclusion: AI发展机遇与挑战并存，需要关注技术和经济因素，构建可持续的AI生态系统。

Abstract: The focus of AI development has shifted from academic research to practical
applications. However, AI development faces numerous challenges at various
levels. This article will attempt to analyze the opportunities and challenges
of AI from several different perspectives using a structured approach. This
article proposes a seven-layer model for AI compute architecture, including
Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,
Orchestrator Layer, and Application Layer, from bottom to top. It also explains
how AI computing has evolved into this 7-layer architecture through the
three-stage evolution on large-scale language models (LLMs). For each layer, we
describe the development trajectory and key technologies. In Layers 1 and 2 we
discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies
on computing architecture. In Layer 3 we explore two different development
paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs
and compares it to traditional processor memory. In Layers 5 to 7 we discuss
the trends of AI agents and explore the issues in evolution from a single AI
agent to an AI-based ecosystem, and their impact on the AI industry.
Furthermore, AI development involves not only technical challenges but also the
economic issues to build self-sustainable ecosystem. This article analyzes the
internet industry to provide predictions on the future trajectory of AI
development.

</details>


### [8] [CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN](https://arxiv.org/abs/2508.21411)
*Leonard Frank Neis,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: CARJAN工具结合AJAN和CARLA模拟城市交通场景，支持多种交互代理。


<details>
  <summary>Details</summary>
Motivation: 现有工具难以对包含行人、自行车和自动驾驶车辆等多种交互代理的城市交通场景进行用户友好的建模和虚拟仿真。

Method: 基于多智能体工程框架AJAN和驾驶模拟器CARLA，使用SPARQL行为树进行决策和交互，提供可视化用户界面进行建模、存储和维护。

Result: 提供了一种交互式、基于智能代理的虚拟交通场景生成和仿真方法。

Conclusion: CARJAN是首个集成方法，用于在CARLA中交互式、智能地基于代理生成和模拟虚拟交通场景。

Abstract: User-friendly modeling and virtual simulation of urban traffic scenarios with
different types of interacting agents such as pedestrians, cyclists and
autonomous vehicles remains a challenge. We present CARJAN, a novel tool for
semi-automated generation and simulation of such scenarios based on the
multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN
provides a visual user interface for the modeling, storage and maintenance of
traffic scenario layouts, and leverages SPARQL Behavior Tree-based
decision-making and interactions for agents in dynamic scenario simulations in
CARLA. CARJAN provides a first integrated approach for interactive, intelligent
agent-based generation and simulation of virtual traffic scenarios in CARLA.

</details>


### [9] [A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions](https://arxiv.org/abs/2508.21441)
*Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald*

Main category: cs.AI

TL;DR: 本文研究了知识库中遗忘操作的语义结构，提出了五种类型的认知遗忘和七种具体的遗忘操作，并基于逻辑编程和AGM理论的公理对这些操作进行了评估。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘操作主要基于经典逻辑，本文从认知角度，研究更丰富的语义结构下的遗忘操作。

Method: 提出五种类型的认知遗忘和七种具体的遗忘操作，并基于逻辑编程和AGM理论的公理进行评估。

Result: 对七种遗忘操作进行了评估，揭示了它们之间的差异和共性。

Conclusion: 本文丰富了遗忘操作的研究，为评估遗忘操作提供了全面的概述。

Abstract: Forgetting as a knowledge management operation deliberately ignores parts of
the knowledge and beliefs of an agent, for various reasons. Forgetting has many
facets, one may want to forget parts of the syntax, a proposition, or a
conditional. In the literature, two main operators suitable for performing
forgetting have been proposed and investigated in depth: First, variable
elimination is a syntactical method that blends out certain atomic variables to
focus on the rest of the language. It has been mainly used in the area of logic
programming and answer set programming. Second, contraction in AGM belief
revision theory effectively removes propositions from belief sets under logical
deduction. Both operations rely mainly on classical logics. In this article, we
take an epistemic perspective and study forgetting operations in epistemic
states with richer semantic structures, but with clear links to propositional
logic. This allows us to investigate what forgetting in the epistemic
background means, thereby lifting well-known and novel forgetting operations to
the epistemic level. We present five general types of epistemic forgetting and
instantiate them with seven concrete forgetting operations for Spohn's ranking
functions. We take inspiration from postulates of forgetting both from logic
programming and AGM theory to propose a rich landscape of axioms for evaluating
forgetting operations. Finally, we evaluate all concrete forgetting operations
according to all postulates, leading to a novel comprehensive overview
highlighting differences and commonalities among the forgetting operators.

</details>


### [10] [Learning Lifted Action Models From Traces of Incomplete Actions and States](https://arxiv.org/abs/2508.21449)
*Niklas Jansen,Jonas Gösgens,Hector Geffner*

Main category: cs.AI

TL;DR: 本文介绍了一种从不完整的滑块拼图状态-动作轨迹中学习提升的STRIPS模型的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设动作是完整的STRIPS动作或所有领域谓词都可观察，这与现实情况不符。本文提出一种更现实的设置，其中观察到的原子传达了世界的状态，但不是完整的STRIPS状态，动作揭示了选择动作所需的论证，但不是在STRIPS中建模所需的论证。

Method: 本文提出了一种名为STRIPS+的STRIPS变体和一种名为SYNTH的学习算法。STRIPS+允许在先决条件中省略某些STRIPS动作参数，并允许有限形式的存在量化。SYNTH算法构建一个分层的先决条件表达式序列，用于唯一地表示状态中的对象并确定STRIPS+中隐式动作的参数。

Result: 本文证明了SYNTH算法的正确性和完整性，并在从现有STRIPS领域导出的STRIPS+模型获得的状态-动作轨迹上测试了其可扩展性。

Conclusion: 本文提出了一种新颖的STRIPS+模型和学习算法SYNTH，能够从不完整的观测数据中学习提升的STRIPS模型，为更现实的模型学习问题提供了解决方案。

Abstract: Consider the problem of learning a lifted STRIPS model of the sliding-tile
puzzle from random state-action traces where the states represent the location
of the tiles only, and the actions are the labels up, down, left, and right,
with no arguments. Two challenges are involved in this problem. First, the
states are not full STRIPS states, as some predicates are missing, like the
atoms representing the position of the ``blank''. Second, the actions are not
full STRIPS either, as they do not reveal all the objects involved in the
actions effects and preconditions. Previous approaches have addressed different
versions of this model learning problem, but most assume that actions in the
traces are full STRIPS actions or that the domain predicates are all
observable. The new setting considered in this work is more ``realistic'', as
the atoms observed convey the state of the world but not full STRIPS states,
and the actions reveal the arguments needed for selecting the action but not
the ones needed for modeling it in STRIPS. For formulating and addressing the
learning problem, we introduce a variant of STRIPS, which we call STRIPS+,
where certain STRIPS action arguments can be left implicit in preconditions
which can also involve a limited form of existential quantification. The
learning problem becomes the problem of learning STRIPS+ models from STRIPS+
state-action traces. For this, the proposed learning algorithm, called SYNTH,
constructs a stratified sequence (conjunction) of precondition expressions or
``queries'' for each action, that denote unique objects in the state and ground
the implicit action arguments in STRIPS+. The correctness and completeness of
SYNTH is established, and its scalability is tested on state-action traces
obtained from STRIPS+ models derived from existing STRIPS domains.

</details>


### [11] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: MMSearch-Plus，一个包含311个任务的新基准，用于评估大型多模态语言模型(MLLM)在复杂多模态理解方面的能力，特别是细粒度视觉推理、来源验证和长期工具使用。


<details>
  <summary>Details</summary>
Motivation: 现有基准容易被简单的固定工作流程解决，MMSearch-Plus旨在提高难度，需要模型进行迭代的文本图像搜索和交叉验证。

Method: 提出了一种新的基准MMSearch-Plus和一种模型无关的代理框架，并对一系列闭源和开源MLLM进行了评估，评估指标包括准确率、边界框生成和裁剪图像搜索等。

Result: 最强代理在使用搜索的情况下达到36.0%的准确率，而一个强大的开源模型Qwen-2.5-VL-72B-Instruct仅达到6.9%。错误分析揭示了模型在来源验证、基于部分的推理和长期规划方面的不足。

Conclusion: MMSearch-Plus为评估MLLM的多模态理解能力提供了一个更具挑战性的基准，突显了现有模型在复杂推理任务上的局限性，为未来研究指明了方向。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [12] [Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis](https://arxiv.org/abs/2508.21517)
*Sweta Kaman,Ankita Sharma,Romi Banerjee*

Main category: cs.AI

TL;DR: 该论文提出了一种基于模糊推理系统和Z数的智慧度量框架，用于评估个体在面对道德困境时的智慧水平，并验证了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有智慧度量方法存在局限性，该研究旨在构建一个能够同时考虑智慧的多维度性和不确定性的计算框架。

Method: 采用模糊推理系统和Z数，结合参与者对图片道德困境的思考过程，计算其智慧得分和置信度得分。

Result: 该系统生成的智慧表达与既有量表适度相关，支持其收敛效度和区分效度。

Conclusion: 该研究成功地将智慧形式化为了一个多维度、考虑不确定性的结构，为心理学测量和人工智能的置信敏感推理提供了新方法。

Abstract: Background: Wisdom is a superordinate construct that embraces perspective
taking, reflectiveness, prosocial orientation, reflective empathetic action,
and intellectual humility. Unlike conventional models of reasoning that are
rigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,
requiring both graded evaluation and self-reflective humility. Current measures
depend on self-reports and seldom reflect the humility and uncertainty inherent
in wise reasoning. A computational framework that takes into account both
multidimensionality and confidence has the potential to improve psychological
science and allow humane AI. Method: We present a fuzzy inference system with Z
numbers, each of the decisions being expressed in terms of a wisdom score
(restriction) and confidence score (certainty). As part of this study,
participants (N = 100) were exposed to culturally neutral pictorial moral
dilemma tasks to which they generated think-aloud linguistic responses, which
were mapped into five theoretically based components of wisdom. The scores of
each individual component were combined using a base of 21 rules, with
membership functions tuned via Gaussian kernel density estimation. Results: In
a proof of concept study, the system produced dual attribute wisdom
representations that correlated modestly but significantly with established
scales while showing negligible relations with unrelated traits, supporting
convergent and divergent validity. Contribution: The contribution is to
formalize wisdom as a multidimensional, uncertainty-conscious construct,
operationalized in the form of Z-numbers. In addition to progressing
measurement in psychology, it calculates how fuzzy Z numbers can provide AI
systems with interpretable, confidence-sensitive reasoning that affords a safe,
middle ground between rigorous computation and human-like judgment.

</details>


### [13] [Counterfactual Scenarios for Automated Planning](https://arxiv.org/abs/2508.21521)
*Nicola Gigante,Francesco Leofante,Andrea Micheli*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实场景的新的解释范式，用于解释规划问题。


<details>
  <summary>Details</summary>
Motivation: 现有的反事实解释方法未能捕捉到所解决问题的更高层次属性。

Method: 提出了一种基于反事实场景的新解释范式，并给出了两种定性实例化。

Result: 刻画了生成反事实场景的计算复杂性，表明其计算代价与计算规划问题解的代价相当。

Conclusion: 该方法具有实用价值，为构建实际算法提供了框架。

Abstract: Counterfactual Explanations (CEs) are a powerful technique used to explain
Machine Learning models by showing how the input to a model should be minimally
changed for the model to produce a different output. Similar proposals have
been made in the context of Automated Planning, where CEs have been
characterised in terms of minimal modifications to an existing plan that would
result in the satisfaction of a different goal. While such explanations may
help diagnose faults and reason about the characteristics of a plan, they fail
to capture higher-level properties of the problem being solved. To address this
limitation, we propose a novel explanation paradigm that is based on
counterfactual scenarios. In particular, given a planning problem $P$ and an
\ltlf formula $\psi$ defining desired properties of a plan, counterfactual
scenarios identify minimal modifications to $P$ such that it admits plans that
comply with $\psi$. In this paper, we present two qualitative instantiations of
counterfactual scenarios based on an explicit quantification over plans that
must satisfy $\psi$. We then characterise the computational complexity of
generating such counterfactual scenarios when different types of changes are
allowed on $P$. We show that producing counterfactual scenarios is often only
as expensive as computing a plan for $P$, thus demonstrating the practical
viability of our proposal and ultimately providing a framework to construct
practical algorithms in this area.

</details>


### [14] [HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining](https://arxiv.org/abs/2508.21540)
*Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi*

Main category: cs.AI

TL;DR: HealthProcessAI框架使用GenAI简化医疗流程挖掘，集成LLM自动解释和报告生成，提高可访问性。


<details>
  <summary>Details</summary>
Motivation: 医疗流程挖掘应用受技术复杂性、缺乏标准化方法和培训资源限制，HealthProcessAI框架旨在解决这些问题。

Method: 构建一个整合Python (PM4PY)和R (bupaR)库的GenAI框架，集成多个LLM进行自动化流程图解读和报告生成，并用脓毒症数据进行验证，比较五个LLM模型的输出。

Result: 成功处理脓毒症数据，生成报告，Claude Sonnet-4和Gemini 2.5-Pro的LLM评估一致性得分最高。

Conclusion: HealthProcessAI框架通过整合LLM提高了流程挖掘结果的可访问性，为医疗应用提供了可操作的见解，是医疗流程挖掘领域的新方法。

Abstract: Process mining has emerged as a powerful analytical technique for
understanding complex healthcare workflows. However, its application faces
significant barriers, including technical complexity, a lack of standardized
approaches, and limited access to practical training resources. We introduce
HealthProcessAI, a GenAI framework designed to simplify process mining
applications in healthcare and epidemiology by providing a comprehensive
wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address
unfamiliarity and improve accessibility, the framework integrates multiple
Large Language Models (LLMs) for automated process map interpretation and
report generation, helping translate technical analyses into outputs that
diverse users can readily understand. We validated the framework using sepsis
progression data as a proof-of-concept example and compared the outputs of five
state-of-the-art LLM models through the OpenRouter platform. To test its
functionality, the framework successfully processed sepsis data across four
proof-of-concept scenarios, demonstrating robust technical performance and its
capability to generate reports through automated LLM analysis. LLM evaluation
using five independent LLMs as automated evaluators revealed distinct model
strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency
scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By
integrating multiple Large Language Models (LLMs) for automated interpretation
and report generation, the framework addresses widespread unfamiliarity with
process mining outputs, making them more accessible to clinicians, data
scientists, and researchers. This structured analytics and AI-driven
interpretation combination represents a novel methodological advance in
translating complex process mining results into potentially actionable insights
for healthcare applications.

</details>


### [15] [Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances](https://arxiv.org/abs/2508.21564)
*Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt*

Main category: cs.AI

TL;DR: 提出一种新的框架，学习可泛化于整个领域的标志性节点，用于解决传统算法难以处理的规划问题。


<details>
  <summary>Details</summary>
Motivation: 传统标志性节点提取算法难以处理的规划问题。

Method: 学习基于状态函数的泛化标志性节点，构建有向图，用于启发式搜索。

Result: 在相同领域的大型实例中，从少量小型实例学习到的泛化标志性节点图同样有效；识别循环可显著提升启发式性能。

Conclusion: 泛化标志性节点可捕获领域信息，可用于自动化规划器，且可从少量同领域计划中学习得到。

Abstract: We propose a new framework for discovering landmarks that automatically
generalize across a domain. These generalized landmarks are learned from a set
of solved instances and describe intermediate goals for planning problems where
traditional landmark extraction algorithms fall short. Our generalized
landmarks extend beyond the predicates of a domain by using state functions
that are independent of the objects of a specific problem and apply to all
similar objects, thus capturing repetition. Based on these functions, we
construct a directed generalized landmark graph that defines the landmark
progression, including loop possibilities for repetitive subplans. We show how
to use this graph in a heuristic to solve new problem instances of the same
domain. Our results show that the generalized landmark graphs learned from a
few small instances are also effective for larger instances in the same domain.
If a loop that indicates repetition is identified, we see a significant
improvement in heuristic performance over the baseline. Generalized landmarks
capture domain information that is interpretable and useful to an automated
planner. This information can be discovered from a small set of plans for the
same domain.

</details>


### [16] [Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics](https://arxiv.org/abs/2508.21595)
*Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes*

Main category: cs.AI

TL;DR: 针对确定性分散式POMDP(Det-Dec-POMDP)问题，提出一种名为迭代确定性POMDP规划(IDPP)的实用求解器。


<details>
  <summary>Details</summary>
Motivation: 许多高层次多智能体规划问题，例如多机器人导航和路径规划，可以使用确定性动作和观测有效建模。

Method: IDPP方法基于经典的联合均衡策略搜索框架，针对大规模Det-Dec-POMDP问题进行了优化。

Result: 该方法能够有效解决当前Dec-POMDP求解器难以高效处理的大规模Det-Dec-POMDP问题。

Conclusion: IDPP为解决大规模确定性分散式POMDP问题提供了一种有效的实用方法。

Abstract: Many high-level multi-agent planning problems, including multi-robot
navigation and path planning, can be effectively modeled using deterministic
actions and observations.
  In this work, we focus on such domains and introduce the class of
Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of
Dec-POMDPs characterized by deterministic transitions and observations
conditioned on the state and joint actions.
  We then propose a practical solver called Iterative Deterministic POMDP
Planning (IDPP). This method builds on the classic Joint Equilibrium Search for
Policies framework and is specifically optimized to handle large-scale
Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address
efficiently.

</details>
